#!/usr/bin/env python3
"""
Project AI Orchestrator - æ•´åˆå¼ AI é–‹ç™¼æµç¨‹è‡ªå‹•åŒ–å·¥å…·
"""

import subprocess
import sys
from pathlib import Path
from typing import Dict, Any, Optional, List

# é…ç½®å¸¸é‡
PROJECT_ROOT = Path(__file__).parent.parent.parent
APPS_BACKEND_DIR = PROJECT_ROOT / "apps" / "backend"
TRAINING_DIR = PROJECT_ROOT / "training"
DOCS_DIR = PROJECT_ROOT / "docs"

# è³‡æ–™é›†è·¯å¾‘
DATA_DIR = PROJECT_ROOT / "data"
CONCEPT_DATA_DIR = DATA_DIR / "concept_models"
CONCEPT_DATA_CONFIG = CONCEPT_DATA_DIR / "config.json"
MATH_DATASET_JSON = DATA_DIR / "math_dataset.json"

# è…³æœ¬è·¯å¾‘
SCRIPTS_DIR = PROJECT_ROOT / "tools" / "scripts"
PREPARE_CONCEPT_DATA_SCRIPT = SCRIPTS_DIR / "prepare_concept_data.py"
MATH_DATA_GENERATOR = SCRIPTS_DIR / "generate_math_dataset.py"
TRAIN_MODEL_SCRIPT = SCRIPTS_DIR / "train_model.py"
VALIDATE_LINKS_SCRIPT = SCRIPTS_DIR / "validate_docs_links.py"

def run_cmd(cmd: List[str], cwd=None, verbose=False, dry_run=False) -> int:
    if verbose:
        print(f"$ {' '.join(cmd)}" + (f"  (cwd={cwd})" if cwd else ""))
    if dry_run:
        return 0
    proc = subprocess.run(cmd, cwd=str(cwd) if cwd else None)
    return proc.returncode

def file_mtime(path: Path) -> float:
    try:
        return path.stat().st_mtime
    except Exception:
        return 0.0

def _latest_mtime_in_dir(path: Path) -> float:
    latest = 0.0
    if not path.exists():
        return latest
    for p in path.rglob("*"):
        try:
            if p.is_file():
                mt = p.stat().st_mtime
                if mt > latest:
                    latest = mt
        except Exception:
            pass
    return latest

def check_datasets(verbose=False) -> Dict[str, Any]:
    """æª¢æŸ¥è³‡æ–™é›†ç‹€æ…‹ã€‚"""
    status: Dict[str, Any] = {
        "concept_models": {
            "dir_exists": CONCEPT_DATA_DIR.exists(),
            "config_exists": CONCEPT_DATA_CONFIG.exists(),
            "config_mtime": file_mtime(CONCEPT_DATA_CONFIG),
        },
        "math_model": {
            "dataset_exists": MATH_DATASET_JSON.exists(),
            "dataset_mtime": file_mtime(MATH_DATASET_JSON),
        },
    }
    if verbose:
        print("[DATA] æ¦‚å¿µæ¨¡å‹è³‡æ–™ç›®éŒ„:", status["concept_models"])
        print("[DATA] æ•¸å­¸æ¨¡å‹è³‡æ–™:", status["math_model"])
    return status

def decide_data_generation(data_status: Dict[str, Any], verbose=False) -> Dict[str, bool]:
    """æ ¹æ“šç¾ç‹€åˆ¤æ–·æ˜¯å¦éœ€è¦è³‡æ–™ç”Ÿæˆ/ä¿®å¾©ã€‚"""
    needs = {
        "concept_models": False,
        "math_model": False,
    }
    cm = data_status.get("concept_models", {})
    if not cm.get("dir_exists") or not cm.get("config_exists"):
        needs["concept_models"] = True
    mm = data_status.get("math_model", {})
    if not mm.get("dataset_exists"):
        needs["math_model"] = True
    if verbose:
        print("[DECIDE] è³‡æ–™ç”Ÿæˆéœ€æ±‚:", needs)
    return needs

def generate_or_fix_data(needs: Dict[str, bool], math_args: Optional[List[str]] = None, 
                        verbose=False, dry_run=False) -> Dict[str, int]:
    """è¦–éœ€è¦åŸ·è¡Œè³‡æ–™ç”Ÿæˆè…³æœ¬ã€‚"""
    results = {"concept_models": 0, "math_model": 0}
    if needs.get("concept_models"):
        if PREPARE_CONCEPT_DATA_SCRIPT.exists():
            code = run_cmd([sys.executable, str(PREPARE_CONCEPT_DATA_SCRIPT)], cwd=PROJECT_ROOT, verbose=verbose, dry_run=dry_run)
            results["concept_models"] = code
        else:
            print("[WARN] ç¼ºå°‘æ¦‚å¿µæ¨¡å‹æ•¸æ“šç”Ÿæˆè…³æœ¬:", PREPARE_CONCEPT_DATA_SCRIPT)
            results["concept_models"] = 1
    # å…è¨±ç•¶æä¾›äº† math_args æ™‚å¼·åˆ¶è§¸ç™¼æ•¸å­¸è³‡æ–™ç”Ÿæˆï¼ˆå³ä¾¿ needs["math_model"] ç‚º Falseï¼‰ï¼Œä»¥æ”¯æ´å¯é¸åƒæ•¸é€å‚³çš„é¡¯å¼è«‹æ±‚
    if needs.get("math_model") or (math_args is not None and len(math_args) > 0):
        if MATH_DATA_GENERATOR.exists():
            cmd = [sys.executable, str(MATH_DATA_GENERATOR)]
            if math_args:
                cmd.extend([str(x) for x in math_args])
            code = run_cmd(cmd, cwd=APPS_BACKEND_DIR, verbose=verbose, dry_run=dry_run)
            results["math_model"] = code
        else:
            print("[WARN] ç¼ºå°‘æ•¸å­¸æ¨¡å‹æ•¸æ“šç”Ÿæˆè…³æœ¬:", MATH_DATA_GENERATOR)
            results["math_model"] = 1
    return results

def check_models_and_training(verbose=False) -> Dict[str, Any]:
    """æª¢æŸ¥æ¨¡å‹èˆ‡è¨“ç·´ç³»çµ±ç‹€æ…‹ã€‚"""
    models_dir = TRAINING_DIR / "models"
    checkpoints_dir = TRAINING_DIR / "checkpoints"
    status = {
        "train_script_exists": TRAIN_MODEL_SCRIPT.exists(),
        "models_dir_exists": models_dir.exists(),
        "checkpoints_dir_exists": checkpoints_dir.exists(),
        "has_models": any(models_dir.glob("**/*")) if models_dir.exists() else False,
        "has_checkpoints": any(checkpoints_dir.glob("**/*")) if checkpoints_dir.exists() else False,
        "latest_model_mtime": _latest_mtime_in_dir(models_dir),
        "latest_checkpoint_mtime": _latest_mtime_in_dir(checkpoints_dir),
    }
    if verbose:
        print("[TRAIN] è¨“ç·´ç‹€æ…‹:", status)
    return status

def decide_training(data_status: Dict[str, Any], train_status: Dict[str, Any], verbose=False) -> Dict[str, bool]:
    """æ ¹æ“šæ•¸æ“šèˆ‡æ¨¡å‹ç‹€æ…‹æ±ºç­–æ˜¯å¦éœ€è¦è¨“ç·´èˆ‡æ˜¯å¦å¯ resumeã€‚"""
    need_train = False
    can_resume = False

    cm_ok = data_status.get("concept_models", {}).get("config_exists")
    mm_ok = data_status.get("math_model", {}).get("dataset_exists")

    data_latest = max(
        data_status.get("concept_models", {}).get("config_mtime", 0.0),
        data_status.get("math_model", {}).get("dataset_mtime", 0.0),
    )
    model_latest = train_status.get("latest_model_mtime", 0.0)

    # è¦å‰‡ï¼š
    # 1) æ²’æœ‰ä»»ä½•æ¨¡å‹ä¸”æœ‰å¯ç”¨æ•¸æ“š => éœ€è¦è¨“ç·´
    if not train_status.get("has_models") and (cm_ok or mm_ok):
        need_train = True

    # 2) æ•¸æ“šæ¯”æ¨¡å‹æ–°ï¼ˆå¯èƒ½æ›´æ–°/é‡ç”Ÿï¼‰ => å»ºè­°é‡æ–°è¨“ç·´
    if (cm_ok or mm_ok) and data_latest > 0 and model_latest > 0 and data_latest > model_latest:
        need_train = True

    # 3) æœ‰ checkpoint å‰‡å¯çºŒè¨“
    if train_status.get("has_checkpoints"):
        can_resume = True

    if verbose:
        print(f"[DECIDE] need_train={need_train}, can_resume={can_resume}, data_latest={data_latest}, model_latest={model_latest}")
    return {"need_train": need_train, "can_resume": can_resume}

def run_training(*, preset: Optional[str] = None, resume: bool = False, verbose=False, dry_run=False) -> int:
    if not TRAIN_MODEL_SCRIPT.exists():
        print("[ERROR] æ‰¾ä¸åˆ°è¨“ç·´è…³æœ¬:", TRAIN_MODEL_SCRIPT)
        return 1
    cmd = [sys.executable, str(TRAIN_MODEL_SCRIPT)]
    if preset is not None:
        cmd.extend(["--preset", preset])
    if resume:
        cmd.append("--resume")
    return run_cmd(cmd, cwd=TRAINING_DIR, verbose=verbose, dry_run=dry_run)

def check_docs_links(verbose=False, dry_run=False) -> Dict[str, Any]:
    if not VALIDATE_LINKS_SCRIPT.exists():
        print("[ERROR] ç¼ºå°‘æ–‡æª”éˆæ¥æ ¡é©—è…³æœ¬:", VALIDATE_LINKS_SCRIPT)
        return {"ok": False, "broken": -1}
    json_report = PROJECT_ROOT / "docs_link_check_errors.json"
    text_report = PROJECT_ROOT / "docs_link_check_errors.txt"
    cmd = [sys.executable, str(VALIDATE_LINKS_SCRIPT), "--root", str(DOCS_DIR), "--report-json", str(json_report), "--report-text", str(text_report)]
    if verbose:
        cmd.append("-v")
    code = run_cmd(cmd, cwd=PROJECT_ROOT, verbose=verbose, dry_run=dry_run)
    result = {"ok": code == 0, "json_report": str(json_report), "text_report": str(text_report)}
    if json_report.exists():
        result["json_report_exists"] = True
    if text_report.exists():
        result["text_report_exists"] = True
    return result

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    parser = argparse.ArgumentParser(description="Project AI Orchestrator")
    parser.add_argument("--verbose", "-v", action="store_true", help="é¡¯ç¤ºè©³ç´°è³‡è¨Š")
    parser.add_argument("--dry-run", action="store_true", help="åƒ…é¡¯ç¤ºå°‡åŸ·è¡Œçš„å‘½ä»¤ï¼Œä¸å¯¦éš›åŸ·è¡Œ")
    parser.add_argument("--check-only", action="store_true", help="åƒ…æª¢æŸ¥ç‹€æ…‹ï¼Œä¸åŸ·è¡Œä»»ä½•æ“ä½œ")
    parser.add_argument("--math-args", nargs="*", help="å‚³éçµ¦æ•¸å­¸è³‡æ–™ç”Ÿæˆå™¨çš„åƒæ•¸")
    
    args = parser.parse_args()
    
    verbose = args.verbose
    dry_run = args.dry_run
    check_only = args.check_only
    math_args = args.math_args
    
    print("ğŸš€ Project AI Orchestrator å•Ÿå‹•")
    print("=" * 50)
    
    # 1. æª¢æŸ¥è³‡æ–™é›†ç‹€æ…‹
    print("\nğŸ“Š æª¢æŸ¥è³‡æ–™é›†ç‹€æ…‹...")
    data_status = check_datasets(verbose=verbose)
    
    # 2. æ±ºå®šæ˜¯å¦éœ€è¦è³‡æ–™ç”Ÿæˆ
    print("\nğŸ¤” åˆ¤æ–·è³‡æ–™ç”Ÿæˆéœ€æ±‚...")
    needs = decide_data_generation(data_status, verbose=verbose)
    
    # 3. åŸ·è¡Œè³‡æ–™ç”Ÿæˆï¼ˆé™¤éåƒ…æª¢æŸ¥ï¼‰
    if not check_only:
        print("\nâš™ï¸  åŸ·è¡Œè³‡æ–™ç”Ÿæˆ...")
        gen_results = generate_or_fix_data(needs, math_args=math_args, verbose=verbose, dry_run=dry_run)
        if any(code != 0 for code in gen_results.values()):
            print("[WARN] è³‡æ–™ç”Ÿæˆéç¨‹ä¸­å‡ºç¾éŒ¯èª¤")
    
    # 4. æª¢æŸ¥æ¨¡å‹èˆ‡è¨“ç·´ç‹€æ…‹
    print("\nğŸ” æª¢æŸ¥æ¨¡å‹èˆ‡è¨“ç·´ç‹€æ…‹...")
    train_status = check_models_and_training(verbose=verbose)
    
    # 5. æ±ºå®šæ˜¯å¦éœ€è¦è¨“ç·´
    print("\nğŸ§  åˆ¤æ–·è¨“ç·´éœ€æ±‚...")
    train_decision = decide_training(data_status, train_status, verbose=verbose)
    
    # 6. åŸ·è¡Œè¨“ç·´ï¼ˆé™¤éåƒ…æª¢æŸ¥ï¼‰
    if not check_only and train_decision["need_train"]:
        print("\nğŸ‹ï¸  åŸ·è¡Œæ¨¡å‹è¨“ç·´...")
        train_code = run_training(resume=train_decision["can_resume"], verbose=verbose, dry_run=dry_run)
        if train_code != 0:
            print("[ERROR] è¨“ç·´éç¨‹ä¸­å‡ºç¾éŒ¯èª¤")
            return train_code
    
    # 7. æª¢æŸ¥æ–‡æª”éˆæ¥
    print("\nğŸ”— æª¢æŸ¥æ–‡æª”éˆæ¥...")
    link_check_result = check_docs_links(verbose=verbose, dry_run=dry_run)
    if not link_check_result["ok"]:
        print("[WARN] æ–‡æª”éˆæ¥æª¢æŸ¥ç™¼ç¾å•é¡Œ")
    
    print("\nâœ… Project AI Orchestrator åŸ·è¡Œå®Œæˆ")
    return 0

if __name__ == "__main__":
    sys.exit(main())
