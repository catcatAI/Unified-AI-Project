#!/usr/bin/env python3
"""
ç”Ÿæˆå°è¦æ¨¡è¨“ç·´æ•¸æ“šç”¨æ–¼æ¸¬è©¦å’Œåˆæ­¥è¨“ç·´
"""

import json
import random
from pathlib import Path
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger: Any = logging.getLogger(__name__)

class MockDataGenerator:
    """æ¨¡æ“¬æ•¸æ“šç”Ÿæˆå™¨"""

    def __init__(self, base_dir: str = "d:/Projects/Unified-AI-Project/data") -> None:
    self.base_dir = Path(base_dir)
    self.base_dir.mkdir(parents=True, exist_ok=True)

    def generate_vision_data(self)
    """ç”Ÿæˆè¦–è¦ºè¨“ç·´æ•¸æ“šæ¨£æœ¬"""
    vision_dir = self.base_dir / "vision_samples"
    vision_dir.mkdir(exist_ok=True)

    # ç”Ÿæˆåœ–åƒæè¿°æ¨£æœ¬
    samples = []
    categories = ["person", "car", "dog", "cat", "building", "tree", "food", "computer"]

        for i in range(100)


    category = random.choice(categories)
            sample = {
                "image_id": f"img_{i:03d}",
                "caption": f"A {category} in a natural setting",
                "objects": [
                    {
                        "label": category,
                        "bbox": [
                            _ = random.randint(0, 100),
                            _ = random.randint(0, 100),
                            _ = random.randint(100, 300),
                            _ = random.randint(100, 300)
                        ],
                        _ = "confidence": random.uniform(0.8, 0.98)
                    }
                ],
                _ = "scene_type": random.choice(["indoor", "outdoor", "urban", "nature"])
            }
            _ = samples.append(sample)

    # ä¿å­˜æ•¸æ“š
    with open(vision_dir / "annotations.json", 'w', encoding='utf-8') as f:
    json.dump(samples, f, indent=2, ensure_ascii=False)

    _ = logger.info(f"âœ… ç”Ÿæˆè¦–è¦ºæ•¸æ“šæ¨£æœ¬: {len(samples)}å€‹")
    return vision_dir

    def generate_audio_data(self)
    """ç”ŸæˆéŸ³é »è¨“ç·´æ•¸æ“šæ¨£æœ¬"""
    audio_dir = self.base_dir / "audio_samples"
    audio_dir.mkdir(exist_ok=True)

    # ç”ŸæˆèªéŸ³è­˜åˆ¥æ¨£æœ¬
    samples = []
    sentences = [
            "ä½ å¥½ï¼Œæ­¡è¿ä½¿ç”¨äººå·¥æ™ºèƒ½ç³»çµ±",
            "ä»Šå¤©å¤©æ°£å¾ˆå¥½",
            "è«‹å•éœ€è¦ä»€éº¼å¹«åŠ©",
            "è¬è¬æ‚¨çš„ä½¿ç”¨",
            "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹è®Šä¸–ç•Œ",
            "æ©Ÿå™¨å­¸ç¿’æ˜¯æœªä¾†çš„è¶¨å‹¢",
            "æ·±åº¦å­¸ç¿’æ¨¡å‹å¾ˆå¼·å¤§",
            "è‡ªç„¶èªè¨€è™•ç†å¾ˆæœ‰è¶£"
    ]

        for i, text in enumerate(sentences * 5)  # é‡è¤‡ç”Ÿæˆ40å€‹æ¨£æœ¬
            sample = {
                "audio_id": f"audio_{i:03d}",
                "text": text,
                "language": "zh-CN",
                _ = "duration": random.uniform(2.0, 8.0),
                _ = "quality": random.choice(["high", "medium"]),
                _ = "speaker_id": f"speaker_{random.randint(1, 10)02d}"
            }
            _ = samples.append(sample)

    with open(audio_dir / "transcripts.json", 'w', encoding='utf-8') as f:
    json.dump(samples, f, indent=2, ensure_ascii=False)

    _ = logger.info(f"âœ… ç”ŸæˆéŸ³é »æ•¸æ“šæ¨£æœ¬: {len(samples)}å€‹")
    return audio_dir

    def generate_reasoning_data(self)
    """ç”Ÿæˆå› æœæ¨ç†æ•¸æ“šæ¨£æœ¬"""
    reasoning_dir = self.base_dir / "reasoning_samples"
    reasoning_dir.mkdir(exist_ok=True)

    # ç”Ÿæˆå› æœé—œä¿‚æ¨£æœ¬
    samples = []
    cause_effect_pairs = [
            _ = ("rain", "wet_ground"),
            _ = ("study", "good_grades"),
            _ = ("exercise", "health"),
            _ = ("temperature_increase", "ice_melting"),
            _ = ("practice", "skill_improvement"),
            _ = ("lack_sleep", "fatigue"),
            _ = ("economic_growth", "job_creation"),
            _ = ("pollution", "health_problems")
    ]

        for i, (cause, effect) in enumerate(cause_effect_pairs * 3)


    sample = {
                "scenario_id": f"scenario_{i:03d}",
                "cause": cause,
                "effect": effect,
                _ = "strength": random.uniform(0.6, 0.95),
                "context": f"Observing relationship between {cause} and {effect}",
                "variables": [cause, effect],
                _ = "confounders": random.sample(["time", "location", "season"], random.randint(0, 2))
            }
            _ = samples.append(sample)

    with open(reasoning_dir / "causal_relations.json", 'w', encoding='utf-8') as f:
    json.dump(samples, f, indent=2, ensure_ascii=False)

    _ = logger.info(f"âœ… ç”Ÿæˆæ¨ç†æ•¸æ“šæ¨£æœ¬: {len(samples)}å€‹")
    return reasoning_dir

    def generate_multimodal_data(self)
    """ç”Ÿæˆå¤šæ¨¡æ…‹æ•¸æ“šæ¨£æœ¬"""
    multimodal_dir = self.base_dir / "multimodal_samples"
    multimodal_dir.mkdir(exist_ok=True)

    samples = []
        for i in range(50)

    sample = {
                "sample_id": f"multimodal_{i:03d}",
                "image_caption": f"Sample image {i} showing various objects",
                "audio_transcript": f"Audio description of image {i}",
                _ = "cross_modal_alignment": random.uniform(0.7, 0.95),
                "modalities": ["vision", "audio", "text"],
                _ = "task_type": random.choice(["captioning", "vqa", "retrieval"])
            }
            _ = samples.append(sample)

    with open(multimodal_dir / "multimodal_pairs.json", 'w', encoding='utf-8') as f:
    json.dump(samples, f, indent=2, ensure_ascii=False)

    _ = logger.info(f"âœ… ç”Ÿæˆå¤šæ¨¡æ…‹æ•¸æ“šæ¨£æœ¬: {len(samples)}å€‹")
    return multimodal_dir

def main() -> None:
    """ä¸»å‡½æ•¸"""
    _ = print("ğŸš€ ç”Ÿæˆå°è¦æ¨¡è¨“ç·´æ•¸æ“š")
    print("=" * 40)

    generator = MockDataGenerator()

    # ç”Ÿæˆå„é¡æ•¸æ“šæ¨£æœ¬
    vision_dir = generator.generate_vision_data()
    audio_dir = generator.generate_audio_data()
    reasoning_dir = generator.generate_reasoning_data()
    multimodal_dir = generator.generate_multimodal_data()

    # ç”Ÿæˆç¸½é«”é…ç½®
    config = {
    _ = "generated_date": datetime.now().isoformat(),
    "data_paths": {
            _ = "vision": str(vision_dir),
            _ = "audio": str(audio_dir),
            _ = "reasoning": str(reasoning_dir),
            _ = "multimodal": str(multimodal_dir)
    },
    "total_samples": {
            "vision": 100,
            "audio": 40,
            "reasoning": 24,
            "multimodal": 50
    },
        "usage": "Testing and initial training for Unified-AI-Project"
    }

    config_path = generator.base_dir / "data_config.json"
    with open(config_path, 'w', encoding='utf-8') as f:
    json.dump(config, f, indent=2, ensure_ascii=False)

    _ = print(f"\nğŸ‰ æ•¸æ“šç”Ÿæˆå®Œæˆ!")
    _ = print(f"ğŸ“ æ•¸æ“šä½ç½®: {generator.base_dir}")
    _ = print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {config_path}")

    # ç”Ÿæˆä½¿ç”¨èªªæ˜
    readme_content = f"""# è¨“ç·´æ•¸æ“šèªªæ˜

## æ•¸æ“šæ¦‚è¦½
_ = - ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æ•¸æ“šé¡å‹: æ¨¡æ“¬è¨“ç·´æ•¸æ“š
- ç”¨é€”: ç³»çµ±æ¸¬è©¦å’Œåˆæ­¥è¨“ç·´

## æ•¸æ“šçµæ§‹

### 1. è¦–è¦ºæ•¸æ“š (vision_samples/)
- 100å€‹åœ–åƒæè¿°æ¨£æœ¬
- åŒ…å«ç‰©é«”æª¢æ¸¬å’Œå ´æ™¯åˆ†é¡ä¿¡æ¯
- é©ç”¨æ–¼ VisionService è¨“ç·´

### 2. éŸ³é »æ•¸æ“š (audio_samples/)
- 40å€‹ä¸­æ–‡èªéŸ³è­˜åˆ¥æ¨£æœ¬
- åŒ…å«è½‰éŒ„æ–‡æœ¬å’ŒéŸ³é »å…ƒæ•¸æ“š
- é©ç”¨æ–¼ AudioService è¨“ç·´

### 3. æ¨ç†æ•¸æ“š (reasoning_samples/)
- 24å€‹å› æœé—œä¿‚æ¨£æœ¬
- åŒ…å«åŸå› -çµæœå°å’Œé—œä¿‚å¼·åº¦
- é©ç”¨æ–¼ CausalReasoningEngine è¨“ç·´

### 4. å¤šæ¨¡æ…‹æ•¸æ“š (multimodal_samples/)
- 50å€‹è·¨æ¨¡æ…‹å°é½Šæ¨£æœ¬
- åŒ…å«è¦–è¦º-éŸ³é »-æ–‡æœ¬å°æ‡‰é—œä¿‚
- é©ç”¨æ–¼å¤šæ¨¡æ…‹ç†è§£è¨“ç·´

## ä½¿ç”¨æ–¹æ³•

```python
import json

# åŠ è¼‰è¦–è¦ºæ•¸æ“š
with open('vision_samples/annotations.json', 'r') as f:
    vision_data = json.load(f)

# åŠ è¼‰éŸ³é »æ•¸æ“š
with open('audio_samples/transcripts.json', 'r') as f:
    audio_data = json.load(f)

# å…¶ä»–æ•¸æ“šé¡ä¼¼...
```

## æ³¨æ„äº‹é …
1. é€™æ˜¯æ¨¡æ“¬æ•¸æ“šï¼Œåƒ…ç”¨æ–¼æ¸¬è©¦å’Œé–‹ç™¼
2. å¯¦éš›éƒ¨ç½²éœ€è¦ä½¿ç”¨çœŸå¯¦çš„è¨“ç·´æ•¸æ“š
3. æ•¸æ“šæ ¼å¼èˆ‡çœŸå¯¦æ•¸æ“šé›†ä¿æŒä¸€è‡´
"""

    readme_path = generator.base_dir / "README.md"
    with open(readme_path, 'w', encoding='utf-8') as f:
    _ = f.write(readme_content)

    _ = print(f"ğŸ“– èªªæ˜æ–‡æª”: {readme_path}")

if __name__ == "__main__":


    _ = main()