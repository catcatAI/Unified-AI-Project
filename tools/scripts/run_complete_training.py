#!/usr/bin/env python3
"""
è¿è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹
"""

import subprocess
import sys
import time
from pathlib import Path

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
BACKEND_PATH = PROJECT_ROOT / "apps" / "backend"
TRAINING_PATH = PROJECT_ROOT / "training"

def print_header(text):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{'='*50}")
    _ = print(f"  {text}")
    print(f"{'='*50}")

def check_tensorflow():
    """æ£€æŸ¥TensorFlowæ˜¯å¦å¯ç”¨"""
    try:

    import tensorflow as tf
    _ = print(f"âœ… TensorFlowå¯ç”¨ - ç‰ˆæœ¬: {tf.__version__}")
    return True
    except ImportError:

    _ = print("âŒ TensorFlowä¸å¯ç”¨")
    return False

def run_math_model_training():
    """è¿è¡Œæ•°å­¦æ¨¡å‹è®­ç»ƒ"""
    _ = print_header("å¼€å§‹æ•°å­¦æ¨¡å‹è®­ç»ƒ")

    # æ•°å­¦æ¨¡å‹è®­ç»ƒè„šæœ¬è·¯å¾„
    math_train_script = BACKEND_PATH / "src" / "tools" / "math_model" / "train.py"

    if not math_train_script.exists()


    _ = print(f"âŒ æ•°å­¦æ¨¡å‹è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: {math_train_script}")
    return False

    # æ£€æŸ¥è®­ç»ƒæ•°æ®
    train_data = BACKEND_PATH / "data" / "raw_datasets" / "arithmetic_train_dataset.json"
    if not train_data.exists()

    _ = print(f"âŒ æ•°å­¦æ¨¡å‹è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {train_data}")
    _ = print("è¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬")
    return False

    try:


    _ = print("ğŸš€ å¯åŠ¨æ•°å­¦æ¨¡å‹è®­ç»ƒ...")
    start_time = time.time()

    # è¿è¡Œè®­ç»ƒè„šæœ¬
    cmd = [sys.executable, str(math_train_script)]
    result = subprocess.run(cmd, cwd=BACKEND_PATH, capture_output=True, text=True)

    end_time = time.time()
    training_time = end_time - start_time

        if result.returncode == 0:


    _ = print("âœ… æ•°å­¦æ¨¡å‹è®­ç»ƒå®Œæˆ")
            _ = print(f"â±ï¸  è®­ç»ƒè€—æ—¶: {training_time:.2f} ç§’")
            if result.stdout:

    _ = print(f"ğŸ“ è®­ç»ƒè¾“å‡º: {result.stdout[:500]}...")  # åªæ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦
            return True
        else:

            _ = print("âŒ æ•°å­¦æ¨¡å‹è®­ç»ƒå¤±è´¥")
            if result.stderr:

    _ = print(f"ğŸ“ é”™è¯¯ä¿¡æ¯: {result.stderr}")
            return False
    except Exception as e:

    _ = print(f"âŒ è¿è¡Œæ•°å­¦æ¨¡å‹è®­ç»ƒæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    return False

def run_logic_model_training():
    """è¿è¡Œé€»è¾‘æ¨¡å‹è®­ç»ƒ"""
    _ = print_header("å¼€å§‹é€»è¾‘æ¨¡å‹è®­ç»ƒ")

    # é€»è¾‘æ¨¡å‹è®­ç»ƒè„šæœ¬è·¯å¾„
    logic_train_script = BACKEND_PATH / "src" / "tools" / "logic_model" / "train_logic_model.py"

    if not logic_train_script.exists()


    _ = print(f"âŒ é€»è¾‘æ¨¡å‹è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: {logic_train_script}")
    return False

    # æ£€æŸ¥è®­ç»ƒæ•°æ®
    train_data = BACKEND_PATH / "data" / "raw_datasets" / "logic_train.json"
    if not train_data.exists()

    _ = print(f"âŒ é€»è¾‘æ¨¡å‹è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {train_data}")
    _ = print("è¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬")
    return False

    try:


    _ = print("ğŸš€ å¯åŠ¨é€»è¾‘æ¨¡å‹è®­ç»ƒ...")
    start_time = time.time()

    # è¿è¡Œè®­ç»ƒè„šæœ¬
    cmd = [sys.executable, str(logic_train_script)]
    result = subprocess.run(cmd, cwd=BACKEND_PATH, capture_output=True, text=True)

    end_time = time.time()
    training_time = end_time - start_time

        if result.returncode == 0:


    _ = print("âœ… é€»è¾‘æ¨¡å‹è®­ç»ƒå®Œæˆ")
            _ = print(f"â±ï¸  è®­ç»ƒè€—æ—¶: {training_time:.2f} ç§’")
            if result.stdout:

    _ = print(f"ğŸ“ è®­ç»ƒè¾“å‡º: {result.stdout[:500]}...")  # åªæ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦
            return True
        else:

            _ = print("âŒ é€»è¾‘æ¨¡å‹è®­ç»ƒå¤±è´¥")
            if result.stderr:

    _ = print(f"ğŸ“ é”™è¯¯ä¿¡æ¯: {result.stderr}")
            return False
    except Exception as e:

    _ = print(f"âŒ è¿è¡Œé€»è¾‘æ¨¡å‹è®­ç»ƒæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    return False

def check_model_files():
    """æ£€æŸ¥ç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶"""
    _ = print_header("æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")

    models_dir = BACKEND_PATH / "data" / "models"
    if not models_dir.exists()

    _ = print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
    return False

    required_files = [
    "arithmetic_model.keras",
    "arithmetic_char_maps.json",
    "logic_model_nn.keras",
    "logic_model_char_maps.json"
    ]

    missing_files = []
    found_files = []

    for file_name in required_files:


    file_path = models_dir / file_name
        if file_path.exists()

    size = file_path.stat().st_size
            _ = found_files.append(f"  âœ… {file_name} ({size} bytes)")
        else:

            _ = missing_files.append(file_name)

    if found_files:


    _ = print("æ‰¾åˆ°ä»¥ä¸‹æ¨¡å‹æ–‡ä»¶:")
        for file_info in found_files:

    _ = print(file_info)

    if missing_files:


    _ = print("âŒ ç¼ºå°‘ä»¥ä¸‹æ¨¡å‹æ–‡ä»¶:")
        for file_name in missing_files:

    _ = print(f"  - {file_name}")
    return False
    else:

    _ = print("âœ… æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹æ–‡ä»¶éƒ½å·²ç”Ÿæˆ")
    return True

def generate_training_report(model_type, success, training_time, details=""):
    """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
    _ = print_header("ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š")

    reports_dir = TRAINING_PATH / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)

    timestamp = time.strftime("%Y%m%d_%H%M%S")
    report_file = reports_dir / f"training_report_{model_type}_{timestamp}.md"

    report_content = f"""# {model_type.capitalize()}æ¨¡å‹è®­ç»ƒæŠ¥å‘Š

## è®­ç»ƒä¿¡æ¯
_ = - è®­ç»ƒæ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S")}
- æ¨¡å‹ç±»å‹: {model_type}
- è®­ç»ƒçŠ¶æ€: {"æˆåŠŸ" if success else "å¤±è´¥"}

## è®­ç»ƒè¯¦æƒ…
- è®­ç»ƒè€—æ—¶: {training_time:.2f} ç§’
- è®­ç»ƒç»†èŠ‚: {details}

## ä¸‹ä¸€æ­¥å»ºè®®
1. {"éªŒè¯æ¨¡å‹æ€§èƒ½" if success else "æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡æ–°è®­ç»ƒ"}
2. {"æ ¹æ®éœ€è¦è°ƒæ•´è¶…å‚æ•°" if success else "ä¿®å¤é—®é¢˜åé‡è¯•"}
3. {"ä½¿ç”¨æ›´å¤šæ•°æ®è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒ" if success else "ç¡®ä¿ç¯å¢ƒé…ç½®æ­£ç¡®"}
"""

    try:


    with open(report_file, 'w', encoding='utf-8') as f:
    _ = f.write(report_content)
    _ = print(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    return True
    except Exception as e:

    _ = print(f"âŒ ç”Ÿæˆè®­ç»ƒæŠ¥å‘Šå¤±è´¥: {e}")
    return False

def main() -> None:
    print("=== Unified AI Project - å®Œæ•´æ¨¡å‹è®­ç»ƒæµç¨‹ ===")

    # æ£€æŸ¥TensorFlow
    if not check_tensorflow()

    _ = print("âŒ è¯·å…ˆå®‰è£…TensorFlowä¾èµ–")
    return

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    models_dir = BACKEND_PATH / "data" / "models"
    models_dir.mkdir(parents=True, exist_ok=True)

    # è¿è¡Œæ•°å­¦æ¨¡å‹è®­ç»ƒ
    math_start_time = time.time()
    math_success = run_math_model_training()
    math_end_time = time.time()
    math_training_time = math_end_time - math_start_time

    # è¿è¡Œé€»è¾‘æ¨¡å‹è®­ç»ƒ
    logic_start_time = time.time()
    logic_success = run_logic_model_training()
    logic_end_time = time.time()
    logic_training_time = logic_end_time - logic_start_time

    # æ£€æŸ¥ç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶
    files_ok = check_model_files()

    # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
    generate_training_report("math_model", math_success, math_training_time,
                           "æ•°å­¦æ¨¡å‹è®­ç»ƒå®Œæˆ" if math_success else "æ•°å­¦æ¨¡å‹è®­ç»ƒå¤±è´¥")
    generate_training_report("logic_model", logic_success, logic_training_time,
                           "é€»è¾‘æ¨¡å‹è®­ç»ƒå®Œæˆ" if logic_success else "é€»è¾‘æ¨¡å‹è®­ç»ƒå¤±è´¥")

    _ = print_header("è®­ç»ƒå®Œæˆ")
    print(f"æ•°å­¦æ¨¡å‹è®­ç»ƒ: {'âœ… æˆåŠŸ' if math_success else 'âŒ å¤±è´¥'}")
    print(f"é€»è¾‘æ¨¡å‹è®­ç»ƒ: {'âœ… æˆåŠŸ' if logic_success else 'âŒ å¤±è´¥'}")
    print(f"æ¨¡å‹æ–‡ä»¶æ£€æŸ¥: {'âœ… é€šè¿‡' if files_ok else 'âŒ å¤±è´¥'}")

    if math_success and logic_success and files_ok:


    _ = print("ğŸ‰ æ‰€æœ‰æ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    return True
    else:

    _ = print("âš ï¸ éƒ¨åˆ†æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    return False

if __name__ == "__main__":


    success = main()
    sys.exit(0 if success else 1)