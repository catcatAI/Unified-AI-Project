#!/usr/bin/env python3
"""
Common Voice æ•¸æ“šé›†è§£å£“ç¸®å·¥å…· - æ”¹é€²ç‰ˆ
æ”¯æŒçºŒå‚³ã€é€²åº¦ä¿å­˜å’Œæ›´å¥½çš„éŒ¯èª¤è™•ç†
"""

import tarfile
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Any

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('common_voice_extraction_improved.log'),
        logging.StreamHandler()
    ]
)
logger: Any = logging.getLogger(__name__)

class ImprovedCommonVoiceExtractor:
    """æ”¹é€²çš„Common Voice è§£å£“å™¨"""

    def __init__(self, base_dir: str = "d:/Projects/Unified-AI-Project/data/common_voice_zh") -> None:
        self.base_dir = Path(base_dir)
        self.progress_file = self.base_dir / "extraction_progress.json"

    def save_progress(self, dataset_name: str, extracted_count: int, total_count: int) -> None:
        """ä¿å­˜è§£å£“é€²åº¦"""
        progress_data = {}
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    progress_data = json.load(f)
            except:
                progress_data = {}

        progress_data[dataset_name] = {
            'extracted_count': extracted_count,
            'total_count': total_count,
            'last_update': datetime.now().isoformat()
        }

        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, indent=2)

    def load_progress(self, dataset_name: str) -> int:
        """åŠ è¼‰è§£å£“é€²åº¦"""
        if not self.progress_file.exists():
            return 0

        try:
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
                return progress_data.get(dataset_name, {}).get('extracted_count', 0)
        except:
            return 0

    def extract_with_resume(self, archive_path: Path, extract_dir: Path, dataset_name: str) -> bool:
        """æ”¯æŒçºŒå‚³çš„è§£å£“ç¸®"""
        try:
            logger.info(f"ğŸ”„ é–‹å§‹è§£å£“ç¸®: {archive_path.name}")

            # å‰µå»ºè§£å£“ç›®éŒ„
            extract_dir.mkdir(parents=True, exist_ok=True)

            # åŠ è¼‰ä¹‹å‰çš„é€²åº¦
            start_from = self.load_progress(dataset_name)

            with tarfile.open(archive_path, 'r:gz') as tar:
                members = tar.getmembers()
                total_files = len(members)

                logger.info(f"ğŸ“Š ç¸½æ–‡ä»¶æ•¸: {total_files}")
                if start_from > 0:
                    logger.info(f"ğŸ”„ å¾ç¬¬ {start_from} å€‹æ–‡ä»¶çºŒå‚³")

                # ä½¿ç”¨ extractall ä½†åªè™•ç†æœªè§£å£“çš„æ–‡ä»¶
                if start_from == 0:
                    # ç¬¬ä¸€æ¬¡è§£å£“ï¼Œä½¿ç”¨ extractall æ›´é«˜æ•ˆ
                    try:
                        logger.info("âš¡ ä½¿ç”¨é«˜é€Ÿè§£å£“æ¨¡å¼...")
                        tar.extractall(path=extract_dir, filter='data')
                        logger.info(f"âœ… è§£å£“ç¸®å®Œæˆ: {dataset_name}")
                        self.save_progress(dataset_name, total_files, total_files)
                        return True
                    except TypeError:
                        # Pythonç‰ˆæœ¬ä¸æ”¯æŒfilteråƒæ•¸
                        logger.info("âš¡ ä½¿ç”¨æ¨™æº–è§£å£“æ¨¡å¼...")
                        tar.extractall(path=extract_dir)
                        logger.info(f"âœ… è§£å£“ç¸®å®Œæˆ: {dataset_name}")
                        self.save_progress(dataset_name, total_files, total_files)
                        return True
                    except Exception as e:
                        logger.warning(f"âš ï¸ é«˜é€Ÿè§£å£“å¤±æ•—ï¼Œåˆ‡æ›åˆ°é€å€‹æ–‡ä»¶æ¨¡å¼: {e}")
                        # ç¹¼çºŒä½¿ç”¨é€å€‹æ–‡ä»¶æ¨¡å¼

                # é€å€‹æ–‡ä»¶è§£å£“ï¼ˆçºŒå‚³æ¨¡å¼ï¼‰
                for i, member in enumerate(members):
                    if i < start_from:
                        continue

                    try:
                        tar.extract(member, extract_dir)

                        # æ¯1000å€‹æ–‡ä»¶é¡¯ç¤ºé€²åº¦ä¸¦ä¿å­˜
                        if (i + 1) % 1000 == 0:
                            progress = ((i + 1) / total_files) * 100
                            logger.info(f"ğŸ“ˆ è§£å£“é€²åº¦: {progress:.1f}% ({i + 1}/{total_files})")
                            self.save_progress(dataset_name, i + 1, total_files)

                    except KeyboardInterrupt:
                        logger.info(f"â¸ï¸ ç”¨æˆ¶ä¸­æ–·ï¼Œå·²ä¿å­˜é€²åº¦: {i}/{total_files}")
                        self.save_progress(dataset_name, i, total_files)
                        return False
                    except Exception as e:
                        logger.warning(f"âš ï¸ è·³éæ–‡ä»¶ {member.name}: {e}")
                        continue

                logger.info(f"âœ… è§£å£“ç¸®å®Œæˆ: {dataset_name}")
                self.save_progress(dataset_name, total_files, total_files)
                return True

        except Exception as e:
            logger.error(f"âŒ è§£å£“ç¸®å¤±æ•— {dataset_name}: {e}")
            return False

    def extract_all_datasets(self) -> 'dict[str, bool]':
        """è§£å£“æ‰€æœ‰æ•¸æ“šé›†"""
        datasets = [
            {
                'file': 'cv-corpus-22.0-2025-06-20-zh-CN.tar.gz',
                'name': 'zh-CN',
                'display_name': 'Common Voice ä¸­æ–‡å¤§é™¸ v22.0'
            },
            {
                'file': 'cv-corpus-22.0-2025-06-20-zh-TW.tar.gz',
                'name': 'zh-TW',
                'display_name': 'Common Voice ä¸­æ–‡å°ç£ v22.0'
            },
            {
                'file': 'cv-corpus-7.0-singleword.tar.gz',
                'name': 'singleword',
                'display_name': 'Common Voice å–®å­—æ•¸æ“šé›† v7.0'
            }
        ]

        results = {}

        for dataset in datasets:
            archive_path = self.base_dir / dataset['file']
            extract_dir = self.base_dir / dataset['name']

            if not archive_path.exists():
                logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {archive_path}")
                results[dataset['name']] = False
                continue

            # æª¢æŸ¥æ˜¯å¦å·²å®Œå…¨è§£å£“
            progress = self.load_progress(dataset['name'])
            if progress > 0:
                logger.info(f"ğŸ”„ {dataset['display_name']} å°‡å¾ä¸­æ–·è™•çºŒå‚³")

            success = self.extract_with_resume(archive_path, extract_dir, dataset['name'])
            results[dataset['name']] = success

        return results

def main() -> None:
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ Common Voice æ•¸æ“šé›†è§£å£“ç¸®å·¥å…· - æ”¹é€²ç‰ˆ")
    print("æ”¯æŒçºŒå‚³å’Œé€²åº¦ä¿å­˜")
    print("=" * 60)

    extractor = ImprovedCommonVoiceExtractor()

    # é–‹å§‹è§£å£“
    results = extractor.extract_all_datasets()

    # é¡¯ç¤ºçµæœ
    print("\nğŸ“Š è§£å£“çµæœ:")
    for dataset_name, success in results.items():
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
        print(f"  â€¢ {dataset_name}: {status}")

    success_count = sum(1 for success in results.values() if success)
    total_count = len(results)

    print(f"\nğŸ‰ å®Œæˆ! æˆåŠŸè§£å£“ {success_count}/{total_count} å€‹æ•¸æ“šé›†")

    if success_count < total_count:
        print("\nğŸ’¡ æç¤º: å¦‚æœè§£å£“è¢«ä¸­æ–·ï¼Œå¯ä»¥é‡æ–°é‹è¡Œæ­¤è…³æœ¬çºŒå‚³")

if __name__ == "__main__":
    main()