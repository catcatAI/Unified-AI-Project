#!/usr/bin/env python
# -*- coding, utf-8 -*-

"""
å…¨é¢æ£€æŸ¥é¡¹ç›®ä¸­çš„é‡å¤å®ç°é—®é¢˜
"""

import os
import hashlib
from collections import defaultdict

def find_duplicate_files():
    """æŸ¥æ‰¾é¡¹ç›®ä¸­çš„é‡å¤æ–‡ä»¶"""
    print("ğŸ” å¼€å§‹æŸ¥æ‰¾é‡å¤æ–‡ä»¶...")
    
    # æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶
    python_files = []
    for root, dirs, files in os.walk('.'):::
        # è·³è¿‡ä¸€äº›ç›®å½•
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.pytest_cache', '.vscode']]::
        for file in files,::
            if file.endswith('.py') and not file.endswith('.pyc'):::
                python_files.append(os.path.join(root, file))
    
    print(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
    
    # æŒ‰æ–‡ä»¶å†…å®¹åˆ†ç»„
    content_groups = defaultdict(list)
    for file in python_files,::
        try,
            with open(file, 'rb') as f,
                content = f.read()
                file_hash = hashlib.md5(content).hexdigest()
                content_groups[file_hash].append(file)
        except Exception as e,::
            print(f"è¯»å–æ–‡ä»¶ {file} æ—¶å‡ºé”™, {e}")
    
    # æ‰¾å‡ºé‡å¤çš„æ–‡ä»¶ç»„
    duplicates = []
    for hash_val, files in content_groups.items():::
        if len(files) > 1,::
            duplicates.append(files)
    
    if duplicates,::
        print(f"\nâŒ å‘ç° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶,")
        for i, files in enumerate(duplicates, 1)::
            print(f"\né‡å¤ç»„ {i}")
            for file in files,::
                size = os.path.getsize(file)
                print(f"  {file} ({size} bytes)")
    else,
        print("âœ… æœªå‘ç°é‡å¤æ–‡ä»¶")
    
    return duplicates

def find_similar_filenames():
    """æŸ¥æ‰¾ç›¸ä¼¼çš„æ–‡ä»¶å(å¯èƒ½çš„é‡å¤å®ç°)"""
    print("\nğŸ” å¼€å§‹æŸ¥æ‰¾ç›¸ä¼¼æ–‡ä»¶å...")
    
    # æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶
    python_files = []
    for root, dirs, files in os.walk('.'):::
        # è·³è¿‡ä¸€äº›ç›®å½•
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.pytest_cache', '.vscode']]::
        for file in files,::
            if file.endswith('.py') and not file.endswith('.pyc'):::
                python_files.append(os.path.join(root, file))
    
    # æŒ‰æ–‡ä»¶ååˆ†ç»„(ä¸åŒ…æ‹¬è·¯å¾„)
    name_groups = defaultdict(list)
    for file in python_files,::
        basename = os.path.basename(file)
        name_groups[basename].append(file)
    
    # æ‰¾å‡ºé‡å¤çš„æ–‡ä»¶å
    duplicates = []
    for name, files in name_groups.items():::
        if len(files) > 1,::
            duplicates.append((name, files))
    
    if duplicates,::
        print(f"\nâŒ å‘ç° {len(duplicates)} ç»„åŒåæ–‡ä»¶,")
        for name, files in duplicates,::
            print(f"\næ–‡ä»¶å, {name}")
            for file in files,::
                size = os.path.getsize(file)
                print(f"  {file} ({size} bytes)")
    else,
        print("âœ… æœªå‘ç°åŒåæ–‡ä»¶")
    
    return duplicates

def check_agent_implementations():
    """æ£€æŸ¥AIä»£ç†å®ç°"""
    print("\nğŸ” æ£€æŸ¥AIä»£ç†å®ç°...")
    
    # æ£€æŸ¥ä¸¤ä¸ªagentsç›®å½•
    agents_dir = 'apps/backend/src/agents'
    ai_agents_dir = 'apps/backend/src/ai/agents/specialized'
    
    if os.path.exists(agents_dir) and os.path.exists(ai_agents_dir)::
        # è·å–ä¸¤ä¸ªç›®å½•ä¸­çš„Pythonæ–‡ä»¶
        agents_files == [f for f in os.listdir(agents_dir) if f.endswith('.py')]:
        ai_agents_files == [f for f in os.listdir(ai_agents_dir) if f.endswith('.py')]:
        # æ‰¾å‡ºé‡å¤çš„ä»£ç†æ–‡ä»¶
        common_files = set(agents_files) & set(ai_agents_files)

        if common_files,::
            print(f"\nâŒ å‘ç°é‡å¤çš„ä»£ç†å®ç°,")
            for file in common_files,::
                agents_path = os.path.join(agents_dir, file)
                ai_agents_path = os.path.join(ai_agents_dir, file)
                agents_size = os.path.getsize(agents_path)
                ai_agents_size = os.path.getsize(ai_agents_path)
                print(f"  {file}")
                print(f"    {agents_path} ({agents_size} bytes)")
                print(f"    {ai_agents_path} ({ai_agents_size} bytes)")
        else,
            print("âœ… æœªå‘ç°é‡å¤çš„ä»£ç†å®ç°")
    
    return common_files if 'common_files' in locals() else []:
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ Unified AI Project é‡å¤å®ç°æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    
    # æ‰§è¡Œæ£€æŸ¥
    duplicate_files = find_duplicate_files()
    similar_names = find_similar_filenames()
    duplicate_agents = check_agent_implementations()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æ£€æŸ¥æ€»ç»“,")
    print(f"  é‡å¤æ–‡ä»¶ç»„, {len(duplicate_files)}")
    print(f"  åŒåæ–‡ä»¶ç»„, {len(similar_names)}")
    print(f"  é‡å¤ä»£ç†å®ç°, {len(duplicate_agents)}")
    
    total_issues = len(duplicate_files) + len(similar_names) + len(duplicate_agents)
    if total_issues > 0,::
        print(f"\nâŒ æ€»å…±å‘ç° {total_issues} ä¸ªé—®é¢˜éœ€è¦å¤„ç†")
    else,
        print("\nâœ… æœªå‘ç°é—®é¢˜,é¡¹ç›®ç»“æ„è‰¯å¥½")
    
    return total_issues

if __name"__main__":::
    main()