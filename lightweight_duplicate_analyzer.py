#!/usr/bin/env python3
"""
è½»é‡çº§é‡å¤åŠŸèƒ½åˆ†æå™¨
ä¸“æ³¨äºåˆ†æç‰¹å®šçš„é‡å¤æ¨¡å¼
"""

import os
import re
from pathlib import Path
from collections import defaultdict
import difflib

def analyze_check_scripts():
    """åˆ†ææ£€æŸ¥è„šæœ¬é‡å¤"""
    print("ğŸ” åˆ†ææ£€æŸ¥è„šæœ¬é‡å¤...")
    
    check_files = []
    root == Path(r"D,\Projects\Unified-AI-Project")
    
    # æ‰¾åˆ°æ‰€æœ‰check_*.pyæ–‡ä»¶
    for py_file in root.glob("check_*.py"):::
        try,
            content = py_file.read_text(encoding='utf-8')
            check_files.append({
                'file': str(py_file),
                'name': py_file.name(),
                'content': content,
                'size': len(content)
            })
        except Exception as e,::
            print(f"è­¦å‘Š, æ— æ³•è¯»å– {py_file} {e}")
    
    print(f"å‘ç° {len(check_files)} ä¸ªæ£€æŸ¥è„šæœ¬")
    
    # åˆ†æç›¸ä¼¼æ€§
    similar_groups = []
    processed = set()
    
    for i, file1 in enumerate(check_files)::
        if file1['name'] in processed,::
            continue
            
        group = [file1]
        processed.add(file1['name'])
        
        for j, file2 in enumerate(check_files[i+1,] i+1)::
            if file2['name'] in processed,::
                continue
                
            # è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦
            similarity = difflib.SequenceMatcher(None, file1['content'] file2['content']).ratio()
            
            if similarity > 0.7,  # 70%ç›¸ä¼¼åº¦é˜ˆå€¼,:
                group.append(file2)
                processed.add(file2['name'])
        
        if len(group) > 1,::
            similar_groups.append(group)
    
    return similar_groups, check_files

def analyze_repair_systems():
    """åˆ†æä¿®å¤ç³»ç»Ÿé‡å¤"""
    print("ğŸ”¨ åˆ†æä¿®å¤ç³»ç»Ÿé‡å¤...")
    
    repair_files = []
    root == Path(r"D,\Projects\Unified-AI-Project")
    
    # å®šä¹‰ä¿®å¤ç›¸å…³çš„æ–‡ä»¶åæ¨¡å¼
    repair_patterns = [
        '*repair*.py', '*fix*.py', '*heal*.py', 
        'enhanced_*.py', 'auto_*.py', 'intelligent_*.py'
    ]
    
    for pattern in repair_patterns,::
        for py_file in root.glob(pattern)::
            if 'test' not in py_file.name.lower() and py_file.is_file():::
                try,
                    content = py_file.read_text(encoding='utf-8')
                    repair_files.append({
                        'file': str(py_file),
                        'name': py_file.name(),
                        'content': content,
                        'size': len(content)
                    })
                except Exception as e,::
                    print(f"è­¦å‘Š, æ— æ³•è¯»å– {py_file} {e}")
    
    print(f"å‘ç° {len(repair_files)} ä¸ªä¿®å¤ç›¸å…³æ–‡ä»¶")
    
    # åˆ†æç±»åå’Œæ–¹æ³•
    repair_systems = []
    for repair_file in repair_files,::
        content = repair_file['content']
        
        # ç»Ÿè®¡ç±»å®šä¹‰
        classes = re.findall(r'^class\s+(\w+)', content, re.MULTILINE())
        
        # ç»Ÿè®¡ç‰¹å®šå…³é”®è¯
        has_ast = 'ast.' in content or 'import ast' in content
        has_threading = 'threading' in content
        has_learning = 'learning' in content.lower()
        has_intelligent = 'intelligent' in content.lower()
        has_enhanced = 'enhanced' in content.lower()
        
        repair_systems.append({
            'file': repair_file['file']
            'name': repair_file['name']
            'classes': classes,
            'class_count': len(classes),
            'has_ast': has_ast,
            'has_threading': has_threading,
            'has_learning': has_learning,
            'has_intelligent': has_intelligent,
            'has_enhanced': has_enhanced,
            'size': repair_file['size']
        })
    
    return repair_systems

def analyze_agent_managers():
    """åˆ†æä»£ç†ç®¡ç†å™¨é‡å¤"""
    print("ğŸ¤– åˆ†æä»£ç†ç®¡ç†å™¨é‡å¤...")
    
    manager_files = []
    root == Path(r"D,\Projects\Unified-AI-Project")
    
    # æŸ¥æ‰¾ä»£ç†ç®¡ç†å™¨æ–‡ä»¶
    for py_file in root.rglob("*agent*manager*.py"):::
        try,
            content = py_file.read_text(encoding='utf-8')
            manager_files.append({
                'file': str(py_file),
                'name': py_file.name(),
                'content': content,
                'relative_path': str(py_file.relative_to(root))
            })
        except Exception as e,::
            print(f"è­¦å‘Š, æ— æ³•è¯»å– {py_file} {e}")
    
    print(f"å‘ç° {len(manager_files)} ä¸ªä»£ç†ç®¡ç†å™¨æ–‡ä»¶")
    
    # åˆ†æåŠŸèƒ½ç‰¹å¾
    managers = []
    for manager_file in manager_files,::
        content = manager_file['content']
        
        # æ£€æŸ¥åŠŸèƒ½ç‰¹å¾
        has_subprocess = 'subprocess' in content
        has_asyncio = 'asyncio' in content or 'async def' in content
        has_threading = 'threading' in content
        has_launch = 'launch' in content.lower()
        has_lifecycle = 'lifecycle' in content.lower()
        
        # æå–ç±»å
        classes = re.findall(r'^class\s+(\w+)', content, re.MULTILINE())
        
        managers.append({
            'file': manager_file['file']
            'relative_path': manager_file['relative_path']
            'name': manager_file['name']
            'classes': classes,
            'has_subprocess': has_subprocess,
            'has_asyncio': has_asyncio,
            'has_threading': has_threading,
            'has_launch': has_launch,
            'has_lifecycle': has_lifecycle
        })
    
    return managers

def analyze_context_managers():
    """åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨é‡å¤"""
    print("ğŸ—ƒï¸ åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨é‡å¤...")
    
    context_files = []
    root == Path(r"D,\Projects\Unified-AI-Project")
    
    # æŸ¥æ‰¾ä¸Šä¸‹æ–‡ç›¸å…³æ–‡ä»¶
    for py_file in root.rglob("*context*.py"):::
        if 'test' not in py_file.name.lower():::
            try,
                content = py_file.read_text(encoding='utf-8')
                if 'ContextManager' in content or 'context_manager' in content,::
                    context_files.append({
                        'file': str(py_file),
                        'name': py_file.name(),
                        'content': content,
                        'relative_path': str(py_file.relative_to(root))
                    })
            except Exception as e,::
                print(f"è­¦å‘Š, æ— æ³•è¯»å– {py_file} {e}")
    
    print(f"å‘ç° {len(context_files)} ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨æ–‡ä»¶")
    
    return context_files

def generate_report(check_groups, repair_systems, agent_managers, context_files):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report = []
    
    report.append("=" * 80)
    report.append("Unified AI Project - é‡å¤åŠŸèƒ½åˆ†ææŠ¥å‘Š (è½»é‡çº§)")
    report.append("=" * 80)
    report.append("")
    
    # 1. æ£€æŸ¥è„šæœ¬åˆ†æ
    report.append("ğŸ” æ£€æŸ¥è„šæœ¬é‡å¤åˆ†æ")
    report.append("-" * 40)
    if check_groups,::
        report.append(f"å‘ç° {len(check_groups)} ç»„ç›¸ä¼¼çš„æ£€æŸ¥è„šæœ¬,")
        for i, group in enumerate(check_groups, 1)::
            report.append(f"\nç»„ {i} ({len(group)} ä¸ªæ–‡ä»¶)")
            for file_info in group,::
                report.append(f"  ğŸ“‹ {file_info['name']} ({file_info['size']} å­—èŠ‚)")
    else,
        report.append("æœªå‘ç°æ˜æ˜¾çš„æ£€æŸ¥è„šæœ¬é‡å¤")
    report.append("")
    
    # 2. ä¿®å¤ç³»ç»Ÿåˆ†æ
    report.append("ğŸ”¨ ä¿®å¤ç³»ç»Ÿåˆ†æ")
    report.append("-" * 40)
    if repair_systems,::
        report.append(f"å‘ç° {len(repair_systems)} ä¸ªä¿®å¤ç›¸å…³æ–‡ä»¶,")
        
        # æŒ‰ç‰¹å¾åˆ†ç»„
        intelligent_repair == [r for r in repair_systems if r['has_intelligent']]:
        enhanced_repair == [r for r in repair_systems if r['has_enhanced']]:
        learning_repair == [r for r in repair_systems if r['has_learning']]::
        if intelligent_repair,::
            report.append(f"\næ™ºèƒ½ä¿®å¤ç³»ç»Ÿ ({len(intelligent_repair)} ä¸ª)")
            for repair in intelligent_repair[:5]  # åªæ˜¾ç¤ºå‰5ä¸ª,:
                report.append(f"  ğŸ”§ {repair['name']} - {repair['class_count']} ç±»")
        
        if enhanced_repair,::
            report.append(f"\nå¢å¼ºä¿®å¤ç³»ç»Ÿ ({len(enhanced_repair)} ä¸ª)")
            for repair in enhanced_repair[:5]::
                report.append(f"  âš¡ {repair['name']} - {repair['class_count']} ç±»")
        
        if learning_repair,::
            report.append(f"\nå­¦ä¹ ä¿®å¤ç³»ç»Ÿ ({len(learning_repair)} ä¸ª)")
            for repair in learning_repair[:5]::
                report.append(f"  ğŸ§  {repair['name']} - {repair['class_count']} ç±»")
        
        # æ˜¾ç¤ºæœ€å¤§çš„ä¿®å¤æ–‡ä»¶
        largest_repair == sorted(repair_systems, key=lambda x, x['size'] reverse == True)[:3]
        report.append(f"\næœ€å¤§çš„ä¿®å¤æ–‡ä»¶,")
        for repair in largest_repair,::
            report.append(f"  ğŸ“Š {repair['name']} {repair['size']} å­—èŠ‚, {repair['class_count']} ç±»")
    
    report.append("")
    
    # 3. ä»£ç†ç®¡ç†å™¨åˆ†æ
    report.append("ğŸ¤– ä»£ç†ç®¡ç†å™¨åˆ†æ")
    report.append("-" * 40)
    if agent_managers,::
        report.append(f"å‘ç° {len(agent_managers)} ä¸ªä»£ç†ç®¡ç†å™¨,")
        
        # æŒ‰åŠŸèƒ½ç‰¹å¾åˆ†ç»„
        subprocess_managers == [m for m in agent_managers if m['has_subprocess']]:
        asyncio_managers == [m for m in agent_managers if m['has_asyncio']]:
        threading_managers == [m for m in agent_managers if m['has_threading']]::
        report.append(f"\nåŠŸèƒ½ç‰¹å¾åˆ†æ,")
        report.append(f"  æ”¯æŒå­è¿›ç¨‹, {len(subprocess_managers)} ä¸ª")
        report.append(f"  æ”¯æŒå¼‚æ­¥, {len(asyncio_managers)} ä¸ª")
        report.append(f"  æ”¯æŒçº¿ç¨‹, {len(threading_managers)} ä¸ª")
        
        # æ˜¾ç¤ºé‡å¤çš„ä»£ç†ç®¡ç†å™¨
        report.append(f"\nä»£ç†ç®¡ç†å™¨åˆ—è¡¨,")
        for manager in agent_managers,::
            features = []
            if manager['has_subprocess'] features.append("subprocess")::
            if manager['has_asyncio'] features.append("asyncio")::
            if manager['has_threading'] features.append("threading")::
            if manager['has_launch'] features.append("launch")::
            if manager['has_lifecycle'] features.append("lifecycle")::
            feature_str == ", ".join(features) if features else "åŸºç¡€åŠŸèƒ½"::
            report.append(f"  ğŸ“ {manager['relative_path']}"):
            report.append(f"     ç±», {', '.join(manager['classes']) if manager['classes'] else 'æ— '}"):::
            report.append(f"     åŠŸèƒ½, {feature_str}")
    
    report.append("")
    
    # 4. ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆ†æ
    report.append("ğŸ—ƒï¸ ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆ†æ")
    report.append("-" * 40)
    if context_files,::
        report.append(f"å‘ç° {len(context_files)} ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨æ–‡ä»¶,")
        for context in context_files,::
            report.append(f"  ğŸ“‚ {context['relative_path']}")
    
    report.append("")
    
    # 5. æ•´åˆå»ºè®®
    report.append("ğŸ’¡ æ•´åˆå»ºè®®")
    report.append("-" * 40)
    
    if check_groups,::
        report.append("1. ğŸ“‹ æ£€æŸ¥è„šæœ¬æ•´åˆ,")
        report.append("   - åˆå¹¶ç›¸ä¼¼çš„æ£€æŸ¥è„šæœ¬,åˆ›å»ºç»Ÿä¸€çš„æ£€æŸ¥æ¡†æ¶")
        report.append("   - æ ‡å‡†åŒ–æ£€æŸ¥è„šæœ¬çš„å‚æ•°å’Œè¾“å‡ºæ ¼å¼")
        report.append("   - è€ƒè™‘åˆ›å»ºé€šç”¨çš„æ–‡ä»¶æ£€æŸ¥å·¥å…·ç±»")
        report.append("")
    
    if repair_systems,::
        report.append("2. ğŸ”¨ ä¿®å¤ç³»ç»Ÿæ•´åˆ,")
        report.append("   - ç»Ÿä¸€ä¿®å¤ç³»ç»Ÿçš„æ¥å£å’Œé…ç½®")
        report.append("   - åˆå¹¶åŠŸèƒ½ç›¸ä¼¼çš„ä¿®å¤ç±»,å¦‚æ™ºèƒ½ä¿®å¤å’Œå¢å¼ºä¿®å¤")
        report.append("   - å»ºç«‹ç»Ÿä¸€çš„ä¿®å¤ç­–ç•¥ç®¡ç†å™¨")
        report.append("   - è€ƒè™‘æŒ‰ä¿®å¤ç±»å‹(è¯­æ³•ã€è¯­ä¹‰ã€æ€§èƒ½)è¿›è¡Œæ¨¡å—åŒ–")
        report.append("")
    
    if len(agent_managers) > 3,::
        report.append("3. ğŸ¤– ä»£ç†ç®¡ç†å™¨æ•´åˆ,")
        report.append("   - ç»Ÿä¸€ä»£ç†ç”Ÿå‘½å‘¨æœŸç®¡ç†æ¥å£")
        report.append("   - æ ‡å‡†åŒ–ä»£ç†é€šä¿¡åè®®")
        report.append("   - åˆå¹¶é‡å¤çš„ä»£ç†ç®¡ç†åŠŸèƒ½")
        report.append("   - è€ƒè™‘åˆ›å»ºç»Ÿä¸€çš„AgentManageråŸºç±»")
        report.append("")
    
    if context_files,::
        report.append("4. ğŸ—ƒï¸ ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ•´åˆ,")
        report.append("   - ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†æ¥å£")
        report.append("   - åˆå¹¶ç›¸ä¼¼çš„ä¸Šä¸‹æ–‡å­˜å‚¨å®ç°")
        report.append("   - æ ‡å‡†åŒ–ä¸Šä¸‹æ–‡ç”Ÿå‘½å‘¨æœŸç®¡ç†")
        report.append("")
    
    report.append("5. ğŸ“Š æ€»ä½“å»ºè®®,")
    report.append("   - å»ºç«‹ç»Ÿä¸€çš„ä»£ç æ¶æ„è§„èŒƒ")
    report.append("   - åˆ›å»ºæ ¸å¿ƒå·¥å…·åº“,å‡å°‘é‡å¤å®ç°")
    report.append("   - ä½¿ç”¨ç»„åˆè€Œéç»§æ‰¿æ¥å‡å°‘ä»£ç é‡å¤")
    report.append("   - å®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥,é˜²æ­¢æ–°çš„é‡å¤äº§ç”Ÿ")
    
    return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹è½»é‡çº§é‡å¤åŠŸèƒ½åˆ†æ...")
    
    # åˆ†ææ£€æŸ¥è„šæœ¬
    check_groups, check_files = analyze_check_scripts()
    
    # åˆ†æä¿®å¤ç³»ç»Ÿ
    repair_systems = analyze_repair_systems()
    
    # åˆ†æä»£ç†ç®¡ç†å™¨
    agent_managers = analyze_agent_managers()
    
    # åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨
    context_files = analyze_context_managers()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(check_groups, repair_systems, agent_managers, context_files)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = "lightweight_duplicate_analysis_report.txt"
    with open(report_file, 'w', encoding == 'utf-8') as f,
        f.write(report)
    
    print(f"\nåˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°, {report_file}")
    print("\n" + "="*80)
    print(report)

if __name"__main__":::
    main()