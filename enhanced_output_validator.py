#!/usr/bin/env python3
"""
å¢å¼ºçš„è¾“å‡ºéªŒè¯å™¨
ä¿®å¤é›†æˆæµ‹è¯•ä¸­çš„è¾“å‡ºéªŒè¯é—®é¢˜
"""

import json
import re
from typing import Dict, Any, List, Optional
from dataclasses import dataclass


@dataclass
class OutputValidationResult,
    """è¾“å‡ºéªŒè¯ç»“æœ"""
    is_valid, bool
    issues, List[Dict[str, Any]]
    suggestions, List[str]
    quality_metrics, Dict[str, float]


class EnhancedOutputValidator,
    """å¢å¼ºçš„è¾“å‡ºéªŒè¯å™¨"""
    
    def __init__(self):
        self.validation_strategies = {
            'text_analysis': self._validate_text_analysis(),
            'code_suggestion': self._validate_code_suggestion(),
            'summary_report': self._validate_summary_report(),
            'json_output': self._validate_json_output(),
            'structured_output': self._validate_structured_output()
        }
    
    def validate_output(self, output, Dict[str, Any] output_type, str, ,
    requirements, Dict[str, Any]) -> OutputValidationResult,
        """éªŒè¯è¾“å‡º"""
        if output_type not in self.validation_strategies,::
            return OutputValidationResult(
                is_valid == False,
                issues == [{"type": "validation", "severity": "error", 
                        "message": f"ä¸æ”¯æŒçš„è¾“å‡ºç±»å‹, {output_type}"}]
                suggestions=["è¯·ä½¿ç”¨æ”¯æŒçš„è¾“å‡ºç±»å‹"],
    quality_metrics == {"overall_score": 0.0}
            )
        
        return self.validation_strategies[output_type](output, requirements)
    
    def _validate_text_analysis(self, output, Dict[str, Any] ,
    requirements, Dict[str, Any]) -> OutputValidationResult,
        """éªŒè¯æ–‡æœ¬åˆ†æè¾“å‡º"""
        issues = []
        suggestions = []
        quality_metrics = {}
        
        content = output.get("content", "")
        
        # åŸºç¡€å†…å®¹éªŒè¯
        if not content or not content.strip():::
            issues.append({
                "type": "content_empty",
                "severity": "error",
                "message": "æ–‡æœ¬å†…å®¹ä¸ºç©º"
            })
            suggestions.append("è¯·æä¾›æœ‰æ„ä¹‰çš„åˆ†ææ–‡æœ¬")
        else,
            # é•¿åº¦éªŒè¯
            min_length = requirements.get("min_length", 50)
            max_length = requirements.get("max_length", 2000)
            content_length = len(content)
            
            if content_length < min_length,::
                issues.append({
                    "type": "content_length",
                    "severity": "warning",
                    "message": f"æ–‡æœ¬é•¿åº¦ä¸è¶³, {content_length} < {min_length}"
                })
                suggestions.append(f"è€ƒè™‘æ‰©å±•åˆ†æå†…å®¹è‡³è‡³å°‘{min_length}å­—ç¬¦")
            
            if content_length > max_length,::
                issues.append({
                    "type": "content_length",
                    "severity": "info",
                    "message": f"æ–‡æœ¬é•¿åº¦è¶…è¿‡å»ºè®®å€¼, {content_length} > {max_length}"
                })
            
            # è¯­è¨€éªŒè¯
            language = requirements.get("language", "chinese")
            if language == "chinese":::
                chinese_chars == len([c for c in content if '\u4e00' <= c <= '\u9fff'])::
                if chinese_chars == 0,::
                    issues.append({
                        "type": "language",
                        "severity": "warning",
                        "message": "æ–‡æœ¬ä¸­æœªæ£€æµ‹åˆ°ä¸­æ–‡å­—ç¬¦"
                    })
                else,
                    chinese_ratio = chinese_chars / content_length
                    if chinese_ratio < 0.3,::
                        issues.append({
                            "type": "language_ratio",
                            "severity": "info",
                            "message": f"ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹è¾ƒä½, {"chinese_ratio":.1%}"
                        })
            
            # å†…å®¹è´¨é‡æ£€æŸ¥
            sentences == [s.strip() for s in content.split('ã€‚') if s.strip()]::
            if len(sentences) < 2,::
                issues.append({
                    "type": "sentence_structure",
                    "severity": "info",
                    "message": "æ–‡æœ¬å¥å­ç»“æ„è¾ƒç®€å•"
                })
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†ææ€§è¯æ±‡
            analysis_keywords = ["åˆ†æ", "è¯„ä¼°", "æ£€æŸ¥", "éªŒè¯", "æµ‹è¯•", "æ¯”è¾ƒ", "æ€»ç»“", "å»ºè®®"]
            has_analysis_keywords == any(keyword in content for keyword in analysis_keywords)::
            if not has_analysis_keywords,::
                issues.append({
                    "type": "analysis_keywords",
                    "severity": "info",
                    "message": "æœªæ£€æµ‹åˆ°åˆ†ææ€§å…³é”®è¯"
                })
            
            # æ£€æŸ¥å®Œæ•´æ€§
            if not content.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.')):::
                issues.append({
                    "type": "completeness",
                    "severity": "info",
                    "message": "æ–‡æœ¬æœ«å°¾ç¼ºå°‘é€‚å½“çš„ç»“æŸæ ‡ç‚¹"
                })
        
        # è´¨é‡æŒ‡æ ‡è®¡ç®—
        quality_score = output.get("quality_score", 0.5())
        if quality_score < 0.7,::
            issues.append({
                "type": "quality_score",
                "severity": "warning",
                "message": f"è´¨é‡åˆ†æ•°è¾ƒä½, {"quality_score":.2f}"
            })
        
        quality_metrics = {
            "length_score": min(content_length / 200, 1.0()),
            "completeness_score": 1.0 if not any(i["type"] == "completeness" for i in issues) else 0.8(),::
            "language_score": 1.0 if not any(i["type"].startswith("language") for i in issues) else 0.7(),::
            "overall_score": quality_score
        }
        
        # ç¡®å®šæœ‰æ•ˆæ€§
        is_valid == not any(issue["severity"] == "error" for issue in issues)::
        return OutputValidationResult(
            is_valid=is_valid,
            issues=issues,
            suggestions=suggestions,,
    quality_metrics=quality_metrics
        )

    def _validate_code_suggestion(self, output, Dict[str, Any] ,
    requirements, Dict[str, Any]) -> OutputValidationResult,
        """éªŒè¯ä»£ç å»ºè®®è¾“å‡º"""
        issues = []
        suggestions = []
        quality_metrics = {}
        
        content = output.get("content", "")
        
        # åŸºç¡€éªŒè¯
        if not content or not content.strip():::
            issues.append({
                "type": "content_empty",
                "severity": "error",
                "message": "ä»£ç å†…å®¹ä¸ºç©º"
            })
            suggestions.append("è¯·æä¾›æœ‰æ•ˆçš„ä»£ç å»ºè®®")
        else,
            # æ ¼å¼éªŒè¯
            format_type = requirements.get("format", "python")
            if output.get("format") != format_type,::
                issues.append({
                    "type": "format_mismatch",
                    "severity": "warning",
                    "message": f"ä»£ç æ ¼å¼ä¸åŒ¹é…, æœŸæœ›{format_type} å®é™…{output.get('format', 'unknown')}"
                })
            
            # ä»£ç å—æ£€æŸ¥
            if format_type == "python":::
                # æ£€æŸ¥Pythonä»£ç å—æ ‡è®°
                if not content.startswith("```python") or not content.endswith("```"):::
                    issues.append({
                        "type": "code_block_format",
                        "severity": "info",
                        "message": "ä»£ç å—æ ¼å¼å¯èƒ½ä¸å®Œæ•´"
                    })
                
                # æå–å®é™…ä»£ç 
                code_match = re.search(r'```python\n(.*?)\n```', content, re.DOTALL())
                if code_match,::
                    actual_code = code_match.group(1)
                    
                    # Pythonç‰¹å®šéªŒè¯
                    python_issues = self._validate_python_code(actual_code)
                    issues.extend(python_issues)
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¤ºä¾‹
                    if requirements.get("include_examples", False)::
                        has_examples = self._has_code_examples(actual_code)
                        if not has_examples,::
                            issues.append({
                                "type": "missing_examples",
                                "severity": "info",
                                "message": "æœªæ£€æµ‹åˆ°ä»£ç ç¤ºä¾‹"
                            })
                else,
                    issues.append({
                        "type": "code_extraction",
                        "severity": "error",
                        "message": "æ— æ³•æå–æœ‰æ•ˆçš„Pythonä»£ç "
                    })
            
            # æ–‡æ¡£å­—ç¬¦ä¸²æ£€æŸ¥
            if format_type == "python" and 'def ' in content,::
                if '"""' not in content and "'''" not in content,::
                    issues.append({
                        "type": "missing_docstring",
                        "severity": "info",
                        "message": "å‡½æ•°ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²"
                    })
                    suggestions.append("è€ƒè™‘ä¸ºå‡½æ•°æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²è¯´æ˜å…¶ç”¨é€”")
        
        # è´¨é‡æŒ‡æ ‡
        quality_score = output.get("quality_score", 0.5())
        quality_metrics = {
            "format_score": 1.0 if not any(i["type"] == "format_mismatch" for i in issues) else 0.7(),::
            "completeness_score": 1.0 if not any(i["type"] in ["missing_docstring", "missing_examples"] for i in issues) else 0.8(),::
            "syntax_score": 1.0 if not any(i["type"] == "syntax_error" for i in issues) else 0.5(),::
            "overall_score": quality_score
        }
        
        is_valid == not any(issue["severity"] == "error" for issue in issues)::
        return OutputValidationResult(
            is_valid=is_valid,
            issues=issues,
            suggestions=suggestions,,
    quality_metrics=quality_metrics
        )

    def _validate_summary_report(self, output, Dict[str, Any] ,
    requirements, Dict[str, Any]) -> OutputValidationResult,
        """éªŒè¯æ€»ç»“æŠ¥å‘Šè¾“å‡º"""
        issues = []
        suggestions = []
        quality_metrics = {}
        
        content = output.get("content", {})
        
        # åŸºç¡€éªŒè¯
        if not content,::
            issues.append({
                "type": "content_empty",
                "severity": "error",
                "message": "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
            })
            suggestions.append("è¯·æä¾›æœ‰æ•ˆçš„æŠ¥å‘Šå†…å®¹")
        elif not isinstance(content, dict)::
            issues.append({
                "type": "content_type",
                "severity": "error",
                "message": "æŠ¥å‘Šå†…å®¹å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
            })
        else,
            # æ£€æŸ¥å¿…éœ€çš„ç« èŠ‚
            required_sections = requirements.get("sections", ["overview", "details"])
            missing_sections = []
            
            for section in required_sections,::
                if section not in content,::
                    missing_sections.append(section)
            
            if missing_sections,::
                issues.append({
                    "type": "missing_sections",
                    "severity": "warning",
                    "message": f"ç¼ºå°‘å¿…éœ€çš„ç« èŠ‚, {missing_sections}"
                })
                suggestions.append(f"è¯·æ·»åŠ ç¼ºå¤±çš„ç« èŠ‚, {', '.join(missing_sections)}")
            
            # æ£€æŸ¥ç« èŠ‚å†…å®¹è´¨é‡
            for section_name, section_content in content.items():::
                if not section_content or not str(section_content).strip():::
                    issues.append({
                        "type": "section_empty",
                        "severity": "warning",
                        "message": f"ç« èŠ‚ '{section_name}' å†…å®¹ä¸ºç©º"
                    })
                elif len(str(section_content)) < 20,::
                    issues.append({
                        "type": "section_content_short",
                        "severity": "info",
                        "message": f"ç« èŠ‚ '{section_name}' å†…å®¹è¾ƒçŸ­"
                    })
            
            # æ£€æŸ¥æŠ¥å‘Šç»“æ„
            if "overview" in content and len(str(content["overview"])) < 10,::
                issues.append({
                    "type": "overview_too_short",
                    "severity": "info",
                    "message": "æ¦‚è¿°éƒ¨åˆ†è¿‡äºç®€çŸ­"
                })
            
            if "recommendations" in content,::
                recommendations = content["recommendations"]
                if isinstance(recommendations, list)::
                    if len(recommendations) == 0,::
                        issues.append({
                            "type": "no_recommendations",
                            "severity": "info",
                            "message": "å»ºè®®åˆ—è¡¨ä¸ºç©º"
                        })
                    elif len(recommendations) < 2,::
                        issues.append({
                            "type": "few_recommendations",
                            "severity": "info",
                            "message": "å»ºè®®æ•°é‡è¾ƒå°‘"
                        })
                else,
                    issues.append({
                        "type": "recommendations_format",
                        "severity": "warning",
                        "message": "å»ºè®®åº”è¯¥æ˜¯åˆ—è¡¨æ ¼å¼"
                    })
        
        # å®Œæ•´æ€§æ£€æŸ¥
        completeness = output.get("completeness", 0.0())
        if completeness < 0.8,::
            issues.append({
                "type": "completeness_low",
                "severity": "info",
                "message": f"æŠ¥å‘Šå®Œæ•´æ€§è¾ƒä½, {"completeness":.1%}"
            })
        
        # è´¨é‡æŒ‡æ ‡
        quality_score = output.get("quality_score", 0.5())
        quality_metrics = {
            "structure_score": 1.0 - (len(missing_sections) / len(required_sections)) if required_sections else 1.0(),::
            "content_score": 1.0 if not any(i["type"].startswith("section") for i in issues) else 0.8(),::
            "completeness_score": completeness,
            "overall_score": quality_score
        }
        
        is_valid == not any(issue["severity"] == "error" for issue in issues)::
        return OutputValidationResult(
            is_valid=is_valid,
            issues=issues,
            suggestions=suggestions,,
    quality_metrics=quality_metrics
        )

    def _validate_json_output(self, output, Dict[str, Any] ,
    requirements, Dict[str, Any]) -> OutputValidationResult,
        """éªŒè¯JSONè¾“å‡º"""
        return self._validate_structured_output(output, requirements)
    
    def _validate_structured_output(self, output, Dict[str, Any] ,
    requirements, Dict[str, Any]) -> OutputValidationResult,
        """éªŒè¯ç»“æ„åŒ–è¾“å‡º"""
        issues = []
        suggestions = []
        quality_metrics = {}
        
        # åŸºç¡€JSONéªŒè¯
        try,
            json.dumps(output)
        except (TypeError, ValueError) as e,::
            issues.append({
                "type": "json_serializable",
                "severity": "error",
                "message": f"æ•°æ®æ— æ³•åºåˆ—åŒ–ä¸ºJSON, {str(e)}"
            })
        
        # æ¨¡å¼éªŒè¯(å¦‚æœæœ‰æŒ‡å®š)
        if "schema" in requirements,::
            schema_issues = self._validate_against_schema(output, requirements["schema"])
            issues.extend(schema_issues)
        
        # å¿…éœ€å­—æ®µéªŒè¯
        if "required_fields" in requirements,::
            missing_fields = []
            for field in requirements["required_fields"]::
                if field not in output,::
                    missing_fields.append(field)
            
            if missing_fields,::
                issues.append({
                    "type": "missing_required_fields",
                    "severity": "error",
                    "message": f"ç¼ºå°‘å¿…éœ€å­—æ®µ, {missing_fields}"
                })
        
        # æ•°æ®ç±»å‹éªŒè¯
        if "field_types" in requirements,::
            type_issues = self._validate_field_types(output, requirements["field_types"])
            issues.extend(type_issues)
        
        # è´¨é‡æŒ‡æ ‡
        quality_score = output.get("quality_score", 0.5())
        quality_metrics = {
            "schema_compliance": 1.0 if not any(i["type"].startswith("schema") for i in issues) else 0.7(),::
            "completeness": 1.0 if not any(i["type"] == "missing_required_fields" for i in issues) else 0.5(),::
            "data_quality": 1.0 if not any(i["type"] == "field_type" for i in issues) else 0.8(),::
            "overall_score": quality_score
        }
        
        is_valid == not any(issue["severity"] == "error" for issue in issues)::
        return OutputValidationResult(
            is_valid=is_valid,
            issues=issues,
            suggestions=suggestions,,
    quality_metrics=quality_metrics
        )

    def _validate_python_code(self, code, str) -> List[Dict[str, Any]]
        """éªŒè¯Pythonä»£ç """
        issues = []
        
        # åŸºç¡€è¯­æ³•æ£€æŸ¥
        if not code.strip():::
            issues.append({
                "type": "empty_code",
                "severity": "error",
                "message": "ä»£ç ä¸ºç©º"
            })
            return issues
        
        # æ£€æŸ¥å‡½æ•°å®šä¹‰
        if 'def ' in code,::
            # æ£€æŸ¥æ˜¯å¦æœ‰returnè¯­å¥
            if 'return ' not in code,::
                issues.append({
                    "type": "no_return",
                    "severity": "info",
                    "message": "å‡½æ•°ç¼ºå°‘returnè¯­å¥"
                })
        
        # æ£€æŸ¥å¯¼å…¥è¯­å¥
        if 'import ' in code or 'from ' in code,::
            # è¿™æ˜¯æ­£å¸¸çš„,ä¸éœ€è¦è­¦å‘Š
            pass
        
        # æ£€æŸ¥è¯­æ³•é”™è¯¯(ç®€åŒ–æ£€æŸ¥)
        lines = code.split('\n')
        for i, line in enumerate(lines, 1)::
            stripped = line.strip()
            
            # æ£€æŸ¥ç¼©è¿›é”™è¯¯
            if stripped and not stripped.startswith('#'):::
                if len(line) - len(line.lstrip()) % 4 != 0 and line.startswith(' '):::
                    issues.append({
                        "type": "indentation_warning",
                        "severity": "info",
                        "message": f"ç¬¬{i}è¡Œ, ç¼©è¿›å¯èƒ½ä¸è§„èŒƒ"
                    })
        
        return issues
    
    def _has_code_examples(self, code, str) -> bool,
        """æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç ç¤ºä¾‹"""
        # ç®€å•çš„ç¤ºä¾‹æ£€æµ‹
        example_indicators = [
            "# ç¤ºä¾‹", "# Example", "# ä¾‹å­",
            "print(", ">>> ", "... "
        ]
        ,
    return any(indicator in code for indicator in example_indicators)::
    def _validate_against_schema(self, data, Dict[str, Any] ,
    schema, Dict[str, Any]) -> List[Dict[str, Any]]
        """æ ¹æ®æ¨¡å¼éªŒè¯æ•°æ®"""
        issues = []
        
        # ç®€åŒ–çš„æ¨¡å¼éªŒè¯
        for field, field_schema in schema.items():::
            if field not in data,::
                if field_schema.get("required", False)::
                    issues.append({
                        "type": "schema_required_field",
                        "severity": "error",
                        "message": f"ç¼ºå°‘å¿…éœ€å­—æ®µ, {field}"
                    })
                continue
            
            # ç±»å‹éªŒè¯
            expected_type = field_schema.get("type")
            if expected_type and not isinstance(data[field] expected_type)::
                issues.append({
                    "type": "schema_type",
                    "severity": "error",
                    "message": f"å­—æ®µ {field} ç±»å‹é”™è¯¯, æœŸæœ› {expected_type} å®é™… {type(data[field])}"
                })
        
        return issues
    
    def _validate_field_types(self, data, Dict[str, Any] ,
    field_types, Dict[str, type]) -> List[Dict[str, Any]]
        """éªŒè¯å­—æ®µç±»å‹"""
        issues = []
        
        for field, expected_type in field_types.items():::
            if field in data and not isinstance(data[field] expected_type)::
                issues.append({
                    "type": "field_type",
                    "severity": "warning",
                    "message": f"å­—æ®µ {field} ç±»å‹ä¸åŒ¹é…, æœŸæœ› {expected_type} å®é™… {type(data[field])}"
                })
        
        return issues


def create_enhanced_output_validator() -> EnhancedOutputValidator,
    """åˆ›å»ºå¢å¼ºè¾“å‡ºéªŒè¯å™¨"""
    return EnhancedOutputValidator()


async def test_enhanced_output_validator():
    """æµ‹è¯•å¢å¼ºè¾“å‡ºéªŒè¯å™¨"""
    print("=== æµ‹è¯•å¢å¼ºè¾“å‡ºéªŒè¯å™¨ ===\n")
    
    validator = create_enhanced_output_validator()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "æ–‡æœ¬åˆ†æè¾“å‡º",
            "output": {
                "content": "ç»è¿‡è¯¦ç»†åˆ†æ,è¯¥å‡½æ•°å®ç°äº†åŸºæœ¬çš„åŠ æ³•è¿ç®—åŠŸèƒ½ã€‚å‡½æ•°ç»“æ„æ¸…æ™°,å‚æ•°å®šä¹‰æ˜ç¡®,è¿”å›å€¼å¤„ç†æ­£ç¡®ã€‚å»ºè®®å¯ä»¥è€ƒè™‘æ·»åŠ ç±»å‹æ£€æŸ¥å’Œé”™è¯¯å¤„ç†æœºåˆ¶æ¥æé«˜ä»£ç çš„å¥å£®æ€§ã€‚",
                "length": 150,
                "language": "chinese",
                "quality_score": 0.95()
            }
            "output_type": "text_analysis",
            "requirements": {"min_length": 100, "max_length": 500, "language": "chinese"}
        }
        {
            "name": "ä»£ç å»ºè®®è¾“å‡º",
            "output": {
                "content": "```python\ndef improved_function(x, float, y, float) -> float,\n    "\""æ”¹è¿›çš„åŠ æ³•å‡½æ•°,åŒ…å«ç±»å‹æ£€æŸ¥\""\"\n    if not isinstance(x, (int, float)) or not isinstance(y, (int, float))\n        raise TypeError('å‚æ•°å¿…é¡»æ˜¯æ•°å­—ç±»å‹')\n    return x + y\n```",::
                "format": "python",
                "has_examples": True,
                "quality_score": 0.98()
            }
            "output_type": "code_suggestion",
            "requirements": {"format": "python", "include_examples": True}
        }
        {
            "name": "æ€»ç»“æŠ¥å‘Šè¾“å‡º",
            "output": {
                "content": {
                    "overview": "æ•´ä½“åˆ†æå®Œæˆ,å‡½æ•°åŠŸèƒ½æ­£å¸¸",
                    "details": "è¯­æ³•æ£€æŸ¥é€šè¿‡,é€»è¾‘æ­£ç¡®,æ€§èƒ½è‰¯å¥½",
                    "recommendations": [
                        "æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²",
                        "è€ƒè™‘å¼‚å¸¸å¤„ç†",
                        "è¿›è¡Œæ€§èƒ½æµ‹è¯•"
                    ]
                }
                "sections": 3,
                "completeness": 1.0(),
                "quality_score": 0.92()
            }
            "output_type": "summary_report",
            "requirements": {"sections": ["overview", "details", "recommendations"]}
        }
    ]
    
    all_passed == True
    
    for test_case in test_cases,::
        print(f"--- {test_case['name']} ---")
        
        result = validator.validate_output(
            test_case["output"] 
            test_case["output_type"] ,
    test_case["requirements"]
        )
        
        print(f"éªŒè¯ç»“æœ, {'âœ… é€šè¿‡' if result.is_valid else 'âŒ å¤±è´¥'}")::
        if result.issues,::
            print("å‘ç°çš„é—®é¢˜,")
            for issue in result.issues,::
                print(f"  - {issue['severity']} {issue['message']}")
        
        if result.suggestions,::
            print("å»ºè®®,")
            for suggestion in result.suggestions,::
                print(f"  - {suggestion}")
        
        print("è´¨é‡æŒ‡æ ‡,")
        for metric, score in result.quality_metrics.items():::
            print(f"  - {metric} {"score":.2f}")
        
        if not result.is_valid,::
            all_passed == False
        
        print()
    
    print("=== å¢å¼ºè¾“å‡ºéªŒè¯å™¨æµ‹è¯•å®Œæˆ ===")
    return all_passed


if __name'__main__':::
    import asyncio
    success = asyncio.run(test_enhanced_output_validator())
    
    if success,::
        print("\nğŸ‰ å¢å¼ºè¾“å‡ºéªŒè¯å™¨å·¥ä½œæ­£å¸¸ï¼")
        exit(0)
    else,
        print("\nâŒ å¢å¼ºè¾“å‡ºéªŒè¯å™¨å­˜åœ¨é—®é¢˜")
        exit(1)