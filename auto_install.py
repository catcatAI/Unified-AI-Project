#!/usr/bin/env python3
"""
Angela AI è‡ªå‹•å®‰è£å™¨ - Python ç‰ˆæœ¬
è‡ªå‹•è™•ç†æ‰€æœ‰å‰ç½®æ¢ä»¶å’Œä¾è³´
"""

import os
import sys
import subprocess
import platform
import urllib.request
import json
import time
from pathlib import Path

class AngelaAutoInstaller:
    def __init__(self):
        self.os_type = platform.system().lower()
        self.project_root = Path(__file__).parent
        self.venv_path = self.project_root / "venv"
        
    def print_step(self, message):
        print(f"ğŸ”§ {message}")
        
    def print_success(self, message):
        print(f"âœ… {message}")
        
    def print_warning(self, message):
        print(f"âš ï¸ {message}")
        
    def print_error(self, message):
        print(f"âŒ {message}")
        
    def run_command(self, command, check=True, shell=False):
        """åŸ·è¡Œå‘½ä»¤ä¸¦è¿”å›çµæœ"""
        try:
            if shell:
                result = subprocess.run(command, shell=True, capture_output=True, text=True)
            else:
                result = subprocess.run(command, capture_output=True, text=True)
            
            if check and result.returncode != 0:
                self.print_error(f"å‘½ä»¤å¤±æ•—: {' '.join(command) if isinstance(command, list) else command}")
                self.print_error(f"éŒ¯èª¤ä¿¡æ¯: {result.stderr}")
                return False, result.stderr
            return True, result.stdout
            
        except Exception as e:
            self.print_error(f"å‘½ä»¤åŸ·è¡Œç•°å¸¸: {e}")
            return False, str(e)
    
    def detect_os(self):
        """æª¢æ¸¬æ“ä½œç³»çµ±"""
        self.print_step("æª¢æ¸¬æ“ä½œç³»çµ±...")
        
        if self.os_type == "linux":
            # æª¢æ¸¬ Linux ç™¼è¡Œç‰ˆ
            try:
                with open("/etc/os-release", "r") as f:
                    os_info = f.read()
                    if "ubuntu" in os_info.lower():
                        self.distro = "ubuntu"
                    elif "debian" in os_info.lower():
                        self.distro = "debian"
                    elif "centos" in os_info.lower() or "rhel" in os_info.lower():
                        self.distro = "rhel"
                    elif "arch" in os_info.lower():
                        self.distro = "arch"
                    else:
                        self.distro = "unknown"
            except:
                self.distro = "unknown"
                
            self.print_success(f"Linux ({self.distro})")
            
        elif self.os_type == "darwin":
            self.distro = "macos"
            self.print_success("macOS")
            
        elif self.os_type == "windows":
            self.distro = "windows"
            self.print_success("Windows")
            
        else:
            self.distro = "unknown"
            self.print_warning(f"æœªçŸ¥æ“ä½œç³»çµ±: {self.os_type}")
    
    def check_python(self):
        """æª¢æŸ¥ Python ç’°å¢ƒ"""
        self.print_step("æª¢æŸ¥ Python ç’°å¢ƒ...")
        
        version = sys.version_info
        if version.major < 3 or (version.major == 3 and version.minor < 9):
            self.print_error(f"Python ç‰ˆæœ¬éä½: {version.major}.{version.minor}ï¼Œéœ€è¦ 3.9+")
            return False
            
        self.print_success(f"Python {version.major}.{version.minor}.{version.micro}")
        return True
    
    def install_pip_if_needed(self):
        """å®‰è£ pip å¦‚æœéœ€è¦"""
        self.print_step("æª¢æŸ¥ pip...")
        
        try:
            import pip
            self.print_success("pip å·²å®‰è£")
            return True
        except ImportError:
            self.print_warning("pip æœªå®‰è£ï¼Œå˜—è©¦å®‰è£...")
            
            if self.os_type == "linux":
                if self.distro in ["ubuntu", "debian"]:
                    success, _ = self.run_command([
                        "sudo", "apt", "update"
                    ], shell=False)
                    if success:
                        success, _ = self.run_command([
                            "sudo", "apt", "install", "-y", "python3-pip"
                        ], shell=False)
                        
            elif self.os_type == "windows":
                success, _ = self.run_command([
                    "python", "-m", "ensurepip", "--default-pip"
                ], shell=False)
                
            return success
    
    def create_virtual_env(self):
        """å‰µå»ºè™›æ“¬ç’°å¢ƒ"""
        self.print_step("å‰µå»ºè™›æ“¬ç’°å¢ƒ...")
        
        if self.venv_path.exists():
            self.print_warning("è™›æ“¬ç’°å¢ƒå·²å­˜åœ¨ï¼Œå°‡é‡æ–°å‰µå»º...")
            import shutil
            shutil.rmtree(self.venv_path)
        
        success, _ = self.run_command([
            sys.executable, "-m", "venv", str(self.venv_path)
        ])
        
        if success:
            self.print_success("è™›æ“¬ç’°å¢ƒå‰µå»ºæˆåŠŸ")
            return True
        return False
    
    def activate_venv(self):
        """ç²å–è™›æ“¬ç’°å¢ƒçš„è·¯å¾‘"""
        if self.os_type == "windows":
            python_exe = self.venv_path / "Scripts" / "python.exe"
            pip_exe = self.venv_path / "Scripts" / "pip.exe"
        else:
            python_exe = self.venv_path / "bin" / "python"
            pip_exe = self.venv_path / "bin" / "pip"
            
        return str(python_exe), str(pip_exe)
    
    def install_python_dependencies(self):
        """å®‰è£ Python ä¾è³´"""
        self.print_step("å®‰è£ Python ä¾è³´...")
        
        python_exe, pip_exe = self.activate_venv()
        
        # å‡ç´š pip
        success, _ = self.run_command([pip_exe, "install", "--upgrade", "pip", "setuptools", "wheel"])
        if not success:
            self.print_warning("pip å‡ç´šå¤±æ•—ï¼Œç¹¼çºŒå®‰è£...")
        
        # æª¢æŸ¥ requirements.txt
        requirements_file = self.project_root / "requirements.txt"
        if requirements_file.exists():
            self.print_step("å¾ requirements.txt å®‰è£ä¾è³´...")
            success, _ = self.run_command([pip_exe, "install", "-r", str(requirements_file)])
        else:
            self.print_step("å®‰è£åŸºç¤ä¾è³´...")
            
            # åŸºç¤ä¾è³´åˆ—è¡¨
            basic_deps = [
                "fastapi>=0.109.0",
                "uvicorn[standard]>=0.27.0", 
                "pydantic>=2.6.0",
                "python-multipart>=0.0.9",
                "aiohttp>=3.9.3",
                "requests>=2.31.0",
                "websockets>=13.0",
                "python-dotenv>=1.0.1",
                "cryptography>=42.0.0",
                "psutil>=5.9.8",
                "loguru>=0.7.2"
            ]
            
            for dep in basic_deps:
                self.print_step(f"å®‰è£ {dep}...")
                success, _ = self.run_command([pip_exe, "install", dep])
                if not success:
                    self.print_warning(f"{dep} å®‰è£å¤±æ•—ï¼Œç¹¼çºŒå®‰è£å…¶ä»–ä¾è³´...")
        
        return success
    
    def check_nodejs(self):
        """æª¢æŸ¥ Node.js"""
        self.print_step("æª¢æŸ¥ Node.js...")
        
        success, output = self.run_command(["node", "--version"], check=False)
        if success:
            self.print_success(f"Node.js {output.strip()}")
            return True
        else:
            self.print_warning("Node.js æœªå®‰è£ï¼Œå°‡å˜—è©¦å®‰è£...")
            return self.install_nodejs()
    
    def install_nodejs(self):
        """å®‰è£ Node.js"""
        if self.os_type == "linux":
            if self.distro in ["ubuntu", "debian"]:
                success, _ = self.run_command([
                    "sudo", "apt", "install", "-y", "nodejs", "npm"
                ])
            elif self.distro == "arch":
                success, _ = self.run_command([
                    "sudo", "pacman", "-S", "--noconfirm", "nodejs", "npm"
                ])
            elif self.distro in ["centos", "rhel"]:
                success, _ = self.run_command([
                    "sudo", "yum", "install", "-y", "nodejs", "npm"
                ])
            else:
                self.print_warning("ç„¡æ³•è‡ªå‹•å®‰è£ Node.jsï¼Œè«‹æ‰‹å‹•å®‰è£")
                return False
                
        elif self.os_type == "windows":
            self.print_warning("è«‹æ‰‹å‹•å®‰è£ Node.js: https://nodejs.org/")
            return False
            
        elif self.os_type == "macos":
            success, _ = self.run_command(["brew", "install", "node"], check=False)
            if not success:
                success, _ = self.run_command([
                    "sudo", "port", "install", "nodejs"
                ], check=False)
                
        return success
    
    def install_npm_dependencies(self):
        """å®‰è£ npm ä¾è³´"""
        self.print_step("å®‰è£ npm ä¾è³´...")
        
        # æ¡Œé¢æ‡‰ç”¨ä¾è³´
        desktop_app = self.project_root / "apps" / "desktop-app" / "electron_app"
        if desktop_app.exists():
            package_json = desktop_app / "package.json"
            if package_json.exists():
                self.print_step("å®‰è£æ¡Œé¢æ‡‰ç”¨ä¾è³´...")
                success, _ = self.run_command(["npm", "install"], cwd=desktop_app)
                if not success:
                    self.print_warning("æ¡Œé¢æ‡‰ç”¨ä¾è³´å®‰è£å¤±æ•—")
        
        # ç§»å‹•ç«¯æ‡‰ç”¨ä¾è³´
        mobile_app = self.project_root / "apps" / "mobile-app"
        if mobile_app.exists():
            package_json = mobile_app / "package.json"
            if package_json.exists():
                self.print_step("å®‰è£ç§»å‹•ç«¯ä¾è³´...")
                success, _ = self.run_command(["npm", "install"], cwd=mobile_app)
                if not success:
                    self.print_warning("ç§»å‹•ç«¯ä¾è³´å®‰è£å¤±æ•—")
    
    def create_config_files(self):
        """å‰µå»ºé…ç½®æ–‡ä»¶"""
        self.print_step("å‰µå»ºé…ç½®æ–‡ä»¶...")
        
        # å‰µå»º .env æ–‡ä»¶
        env_file = self.project_root / ".env"
        if not env_file.exists():
            env_example = self.project_root / ".env.example"
            if env_example.exists():
                import shutil
                shutil.copy(env_example, env_file)
                self.print_success("å·²è¤‡è£½ .env.example åˆ° .env")
            else:
                # å‰µå»ºé»˜èªé…ç½®
                import secrets
                with open(env_file, 'w') as f:
                    f.write(f"""# Angela AI Environment Configuration
ANGELA_ENV=development
NODE_ENV=development
ANGELA_TESTING=true

# Backend Configuration
BACKEND_HOST=127.0.0.1
BACKEND_PORT=8000
BACKEND_URL=http://127.0.0.1:8000

# Security Keys (Auto-generated)
ANGELA_KEY_A={secrets.token_hex(32)}
ANGELA_KEY_B={secrets.token_hex(32)}
ANGELA_KEY_C={secrets.token_hex(32)}

# Performance Settings
PERFORMANCE_MODE=auto
TARGET_FPS=60
ENABLE_HARDWARE_ACCELERATION=true

# Logging
LOG_LEVEL=info
DEBUG_MODE=true
""")
                self.print_success("å·²å‰µå»ºé»˜èª .env é…ç½®æ–‡ä»¶")
        
        # å‰µå»ºå¿…è¦ç›®éŒ„
        dirs_to_create = [
            "logs",
            "data/models",
            "data/memories", 
            "data/cache",
            "data/temp"
        ]
        
        for dir_path in dirs_to_create:
            full_path = self.project_root / dir_path
            full_path.mkdir(parents=True, exist_ok=True)
        
        self.print_success("é…ç½®æ–‡ä»¶å‰µå»ºå®Œæˆ")
    
    def create_startup_scripts(self):
        """å‰µå»ºå•Ÿå‹•è…³æœ¬"""
        self.print_step("å‰µå»ºå•Ÿå‹•è…³æœ¬...")
        
        # å•Ÿå‹•è…³æœ¬
        start_script = self.project_root / "start.py"
        with open(start_script, 'w') as f:
            f.write('''#!/usr/bin/env python3
"""
Angela AI å•Ÿå‹•è…³æœ¬
"""

import os
import sys
import subprocess
import time
from pathlib import Path

def main():
    project_root = Path(__file__).parent
    
    # è¨­ç½®ç’°å¢ƒè®Šé‡
    os.environ['ANGELA_ENV'] = 'development'
    os.environ['ANGELA_TESTING'] = 'true'
    
    print("ğŸŒŸ å•Ÿå‹• Angela AI...")
    print("ğŸ“ å¾Œç«¯åœ°å€: http://127.0.0.1:8000")
    print("ğŸ”— å¥åº·æª¢æŸ¥: http://127.0.0.1:8000/health")
    print("")
    
    # æ¿€æ´»è™›æ“¬ç’°å¢ƒä¸¦å•Ÿå‹•
    venv_python = project_root / "venv" / ("Scripts" if os.name == 'nt' else "bin") / "python"
    
    if venv_python.exists():
        # å˜—è©¦å•Ÿå‹•å®Œæ•´å¾Œç«¯
        backend_main = project_root / "apps" / "backend" / "main.py"
        if backend_main.exists():
            print("ğŸš€ å•Ÿå‹•å®Œæ•´å¾Œç«¯æœå‹™...")
            subprocess.run([str(venv_python), str(backend_main)])
        else:
            # å•Ÿå‹•æœ€å°å¾Œç«¯
            quick_start = project_root / "quick_start.py"
            if quick_start.exists():
                print("ğŸš€ å•Ÿå‹•æœ€å°å¾Œç«¯æœå‹™...")
                subprocess.run([str(venv_python), str(quick_start)])
            else:
                print("âŒ æ‰¾ä¸åˆ°å¾Œç«¯æœå‹™")
                return 1
    else:
        print("âŒ è™›æ“¬ç’°å¢ƒä¸å­˜åœ¨ï¼Œè«‹å…ˆé‹è¡Œå®‰è£ç¨‹åº")
        return 1

if __name__ == "__main__":
    main()
''')
        
        # åœæ­¢è…³æœ¬
        stop_script = self.project_root / "stop.py"
        with open(stop_script, 'w') as f:
            f.write('''#!/usr/bin/env python3
"""
Angela AI åœæ­¢è…³æœ¬
"""

import os
import signal
import psutil

def main():
    print("ğŸ›‘ åœæ­¢ Angela AI...")
    
    # æŸ¥æ‰¾ä¸¦åœæ­¢ Angela ç›¸é—œé€²ç¨‹
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            cmdline = proc.info['cmdline']
            if cmdline and any('angela' in str(cmd).lower() or 'quick_start.py' in str(cmd) for cmd in cmdline):
                pid = proc.info['pid']
                os.kill(pid, signal.SIGTERM)
                print(f"âœ… å·²åœæ­¢é€²ç¨‹ {pid}")
        except:
            pass
    
    print("ğŸ‘‹ Angela AI å·²åœæ­¢")

if __name__ == "__main__":
    main()
''')
        
        if os.name != 'nt':
            os.chmod(start_script, 0o755)
            os.chmod(stop_script, 0o755)
        
        self.print_success("å•Ÿå‹•è…³æœ¬å‰µå»ºå®Œæˆ")
    
    def detect_hardware(self):
        """æª¢æ¸¬ç¡¬ä»¶é…ç½®"""
        self.print_step("æª¢æ¸¬ç¡¬ä»¶é…ç½®...")

        import psutil

        # ç²å– CPU æ ¸å¿ƒæ•¸
        cpu_count = psutil.cpu_count(logical=False)
        self.cpu_cores = cpu_count

        # ç²å–å…§å­˜å¤§å°
        memory = psutil.virtual_memory()
        ram_gb = memory.total / (1024**3)
        self.ram_gb = ram_gb

        # ä¼°ç®— VRAM (ä½¿ç”¨ CUDA æˆ– AMD è¨­å‚™)
        vram_mb = 0
        try:
            # å˜—è©¦æª¢æ¸¬ NVIDIA GPU
            result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total', '--format=csv,noheader,nounits'],
                                 capture_output=True, text=True)
            if result.returncode == 0:
                vram_mb = int(result.stdout.strip().split('\n')[0])
        except:
            pass

        self.vram_mb = vram_mb

        self.print_success(f"CPU æ ¸å¿ƒæ•¸: {cpu_count}, RAM: {ram_gb:.1f}GB, VRAM: {vram_mb}MB")
        return {"cpu_cores": cpu_count, "ram_gb": ram_gb, "vram_mb": vram_mb}

    def detect_ollama(self) -> bool:
        """æª¢æ¸¬ Ollama æ˜¯å¦å·²å®‰è£"""
        success, _ = self.run_command(["ollama", "--version"], check=False)
        return success

    def install_ollama(self) -> bool:
        """å®‰è£ Ollama"""
        self.print_step("å®‰è£ Ollama...")

        if self.detect_ollama():
            self.print_success("Ollama å·²å®‰è£")
            return True

        if self.os_type == "linux":
            # å®‰è£ curl å¦‚æœéœ€è¦
            self.run_command(["sudo", "apt", "install", "-y", "curl"], check=False)

            # å®‰è£ Ollama
            curl_command = "curl -fsSL https://ollama.ai/install.sh | sh"
            success, _ = self.run_command(curl_command, shell=True, check=False)

            if success:
                self.print_success("Ollama å®‰è£æˆåŠŸ")
                return True
            else:
                self.print_warning("Ollama å®‰è£å¤±æ•—ï¼Œè«‹æ‰‹å‹•å®‰è£")
                return False

        elif self.os_type == "macos":
            success, _ = self.run_command(["brew", "install", "ollama"], check=False)
            if success:
                self.print_success("Ollama å®‰è£æˆåŠŸ")
                return True
            else:
                self.print_warning("è«‹æ‰‹å‹•å®‰è£ Ollama: https://ollama.ai/")
                return False

        else:
            self.print_warning("è«‹æ‰‹å‹•å®‰è£ Ollama: https://ollama.ai/")
            return False

    def download_ollama_model(self, model_name: str = "llama3") -> bool:
        """ä¸‹è¼‰ Ollama æ¨¡å‹"""
        self.print_step(f"ä¸‹è¼‰ Ollama æ¨¡å‹: {model_name}...")

        if not self.detect_ollama():
            self.print_warning("Ollama æœªå®‰è£ï¼Œç„¡æ³•ä¸‹è¼‰æ¨¡å‹")
            return False

        success, _ = self.run_command(["ollama", "pull", model_name], check=False)
        if success:
            self.print_success(f"æ¨¡å‹ {model_name} ä¸‹è¼‰æˆåŠŸ")
            return True
        else:
            self.print_warning(f"æ¨¡å‹ {model_name} ä¸‹è¼‰å¤±æ•—")
            return False

    def detect_llama_cpp(self) -> bool:
        """æª¢æ¸¬ llama.cpp æ˜¯å¦å·²å®‰è£"""
        return self.run_command(["./llama.cpp/llama-server", "--version"], check=False, cwd=self.project_root)[0]

    def install_llama_cpp(self) -> bool:
        """ç·¨è­¯å’Œå®‰è£ llama.cpp"""
        self.print_step("ç·¨è­¯ llama.cpp...")

        llama_cpp_path = self.project_root / "llama.cpp"
        if llama_cpp_path.exists():
            self.print_warning("llama.cpp å·²å­˜åœ¨ï¼Œè·³éå…‹éš†")
        else:
            # å…‹éš† llama.cpp
            success, _ = self.run_command([
                "git", "clone", "https://github.com/ggerganov/llama.cpp", "llama.cpp"
            ], check=False)
            if not success:
                self.print_warning("å…‹éš† llama.cpp å¤±æ•—")
                return False

        # ç·¨è­¯ llama.cpp
        self.print_step("ç·¨è­¯ llama.cpp (é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜)...")

        success, _ = self.run_command(["make"], cwd=llama_cpp_path, check=False)

        if success:
            self.print_success("llama.cpp ç·¨è­¯æˆåŠŸ")
            return True
        else:
            self.print_warning("llama.cpp ç·¨è­¯å¤±æ•—ï¼Œè«‹æ‰‹å‹•ç·¨è­¯")
            return False

    def download_llama_cpp_model(self, model_url: str = None) -> bool:
        """ä¸‹è¼‰ llama.cpp æ¨¡å‹"""
        self.print_step("ä¸‹è¼‰ llama.cpp æ¨¡å‹...")

        models_path = self.project_root / "models"
        models_path.mkdir(exist_ok=True)

        if model_url:
            # ä¸‹è¼‰æŒ‡å®šæ¨¡å‹
            success, _ = self.run_command([
                "wget", "-O", str(models_path / "model.gguf"), model_url
            ], check=False)
        else:
            # ä¸‹è¼‰è¼ƒå°çš„é‡åŒ–æ¨¡å‹ (Q4_0)
            model_url = "https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_0.gguf"
            success, _ = self.run_command([
                "wget", "-O", str(models_path / "llama-2-7b-chat.Q4_0.gguf"), model_url
            ], check=False)

        if success:
            self.print_success("æ¨¡å‹ä¸‹è¼‰æˆåŠŸ")
            return True
        else:
            self.print_warning("æ¨¡å‹ä¸‹è¼‰å¤±æ•—")
            return False

    def start_llm_service(self, service_type: str = "ollama"):
        """å•Ÿå‹• LLM æœå‹™"""
        self.print_step(f"å•Ÿå‹• LLM æœå‹™ ({service_type})...")

        if service_type == "ollama":
            if self.detect_ollama():
                self.run_command(["ollama", "serve"], check=False)
                self.print_success("Ollama æœå‹™å·²å•Ÿå‹• (localhost:11434)")
                return True
            else:
                self.print_warning("Ollama æœªå®‰è£ï¼Œç„¡æ³•å•Ÿå‹•æœå‹™")
                return False

        elif service_type == "llama_cpp":
            llama_cpp_path = self.project_root / "llama.cpp"
            if (llama_cpp_path / "llama-server").exists():
                model_path = self.project_root / "models" / "model.gguf"
                if model_path.exists():
                    self.run_command([
                        "./llama-server", "-m", str(model_path), "--port", "8080", "--host", "0.0.0.0"
                    ], cwd=llama_cpp_path, check=False)
                    self.print_success("llama.cpp æœå‹™å·²å•Ÿå‹• (localhost:8080)")
                    return True
                else:
                    self.print_warning("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç„¡æ³•å•Ÿå‹• llama.cpp")
                    return False
            else:
                self.print_warning("llama.cpp æœªç·¨è­¯ï¼Œç„¡æ³•å•Ÿå‹•æœå‹™")
                return False

        return False

    def install_llm_services(self):
        """å®‰è£ LLM æœå‹™ (Ollama æˆ– llama.cpp)"""
        self.print_step("å®‰è£ LLM æœå‹™...")

        # æª¢æ¸¬ç¡¬ä»¶
        hardware = self.detect_hardware()

        # é¸æ“‡æœ€ä½³æ–¹æ¡ˆ
        if hardware["ram_gb"] >= 16:
            # å…§å­˜è¶³å¤ ï¼Œå„ªå…ˆä½¿ç”¨ Ollama
            if self.install_ollama():
                self.download_ollama_model()
                self.start_llm_service("ollama")
        elif hardware["ram_gb"] >= 8:
            # å…§å­˜è¼ƒå°‘ï¼Œå˜—è©¦ Ollama
            if not self.install_ollama():
                self.print_warning("Ollama å®‰è£å¤±æ•—ï¼Œå˜—è©¦ llama.cpp...")
                self.install_llama_cpp()
        else:
            # å…§å­˜è¼ƒå°ï¼Œä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
            self.print_warning("å¯ç”¨å…§å­˜è¼ƒå°‘ï¼Œå»ºè­°ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹")
            if self.install_ollama():
                self.download_ollama_model("llama3:8b-instruct-q4_0")
                self.start_llm_service("ollama")

    def test_installation(self):
        """æ¸¬è©¦å®‰è£"""
        self.print_step("æ¸¬è©¦å®‰è£...")
        
        python_exe, _ = self.activate_venv()
        
        # æ¸¬è©¦ Python ä¾è³´
        try:
            success, _ = self.run_command([
                python_exe, "-c", 
                "import fastapi, uvicorn, pydantic; print('âœ… Python ä¾è³´æ¸¬è©¦é€šé')"
            ])
        except:
            self.print_warning("Python ä¾è³´æ¸¬è©¦å¤±æ•—")
    
    def start_angela(self):
        """å•Ÿå‹• Angela"""
        print("\nğŸ‰ å®‰è£å®Œæˆï¼")
        print("ğŸš€ è‡ªå‹•å•Ÿå‹• Angela AI...")
        print()
        
        python_exe, _ = self.activate_venv()
        
        # å•Ÿå‹•æœ€å°å¾Œç«¯
        quick_start = self.project_root / "quick_start.py"
        if quick_start.exists():
            success, _ = self.run_command([python_exe, str(quick_start)], check=False)
            if success:
                print("âœ… Angela AI å·²å•Ÿå‹•ï¼")
                print("ğŸ“ å¾Œç«¯åœ°å€: http://127.0.0.1:8000")
                print("ğŸ”— å¥åº·æª¢æŸ¥: http://127.0.0.1:8000/health")
                print("ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢æœå‹™")
            else:
                self.print_error("å•Ÿå‹•å¤±æ•—")
    
    def run(self):
        """é‹è¡Œå®Œæ•´å®‰è£æµç¨‹"""
        print("ğŸŒŸ Angela AI - å…¨è‡ªå‹•å®‰è£å™¨")
        print("=" * 50)
        print()

        # æª¢æ¸¬æ“ä½œç³»çµ±
        self.detect_os()

        # æª¢æŸ¥ Python
        if not self.check_python():
            self.print_error("Python ç’°å¢ƒä¸æ»¿è¶³è¦æ±‚")
            return False

        # å®‰è£ pip
        if not self.install_pip_if_needed():
            self.print_warning("pip å®‰è£å¤±æ•—ï¼Œå¯èƒ½æœƒå½±éŸ¿å¾ŒçºŒå®‰è£")

        # å‰µå»ºè™›æ“¬ç’°å¢ƒ
        if not self.create_virtual_env():
            self.print_error("è™›æ“¬ç’°å¢ƒå‰µå»ºå¤±æ•—")
            return False

        # å®‰è£ Python ä¾è³´
        if not self.install_python_dependencies():
            self.print_error("Python ä¾è³´å®‰è£å¤±æ•—")
            return False

        # æª¢æŸ¥ä¸¦å®‰è£ Node.js
        node_available = self.check_nodejs()
        if node_available:
            self.install_npm_dependencies()

        # å®‰è£ LLM æœå‹™ (Ollama æˆ– llama.cpp)
        self.install_llm_services()

        # å‰µå»ºé…ç½®æ–‡ä»¶
        self.create_config_files()

        # å‰µå»ºå•Ÿå‹•è…³æœ¬
        self.create_startup_scripts()

        # æ¸¬è©¦å®‰è£
        self.test_installation()

        # å•Ÿå‹•æ‡‰ç”¨
        self.start_angela()

        return True

if __name__ == "__main__":
    installer = AngelaAutoInstaller()
    installer.run()