#!/usr/bin/env python3
"""
ç›´æ¥å°è©±æ¸¬è©¦å·¥å…·
é€šéç›´æ¥èª¿ç”¨ç³»çµ±çµ„ä»¶ä¾†æ¸¬è©¦AIå°è©±èƒ½åŠ›
ç¹éAPIæœå‹™å™¨å•é¡Œï¼Œç›´æ¥æ¸¬è©¦æ ¸å¿ƒåŠŸèƒ½
"""

import asyncio
import sys
import time
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
PROJECT_ROOT = str(Path(__file__).resolve().parent)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

class DirectConversationTester:
    """ç›´æ¥å°è©±æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.orchestrator = None
        self.memory_manager = None
        
    async def initialize_system(self):
        """åˆå§‹åŒ–AIç³»çµ±"""
        print("ğŸš€ åˆå§‹åŒ–AIç³»çµ±...")
        try:
            # ç›´æ¥åˆå§‹åŒ–çµ„ä»¶
            from apps.backend.src.ai.memory.ham_memory_manager import HAMMemoryManager
            from apps.backend.src.core.orchestrator import CognitiveOrchestrator
            
            self.memory_manager = HAMMemoryManager()
            self.orchestrator = CognitiveOrchestrator(
                experience_buffer=None,
                ham_memory_manager=self.memory_manager,
                learning_controller=None
            )
            
            print("âœ… AIç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ AIç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            return False
    
    async def test_direct_conversation(self):
        """æ¸¬è©¦ç›´æ¥å°è©±åŠŸèƒ½"""
        if not await self.initialize_system():
            return False
            
        print("\n" + "="*60)
        print("ğŸ¯ é–‹å§‹ç›´æ¥å°è©±æ¸¬è©¦")
        print("="*60)
        
        # æ¸¬è©¦å°è©±åºåˆ—
        test_conversations = [
            {
                "topic": "åŸºç¤å•å€™",
                "messages": [
                    "ä½ å¥½ï¼Œè«‹å•ä½ æ˜¯èª°ï¼Ÿ",
                    "ä½ ä»Šå¤©æ„Ÿè¦ºå¦‚ä½•ï¼Ÿ",
                    "è¬è¬ä½ çš„å›ç­”"
                ]
            },
            {
                "topic": "çŸ¥è­˜å•ç­”", 
                "messages": [
                    "ä»€éº¼æ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                    "AIæœ‰ä»€éº¼æ‡‰ç”¨ï¼Ÿ",
                    "AIçš„æœªä¾†ç™¼å±•å¦‚ä½•ï¼Ÿ"
                ]
            },
            {
                "topic": "å€‹äººå°è©±",
                "messages": [
                    "æˆ‘æœ€è¿‘æ„Ÿåˆ°æœ‰äº›å£“åŠ›",
                    "ä½ æœ‰ä»€éº¼å»ºè­°å—ï¼Ÿ",
                    "è¬è¬ä½ çš„å®‰æ…°"
                ]
            },
            {
                "topic": "è¨˜æ†¶æ¸¬è©¦",
                "messages": [
                    "æˆ‘å«ç‹å°æ˜ï¼Œæˆ‘å–œæ­¡ç·¨ç¨‹",
                    "é‚„è¨˜å¾—æˆ‘å«ä»€éº¼åå­—å—ï¼Ÿ",
                    "æˆ‘èªªéæˆ‘å–œæ­¡ä»€éº¼ï¼Ÿ"
                ]
            }
        ]
        
        results = {
            "total_messages": 0,
            "successful_responses": 0,
            "failed_responses": 0,
            "response_times": [],
            "conversation_details": [],
            "issues": []
        }
        
        for topic_test in test_conversations:
            topic_result = await self.test_topic(topic_test)
            results["conversation_details"].append(topic_result)
            results["total_messages"] += topic_result["message_count"]
            results["successful_responses"] += topic_result["successful_count"]
            results["failed_responses"] += topic_result["failed_count"]
            results["response_times"].extend(topic_result["response_times"])
            
            if topic_result["issues"]:
                results["issues"].extend(topic_result["issues"])
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_report(results)
        return results
    
    async def test_topic(self, topic_test):
        """æ¸¬è©¦ç‰¹å®šä¸»é¡Œ"""
        topic = topic_test["topic"]
        messages = topic_test["messages"]
        
        print(f"\nğŸ” æ¸¬è©¦ä¸»é¡Œ: {topic}")
        print("-" * 40)
        
        result = {
            "topic": topic,
            "message_count": len(messages),
            "successful_count": 0,
            "failed_count": 0,
            "response_times": [],
            "responses": [],
            "issues": []
        }
        
        for i, message in enumerate(messages):
            print(f"\nğŸ‘¤ ç”¨æˆ¶ ({i+1}/{len(messages)}): {message}")
            
            try:
                start_time = time.time()
                
                # ç›´æ¥èª¿ç”¨ç·¨æ’å™¨è™•ç†æ¶ˆæ¯
                response_data = await self.orchestrator.process_user_input(message)
                
                response_time = time.time() - start_time
                result["response_times"].append(response_time)
                
                ai_response = response_data.get("response", "")
                confidence = response_data.get("confidence", 0)
                reasoning = response_data.get("reasoning", "")
                
                print(f"ğŸ¤– AI ({response_time:.1f}s): {ai_response}")
                print(f"   ç½®ä¿¡åº¦: {confidence:.2f}")
                print(f"   æ¨ç†: {reasoning}")
                
                # è©•ä¼°éŸ¿æ‡‰è³ªé‡
                quality = self.evaluate_response(message, ai_response, topic)
                
                result["responses"].append({
                    "user_message": message,
                    "ai_response": ai_response,
                    "confidence": confidence,
                    "reasoning": reasoning,
                    "response_time": response_time,
                    "quality": quality
                })
                
                if quality["is_acceptable"]:
                    result["successful_count"] += 1
                    print(f"   âœ… {quality['assessment']}")
                else:
                    result["failed_count"] += 1
                    result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: {quality['issues']}")
                    print(f"   âŒ {quality['issues']}")
                
            except Exception as e:
                print(f"   âŒ éŒ¯èª¤: {str(e)}")
                result["failed_count"] += 1
                result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: {str(e)}")
            
            await asyncio.sleep(1)  # çŸ­æš«å»¶é²
        
        return result
    
    def evaluate_response(self, user_message, ai_response, topic):
        """è©•ä¼°AIéŸ¿æ‡‰è³ªé‡"""
        evaluation = {
            "is_acceptable": False,
            "assessment": "",
            "issues": [],
            "strengths": []
        }
        
        # åŸºæœ¬æª¢æŸ¥
        if len(ai_response.strip()) < 5:
            evaluation["issues"].append("éŸ¿æ‡‰éçŸ­")
        elif len(ai_response.strip()) > 500:
            evaluation["strengths"].append("éŸ¿æ‡‰è©³ç´°")
        else:
            evaluation["strengths"].append("éŸ¿æ‡‰é•·åº¦é©ä¸­")
        
        # ç›¸é—œæ€§æª¢æŸ¥
        response_lower = ai_response.lower()
        user_lower = user_message.lower()
        
        # æ ¹æ“šä¸»é¡Œæª¢æŸ¥é—œéµè©
        topic_keywords = {
            "åŸºç¤å•å€™": ["ä½ å¥½", "æˆ‘æ˜¯", "åŠ©æ‰‹", "å¹«åŠ©", "ai"],
            "çŸ¥è­˜å•ç­”": ["å®šç¾©", "äººå·¥æ™ºèƒ½", "æ‡‰ç”¨", "ç™¼å±•", "æŠ€è¡“"],
            "å€‹äººå°è©±": ["ç†è§£", "å»ºè­°", "å£“åŠ›", "æ”¯æŒ", "å®‰æ…°"],
            "è¨˜æ†¶æ¸¬è©¦": ["è¨˜å¾—", "åå­—", "ç‹å°æ˜", "ç·¨ç¨‹", "å–œæ­¡"]
        }
        
        if topic in topic_keywords:
            keywords = topic_keywords[topic]
            keyword_matches = sum(1 for kw in keywords if kw in response_lower)
            
            if keyword_matches >= 1:
                evaluation["strengths"].append("å›æ‡‰ç›¸é—œ")
            else:
                evaluation["issues"].append("å›æ‡‰å¯èƒ½ä¸å¤ ç›¸é—œ")
        
        # éŒ¯èª¤æª¢æŸ¥
        error_indicators = ["éŒ¯èª¤", "å¤±æ•—", "ç„¡æ³•", "æŠ±æ­‰", "å°ä¸èµ·"]
        if any(indicator in response_lower for indicator in error_indicators):
            if "ç„¡æ³•" in response_lower:
                evaluation["issues"].append("ç³»çµ±è¡¨ç¤ºç„¡æ³•è™•ç†")
            else:
                evaluation["issues"].append("éŸ¿æ‡‰åŒ…å«éŒ¯èª¤æŒ‡ç¤ºè©")
        
        # ç¶œåˆè©•ä¼°
        if len(evaluation["issues"]) == 0:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "å„ªç§€éŸ¿æ‡‰"
        elif len(evaluation["issues"]) <= 1:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "å¯æ¥å—éŸ¿æ‡‰"
        else:
            evaluation["assessment"] = "éœ€è¦æ”¹é€²"
        
        return evaluation
    
    def generate_report(self, results):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        print("\n" + "="*80)
        print("ğŸ¯ ç›´æ¥å°è©±æ¸¬è©¦å ±å‘Š")
        print("="*80)
        
        success_rate = results["successful_responses"] / results["total_messages"] * 100 if results["total_messages"] > 0 else 0
        
        print(f"ğŸ“Š ç¸½é«”çµ±è¨ˆ:")
        print(f"   ç¸½æ¶ˆæ¯æ•¸: {results['total_messages']}")
        print(f"   æˆåŠŸéŸ¿æ‡‰: {results['successful_responses']}")
        print(f"   å¤±æ•—éŸ¿æ‡‰: {results['failed_responses']}")
        print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        
        if results["response_times"]:
            avg_time = sum(results["response_times"]) / len(results["response_times"])
            min_time = min(results["response_times"])
            max_time = max(results["response_times"])
            print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.1f}s")
            print(f"   æœ€å¿«éŸ¿æ‡‰: {min_time:.1f}s")
            print(f"   æœ€æ…¢éŸ¿æ‡‰: {max_time:.1f}s")
        
        print(f"\nğŸ“‹ å„ä¸»é¡Œè©³æƒ…:")
        for topic_result in results["conversation_details"]:
            topic = topic_result["topic"]
            success_rate = topic_result["successful_count"] / topic_result["message_count"] * 100
            print(f"   {topic}:")
            print(f"     æˆåŠŸç‡: {success_rate:.1f}% ({topic_result['successful_count']}/{topic_result['message_count']})")
            
            if topic_result["issues"]:
                print(f"     å•é¡Œ: {', '.join(topic_result['issues'][:2])}")
        
        if results["issues"]:
            print(f"\nâš ï¸ ç™¼ç¾çš„å•é¡Œ:")
            for issue in results["issues"][:5]:
                print(f"   - {issue}")
        
        # ç¸½é«”è©•ä¼°
        if success_rate >= 80:
            overall = "ç³»çµ±è¡¨ç¾å„ªç§€"
        elif success_rate >= 60:
            overall = "ç³»çµ±è¡¨ç¾è‰¯å¥½"
        elif success_rate >= 40:
            overall = "ç³»çµ±åŸºæœ¬å¯ç”¨"
        else:
            overall = "ç³»çµ±éœ€è¦é‡å¤§æ”¹é€²"
        
        print(f"\nğŸ¯ ç¸½é«”è©•ä¼°: {overall}")
        
        print("="*80)
        
        # ä¿å­˜å ±å‘Š
        import json
        report_data = {
            "test_type": "direct_conversation",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "results": results,
            "overall_assessment": overall
        }
        
        with open("DIRECT_CONVERSATION_TEST_REPORT.json", "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: DIRECT_CONVERSATION_TEST_REPORT.json")

async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¤– å•Ÿå‹•ç›´æ¥å°è©±æ¸¬è©¦...")
    print("é€™å°‡é€šéç›´æ¥èª¿ç”¨ç³»çµ±çµ„ä»¶ä¾†æ¸¬è©¦AIçš„å¯¦éš›å°è©±èƒ½åŠ›")
    
    tester = DirectConversationTester()
    
    try:
        await tester.test_direct_conversation()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    asyncio.run(main())