# ğŸ¤– AI å¤§æ¨¡å‹é›†æˆæŒ‡å—

## æ¦‚è¿°

æœ¬é¡¹ç›®ç°å·²é›†æˆå¤šç§ä¸»æµ AI å¤§æ¨¡å‹æœåŠ¡ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£å’Œä¾¿æ·çš„å‘½ä»¤è¡Œå·¥å…·ã€‚

## ğŸš€ æ”¯æŒçš„ AI æ¨¡å‹

### å•†ä¸šæ¨¡å‹
- **OpenAI GPT-4/3.5** - æœ€å¼ºå¤§çš„é€šç”¨è¯­è¨€æ¨¡å‹
- **Google Gemini Pro** - å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œæ”¯æŒæ–‡æœ¬å’Œå›¾åƒ
- **Anthropic Claude-3** - å®‰å…¨å¯é çš„å¯¹è¯æ¨¡å‹
- **Azure OpenAI** - ä¼ä¸šçº§ GPT æœåŠ¡
- **Cohere Command** - ä¸“ä¸šçš„ä¼ä¸šçº§æ¨¡å‹

### å¼€æº/æœ¬åœ°æ¨¡å‹
- **Ollama** - æœ¬åœ°è¿è¡Œçš„å¼€æºæ¨¡å‹
  - Llama2 (7B/13B)
  - CodeLlama (ä»£ç ç”Ÿæˆ)
  - Mistral 7B
  - æ›´å¤šæ¨¡å‹...
- **Hugging Face** - å¼€æºæ¨¡å‹æ‰˜ç®¡å¹³å°

## ğŸ“¦ å¿«é€Ÿå®‰è£…

### 1. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 2. é…ç½® API å¯†é’¥
```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„ API å¯†é’¥
# OPENAI_API_KEY=sk-your-openai-key
# GEMINI_API_KEY=your-gemini-key
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
```

### 3. æµ‹è¯•å®‰è£…
```bash
python tmp_rovodev_test_multi_llm.py
```

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### å‘½ä»¤è¡Œå·¥å…·

#### åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
```bash
python scripts/ai_models.py list
```

#### å•æ¬¡æŸ¥è¯¢
```bash
# ä½¿ç”¨ GPT-4
python scripts/ai_models.py query "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±" --model gpt-4

# ä½¿ç”¨ Gemini Pro
python scripts/ai_models.py query "è§£é‡Šé‡å­è®¡ç®—" --model gemini-pro --verbose
```

#### è¿›å…¥èŠå¤©æ¨¡å¼
```bash
# æµå¼èŠå¤©
python scripts/ai_models.py chat --model claude-3-sonnet --stream

# å¸¦ç³»ç»Ÿæç¤ºçš„èŠå¤©
python scripts/ai_models.py chat --model gpt-4 --system "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹"
```

#### æ¯”è¾ƒå¤šä¸ªæ¨¡å‹
```bash
python scripts/ai_models.py compare "å†™ä¸€é¦–å…³äºAIçš„è¯—" --models gpt-4 claude-3-sonnet gemini-pro
```

#### å¥åº·æ£€æŸ¥
```bash
python scripts/ai_models.py health
```

#### æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡
```bash
python scripts/ai_models.py stats
```

### ç¼–ç¨‹æ¥å£

```python
import asyncio
from src.services.multi_llm_service import MultiLLMService, ChatMessage

async def example():
    # åˆå§‹åŒ–æœåŠ¡
    service = MultiLLMService('configs/multi_llm_config.json')
    
    # åˆ›å»ºæ¶ˆæ¯
    messages = [
        ChatMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹"),
        ChatMessage(role="user", content="ä½ å¥½ï¼")
    ]
    
    # å‘é€è¯·æ±‚
    response = await service.chat_completion(messages, model_id="gpt-4")
    print(f"å›å¤: {response.content}")
    print(f"æˆæœ¬: ${response.cost:.4f}")
    print(f"å»¶è¿Ÿ: {response.latency:.2f}s")
    
    # æµå¼å“åº”
    async for chunk in service.stream_completion(messages, model_id="claude-3-sonnet"):
        print(chunk, end="", flush=True)
    
    await service.close()

asyncio.run(example())
```

## ğŸ¯ æ¨¡å‹é€‰æ‹©å»ºè®®

### æŒ‰ç”¨é€”é€‰æ‹©
- **åˆ›æ„å†™ä½œ**: Claude-3 Opus, GPT-4
- **ä»£ç ç”Ÿæˆ**: CodeLlama, GPT-4
- **å¿«é€Ÿé—®ç­”**: GPT-3.5-turbo, Claude-3 Haiku
- **å¤šè¯­è¨€æ”¯æŒ**: Gemini Pro
- **æœ¬åœ°éƒ¨ç½²**: Ollama æ¨¡å‹
- **ä¼ä¸šåº”ç”¨**: Azure OpenAI

### æŒ‰æˆæœ¬é€‰æ‹©
- **æœ€ç»æµ**: Ollama æœ¬åœ°æ¨¡å‹ (å…è´¹)
- **æ€§ä»·æ¯”é«˜**: GPT-3.5-turbo, Claude-3 Haiku
- **é«˜è´¨é‡**: GPT-4, Claude-3 Opus

## ğŸ” å®‰å…¨é…ç½®

### API å¯†é’¥ç®¡ç†
- ä½¿ç”¨ `.env` æ–‡ä»¶å­˜å‚¨å¯†é’¥
- ä¸è¦å°†å¯†é’¥æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
- å®šæœŸè½®æ¢ API å¯†é’¥

### æˆæœ¬æ§åˆ¶
- è®¾ç½®åˆç†çš„ `max_tokens` é™åˆ¶
- ç›‘æ§ä½¿ç”¨ç»Ÿè®¡
- ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹è¿›è¡Œæµ‹è¯•

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### è´Ÿè½½å‡è¡¡
```json
{
  "fallback_chain": [
    "gpt-4",
    "claude-3-sonnet", 
    "gemini-pro",
    "llama2-7b"
  ]
}
```

### é€Ÿç‡é™åˆ¶
```json
{
  "rate_limiting": {
    "enabled": true,
    "requests_per_minute": {
      "openai": 60,
      "anthropic": 50
    }
  }
}
```

### è‡ªå®šä¹‰é…ç½®
ç¼–è¾‘ `configs/multi_llm_config.json` æ¥ï¼š
- æ·»åŠ æ–°æ¨¡å‹
- è°ƒæ•´å‚æ•°
- å¯ç”¨/ç¦ç”¨æ¨¡å‹

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **API å¯†é’¥é”™è¯¯**
   ```bash
   # æ£€æŸ¥å¯†é’¥é…ç½®
   python scripts/ai_models.py health
   ```

2. **Ollama è¿æ¥å¤±è´¥**
   ```bash
   # å¯åŠ¨ Ollama æœåŠ¡
   ollama serve
   
   # æ‹‰å–æ¨¡å‹
   ollama pull llama2:7b
   ```

3. **ä¾èµ–å®‰è£…é—®é¢˜**
   ```bash
   # ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # æˆ–
   venv\Scripts\activate     # Windows
   
   pip install -r requirements.txt
   ```

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python scripts/ai_models.py query "test" --model gpt-4 --verbose
```

## ğŸ“š æ›´å¤šèµ„æº

- [è¯¦ç»†æ–‡æ¡£](docs/03-technical-architecture/ai-components/multi-llm-service.md)
- [API å‚è€ƒ](docs/api/multi-llm-api.md)
- [é…ç½®æŒ‡å—](configs/multi_llm_config.json)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®æ–°çš„æ¨¡å‹æä¾›å•†æˆ–åŠŸèƒ½æ”¹è¿›ï¼

### æ·»åŠ æ–°æ¨¡å‹
1. ç»§æ‰¿ `BaseLLMProvider` ç±»
2. å®ç°å¿…è¦çš„æ–¹æ³•
3. æ›´æ–°é…ç½®æ–‡ä»¶
4. æ·»åŠ æµ‹è¯•

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ LICENSE æ–‡ä»¶