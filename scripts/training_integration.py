#!/usr/bin/env python3
"""
è¨“ç·´é›†æˆè…³æœ¬ - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç”Ÿæˆçš„æ•¸æ“šè¨“ç·´å„å€‹çµ„ä»¶
"""

import os
import sys
import json
import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
backend_path = project_root / "apps" / "backend"
sys.path.insert(0, str(backend_path))
sys.path.insert(0, str(backend_path / "src"))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TrainingIntegrator:
    """è¨“ç·´é›†æˆå™¨"""
    
    def __init__(self):
        self.project_root = project_root
        self.data_dir = self.project_root / "data"
        self.training_dir = self.project_root / "training"
        
    def load_training_data(self) -> Dict[str, Any]:
        """åŠ è¼‰è¨“ç·´æ•¸æ“š"""
        data = {}
        
        try:
            # åŠ è¼‰è¦–è¦ºæ•¸æ“š
            vision_path = self.data_dir / "vision_samples" / "annotations.json"
            if vision_path.exists():
                with open(vision_path, 'r', encoding='utf-8') as f:
                    data['vision'] = json.load(f)
                logger.info(f"âœ… åŠ è¼‰è¦–è¦ºæ•¸æ“š: {len(data['vision'])}å€‹æ¨£æœ¬")
            
            # åŠ è¼‰éŸ³é »æ•¸æ“š
            audio_path = self.data_dir / "audio_samples" / "transcripts.json"
            if audio_path.exists():
                with open(audio_path, 'r', encoding='utf-8') as f:
                    data['audio'] = json.load(f)
                logger.info(f"âœ… åŠ è¼‰éŸ³é »æ•¸æ“š: {len(data['audio'])}å€‹æ¨£æœ¬")
            
            # åŠ è¼‰æ¨ç†æ•¸æ“š
            reasoning_path = self.data_dir / "reasoning_samples" / "causal_relations.json"
            if reasoning_path.exists():
                with open(reasoning_path, 'r', encoding='utf-8') as f:
                    data['reasoning'] = json.load(f)
                logger.info(f"âœ… åŠ è¼‰æ¨ç†æ•¸æ“š: {len(data['reasoning'])}å€‹æ¨£æœ¬")
            
            # åŠ è¼‰å¤šæ¨¡æ…‹æ•¸æ“š
            multimodal_path = self.data_dir / "multimodal_samples" / "multimodal_pairs.json"
            if multimodal_path.exists():
                with open(multimodal_path, 'r', encoding='utf-8') as f:
                    data['multimodal'] = json.load(f)
                logger.info(f"âœ… åŠ è¼‰å¤šæ¨¡æ…‹æ•¸æ“š: {len(data['multimodal'])}å€‹æ¨£æœ¬")
                
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šåŠ è¼‰å¤±æ•—: {e}")
        
        return data
    
    async def test_vision_service_integration(self, vision_data: List[Dict]):
        """æ¸¬è©¦è¦–è¦ºæœå‹™é›†æˆ"""
        logger.info("ğŸ” æ¸¬è©¦è¦–è¦ºæœå‹™é›†æˆ...")
        
        try:
            from src.services.vision_service import VisionService
            
            vision_service = VisionService()
            
            # æ¨¡æ“¬åœ–åƒæ•¸æ“š
            mock_image_data = b'\x89PNG\r\n\x1a\n' + b'\x00' * 100
            
            # æ¸¬è©¦åœ–åƒåˆ†æ
            for i, sample in enumerate(vision_data[:3]):
                result = await vision_service.analyze_image(
                    mock_image_data,
                    features=["captioning", "object_detection", "scene_analysis"]
                )
                
                logger.info(f"  æ¨£æœ¬ {i+1}: {sample['caption']}")
                logger.info(f"  åˆ†æçµæœ: {result.get('processing_id', 'N/A')}")
            
            logger.info("âœ… è¦–è¦ºæœå‹™é›†æˆæ¸¬è©¦å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¦–è¦ºæœå‹™é›†æˆå¤±æ•—: {e}")
            return False
    
    async def test_audio_service_integration(self, audio_data: List[Dict]):
        """æ¸¬è©¦éŸ³é »æœå‹™é›†æˆ"""
        logger.info("ğŸ”Š æ¸¬è©¦éŸ³é »æœå‹™é›†æˆ...")
        
        try:
            from src.services.audio_service import AudioService
            
            audio_service = AudioService()
            
            # æ¨¡æ“¬éŸ³é »æ•¸æ“š
            mock_audio_data = b'\x00' * 1000
            
            # æ¸¬è©¦èªéŸ³è­˜åˆ¥
            for i, sample in enumerate(audio_data[:3]):
                result = await audio_service.speech_to_text(
                    mock_audio_data,
                    language=sample.get('language', 'zh-CN'),
                    enhanced_features=True
                )
                
                logger.info(f"  æ¨£æœ¬ {i+1}: {sample['text']}")
                logger.info(f"  è­˜åˆ¥çµæœ: {result.get('processing_id', 'N/A')}")
            
            logger.info("âœ… éŸ³é »æœå‹™é›†æˆæ¸¬è©¦å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »æœå‹™é›†æˆå¤±æ•—: {e}")
            return False
    
    async def test_reasoning_engine_integration(self, reasoning_data: List[Dict]):
        """æ¸¬è©¦æ¨ç†å¼•æ“é›†æˆ"""
        logger.info("ğŸ§  æ¸¬è©¦æ¨ç†å¼•æ“é›†æˆ...")
        
        try:
            from src.core_ai.reasoning.causal_reasoning_engine import CausalReasoningEngine
            
            reasoning_engine = CausalReasoningEngine({'causality_threshold': 0.5})
            
            # æ¸¬è©¦å› æœå­¸ç¿’
            observations = []
            for sample in reasoning_data[:5]:
                observation = {
                    'id': sample['scenario_id'],
                    'variables': sample['variables'],
                    'data': {sample['cause']: 1, sample['effect']: 1},
                    'relationships': []
                }
                observations.append(observation)
            
            relationships = await reasoning_engine.learn_causal_relationships(observations)
            logger.info(f"  å­¸ç¿’åˆ° {len(relationships)} å€‹å› æœé—œä¿‚")
            
            # æ¸¬è©¦åäº‹å¯¦æ¨ç†
            scenario = {
                'name': 'test_scenario',
                'outcome': 'positive',
                'outcome_variable': 'effect'
            }
            intervention = {'variable': 'cause', 'value': 'modified'}
            
            counterfactual = await reasoning_engine.perform_counterfactual_reasoning(scenario, intervention)
            logger.info(f"  åäº‹å¯¦æ¨ç†: {counterfactual.get('counterfactual_outcome', 'N/A')}")
            
            logger.info("âœ… æ¨ç†å¼•æ“é›†æˆæ¸¬è©¦å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨ç†å¼•æ“é›†æˆå¤±æ•—: {e}")
            return False
    
    async def test_memory_system_integration(self, all_data: Dict[str, List]):
        """æ¸¬è©¦è¨˜æ†¶ç³»çµ±é›†æˆ"""
        logger.info("ğŸ§  æ¸¬è©¦è¨˜æ†¶ç³»çµ±é›†æˆ...")
        
        try:
            from src.core_ai.memory.vector_store import VectorMemoryStore
            
            vector_store = VectorMemoryStore(persist_directory="./test_vector_store")
            
            # æ·»åŠ å„é¡è¨˜æ†¶
            memory_count = 0
            for data_type, samples in all_data.items():
                for i, sample in enumerate(samples[:2]):  # æ¯ç¨®é¡å‹å–2å€‹æ¨£æœ¬
                    memory_id = f"{data_type}_memory_{i:03d}"
                    
                    if data_type == 'vision':
                        content = sample.get('caption', '')
                    elif data_type == 'audio':
                        content = sample.get('text', '')
                    elif data_type == 'reasoning':
                        content = f"Causal relationship: {sample.get('cause')} -> {sample.get('effect')}"
                    else:
                        content = str(sample)
                    
                    if content:
                        result = await vector_store.add_memory(
                            memory_id,
                            content,
                            {'data_type': data_type, 'sample_index': i}
                        )
                        if result.get('status') == 'success':
                            memory_count += 1
            
            logger.info(f"  æ·»åŠ äº† {memory_count} å€‹è¨˜æ†¶")
            
            # æ¸¬è©¦èªç¾©æœç´¢
            search_result = await vector_store.semantic_search("learning and intelligence", n_results=3)
            logger.info(f"  æœç´¢çµæœ: {len(search_result.get('documents', []))} å€‹åŒ¹é…")
            
            # ç²å–çµ±è¨ˆä¿¡æ¯
            stats = await vector_store.get_memory_statistics()
            logger.info(f"  è¨˜æ†¶çµ±è¨ˆ: {stats.get('total_memories', 0)} å€‹ç¸½è¨˜æ†¶")
            
            logger.info("âœ… è¨˜æ†¶ç³»çµ±é›†æˆæ¸¬è©¦å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¨˜æ†¶ç³»çµ±é›†æˆå¤±æ•—: {e}")
            return False
    
    def generate_training_report(self, test_results: Dict[str, bool]):
        """ç”Ÿæˆè¨“ç·´å ±å‘Š"""
        report = f"""# è¨“ç·´é›†æˆæ¸¬è©¦å ±å‘Š

## æ¸¬è©¦æ™‚é–“
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ¸¬è©¦çµæœ

"""
        
        total_tests = len(test_results)
        passed_tests = sum(test_results.values())
        
        for test_name, result in test_results.items():
            status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
            report += f"- **{test_name}**: {status}\n"
        
        report += f"""
## ç¸½çµ

- ç¸½æ¸¬è©¦æ•¸: {total_tests}
- é€šéæ¸¬è©¦: {passed_tests}
- æˆåŠŸç‡: {(passed_tests/total_tests*100):.1f}%

## ä¸‹ä¸€æ­¥è¡Œå‹•

{"### âœ… ç³»çµ±å°±ç·’" if passed_tests == total_tests else "### âš ï¸ éœ€è¦ä¿®å¾©"}

1. æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦ä¸¦ä¿®å¾©ç›¸é—œå•é¡Œ
2. ä½¿ç”¨çœŸå¯¦æ•¸æ“šé€²è¡Œå®Œæ•´è¨“ç·´
3. å„ªåŒ–æ¨¡å‹æ€§èƒ½å’Œæº–ç¢ºç‡
4. éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ

## æ•¸æ“šä½ç½®

- è¨“ç·´æ•¸æ“š: `{self.data_dir}`
- é…ç½®æ–‡ä»¶: `{self.training_dir}/configs/`
- æ¨¡å‹ä¿å­˜: `{self.training_dir}/models/`
"""
        
        report_path = self.training_dir / "integration_test_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“„ æ¸¬è©¦å ±å‘Šå·²ç”Ÿæˆ: {report_path}")

async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ Unified-AI-Project è¨“ç·´é›†æˆæ¸¬è©¦")
    print("=" * 50)
    
    integrator = TrainingIntegrator()
    
    # åŠ è¼‰è¨“ç·´æ•¸æ“š
    logger.info("ğŸ“‚ åŠ è¼‰è¨“ç·´æ•¸æ“š...")
    training_data = integrator.load_training_data()
    
    if not training_data:
        logger.error("âŒ æ²’æœ‰æ‰¾åˆ°è¨“ç·´æ•¸æ“šï¼Œè«‹å…ˆé‹è¡Œ generate_mock_data.py")
        return
    
    # é‹è¡Œé›†æˆæ¸¬è©¦
    test_results = {}
    
    if 'vision' in training_data:
        test_results['è¦–è¦ºæœå‹™'] = await integrator.test_vision_service_integration(training_data['vision'])
    
    if 'audio' in training_data:
        test_results['éŸ³é »æœå‹™'] = await integrator.test_audio_service_integration(training_data['audio'])
    
    if 'reasoning' in training_data:
        test_results['æ¨ç†å¼•æ“'] = await integrator.test_reasoning_engine_integration(training_data['reasoning'])
    
    test_results['è¨˜æ†¶ç³»çµ±'] = await integrator.test_memory_system_integration(training_data)
    
    # ç”Ÿæˆå ±å‘Š
    integrator.generate_training_report(test_results)
    
    # é¡¯ç¤ºçµæœ
    print("\nğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    passed = sum(test_results.values())
    total = len(test_results)
    
    for name, result in test_results.items():
        status = "âœ…" if result else "âŒ"
        print(f"  {status} {name}")
    
    print(f"\nğŸ¯ æˆåŠŸç‡: {passed}/{total} ({(passed/total*100):.1f}%)")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰é›†æˆæ¸¬è©¦é€šéï¼ç³»çµ±æº–å‚™å°±ç·’ã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ—¥å¿—å’Œä¿®å¾©å•é¡Œã€‚")

if __name__ == "__main__":
    asyncio.run(main())