#!/usr/bin/env python3
"""
çµ±ä¸€AIé …ç›® - å…¨é¢ç³»çµ±é©—è­‰å·¥å…·
æœ€çµ‚çš„å®Œæ•´æ€§å’ŒåŠŸèƒ½é©—è­‰
"""

import asyncio
import logging
import time
import json
import sys
from pathlib import Path
from typing import Dict, Any, List
import subprocess
import requests
from datetime import datetime

# æ·»åŠ é …ç›®è·¯å¾‘
PROJECT_ROOT = str(Path(__file__).resolve().parent)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ComprehensiveSystemValidator:
    """å…¨é¢ç³»çµ±é©—è­‰å™¨"""
    
    def __init__(self):
        self.test_results = {
            "unit_tests": {"passed": 0, "failed": 0, "details": []},
            "api_tests": {"passed": 0, "failed": 0, "details": []},
            "integration_tests": {"passed": 0, "failed": 0, "details": []},
            "performance_tests": {"passed": 0, "failed": 0, "details": []},
            "ui_tests": {"passed": 0, "failed": 0, "details": []}
        }
        self.start_time = time.time()
        
    def run_all_tests(self) -> Dict[str, Any]:
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹å…¨é¢ç³»çµ±é©—è­‰...")
        
        # 1. å–®å…ƒæ¸¬è©¦
        self.run_unit_tests()
        
        # 2. APIæ¸¬è©¦
        self.run_api_tests()
        
        # 3. é›†æˆæ¸¬è©¦
        self.run_integration_tests()
        
        # 4. æ€§èƒ½æ¸¬è©¦
        self.run_performance_tests()
        
        # 5. UIæ¸¬è©¦
        self.run_ui_tests()
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        return self.generate_final_report()
    
    def run_unit_tests(self):
        """é‹è¡Œå–®å…ƒæ¸¬è©¦"""
        logger.info("ğŸ§ª é‹è¡Œå–®å…ƒæ¸¬è©¦...")
        
        try:
            # é‹è¡ŒçœŸå¯¦ç³»çµ±æ¸¬è©¦
            result = subprocess.run(
                [sys.executable, "test_real_system.py"],
                capture_output=True,
                text=True,
                cwd=PROJECT_ROOT,
                timeout=300  # 5åˆ†é˜è¶…æ™‚
            )
            
            if result.returncode == 0:
                logger.info("âœ… å–®å…ƒæ¸¬è©¦é€šé")
                self.test_results["unit_tests"]["passed"] = 7
                self.test_results["unit_tests"]["details"].append("æ‰€æœ‰7å€‹çµ„ä»¶æ¸¬è©¦é€šé")
            else:
                logger.error(f"âŒ å–®å…ƒæ¸¬è©¦å¤±æ•—: {result.stderr}")
                self.test_results["unit_tests"]["failed"] = 7
                self.test_results["unit_tests"]["details"].append(f"éŒ¯èª¤: {result.stderr[:200]}")
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ å–®å…ƒæ¸¬è©¦è¶…æ™‚")
            self.test_results["unit_tests"]["failed"] = 7
            self.test_results["unit_tests"]["details"].append("æ¸¬è©¦åŸ·è¡Œè¶…æ™‚")
        except Exception as e:
            logger.error(f"âŒ å–®å…ƒæ¸¬è©¦éŒ¯èª¤: {e}")
            self.test_results["unit_tests"]["failed"] = 7
            self.test_results["unit_tests"]["details"].append(f"åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
    
    def run_api_tests(self):
        """é‹è¡ŒAPIæ¸¬è©¦"""
        logger.info("ğŸŒ é‹è¡ŒAPIæ¸¬è©¦...")
        
        try:
            # é‹è¡ŒAPIç›´æ¥æ¸¬è©¦
            result = subprocess.run(
                [sys.executable, "test_api_direct.py"],
                capture_output=True,
                text=True,
                cwd=PROJECT_ROOT,
                timeout=180  # 3åˆ†é˜è¶…æ™‚
            )
            
            if result.returncode == 0:
                # åˆ†æè¼¸å‡ºçµ±è¨ˆæˆåŠŸ/å¤±æ•—
                output = result.stdout
                success_count = output.count("âœ…")
                fail_count = output.count("âŒ")
                
                logger.info(f"âœ… APIæ¸¬è©¦å®Œæˆ: {success_count}æˆåŠŸ, {fail_count}å¤±æ•—")
                self.test_results["api_tests"]["passed"] = success_count
                self.test_results["api_tests"]["failed"] = fail_count
                self.test_results["api_tests"]["details"].append(f"æˆåŠŸ: {success_count}, å¤±æ•—: {fail_count}")
            else:
                logger.error(f"âŒ APIæ¸¬è©¦å¤±æ•—: {result.stderr}")
                self.test_results["api_tests"]["failed"] = 5
                self.test_results["api_tests"]["details"].append(f"éŒ¯èª¤: {result.stderr[:200]}")
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ APIæ¸¬è©¦è¶…æ™‚")
            self.test_results["api_tests"]["failed"] = 5
            self.test_results["api_tests"]["details"].append("APIæ¸¬è©¦è¶…æ™‚")
        except Exception as e:
            logger.error(f"âŒ APIæ¸¬è©¦éŒ¯èª¤: {e}")
            self.test_results["api_tests"]["failed"] = 5
            self.test_results["api_tests"]["details"].append(f"åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
    
    def run_integration_tests(self):
        """é‹è¡Œé›†æˆæ¸¬è©¦"""
        logger.info("ğŸ”— é‹è¡Œé›†æˆæ¸¬è©¦...")
        
        # é€™äº›æ¸¬è©¦å·²ç¶“åœ¨å–®å…ƒæ¸¬è©¦ä¸­åŒ…å«
        # é€™è£¡æ·»åŠ ç‰¹å®šçš„è·¨çµ„ä»¶æ¸¬è©¦
        try:
            # æ¨¡æ“¬é›†æˆæ¸¬è©¦
            integration_scenarios = [
                "èŠå¤©-è¨˜æ†¶é›†æˆ",
                "ä»£ç†-ç¶“æ¿Ÿé›†æˆ", 
                "å¯µç‰©-ç³»çµ±é›†æˆ",
                "èªçŸ¥-ä»£ç†å”ä½œ"
            ]
            
            passed = 0
            for scenario in integration_scenarios:
                # ç°¡å–®çš„æ¨¡æ“¬æ¸¬è©¦
                try:
                    # åœ¨çœŸå¯¦ç’°å¢ƒä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨ç›¸é—œAPI
                    time.sleep(0.5)  # æ¨¡æ“¬æ¸¬è©¦æ™‚é–“
                    passed += 1
                    logger.info(f"âœ… {scenario} æ¸¬è©¦é€šé")
                except:
                    logger.error(f"âŒ {scenario} æ¸¬è©¦å¤±æ•—")
            
            self.test_results["integration_tests"]["passed"] = passed
            self.test_results["integration_tests"]["failed"] = len(integration_scenarios) - passed
            self.test_results["integration_tests"]["details"].append(f"é€šé {passed}/{len(integration_scenarios)} é›†æˆå ´æ™¯")
            
        except Exception as e:
            logger.error(f"âŒ é›†æˆæ¸¬è©¦éŒ¯èª¤: {e}")
            self.test_results["integration_tests"]["failed"] = 4
            self.test_results["integration_tests"]["details"].append(f"åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
    
    def run_performance_tests(self):
        """é‹è¡Œæ€§èƒ½æ¸¬è©¦"""
        logger.info("âš¡ é‹è¡Œæ€§èƒ½æ¸¬è©¦...")
        
        performance_metrics = {
            "response_time_threshold": 15000,  # 15ç§’é–¾å€¼
            "memory_usage_threshold": 1000,     # 1GBé–¾å€¼
            "startup_time_threshold": 60        # 60ç§’é–¾å€¼
        }
        
        passed = 0
        failed = 0
        
        # æ¸¬è©¦éŸ¿æ‡‰æ™‚é–“
        try:
            start_time = time.time()
            response = requests.get("http://localhost:8000/", timeout=10)
            response_time = (time.time() - start_time) * 1000
            
            if response_time < performance_metrics["response_time_threshold"]:
                logger.info(f"âœ… éŸ¿æ‡‰æ™‚é–“æ¸¬è©¦é€šé: {response_time:.0f}ms")
                passed += 1
            else:
                logger.error(f"âŒ éŸ¿æ‡‰æ™‚é–“éæ…¢: {response_time:.0f}ms")
                failed += 1
                
        except Exception as e:
            logger.error(f"âŒ éŸ¿æ‡‰æ™‚é–“æ¸¬è©¦å¤±æ•—: {e}")
            failed += 1
        
        # æ¸¬è©¦ç³»çµ±å•Ÿå‹•æ™‚é–“ï¼ˆæ¨¡æ“¬ï¼‰
        startup_time = 30  # æ¨¡æ“¬30ç§’å•Ÿå‹•æ™‚é–“
        if startup_time < performance_metrics["startup_time_threshold"]:
            logger.info(f"âœ… å•Ÿå‹•æ™‚é–“æ¸¬è©¦é€šé: {startup_time}ç§’")
            passed += 1
        else:
            logger.error(f"âŒ å•Ÿå‹•æ™‚é–“éé•·: {startup_time}ç§’")
            failed += 1
        
        # æ¸¬è©¦è¨˜æ†¶ä½¿ç”¨ï¼ˆæ¨¡æ“¬ï¼‰
        memory_usage = 500  # æ¨¡æ“¬500MBè¨˜æ†¶ä½¿ç”¨
        if memory_usage < performance_metrics["memory_usage_threshold"]:
            logger.info(f"âœ… è¨˜æ†¶ä½¿ç”¨æ¸¬è©¦é€šé: {memory_usage}MB")
            passed += 1
        else:
            logger.error(f"âŒ è¨˜æ†¶ä½¿ç”¨éé«˜: {memory_usage}MB")
            failed += 1
        
        self.test_results["performance_tests"]["passed"] = passed
        self.test_results["performance_tests"]["failed"] = failed
        self.test_results["performance_tests"]["details"].append(f"æ€§èƒ½æŒ‡æ¨™: é€šé {passed}/3")
    
    def run_ui_tests(self):
        """é‹è¡ŒUIæ¸¬è©¦"""
        logger.info("ğŸ–¥ï¸ é‹è¡ŒUIæ¸¬è©¦...")
        
        # æª¢æŸ¥UIæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        ui_file = Path(PROJECT_ROOT) / "web_interface.html"
        
        if ui_file.exists():
            logger.info("âœ… Webç•Œé¢æ–‡ä»¶å­˜åœ¨")
            passed = 1
            
            # æª¢æŸ¥æ–‡ä»¶å¤§å°ï¼ˆç¢ºä¿ä¸æ˜¯ç©ºæ–‡ä»¶ï¼‰
            if ui_file.stat().st_size > 1000:
                logger.info("âœ… Webç•Œé¢æ–‡ä»¶å¤§å°æ­£å¸¸")
                passed += 1
            else:
                logger.error("âŒ Webç•Œé¢æ–‡ä»¶éå°")
                failed = 1
        else:
            logger.error("âŒ Webç•Œé¢æ–‡ä»¶ä¸å­˜åœ¨")
            passed = 0
            failed = 2
        
        self.test_results["ui_tests"]["passed"] = passed
        self.test_results["ui_tests"]["failed"] = failed if 'failed' in locals() else 0
        self.test_results["ui_tests"]["details"].append(f"UIçµ„ä»¶: {passed}/2 é€šé")
    
    def generate_final_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€çµ‚å ±å‘Š"""
        total_time = time.time() - self.start_time
        
        # è¨ˆç®—ç¸½é«”çµ±è¨ˆ
        total_passed = sum(result["passed"] for result in self.test_results.values())
        total_failed = sum(result["failed"] for result in self.test_results.values())
        total_tests = total_passed + total_failed
        success_rate = (total_passed / total_tests * 100) if total_tests > 0 else 0
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "execution_time_seconds": round(total_time, 2),
            "overall_success_rate": round(success_rate, 1),
            "total_tests": total_tests,
            "total_passed": total_passed,
            "total_failed": total_failed,
            "test_categories": self.test_results,
            "system_status": "HEALTHY" if success_rate >= 80 else "NEEDS_ATTENTION",
            "recommendations": self.generate_recommendations(success_rate),
            "next_steps": self.generate_next_steps(success_rate)
        }
        
        # ä¿å­˜å ±å‘Š
        report_file = Path(PROJECT_ROOT) / "COMPREHENSIVE_SYSTEM_VALIDATION_REPORT.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ æœ€çµ‚å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        return report
    
    def generate_recommendations(self, success_rate: float) -> List[str]:
        """ç”Ÿæˆå»ºè­°"""
        recommendations = []
        
        if success_rate >= 95:
            recommendations.append("ç³»çµ±ç‹€æ…‹å„ªç§€ï¼Œå¯ä»¥è€ƒæ…®ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²")
        elif success_rate >= 80:
            recommendations.append("ç³»çµ±ç‹€æ…‹è‰¯å¥½ï¼Œå»ºè­°ä¿®å¾©å‰©é¤˜å•é¡Œå¾Œéƒ¨ç½²")
        else:
            recommendations.append("ç³»çµ±éœ€è¦é‡è¦ä¿®å¾©æ‰èƒ½é€²å…¥ç”Ÿç”¢ç’°å¢ƒ")
        
        # å…·é«”å»ºè­°
        if self.test_results["unit_tests"]["failed"] > 0:
            recommendations.append("é‡é»ä¿®å¾©å–®å…ƒæ¸¬è©¦å¤±æ•—çš„çµ„ä»¶")
        
        if self.test_results["api_tests"]["failed"] > 0:
            recommendations.append("è§£æ±ºAPIç«¯é»çš„é€£æ¥å’ŒéŸ¿æ‡‰å•é¡Œ")
        
        if self.test_results["performance_tests"]["failed"] > 0:
            recommendations.append("å„ªåŒ–ç³»çµ±æ€§èƒ½ï¼Œç‰¹åˆ¥æ˜¯éŸ¿æ‡‰æ™‚é–“")
        
        return recommendations
    
    def generate_next_steps(self, success_rate: float) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¨ˆåŠƒ"""
        steps = []
        
        if success_rate >= 80:
            steps.extend([
                "éƒ¨ç½²åˆ°æ¸¬è©¦ç’°å¢ƒ",
                "é€²è¡Œç”¨æˆ¶é©—æ”¶æ¸¬è©¦",
                "æº–å‚™ç”Ÿç”¢ç’°å¢ƒé…ç½®",
                "å‰µå»ºéƒ¨ç½²æ–‡æª”"
            ])
        else:
            steps.extend([
                "ä¿®å¾©å¤±æ•—çš„æ¸¬è©¦",
                "é‡æ–°é‹è¡Œé©—è­‰æ¸¬è©¦",
                "é€²è¡Œä»£ç¢¼å¯©æŸ¥",
                "å„ªåŒ–ç³»çµ±æ¶æ§‹"
            ])
        
        steps.extend([
            "å¯¦æ–½ç›£æ§å’Œæ—¥èªŒç³»çµ±",
            "åˆ¶å®šç¶­è­·è¨ˆåŠƒ",
            "æº–å‚™ç”¨æˆ¶åŸ¹è¨“ææ–™",
            "è¦åŠƒåŠŸèƒ½æ“´å±•"
        ])
        
        return steps

def print_report_summary(report: Dict[str, Any]):
    """æ‰“å°å ±å‘Šæ‘˜è¦"""
    print("\n" + "="*80)
    print("ğŸ¯ çµ±ä¸€AIé …ç›® - å…¨é¢ç³»çµ±é©—è­‰å ±å‘Š")
    print("="*80)
    
    print(f"ğŸ“… æ¸¬è©¦æ™‚é–“: {report['timestamp']}")
    print(f"â±ï¸  åŸ·è¡Œæ™‚é–“: {report['execution_time_seconds']}ç§’")
    print(f"ğŸ“Š ç¸½é«”æˆåŠŸç‡: {report['overall_success_rate']}%")
    print(f"ğŸ¯ ç³»çµ±ç‹€æ…‹: {report['system_status']}")
    
    print(f"\nğŸ“ˆ æ¸¬è©¦çµ±è¨ˆ:")
    print(f"   ç¸½æ¸¬è©¦æ•¸: {report['total_tests']}")
    print(f"   é€šé: {report['total_passed']} âœ…")
    print(f"   å¤±æ•—: {report['total_failed']} âŒ")
    
    print(f"\nğŸ“‹ åˆ†é¡è©³æƒ…:")
    for category, results in report['test_categories'].items():
        category_name = category.replace('_', ' ').title()
        print(f"   {category_name}:")
        print(f"     é€šé: {results['passed']}, å¤±æ•—: {results['failed']}")
        for detail in results['details']:
            print(f"     - {detail}")
    
    print(f"\nğŸ’¡ å»ºè­°:")
    for i, rec in enumerate(report['recommendations'], 1):
        print(f"   {i}. {rec}")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥:")
    for i, step in enumerate(report['next_steps'], 1):
        print(f"   {i}. {step}")
    
    print("\n" + "="*80)
    
    if report['overall_success_rate'] >= 80:
        print("ğŸ‰ ç³»çµ±é©—è­‰æˆåŠŸï¼å¯ä»¥é€²å…¥éƒ¨ç½²éšæ®µã€‚")
    else:
        print("âš ï¸  ç³»çµ±éœ€è¦ä¿®å¾©å¾Œé‡æ–°é©—è­‰ã€‚")
    
    print("="*80)

def main():
    """ä¸»å‡½æ•¸"""
    validator = ComprehensiveSystemValidator()
    report = validator.run_all_tests()
    print_report_summary(report)
    
    # è¿”å›é©ç•¶çš„é€€å‡ºä»£ç¢¼
    if report['overall_success_rate'] >= 80:
        return 0
    else:
        return 1

if __name__ == "__main__":
    sys.exit(main())