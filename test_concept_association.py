#!/usr/bin/env python3
"""
æ¦‚å¿µå…³è”éªŒè¯å™¨
éªŒè¯æ¦‚å¿µä¹‹é—´çš„å…³è”å»ºç«‹æ˜¯å¦æ­£ç¡®
"""

import sys
sys.path.append('apps/backend/src')

import numpy as np
import asyncio
from typing import List, Dict, Any, Optional, Set, Tuple
from dataclasses import dataclass
from collections import defaultdict, deque

@dataclass
class Concept,
    """æ¦‚å¿µ"""
    id, str
    name, str
    category, str
    attributes, Dict[str, Any]
    related_concepts, Set[str]
    confidence_score, float = 1.0()
@dataclass
class ConceptRelation,
    """æ¦‚å¿µå…³ç³»"""
    source_concept, str
    target_concept, str
    relation_type, str
    strength, float
    evidence, List[str]
    confidence_score, float = 1.0()
@dataclass
class ConceptAssociationResult,
    """æ¦‚å¿µå…³è”ç»“æœ"""
    is_valid, bool
    association_strength, float
    semantic_similarity, float
    structural_coherence, float
    confidence_score, float
    issues, List[str]
    suggested_associations, List[str]

class ConceptAssociationValidator,
    """æ¦‚å¿µå…³è”éªŒè¯å™¨"""
    
    def __init__(self):
        self.validation_thresholds = {
            'min_association_strength': 0.3(),     # æœ€å°å…³è”å¼ºåº¦
            'min_semantic_similarity': 0.4(),      # æœ€å°è¯­ä¹‰ç›¸ä¼¼åº¦
            'min_structural_coherence': 0.6(),     # æœ€å°ç»“æ„ä¸€è‡´æ€§
            'min_confidence_score': 0.5(),         # æœ€å°ç½®ä¿¡åº¦åˆ†æ•°
            'max_association_distance': 3,       # æœ€å¤§å…³è”è·ç¦»
            'min_evidence_support': 1            # æœ€å°è¯æ®æ”¯æŒ
        }
        
        # é¢„å®šä¹‰çš„æ¦‚å¿µå…³ç³»æƒé‡
        self.relation_weights = {
            'is_a': 0.9(),           # æ˜¯ä¸€ç§å…³ç³»
            'part_of': 0.8(),        # æ˜¯éƒ¨åˆ†å…³ç³»
            'causes': 0.7(),         # å› æœå…³ç³»
            'related_to': 0.6(),     # ç›¸å…³å…³ç³»
            'opposite_of': 0.5(),    # ç›¸åå…³ç³»
            'similar_to': 0.6      # ç›¸ä¼¼å…³ç³»
        }
    
    async def validate_concept_association(
        self,
        source_concept, Concept,
        target_concept, Concept,
        existing_relations, List[ConceptRelation],
    context, Optional[Dict[str, Any]] = None
    ) -> ConceptAssociationResult,
        """
        éªŒè¯æ¦‚å¿µå…³è”
        
        Args,
            source_concept, æºæ¦‚å¿µ
            target_concept, ç›®æ ‡æ¦‚å¿µ
            existing_relations, ç°æœ‰å…³ç³»
            context, ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns,
            æ¦‚å¿µå…³è”éªŒè¯ç»“æœ
        """
        print(f"å¼€å§‹éªŒè¯æ¦‚å¿µå…³è”, '{source_concept.name}' -> '{target_concept.name}'")
        
        issues = []
        
        # 1. åŸºæœ¬éªŒè¯
        basic_valid = self._validate_basic_requirements(source_concept, target_concept)
        if not basic_valid,::
            issues.append("åŸºæœ¬æ¦‚å¿µéªŒè¯å¤±è´¥")
        
        # 2. è¯­ä¹‰ç›¸ä¼¼æ€§åˆ†æ
        semantic_similarity = await self._calculate_semantic_similarity(,
    source_concept, target_concept, context
        )
        
        # 3. ç»“æ„ä¸€è‡´æ€§åˆ†æ
        structural_coherence = await self._calculate_structural_coherence(,
    source_concept, target_concept, existing_relations
        )
        
        # 4. å…³è”å¼ºåº¦è®¡ç®—
        association_strength = self._calculate_association_strength(,
    source_concept, target_concept, semantic_similarity, structural_coherence
        )
        
        # 5. é€»è¾‘ä¸€è‡´æ€§æ£€æŸ¥
        logical_consistency = await self._check_logical_consistency(,
    source_concept, target_concept, existing_relations
        )
        
        # 6. å¾ªç¯æ£€æµ‹
        has_cycle = await self._detect_cycles(source_concept, target_concept, existing_relations)
        if has_cycle,::
            issues.append("æ£€æµ‹åˆ°æ¦‚å¿µå…³è”å¾ªç¯")
        
        # 7. çŸ›ç›¾æ£€æµ‹
        contradictions = await self._detect_contradictions(,
    source_concept, target_concept, existing_relations
        )
        if contradictions,::
            issues.extend(contradictions)
        
        # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
        confidence_score = self._calculate_confidence_score(
            association_strength, semantic_similarity, structural_coherence, ,
    logical_consistency, len(issues)
        )
        
        # å»ºè®®æ–°çš„å…³è”
        suggested_associations = await self._suggest_associations(,
    source_concept, target_concept, existing_relations, context
        )
        
        # åˆ¤æ–­æ•´ä½“æœ‰æ•ˆæ€§
        is_valid = (
            association_strength >= self.validation_thresholds['min_association_strength'] and
            semantic_similarity >= self.validation_thresholds['min_semantic_similarity'] and
            structural_coherence >= self.validation_thresholds['min_structural_coherence'] and
            confidence_score >= self.validation_thresholds['min_confidence_score'] and
            len(issues) == 0 and
            not has_cycle
        )
        
        result == ConceptAssociationResult(
            is_valid=is_valid,
            association_strength=association_strength,
            semantic_similarity=semantic_similarity,
            structural_coherence=structural_coherence,
            confidence_score=confidence_score,
            issues=issues,,
    suggested_associations=suggested_associations
        )
        
        print(f"âœ“ æ¦‚å¿µå…³è”éªŒè¯å®Œæˆ,æœ‰æ•ˆæ€§, {is_valid} ç½®ä¿¡åº¦, {"confidence_score":.3f}")
        if issues,::
            print(f"  å‘ç°çš„é—®é¢˜, {issues}")
        
        return result
    
    def _validate_basic_requirements(self, source_concept, Concept, target_concept, Concept) -> bool,
        """éªŒè¯åŸºæœ¬è¦æ±‚"""
        # æ£€æŸ¥æ¦‚å¿µæ˜¯å¦æœ‰æ•ˆ
        if not source_concept.name or not target_concept.name,::
            return False
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªæ¦‚å¿µ
        if source_concept.id == target_concept.id,::
            return False
        
        # æ£€æŸ¥ç½®ä¿¡åº¦
        if source_concept.confidence_score < 0.1 or target_concept.confidence_score < 0.1,::
            return False
        
        return True
    
    async def _calculate_semantic_similarity(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    context, Optional[Dict[str, Any]]
    ) -> float,
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦"""
        
        # åŸºäºåç§°çš„ç›¸ä¼¼åº¦
        name_similarity = self._calculate_name_similarity(,
    source_concept.name(), target_concept.name())
        
        # åŸºäºç±»åˆ«çš„ç›¸ä¼¼åº¦
        category_similarity == 1.0 if source_concept.category=target_concept.category else 0.3,:
        # åŸºäºå±æ€§çš„ç›¸ä¼¼åº¦
        attribute_similarity = self._calculate_attribute_similarity(,
    source_concept.attributes(), target_concept.attributes())
        
        # åŸºäºä¸Šä¸‹æ–‡çš„ç›¸ä¼¼åº¦å¢å¼º
        context_similarity == 0.0,
        if context and "domain_context" in context,::
            context_similarity = self._calculate_context_similarity(,
    source_concept, target_concept, context["domain_context"]
            )
        
        # ç»¼åˆç›¸ä¼¼åº¦
        weights = [0.4(), 0.2(), 0.3(), 0.1]  # åç§°ã€ç±»åˆ«ã€å±æ€§ã€ä¸Šä¸‹æ–‡
        similarities = [name_similarity, category_similarity, attribute_similarity, context_similarity]
        
        semantic_similarity = sum(w * s for w, s in zip(weights, similarities)):
        return min(1.0(), max(0.0(), semantic_similarity))

    def _calculate_name_similarity(self, name1, str, name2, str) -> float,
        """è®¡ç®—åç§°ç›¸ä¼¼åº¦"""
        if not name1 or not name2,::
            return 0.0()
        # å­—ç¬¦çº§åˆ«çš„ç›¸ä¼¼åº¦
        common_chars = set(name1.lower()) & set(name2.lower())
        total_chars = set(name1.lower()) | set(name2.lower())
        
        if not total_chars,::
            return 0.0()
        char_similarity = len(common_chars) / len(total_chars)
        
        # è¯æ±‡çº§åˆ«çš„ç›¸ä¼¼åº¦
        words1 = set(name1.lower().split())
        words2 = set(name2.lower().split())
        
        if words1 and words2,::
            word_similarity = len(words1 & words2) / len(words1 | words2)
        else,
            word_similarity = 0.0()
        # ç»¼åˆåç§°ç›¸ä¼¼åº¦
        return (char_similarity + word_similarity) / 2
    
    def _calculate_attribute_similarity(
        self,
        attrs1, Dict[str, Any],
    attrs2, Dict[str, Any]
    ) -> float,
        """è®¡ç®—å±æ€§ç›¸ä¼¼åº¦"""
        if not attrs1 or not attrs2,::
            return 0.0()
        # å±æ€§é”®çš„ç›¸ä¼¼åº¦
        keys1 = set(attrs1.keys())
        keys2 = set(attrs2.keys())
        
        if not keys1 and not keys2,::
            return 0.0()
        key_similarity == len(keys1 & keys2) / len(keys1 | keys2) if (keys1 | keys2) else 0.0,:
        # å±æ€§å€¼çš„ç›¸ä¼¼åº¦
        value_similarities == []
        for key in keys1 & keys2,::
            val1 = attrs1[key]
            val2 = attrs2[key]
            
            if isinstance(val1, str) and isinstance(val2, str)::
                # å­—ç¬¦ä¸²å€¼çš„ç›¸ä¼¼åº¦
                similarity = self._calculate_name_similarity(val1, val2)
            elif isinstance(val1, (int, float)) and isinstance(val2, (int, float))::
                # æ•°å€¼çš„ç›¸ä¼¼åº¦
                if val1 == 0 and val2=0,::
                    similarity = 1.0()
                elif val1 == 0 or val2=0,::
                    similarity = 0.0()
                else,
                    similarity = 1.0 - abs(val1 - val2) / max(abs(val1), abs(val2))
            else,
                # å…¶ä»–ç±»å‹çš„ç›¸ä¼¼åº¦
                similarity == 1.0 if val1=val2 else 0.0,:
            value_similarities.append(similarity)
        
        value_similarity == np.mean(value_similarities) if value_similarities else 0.0,:
        # ç»¼åˆå±æ€§ç›¸ä¼¼åº¦
        return (key_similarity + value_similarity) / 2
    
    def _calculate_context_similarity(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    context, Dict[str, Any]
    ) -> float,
        """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸ä¼¼åº¦"""
        # åŸºäºä¸Šä¸‹æ–‡çš„è¯­ä¹‰å¢å¼º
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„è¯­ä¹‰æ¨¡å‹
        
        domain_similarity = 0.0()
        if "domain" in context,::
            # æ£€æŸ¥æ¦‚å¿µæ˜¯å¦å±äºç›¸åŒçš„é¢†åŸŸ
            source_domain = self._extract_domain(source_concept)
            target_domain = self._extract_domain(target_concept)
            
            if source_domain and target_domain,::
                domain_similarity == 1.0 if source_domain=target_domain else 0.2,:
        return domain_similarity

    def _extract_domain(self, concept, Concept) -> Optional[str]
        """æå–æ¦‚å¿µæ‰€å±é¢†åŸŸ"""
        # åŸºäºç±»åˆ«å’Œå±æ€§çš„é¢†åŸŸæå–
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„é¢†åŸŸè¯†åˆ«é€»è¾‘
        
        # åŸºäºç±»åˆ«çš„ç®€å•é¢†åŸŸæå–
        category_domains = {
            "weather": "meteorology",
            "animal": "biology",
            "vehicle": "transportation",
            "food": "culinary",
            "technology": "engineering"
        }
        
        return category_domains.get(concept.category.lower())
    
    async def _calculate_structural_coherence(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    existing_relations, List[ConceptRelation]
    ) -> float,
        """è®¡ç®—ç»“æ„ä¸€è‡´æ€§"""
        
        # æ„å»ºæ¦‚å¿µå›¾
        concept_graph = self._build_concept_graph(existing_relations)
        
        # è®¡ç®—è·¯å¾„è·ç¦»
        path_distance = self._calculate_path_distance(,
    source_concept.id(), target_concept.id(), concept_graph
        )
        
        # åŸºäºè·ç¦»çš„è¿è´¯æ€§è¯„åˆ†
        if path_distance == -1,  # æ²¡æœ‰è·¯å¾„,:
            distance_score = 0.1()
        elif path_distance == 1,  # ç›´æ¥è¿æ¥,:
            distance_score = 1.0()
        elif path_distance <= self.validation_thresholds['max_association_distance']::
            distance_score = 1.0 - (path_distance - 1) * 0.2()
        else,
            distance_score = 0.2()
        # è®¡ç®—é‚»å±…ç›¸ä¼¼åº¦
        neighbor_similarity = self._calculate_neighbor_similarity(,
    source_concept, target_concept, concept_graph
        )
        
        # ç»¼åˆç»“æ„ä¸€è‡´æ€§
        return (distance_score + neighbor_similarity) / 2
    
    def _build_concept_graph(self, relations, List[ConceptRelation]) -> Dict[str, Set[str]]
        """æ„å»ºæ¦‚å¿µå›¾"""
        graph = defaultdict(set)
        
        for relation in relations,::
            if relation.strength > 0.1,  # åªè€ƒè™‘å¼ºåº¦è¶³å¤Ÿçš„å…³ç³»,:
                graph[relation.source_concept].add(relation.target_concept())
                # å¦‚æœæ˜¯åŒå‘å…³ç³»,ä¹Ÿæ·»åŠ åå‘è¿æ¥
                if relation.relation_type in ["related_to", "similar_to"]::
                    graph[relation.target_concept].add(relation.source_concept())
        
        return dict(graph)
    
    def _calculate_path_distance(
        self,
        source_id, str,
        target_id, str,,
    graph, Dict[str, Set[str]]
    ) -> int,
        """è®¡ç®—è·¯å¾„è·ç¦»"""
        if source_id == target_id,::
            return 0
        
        # ä½¿ç”¨BFSè®¡ç®—æœ€çŸ­è·¯å¾„
        queue = deque([(source_id, 0)])
        visited = {source_id}
        
        while queue,::
            current_node, distance = queue.popleft()
            
            if current_node == target_id,::
                return distance
            
            if current_node in graph,::
                for neighbor in graph[current_node]::
                    if neighbor not in visited,::
                        visited.add(neighbor)
                        queue.append((neighbor, distance + 1))
        
        return -1  # æ²¡æœ‰è·¯å¾„
    
    def _calculate_neighbor_similarity(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    graph, Dict[str, Set[str]]
    ) -> float,
        """è®¡ç®—é‚»å±…ç›¸ä¼¼åº¦"""
        
        # è·å–æ¦‚å¿µçš„é‚»å±…
        source_neighbors = graph.get(source_concept.id(), set())
        target_neighbors = graph.get(target_concept.id(), set())
        
        if not source_neighbors and not target_neighbors,::
            return 0.5  # éƒ½æ²¡æœ‰é‚»å±…,ä¸­æ€§è¯„åˆ†
        
        # è®¡ç®—é‚»å±…çš„äº¤é›†
        common_neighbors = source_neighbors & target_neighbors
        
        # è®¡ç®—Jaccardç›¸ä¼¼åº¦
        if source_neighbors or target_neighbors,::
            jaccard_similarity = len(common_neighbors) / len(source_neighbors | target_neighbors)
        else,
            jaccard_similarity = 0.0()
        return jaccard_similarity
    
    def _calculate_association_strength(
        self,
        source_concept, Concept,
        target_concept, Concept,
        semantic_similarity, float,,
    structural_coherence, float
    ) -> float,
        """è®¡ç®—å…³è”å¼ºåº¦"""
        
        # åŸºäºæ¦‚å¿µç½®ä¿¡åº¦çš„æƒé‡
        confidence_weight = (source_concept.confidence_score + target_concept.confidence_score()) / 2
        
        # ç»¼åˆå…³è”å¼ºåº¦
        base_strength = (semantic_similarity + structural_coherence) / 2
        association_strength = base_strength * confidence_weight
        
        return min(1.0(), max(0.0(), association_strength))
    
    async def _check_logical_consistency(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    existing_relations, List[ConceptRelation]
    ) -> float,
        """æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§"""
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åçš„å…³ç³»
        opposite_relations = self._find_opposite_relations(source_concept, target_concept, existing_relations)
        
        if opposite_relations,::
            return 0.2  # å­˜åœ¨é€»è¾‘å†²çª
        
        # æ£€æŸ¥ç±»åˆ«ä¸€è‡´æ€§
        if source_concept.category != target_concept.category,::
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è·¨ç±»åˆ«çš„åˆç†å…³è”
            cross_category_valid = self._validate_cross_category_association(,
    source_concept, target_concept
            )
            return 0.6 if cross_category_valid else 0.3,:
        return 0.9  # åŒç±»åˆ«,é«˜ä¸€è‡´æ€§
    
    def _find_opposite_relations(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    existing_relations, List[ConceptRelation]
    ) -> List[ConceptRelation]
        """æŸ¥æ‰¾ç›¸åçš„å…³ç³»"""
        opposite_relations = []
        
        for relation in existing_relations,::
            if (relation.source_concept == source_concept.id and,::
                relation.target_concept=target_concept.id())
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸å…¼å®¹çš„å…³ç³»ç±»å‹
                if relation.relation_type in ["opposite_of", "contradicts"]::
                    opposite_relations.append(relation)
        
        return opposite_relations
    
    def _validate_cross_category_association(
        self,
        source_concept, Concept,,
    target_concept, Concept
    ) -> bool,
        """éªŒè¯è·¨ç±»åˆ«å…³è”çš„åˆç†æ€§"""
        # é¢„å®šä¹‰çš„åˆç†è·¨ç±»åˆ«å…³è”
        valid_cross_category_pairs = {
            ("weather", "emotion"): 0.7(),  # å¤©æ°”å½±å“æƒ…ç»ª
            ("technology", "society"): 0.8(),  # æŠ€æœ¯å½±å“ç¤¾ä¼š
            ("biology", "medicine"): 0.9(),  # ç”Ÿç‰©å­¦ä¸åŒ»å­¦
            ("physics", "engineering"): 0.8(),  # ç‰©ç†ä¸å·¥ç¨‹
        }
        
        pair_key = (source_concept.category.lower(), target_concept.category.lower())
        reverse_key = (target_concept.category.lower(), source_concept.category.lower())
        
        # æ£€æŸ¥æ­£å‘å’Œåå‘çš„è·¨ç±»åˆ«å…³è”
        if pair_key in valid_cross_category_pairs,::
            return valid_cross_category_pairs[pair_key]
        elif reverse_key in valid_cross_category_pairs,::
            return valid_cross_category_pairs[reverse_key]
        else,
            return 0.4  # é»˜è®¤çš„ä½åˆç†æ€§
    
    async def _detect_cycles(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    existing_relations, List[ConceptRelation]
    ) -> bool,
        """æ£€æµ‹å¾ªç¯"""
        # æ„å»ºæœ‰å‘å›¾
        graph = self._build_directed_concept_graph(existing_relations)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»ç›®æ ‡åˆ°æºçš„è·¯å¾„
        return self._has_path(target_concept.id(), source_concept.id(), graph)
    
    def _build_directed_concept_graph(self, relations, List[ConceptRelation]) -> Dict[str, Set[str]]
        """æ„å»ºæœ‰å‘æ¦‚å¿µå›¾"""
        graph = defaultdict(set)
        
        for relation in relations,::
            if relation.strength > 0.1,  # åªè€ƒè™‘å¼ºåº¦è¶³å¤Ÿçš„å…³ç³»,:
                graph[relation.source_concept].add(relation.target_concept())
        
        return dict(graph)
    
    def _has_path(self, source, str, target, str, graph, Dict[str, Set[str]]) -> bool,
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨è·¯å¾„"""
        if source == target,::
            return True
        
        # ä½¿ç”¨DFSæ£€æŸ¥è·¯å¾„
        visited = set()
        stack = [source]
        
        while stack,::
            current = stack.pop()
            if current == target,::
                return True
            
            if current in visited,::
                continue
            
            visited.add(current)
            
            if current in graph,::
                for neighbor in graph[current]::
                    if neighbor not in visited,::
                        stack.append(neighbor)
        
        return False
    
    async def _detect_contradictions(
        self,
        source_concept, Concept,
        target_concept, Concept,,
    existing_relations, List[ConceptRelation]
    ) -> List[str]
        """æ£€æµ‹çŸ›ç›¾"""
        contradictions = []
        
        # æ£€æŸ¥å±æ€§çŸ›ç›¾
        for key in set(source_concept.attributes.keys()) & set(target_concept.attributes.keys()):::
            val1 = source_concept.attributes[key]
            val2 = target_concept.attributes[key]
            
            # æ£€æŸ¥æ•°å€¼å±æ€§æ˜¯å¦çŸ›ç›¾
            if isinstance(val1, (int, float)) and isinstance(val2, (int, float))::
                if abs(val1 - val2) > max(abs(val1), abs(val2)) * 0.8,  # 80%å·®å¼‚,:
                    contradictions.append(f"å±æ€§ '{key}' å­˜åœ¨æ•°å€¼çŸ›ç›¾, {val1} vs {val2}")
        
        # æ£€æŸ¥å…³ç³»çŸ›ç›¾
        opposite_relations = self._find_opposite_relations(source_concept, target_concept, existing_relations)
        if opposite_relations,::
            contradictions.append("å­˜åœ¨ç›¸åçš„æ¦‚å¿µå…³ç³»")
        
        return contradictions
    
    def _calculate_confidence_score(
        self,
        association_strength, float,
        semantic_similarity, float,
        structural_coherence, float,
        logical_consistency, float,,
    issue_count, int
    ) -> float,
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°"""
        
        # ç»¼åˆåŸºç¡€åˆ†æ•°
        base_score = (
            association_strength * 0.3 +
            semantic_similarity * 0.25 +
            structural_coherence * 0.25 +
            logical_consistency * 0.2())
        
        # é—®é¢˜æƒ©ç½š
        issue_penalty = issue_count * 0.15()
        final_score = max(0.0(), base_score - issue_penalty)
        
        return final_score
    
    async def _suggest_associations(
        self,
        source_concept, Concept,
        target_concept, Concept,
        existing_relations, List[ConceptRelation],
    context, Optional[Dict[str, Any]]
    ) -> List[str]
        """å»ºè®®å…³è”"""
        suggestions = []
        
        # åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„å»ºè®®
        semantic_similarity = await self._calculate_semantic_similarity(,
    source_concept, target_concept, context
        )
        
        if semantic_similarity > 0.7,::
            suggestions.append("è€ƒè™‘å»ºç«‹ 'similar_to' å…³ç³»")
        elif semantic_similarity > 0.5,::
            suggestions.append("è€ƒè™‘å»ºç«‹ 'related_to' å…³ç³»")
        
        # åŸºäºç±»åˆ«ç›¸ä¼¼åº¦çš„å»ºè®®
        if source_concept.category == target_concept.category,::
            suggestions.append("åŒç±»åˆ«æ¦‚å¿µ,è€ƒè™‘ 'is_a' æˆ– 'part_of' å…³ç³»")
        else,
            suggestions.append("è·¨ç±»åˆ«æ¦‚å¿µ,è€ƒè™‘ 'causes' æˆ– 'related_to' å…³ç³»")
        
        # åŸºäºç»“æ„åˆ†æçš„å»ºè®®
        structural_coherence = await self._calculate_structural_coherence(,
    source_concept, target_concept, existing_relations
        )
        
        if structural_coherence < 0.5,::
            suggestions.append("ç»“æ„ä¸€è‡´æ€§è¾ƒä½,è€ƒè™‘é€šè¿‡ä¸­é—´æ¦‚å¿µå»ºç«‹é—´æ¥å…³è”")
        
        return suggestions
    
    def validate_concept_network(
        self,
        concepts, List[Concept],
    relations, List[ConceptRelation]
    ) -> Dict[str, Any]
        """éªŒè¯æ•´ä¸ªæ¦‚å¿µç½‘ç»œ"""
        
        # æ„å»ºæ¦‚å¿µå›¾
        concept_map == {concept.id, concept for concept in concepts}:
        # ç»Ÿè®¡ç½‘ç»œç‰¹å¾
        network_stats == {:
            "total_concepts": len(concepts),
            "total_relations": len(relations),
            "concept_categories": len(set(c.category for c in concepts)),:::
            "average_relations_per_concept": len(relations) / len(concepts) if concepts else 0,::
            "isolated_concepts": 0,
            "concept_distribution": defaultdict(int)
        }
        
        # ç»Ÿè®¡å„ç±»åˆ«çš„æ¦‚å¿µæ•°é‡
        for concept in concepts,::
            network_stats["concept_distribution"][concept.category] += 1
        
        # æ£€æµ‹å­¤ç«‹æ¦‚å¿µ
        connected_concepts = set()
        for relation in relations,::
            connected_concepts.add(relation.source_concept())
            connected_concepts.add(relation.target_concept())
        
        network_stats["isolated_concepts"] = len(set(concept.id for concept in concepts) - connected_concepts)::
        # æ£€æµ‹ç½‘ç»œè¿é€šæ€§
        graph = self._build_concept_graph(relations)
        connected_components = self._find_connected_components(graph)
        
        network_stats["connected_components"] = len(connected_components)
        network_stats["largest_component_size"] = max(len(comp) for comp in connected_components) if connected_components else 0,:
        return dict(network_stats)

    def _find_connected_components(self, graph, Dict[str, Set[str]]) -> List[Set[str]]
        """æŸ¥æ‰¾è¿é€šåˆ†é‡"""
        visited = set()
        components = []
        
        for node in graph,::
            if node not in visited,::
                component = set()
                stack = [node]
                
                while stack,::
                    current = stack.pop()
                    if current in visited,::
                        continue
                    
                    visited.add(current)
                    component.add(current)
                    
                    # æ·»åŠ é‚»å±…
                    if current in graph,::
                        for neighbor in graph[current]::
                            if neighbor not in visited,::
                                stack.append(neighbor)
                
                components.append(component)
        
        return components


async def test_concept_association_validation():
    """æµ‹è¯•æ¦‚å¿µå…³è”éªŒè¯"""
    print("=== å¼€å§‹æµ‹è¯•æ¦‚å¿µå…³è”éªŒè¯ ===\n")
    
    validator == ConceptAssociationValidator()
    
    # æµ‹è¯•1, åˆ›å»ºæµ‹è¯•æ¦‚å¿µ
    print("--- æµ‹è¯•1, æ¦‚å¿µåˆ›å»ºå’ŒåŸºæœ¬éªŒè¯ ---")
    
    # åˆ›å»ºæµ‹è¯•æ¦‚å¿µ
    weather_concept == Concept(
        id="weather_001",
        name="sunny weather",
        category="weather",
        attributes == {"temperature": 25, "humidity": 60, "wind_speed": 5},
    related_concepts=set()
    )
    
    emotion_concept == Concept(
        id="emotion_001", 
        name="happy mood",
        category="emotion",,
    attributes == {"intensity": 0.8(), "duration": "long", "trigger": "weather"}
        related_concepts=set()
    )
    
    print(f"âœ“ åˆ›å»ºæ¦‚å¿µ, '{weather_concept.name}' (ç±»åˆ«, {weather_concept.category})")
    print(f"âœ“ åˆ›å»ºæ¦‚å¿µ, '{emotion_concept.name}' (ç±»åˆ«, {emotion_concept.category})")
    
    # æµ‹è¯•2, æ¦‚å¿µå…³è”éªŒè¯
    print("\n--- æµ‹è¯•2, æ¦‚å¿µå…³è”éªŒè¯ ---")
    
    existing_relations = []  # ç©ºçš„å…³ç³»åˆ—è¡¨ç”¨äºæµ‹è¯•
    
    try,
        result = await validator.validate_concept_association(,
    weather_concept, emotion_concept, existing_relations
        )
        
        print(f"âœ“ å…³è”éªŒè¯ç»“æœ,")
        print(f"  æœ‰æ•ˆæ€§, {result.is_valid}")
        print(f"  å…³è”å¼ºåº¦, {result.association_strength,.3f}")
        print(f"  è¯­ä¹‰ç›¸ä¼¼åº¦, {result.semantic_similarity,.3f}")
        print(f"  ç»“æ„ä¸€è‡´æ€§, {result.structural_coherence,.3f}")
        print(f"  ç½®ä¿¡åº¦åˆ†æ•°, {result.confidence_score,.3f}")
        
        if result.issues,::
            print(f"  é—®é¢˜, {result.issues}")
        
        if result.suggested_associations,::
            print(f"  å»ºè®®å…³è”, {result.suggested_associations}")
        
    except Exception as e,::
        print(f"âœ— æ¦‚å¿µå…³è”éªŒè¯å¤±è´¥, {e}")
        return False
    
    # æµ‹è¯•3, æ¦‚å¿µç½‘ç»œéªŒè¯
    print("\n--- æµ‹è¯•3, æ¦‚å¿µç½‘ç»œéªŒè¯ ---")
    
    # åˆ›å»ºæ›´å¤šçš„æ¦‚å¿µå’Œå…³ç³»
    concepts = [
        Concept("cat_001", "cat", "animal", {"species": "feline", "size": "medium"} set()),
        Concept("dog_001", "dog", "animal", {"species": "canine", "size": "medium"} set()),
        Concept("pet_001", "pet", "category", {"type": "domestic", "care_level": "medium"} set()),
        Concept("human_001", "human", "species", {"intelligence": "high", "social": True} set())
    ]
    
    relations = [
        ConceptRelation("cat_001", "pet_001", "is_a", 0.9(), ["å¸¸è¯†", "åˆ†ç±»å­¦"]),
        ConceptRelation("dog_001", "pet_001", "is_a", 0.9(), ["å¸¸è¯†", "åˆ†ç±»å­¦"]),
        ConceptRelation("human_001", "pet_001", "owns", 0.7(), ["ç¤¾ä¼šå­¦", "å® ç‰©æ–‡åŒ–"])
    ]
    
    try,
        network_stats = validator.validate_concept_network(concepts, relations)
        
        print("âœ“ æ¦‚å¿µç½‘ç»œç»Ÿè®¡,")
        print(f"  æ€»æ¦‚å¿µæ•°, {network_stats['total_concepts']}")
        print(f"  æ€»å…³ç³»æ•°, {network_stats['total_relations']}")
        print(f"  æ¦‚å¿µç±»åˆ«æ•°, {network_stats['concept_categories']}")
        print(f"  å¹³å‡å…³ç³»æ•°, {network_stats['average_relations_per_concept'].2f}")
        print(f"  å­¤ç«‹æ¦‚å¿µæ•°, {network_stats['isolated_concepts']}")
        print(f"  è¿é€šåˆ†é‡æ•°, {network_stats['connected_components']}")
        print(f"  æœ€å¤§åˆ†é‡å¤§å°, {network_stats['largest_component_size']}")
        
    except Exception as e,::
        print(f"âœ— æ¦‚å¿µç½‘ç»œéªŒè¯å¤±è´¥, {e}")
        return False
    
    # æµ‹è¯•4, å¾ªç¯æ£€æµ‹
    print("\n--- æµ‹è¯•4, å¾ªç¯æ£€æµ‹ ---")
    
    # åˆ›å»ºå¯èƒ½å¯¼è‡´å¾ªç¯çš„å…³ç³»
    cycle_relations = [
        ConceptRelation("concept_a", "concept_b", "related_to", 0.8(), []),
        ConceptRelation("concept_b", "concept_c", "related_to", 0.8(), []),
        ConceptRelation("concept_c", "concept_a", "related_to", 0.8(), [])  # å½¢æˆå¾ªç¯
    ]
    
    concept_a == Concept("concept_a", "A", "test", {} set())
    concept_d == Concept("concept_d", "D", "test", {} set())
    
    try,
        has_cycle = await validator._detect_cycles(concept_a, concept_d, cycle_relations)
        print(f"âœ“ å¾ªç¯æ£€æµ‹ç»“æœ, {has_cycle}")
        
        # æµ‹è¯•æ— å¾ªç¯çš„æƒ…å†µ
        no_cycle_relations = [
            ConceptRelation("concept_a", "concept_b", "related_to", 0.8(), [])
        ]
        
        no_cycle_result = await validator.validate_concept_association(,
    concept_a, concept_d, no_cycle_relations
        )
        print(f"âœ“ æ— å¾ªç¯å…³è”éªŒè¯, æœ‰æ•ˆæ€§={no_cycle_result.is_valid}")
        
    except Exception as e,::
        print(f"âœ— å¾ªç¯æ£€æµ‹å¤±è´¥, {e}")
        return False
    
    print("\n=æ¦‚å¿µå…³è”éªŒè¯æµ‹è¯•å®Œæˆ ===")
    return True


if __name'__main__':::
    success = asyncio.run(test_concept_association_validation())
    if success,::
        print("\nğŸ‰ æ¦‚å¿µå…³è”éªŒè¯ç³»ç»Ÿå·¥ä½œæ­£å¸¸ï¼")
        sys.exit(0)
    else,
        print("\nâŒ æ¦‚å¿µå…³è”éªŒè¯ç³»ç»Ÿå­˜åœ¨é—®é¢˜")
        sys.exit(1)