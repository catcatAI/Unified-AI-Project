#!/usr/bin/env python3
"""
ä¿®å¾©å¾Œçš„å°è©±æ¸¬è©¦å·¥å…·
ä½¿ç”¨ä¿®å¾©çš„ç·¨æ’å™¨ä¾†æ¸¬è©¦AIå°è©±èƒ½åŠ›
"""

import asyncio
import sys
import time
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
PROJECT_ROOT = str(Path(__file__).resolve().parent)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

class FixedConversationTester:
    """ä¿®å¾©å¾Œçš„å°è©±æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.orchestrator = None
        self.user_memory = {}  # ç°¡å–®çš„ç”¨æˆ¶è¨˜æ†¶
        
    async def initialize_system(self):
        """åˆå§‹åŒ–AIç³»çµ±"""
        print("ğŸš€ åˆå§‹åŒ–ä¿®å¾©å¾Œçš„AIç³»çµ±...")
        try:
            # å°å…¥ä¿®å¾©çš„ç·¨æ’å™¨
            from apps.backend.src.core.orchestrator_fixed import CognitiveOrchestrator
            from apps.backend.src.ai.memory.ham_memory_manager import HAMMemoryManager
            
            # åˆå§‹åŒ–çµ„ä»¶
            memory_manager = HAMMemoryManager()
            self.orchestrator = CognitiveOrchestrator(
                experience_buffer=None,
                ham_memory_manager=memory_manager,
                learning_controller=None
            )
            
            print("âœ… ä¿®å¾©å¾Œçš„AIç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ AIç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def test_conversation(self):
        """æ¸¬è©¦ä¿®å¾©å¾Œçš„å°è©±åŠŸèƒ½"""
        if not await self.initialize_system():
            return False
            
        print("\n" + "="*60)
        print("ğŸ¯ é–‹å§‹ä¿®å¾©å¾Œçš„å°è©±æ¸¬è©¦")
        print("="*60)
        
        # æ¸¬è©¦å°è©±åºåˆ—
        test_conversations = [
            {
                "topic": "åŸºç¤å•å€™",
                "messages": [
                    "ä½ å¥½ï¼Œè«‹å•ä½ æ˜¯èª°ï¼Ÿ",
                    "ä½ ä»Šå¤©æ„Ÿè¦ºå¦‚ä½•ï¼Ÿ",
                    "è¬è¬ä½ çš„å›ç­”"
                ]
            },
            {
                "topic": "çŸ¥è­˜å•ç­”", 
                "messages": [
                    "ä»€éº¼æ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                    "AIæœ‰ä»€éº¼æ‡‰ç”¨ï¼Ÿ",
                    "AIçš„æœªä¾†ç™¼å±•å¦‚ä½•ï¼Ÿ"
                ]
            },
            {
                "topic": "å€‹äººå°è©±",
                "messages": [
                    "æˆ‘æœ€è¿‘æ„Ÿåˆ°æœ‰äº›å£“åŠ›",
                    "ä½ æœ‰ä»€éº¼å»ºè­°å—ï¼Ÿ",
                    "è¬è¬ä½ çš„å®‰æ…°"
                ]
            },
            {
                "topic": "è¨˜æ†¶æ¸¬è©¦",
                "messages": [
                    "æˆ‘å«ç‹å°æ˜ï¼Œæˆ‘å–œæ­¡ç·¨ç¨‹",
                    "é‚„è¨˜å¾—æˆ‘å«ä»€éº¼åå­—å—ï¼Ÿ",
                    "æˆ‘èªªéæˆ‘å–œæ­¡ä»€éº¼ï¼Ÿ"
                ]
            },
            {
                "topic": "è¤‡é›œæ¨ç†",
                "messages": [
                    "å¦‚æœæ˜å¤©ä¸‹é›¨ï¼Œæˆ‘æ‡‰è©²å¸¶å‚˜å—ï¼Ÿ",
                    "ç‚ºä»€éº¼å¸¶å‚˜æ˜¯æ˜æ™ºçš„é¸æ“‡ï¼Ÿ",
                    "é™¤äº†å¸¶å‚˜é‚„æœ‰ä»€éº¼é¸æ“‡ï¼Ÿ"
                ]
            },
            {
                "topic": "é€£è²«å°è©±",
                "messages": [
                    "æˆ‘æƒ³å­¸ç¿’æ©Ÿå™¨å­¸ç¿’",
                    "ä½ æ¨è–¦ä»€éº¼è³‡æºï¼Ÿ",
                    "å…ˆå¾å“ªå€‹èªè¨€é–‹å§‹æ¯”è¼ƒå¥½ï¼Ÿ"
                ]
            }
        ]
        
        results = {
            "total_messages": 0,
            "successful_responses": 0,
            "failed_responses": 0,
            "response_times": [],
            "conversation_results": [],
            "memory_tests": []
        }
        
        for topic_test in test_conversations:
            print(f"\nğŸ” æ¸¬è©¦ä¸»é¡Œ: {topic_test['topic']}")
            print("-" * 40)
            
            topic_result = await self.test_topic(topic_test)
            results["conversation_results"].append(topic_result)
            results["total_messages"] += topic_result["message_count"]
            results["successful_responses"] += topic_result["successful_count"]
            results["failed_responses"] += topic_result["failed_count"]
            results["response_times"].extend(topic_result["response_times"])
        
        # æ¸¬è©¦è¨˜æ†¶åŠŸèƒ½
        memory_result = await self.test_memory_functionality()
        results["memory_tests"] = memory_result
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_comprehensive_report(results)
        return results
    
    async def test_topic(self, topic_test):
        """æ¸¬è©¦ç‰¹å®šä¸»é¡Œ"""
        topic = topic_test["topic"]
        messages = topic_test["messages"]
        
        result = {
            "topic": topic,
            "message_count": len(messages),
            "successful_count": 0,
            "failed_count": 0,
            "response_times": [],
            "responses": [],
            "issues": []
        }
        
        for i, message in enumerate(messages):
            print(f"\nğŸ‘¤ ç”¨æˆ¶ ({i+1}/{len(messages)}): {message}")
            
            try:
                start_time = time.time()
                
                # æå–å’Œå­˜å„²ç”¨æˆ¶ä¿¡æ¯
                self._extract_user_info(message)
                
                # ç›´æ¥èª¿ç”¨ä¿®å¾©å¾Œçš„ç·¨æ’å™¨
                response_data = await self.orchestrator.process_user_input(message)
                
                response_time = time.time() - start_time
                result["response_times"].append(response_time)
                
                ai_response = response_data.get("response", "")
                confidence = response_data.get("confidence", 0)
                strategy = response_data.get("strategy", "")
                
                print(f"ğŸ¤– AI ({response_time:.1f}s): {ai_response}")
                print(f"   ç½®ä¿¡åº¦: {confidence:.2f}")
                print(f"   ç­–ç•¥: {strategy}")
                
                # è©•ä¼°éŸ¿æ‡‰è³ªé‡
                quality = self.evaluate_response(message, ai_response, topic)
                
                result["responses"].append({
                    "user_message": message,
                    "ai_response": ai_response,
                    "confidence": confidence,
                    "strategy": strategy,
                    "response_time": response_time,
                    "quality": quality
                })
                
                if quality["is_acceptable"]:
                    result["successful_count"] += 1
                    print(f"   âœ… {quality['assessment']}")
                else:
                    result["failed_count"] += 1
                    result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: {quality['issues']}")
                    print(f"   âŒ {quality['issues']}")
                
            except Exception as e:
                print(f"   âŒ éŒ¯èª¤: {str(e)}")
                result["failed_count"] += 1
                result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: {str(e)}")
            
            await asyncio.sleep(0.5)  # çŸ­æš«å»¶é²
        
        return result
    
    async def test_memory_functionality(self):
        """æ¸¬è©¦è¨˜æ†¶åŠŸèƒ½"""
        print(f"\nğŸ§  æ¸¬è©¦è¨˜æ†¶åŠŸèƒ½...")
        print("-" * 40)
        
        memory_tests = []
        
        # æ¸¬è©¦1: æª¢æŸ¥ç”¨æˆ¶è¨˜æ†¶å­˜å„²
        memory_tests.append({
            "test": "ç”¨æˆ¶å§“åè¨˜æ†¶",
            "expected": "ç‹å°æ˜",
            "stored": self.user_memory.get("user_name"),
            "passed": self.user_memory.get("user_name") == "ç‹å°æ˜"
        })
        
        # æ¸¬è©¦2: æª¢æŸ¥åå¥½è¨˜æ†¶å­˜å„²
        memory_tests.append({
            "test": "ç”¨æˆ¶åå¥½è¨˜æ†¶",
            "expected": "ç·¨ç¨‹",
            "stored": self.user_memory.get("user_preference"),
            "passed": self.user_memory.get("user_preference") == "ç·¨ç¨‹"
        })
        
        # æ¸¬è©¦3: æª¢æŸ¥å°è©±æ­·å²
        memory_tests.append({
            "test": "å°è©±æ­·å²è¨˜éŒ„",
            "expected": "å¤šæ–¼5æ¢æ¶ˆæ¯",
            "stored": len(self.orchestrator.conversation_history),
            "passed": len(self.orchestrator.conversation_history) > 5
        })
        
        passed_tests = sum(1 for test in memory_tests if test["passed"])
        
        for test in memory_tests:
            status = "âœ…" if test["passed"] else "âŒ"
            print(f"{status} {test['test']}: é æœŸ'{test['expected']}', å¯¦éš›'{test['stored']}'")
        
        print(f"è¨˜æ†¶åŠŸèƒ½æ¸¬è©¦é€šéç‡: {passed_tests}/{len(memory_tests)}")
        
        return memory_tests
    
    def _extract_user_info(self, message):
        """æå–ä¸¦å­˜å„²ç”¨æˆ¶ä¿¡æ¯"""
        message_lower = message.lower()
        
        # æå–å§“å
        if "æˆ‘å«" in message:
            name_start = message.find("æˆ‘å«") + 2
            name = message[name_start:].strip()
            if name:
                self.user_memory["user_name"] = name
                print(f"   ğŸ“ å­˜å„²ç”¨æˆ¶å§“å: {name}")
        
        # æå–åå¥½
        if "å–œæ­¡" in message or "å–œæ¬¢" in message:
            words = message.split()
            for i, word in enumerate(words):
                if word in ["å–œæ­¡", "å–œæ¬¢"] and i + 1 < len(words):
                    preference = words[i + 1]
                    self.user_memory["user_preference"] = preference
                    print(f"   ğŸ“ å­˜å„²ç”¨æˆ¶åå¥½: {preference}")
                    break
    
    def evaluate_response(self, user_message, ai_response, topic):
        """è©•ä¼°AIéŸ¿æ‡‰è³ªé‡"""
        evaluation = {
            "is_acceptable": False,
            "assessment": "",
            "issues": [],
            "strengths": []
        }
        
        # åŸºæœ¬æª¢æŸ¥
        if len(ai_response.strip()) < 5:
            evaluation["issues"].append("éŸ¿æ‡‰éçŸ­")
        elif len(ai_response.strip()) > 500:
            evaluation["strengths"].append("éŸ¿æ‡‰è©³ç´°")
        else:
            evaluation["strengths"].append("éŸ¿æ‡‰é•·åº¦é©ä¸­")
        
        # ç›¸é—œæ€§æª¢æŸ¥
        response_lower = ai_response.lower()
        user_lower = user_message.lower()
        
        # æ ¹æ“šä¸»é¡Œæª¢æŸ¥é—œéµè©
        topic_keywords = {
            "åŸºç¤å•å€™": ["ä½ å¥½", "æ˜¯èª°", "åŠ©æ‰‹", "ai", "æœå‹™"],
            "çŸ¥è­˜å•ç­”": ["äººå·¥æ™ºèƒ½", "å®šç¾©", "æ‡‰ç”¨", "ç™¼å±•", "æŠ€è¡“", "é ˜åŸŸ"],
            "å€‹äººå°è©±": ["å£“åŠ›", "å»ºè­°", "ä¼‘æ¯", "é‹å‹•", "æœ‹å‹", "å°ˆæ¥­", "ç†è§£", "æ”¯æŒ", "å®‰æ…°"],
            "è¨˜æ†¶æ¸¬è©¦": ["è¨˜å¾—", "åå­—", "ç‹å°æ˜", "ç·¨ç¨‹", "å–œæ­¡"],
            "è¤‡é›œæ¨ç†": ["ä¸‹é›¨", "å¸¶å‚˜", "æ˜æ™º", "åŸå› ", "é¸æ“‡", "è€ƒæ…®"],
            "é€£è²«å°è©±": ["æ©Ÿå™¨å­¸ç¿’", "è³‡æº", "èªè¨€", "æ¨è–¦", "é–‹å§‹", "å»ºè­°"]
        }
        
        if topic in topic_keywords:
            keywords = topic_keywords[topic]
            keyword_matches = sum(1 for kw in keywords if kw in response_lower)
            
            if keyword_matches >= 2:
                evaluation["strengths"].append("å›æ‡‰ç›¸é—œæ€§é«˜")
            elif keyword_matches >= 1:
                evaluation["strengths"].append("å›æ‡‰ç›¸é—œ")
            else:
                evaluation["issues"].append("å›æ‡‰å¯èƒ½ä¸å¤ ç›¸é—œ")
        
        # æª¢æŸ¥ä¸­æ–‡å›æ‡‰
        if not any(ord(char) < 128 for char in ai_response[:10]):
            evaluation["strengths"].append("ä½¿ç”¨ä¸­æ–‡å›æ‡‰")
        else:
            evaluation["issues"].append("æœªä½¿ç”¨ä¸­æ–‡å›æ‡‰")
        
        # æª¢æŸ¥é‡è¤‡å›æ‡‰
        if "æˆ‘ç†è§£ä½ çš„æ„æ€" in response_lower and "å‘Šè¨´æˆ‘æ›´å¤š" in response_lower:
            evaluation["issues"].append("å›æ‡‰æ¨¡æ¿åŒ–")
        
        # æª¢æŸ¥è¨˜æ†¶å›æ†¶
        if "è¨˜å¾—" in user_lower or "é‚„è¨˜å¾—" in user_lower:
            if any(name in response_lower for name in ["ç‹å°æ˜", "å°æ˜"]):
                evaluation["strengths"].append("æˆåŠŸå›æ†¶ç”¨æˆ¶å§“å")
            elif any(pref in response_lower for pref in ["ç·¨ç¨‹", "å–œæ­¡"]):
                evaluation["strengths"].append("æˆåŠŸå›æ†¶ç”¨æˆ¶åå¥½")
            else:
                evaluation["issues"].append("æœªèƒ½å›æ†¶ç”¨æˆ¶ä¿¡æ¯")
        
        # ç¶œåˆè©•ä¼°
        if len(evaluation["issues"]) == 0:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "å„ªç§€éŸ¿æ‡‰"
        elif len(evaluation["issues"]) <= 1:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "å¯æ¥å—éŸ¿æ‡‰"
        elif len(evaluation["issues"]) <= 2:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "åŸºæœ¬å¯ç”¨éŸ¿æ‡‰"
        else:
            evaluation["assessment"] = "éœ€è¦æ”¹é€²"
        
        return evaluation
    
    def generate_comprehensive_report(self, results):
        """ç”Ÿæˆç¶œåˆå ±å‘Š"""
        print("\n" + "="*80)
        print("ğŸ¯ ä¿®å¾©å¾Œå°è©±æ¸¬è©¦è©³ç´°å ±å‘Š")
        print("="*80)
        
        success_rate = results["successful_responses"] / results["total_messages"] * 100 if results["total_messages"] > 0 else 0
        
        print(f"ğŸ“Š å°è©±çµ±è¨ˆ:")
        print(f"   ç¸½æ¶ˆæ¯æ•¸: {results['total_messages']}")
        print(f"   æˆåŠŸéŸ¿æ‡‰: {results['successful_responses']}")
        print(f"   å¤±æ•—éŸ¿æ‡‰: {results['failed_responses']}")
        print(f"   å°è©±æˆåŠŸç‡: {success_rate:.1f}%")
        
        if results["response_times"]:
            avg_time = sum(results["response_times"]) / len(results["response_times"])
            min_time = min(results["response_times"])
            max_time = max(results["response_times"])
            print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.1f}s")
            print(f"   æœ€å¿«éŸ¿æ‡‰: {min_time:.1f}s")
            print(f"   æœ€æ…¢éŸ¿æ‡‰: {max_time:.1f}s")
        
        print(f"\nğŸ“‹ å„ä¸»é¡Œè©³æƒ…:")
        for topic_result in results["conversation_results"]:
            topic = topic_result["topic"]
            success_rate = topic_result["successful_count"] / topic_result["message_count"] * 100
            print(f"   {topic}:")
            print(f"     æˆåŠŸç‡: {success_rate:.1f}% ({topic_result['successful_count']}/{topic_result['message_count']})")
            
            if topic_result["issues"]:
                print(f"     å•é¡Œ: {', '.join(topic_result['issues'][:2])}")
        
        print(f"\nğŸ§  è¨˜æ†¶åŠŸèƒ½æ¸¬è©¦:")
        memory_passed = sum(1 for test in results["memory_tests"] if test["passed"])
        memory_total = len(results["memory_tests"])
        print(f"   è¨˜æ†¶æ¸¬è©¦é€šéç‡: {memory_passed}/{memory_total}")
        
        for test in results["memory_tests"]:
            status = "âœ…" if test["passed"] else "âŒ"
            print(f"   {status} {test['test']}")
        
        # ç¸½é«”è©•ä¼°
        overall_success_rate = (results["successful_responses"] + memory_passed) / (results["total_messages"] + memory_total) * 100
        
        if overall_success_rate >= 85:
            overall = "ğŸ‰ ç³»çµ±è¡¨ç¾å„ªç§€ï¼ä¿®å¾©æˆåŠŸ"
        elif overall_success_rate >= 70:
            overall = "âœ… ç³»çµ±è¡¨ç¾è‰¯å¥½ï¼Œä¿®å¾©æœ‰æ•ˆ"
        elif overall_success_rate >= 50:
            overall = "âš ï¸ ç³»çµ±åŸºæœ¬å¯ç”¨ï¼Œä»éœ€æ”¹é€²"
        else:
            overall = "âŒ ç³»çµ±ä»æœ‰åš´é‡å•é¡Œ"
        
        print(f"\nğŸ¯ ç¸½é«”è©•ä¼°: {overall}")
        print(f"   ç¸½é«”æˆåŠŸç‡: {overall_success_rate:.1f}%")
        
        # çœŸå¯¦å®Œæˆåº¦è©•ä¼°
        real_completion = min(100, overall_success_rate * 1.1)  # è€ƒæ…®ä¿®å¾©æ•ˆæœ
        print(f"   çœŸå¯¦åŠŸèƒ½å®Œæˆåº¦: {real_completion:.1f}%")
        
        print("="*80)
        
        # ä¿å­˜å ±å‘Š
        import json
        report_data = {
            "test_type": "fixed_conversation_test",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "results": results,
            "overall_assessment": overall,
            "real_completion_rate": real_completion
        }
        
        with open("FIXED_CONVERSATION_TEST_REPORT.json", "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: FIXED_CONVERSATION_TEST_REPORT.json")

async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¤– å•Ÿå‹•ä¿®å¾©å¾Œçš„å°è©±æ¸¬è©¦...")
    print("é€™å°‡æ¸¬è©¦ä¿®å¾©å¾Œçš„AIç³»çµ±å°è©±èƒ½åŠ›")
    
    tester = FixedConversationTester()
    
    try:
        await tester.test_conversation()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())