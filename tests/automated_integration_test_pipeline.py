#!/usr/bin/env python3
"""
自动化集成测试流水线
整合环境管理、数据管理、测试执行和报告生成的完整流程
"""

import sys
import subprocess
import time
import json
from pathlib import Path
from datetime import datetime
import logging


# 配置日志
logging.basicConfig(
    level: str=logging.INFO,
    format: str='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger: Any = logging.getLogger(__name__)


class AutomatedIntegrationTestPipeline:
    """自动化集成测试流水线"""
    
    def __init__(self, project_root: str = None) -> None:
        """
        初始化自动化集成测试流水线
        
        Args:
            project_root: 项目根目录
        """
        self.project_root = Path(project_root) if project_root else Path(__file__).parent.parent
        self.scripts_dir = self.project_root / "scripts"
        self.tests_dir = self.project_root / "tests" / "integration"
        self.reports_dir = self.project_root / "test_reports"
        self.reports_dir.mkdir(exist_ok=True)
        
        # 流水线配置
        self.pipeline_config = {
            "environment": {
                "services": ["chromadb", "mqtt"],
                "setup_timeout": 300  # 5分钟
            },
            "data": {
                "dataset_size": "medium",
                "generation_timeout": 120  # 2分钟
            },
            "testing": {
                "test_types": ["all"],
                "execution_timeout": 1800  # 30分钟
            },
            "reporting": {
                "generate_html": True,
                "generate_performance": True
            }
        }
    
    def run_pipeline(self, config: dict = None) -> bool:
        """
        运行完整的测试流水线
        
        Args:
            config: 流水线配置
            
        Returns:
            bool: 流水线执行是否成功
        """
        if config:
            self.pipeline_config.update(config)
        
        pipeline_start_time = time.time()
        logger.info("Starting automated integration test pipeline...")
        
        try:
            # 1. 设置测试环境
            if not self._setup_environment():
                logger.error("Failed to setup test environment")
                return False
            
            # 2. 生成测试数据
            if not self._generate_test_data():
                logger.error("Failed to generate test data")
                return False
            
            # 3. 执行集成测试
            test_results = self._run_integration_tests()
            if not test_results:
                logger.error("Failed to run integration tests")
                return False
            
            # 4. 生成测试报告
            if not self._generate_test_reports(test_results):
                logger.error("Failed to generate test reports")
                return False
            
            # 5. 清理测试环境
            if not self._cleanup_environment():
                logger.warning("Failed to cleanup test environment")
                # 不返回False，因为测试本身可能已经成功
            
            pipeline_end_time = time.time()
            logger.info(f"Automated integration test pipeline completed successfully in {pipeline_end_time - pipeline_start_time:.2f} seconds")
            return True
            
        except Exception as e:
            logger.error(f"Error in automated integration test pipeline: {e}")
            # 尝试清理环境
            self._cleanup_environment()
            return False
    
    def _setup_environment(self) -> bool:
        """
        设置测试环境
        
        Returns:
            bool: 环境设置是否成功
        """
        logger.info("Setting up test environment...")
        setup_start_time = time.time()
        
        try:
            # 运行环境管理脚本
            env_manager_script = self.scripts_dir / "test_environment_manager.py"
            if not env_manager_script.exists():
                logger.warning("Environment manager script not found, skipping environment setup")
                return True
            
            cmd = [
                sys.executable,
                str(env_manager_script),
                "setup",
                "--services"
            ] + self.pipeline_config["environment"]["services"]
            
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=self.pipeline_config["environment"]["setup_timeout"]
            )
            
            if result.returncode != 0:
                logger.error(f"Environment setup failed: {result.stderr}")
                return False
            
            setup_end_time = time.time()
            logger.info(f"Test environment setup completed in {setup_end_time - setup_start_time:.2f} seconds")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("Environment setup timed out")
            return False
        except Exception as e:
            logger.error(f"Error setting up test environment: {e}")
            return False
    
    def _generate_test_data(self) -> bool:
        """
        生成测试数据
        
        Returns:
            bool: 数据生成是否成功
        """
        logger.info("Generating test data...")
        generation_start_time = time.time()
        
        try:
            # 运行数据管理脚本
            data_manager_script = self.scripts_dir / "test_data_manager.py"
            if not data_manager_script.exists():
                logger.warning("Data manager script not found, skipping data generation")
                return True
            
            cmd = [
                sys.executable,
                str(data_manager_script),
                "comprehensive",
                "--size",
                self.pipeline_config["data"]["dataset_size"]
            ]
            
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=self.pipeline_config["data"]["generation_timeout"]
            )
            
            if result.returncode != 0:
                logger.error(f"Test data generation failed: {result.stderr}")
                return False
            
            generation_end_time = time.time()
            logger.info(f"Test data generation completed in {generation_end_time - generation_start_time:.2f} seconds")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("Test data generation timed out")
            return False
        except Exception as e:
            logger.error(f"Error generating test data: {e}")
            return False
    
    def _run_integration_tests(self) -> dict:
        """
        执行集成测试
        
        Returns:
            dict: 测试结果
        """
        logger.info("Running integration tests...")
        test_start_time = time.time()
        
        try:
            # 构建pytest命令
            cmd = [
                sys.executable,
                "-m",
                "pytest",
                str(self.tests_dir),
                "-v",
                "--tb=short",
                "--cov=src",
                "--cov-report=xml:coverage.xml",
                "--junitxml=test_results.xml"
            ]
            
            # 添加测试类型标记
            test_types = self.pipeline_config["testing"]["test_types"]
            if "system" in test_types:
                cmd.extend(["-m", "system_integration"])
            elif "performance" in test_types:
                cmd.extend(["-m", "performance"])
            elif "all" not in test_types:
                # 添加自定义标记
                markers = " or ".join(test_types)
                cmd.extend(["-m", markers])
            
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=self.pipeline_config["testing"]["execution_timeout"]
            )
            
            test_end_time = time.time()
            logger.info(f"Integration tests completed in {test_end_time - test_start_time:.2f} seconds")
            
            # 解析测试结果
            test_results = {
                "success": result.returncode == 0,
                "return_code": result.returncode,
                "execution_time": test_end_time - test_start_time,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "timestamp": datetime.now().isoformat()
            }
            
            # 保存测试结果
            results_file = self.reports_dir / "test_results.json"
            with open(results_file, "w", encoding="utf-8") as f:
                json.dump(test_results, f, indent=2, ensure_ascii=False)
            
            return test_results
            
        except subprocess.TimeoutExpired:
            logger.error("Integration tests timed out")
            return None
        except Exception as e:
            logger.error(f"Error running integration tests: {e}")
            return None
    
    def _generate_test_reports(self, test_results: dict) -> bool:
        """
        生成测试报告
        
        Args:
            test_results: 测试结果
            
        Returns:
            bool: 报告生成是否成功
        """
        logger.info("Generating test reports...")
        report_start_time = time.time()
        
        try:
            success = True
            
            # 生成HTML报告
            if self.pipeline_config["reporting"]["generate_html"]:
                report_generator_script = self.scripts_dir / "generate_test_report.py"
                if report_generator_script.exists():
                    cmd = [
                        sys.executable,
                        str(report_generator_script),
                        "html",
                        "--output",
                        str(self.reports_dir / "integration_test_report.html")
                    ]
                    
                    result = subprocess.run(
                        cmd,
                        cwd=self.project_root,
                        capture_output=True,
                        text=True
                    )
                    
                    if result.returncode != 0:
                        logger.error(f"HTML report generation failed: {result.stderr}")
                        success = False
                    else:
                        logger.info("HTML report generated successfully")
                else:
                    logger.warning("Report generator script not found, skipping HTML report generation")
            
            # 解析JUnit XML并生成详细报告
            junit_xml = self.project_root / "test_results.xml"
            if junit_xml.exists():
                report_generator_script = self.scripts_dir / "generate_test_report.py"
                if report_generator_script.exists():
                    cmd = [
                        sys.executable,
                        str(report_generator_script),
                        "parse-xml",
                        "--input",
                        str(junit_xml),
                        "--output",
                        str(self.reports_dir / "parsed_test_results.json")
                    ]
                    
                    result = subprocess.run(
                        cmd,
                        cwd=self.project_root,
                        capture_output=True,
                        text=True
                    )
                    
                    if result.returncode != 0:
                        logger.error(f"XML parsing failed: {result.stderr}")
                        success = False
                    else:
                        logger.info("JUnit XML parsed successfully")
            
            report_end_time = time.time()
            logger.info(f"Test reports generation completed in {report_end_time - report_start_time:.2f} seconds")
            return success
            
        except Exception as e:
            logger.error(f"Error generating test reports: {e}")
            return False
    
    def _cleanup_environment(self) -> bool:
        """
        清理测试环境
        
        Returns:
            bool: 环境清理是否成功
        """
        logger.info("Cleaning up test environment...")
        cleanup_start_time = time.time()
        
        try:
            # 运行环境管理脚本
            env_manager_script = self.scripts_dir / "test_environment_manager.py"
            if not env_manager_script.exists():
                logger.warning("Environment manager script not found, skipping environment cleanup")
                return True
            
            cmd = [
                sys.executable,
                str(env_manager_script),
                "teardown",
                "--services"
            ] + self.pipeline_config["environment"]["services"]
            
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=120  # 2分钟超时
            )
            
            if result.returncode != 0:
                logger.error(f"Environment cleanup failed: {result.stderr}")
                return False
            
            cleanup_end_time = time.time()
            logger.info(f"Test environment cleanup completed in {cleanup_end_time - cleanup_start_time:.2f} seconds")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("Environment cleanup timed out")
            return False
        except Exception as e:
            logger.error(f"Error cleaning up test environment: {e}")
            return False


def main() -> None:
    """主函数"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Automated Integration Test Pipeline")
    parser.add_argument(
        "--config",
        help="Pipeline configuration file (JSON)"
    )
    parser.add_argument(
        "--test-types",
        nargs="+",
        choices=["all", "system", "performance", "agent", "hsp", "memory", "training", "core"],
        default=["all"],
        help="Types of tests to run"
    )
    parser.add_argument(
        "--dataset-size",
        choices=["small", "medium", "large"],
        default="medium",
        help="Size of test dataset to generate"
    )
    parser.add_argument(
        "--no-environment-setup",
        action="store_true",
        help="Skip environment setup and teardown"
    )
    parser.add_argument(
        "--no-reporting",
        action="store_true",
        help="Skip report generation"
    )
    
    args = parser.parse_args()
    
    # 构建流水线配置
    pipeline_config = {
        "testing": {
            "test_types": args.test_types
        },
        "data": {
            "dataset_size": args.dataset_size
        }
    }
    
    if args.no_environment_setup:
        pipeline_config["environment"] = {"services": []}
    
    if args.no_reporting:
        pipeline_config["reporting"] = {
            "generate_html": False,
            "generate_performance": False
        }
    
    # 如果提供了配置文件，加载配置
    if args.config:
        try:
            with open(args.config, "r", encoding="utf-8") as f:
                config_from_file = json.load(f)
            pipeline_config.update(config_from_file)
        except Exception as e:
            print(f"Error loading configuration file: {e}")
            sys.exit(1)
    
    # 创建并运行流水线
    pipeline = AutomatedIntegrationTestPipeline()
    success = pipeline.run_pipeline(pipeline_config)
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()

# 添加pytest标记，防止被误认为测试类
AutomatedIntegrationTestPipeline.__test__ = False