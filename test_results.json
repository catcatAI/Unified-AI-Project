{
  "exit_code": 1,
  "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.12.10, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.10', 'Platform': 'Windows-11-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'langsmith': '0.4.5', 'asyncio': '1.0.0', 'cov': '6.2.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'timeout': '2.4.0'}}\nrootdir: D:\\Projects\\Unified-AI-Project\\apps\\backend\nconfigfile: pytest.ini\ntestpaths: tests\nplugins: anyio-4.9.0, langsmith-0.4.5, asyncio-1.0.0, cov-6.2.1, json-report-1.5.0, metadata-3.1.1, timeout-2.4.0\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ntimeout: 600.0s\ntimeout method: thread\ntimeout func_only: True\ncollecting ... collected 506 items\n\ntests/agents/test_audio_processing_agent.py::test_audio_processing_agent_init PASSED [  0%]\ntests/agents/test_audio_processing_agent.py::test_audio_processing_agent_perform_speech_recognition PASSED [  0%]\ntests/agents/test_audio_processing_agent.py::test_audio_processing_agent_classify_audio PASSED [  0%]\ntests/agents/test_audio_processing_agent.py::test_audio_processing_agent_enhance_audio PASSED [  0%]\ntests/agents/test_audio_processing_agent.py::test_audio_processing_agent_handle_task_request_speech_recognition PASSED [  0%]\ntests/agents/test_audio_processing_agent.py::test_audio_processing_agent_handle_task_request_unsupported_capability PASSED [  1%]\ntests/agents/test_base_agent.py::test_base_agent_init PASSED             [  1%]\ntests/agents/test_base_agent.py::test_base_agent_start_stop PASSED       [  1%]\ntests/agents/test_base_agent.py::test_base_agent_handle_task_request PASSED [  1%]\ntests/agents/test_creative_writing_agent.py::TestCreativeWritingAgent::test_initialization PASSED [  1%]\ntests/agents/test_creative_writing_agent.py::TestCreativeWritingAgent::test_handle_marketing_copy_request PASSED [  2%]\ntests/agents/test_creative_writing_agent.py::TestCreativeWritingAgent::test_handle_polish_text_request PASSED [  2%]\ntests/agents/test_creative_writing_agent.py::TestCreativeWritingAgent::test_unsupported_capability PASSED [  2%]\ntests/agents/test_data_analysis_agent.py::TestDataAnalysisAgent::test_handle_task_request_success PASSED [  2%]\ntests/agents/test_data_analysis_agent.py::TestDataAnalysisAgent::test_handle_task_request_tool_failure PASSED [  2%]\ntests/agents/test_data_analysis_agent.py::TestDataAnalysisAgent::test_initialization PASSED [  3%]\ntests/agents/test_knowledge_graph_agent.py::test_knowledge_graph_agent_init PASSED [  3%]\ntests/agents/test_knowledge_graph_agent.py::test_knowledge_graph_agent_perform_entity_linking PASSED [  3%]\ntests/agents/test_knowledge_graph_agent.py::test_knowledge_graph_agent_extract_relationships PASSED [  3%]\ntests/agents/test_knowledge_graph_agent.py::test_knowledge_graph_agent_query_knowledge_graph PASSED [  3%]\ntests/agents/test_knowledge_graph_agent.py::test_knowledge_graph_agent_handle_task_request_entity_linking PASSED [  4%]\ntests/agents/test_knowledge_graph_agent.py::test_knowledge_graph_agent_handle_task_request_unsupported_capability PASSED [  4%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_analyze_tool_file_no_classes_or_functions PASSED [  4%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_analyze_tool_file_not_found PASSED [  4%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_analyze_tool_file_parsing_error PASSED [  4%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_analyze_tool_file_simple_class_and_function PASSED [  5%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_ambiguous_patterns FAILED [  5%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_direct_invalid_path FAILED [  5%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_direct_valid_path PASSED [  5%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_invalid_tools_directory FAILED [  5%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_name_not_found FAILED [  6%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_path_looks_like_path_but_not_found FAILED [  6%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_prefers_exact_over_pattern PASSED [  6%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_resolve_exact_name_dot_py PASSED [  6%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_resolve_suffix_tool_pattern PASSED [  6%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_resolve_tool_prefix_pattern PASSED [  7%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_list_tool_files PASSED [  7%]\ntests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_list_tool_files_non_existent_dir FAILED [  7%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_compress_decompress_cycle PASSED [  7%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_compression_idempotency PASSED [  7%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_compression_stats PASSED [  8%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_dict_input PASSED [  8%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_different_compression_algorithms PASSED [  8%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_dna_chain_functionality PASSED [  8%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_invalid_input_type_raises_error PASSED [  8%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_learning_mechanism PASSED [  9%]\ntests/core_ai/compression/test_alpha_deep_model.py::TestAlphaDeepModel::test_partial_data_handling PASSED [  9%]\ntests/core_ai/dialogue/test_dialogue_manager.py::test_get_simple_response_project_trigger PASSED [  9%]\ntests/core_ai/dialogue/test_dialogue_manager.py::test_get_simple_response_standard_flow PASSED [  9%]\ntests/core_ai/dialogue/test_dialogue_manager.py::test_start_session_greeting PASSED [  9%]\ntests/core_ai/dialogue/test_dialogue_manager.py::test_handle_incoming_hsp_task_result PASSED [ 10%]\ntests/core_ai/dialogue/test_dialogue_manager.py::test_get_simple_response_no_project_trigger PASSED [ 10%]\ntests/core_ai/dialogue/test_dialogue_manager.py::test_get_simple_response_tool_dispatch_success PASSED [ 10%]\ntests/core_ai/dialogue/test_dialogue_manager.py::test_get_simple_response_tool_dispatch_error PASSED [ 10%]\ntests/core_ai/dialogue/test_project_coordinator.py::test_handle_project_happy_path PASSED [ 10%]\ntests/core_ai/dialogue/test_project_coordinator.py::test_handle_project_decomposition_fails PASSED [ 11%]\ntests/core_ai/dialogue/test_project_coordinator.py::test_execute_task_graph_with_dependencies PASSED [ 11%]\ntests/core_ai/dialogue/test_project_coordinator.py::test_dispatch_single_subtask_agent_not_found PASSED [ 11%]\ntests/core_ai/dialogue/test_project_coordinator.py::test_dispatch_single_subtask_agent_launch_and_discovery PASSED [ 11%]\ntests/core_ai/dialogue/test_project_coordinator.py::test_wait_for_task_result_timeout PASSED [ 11%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_execute_formula PASSED [ 12%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_execute_formula_no_params PASSED [ 12%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_load_formulas_empty_list PASSED [ 12%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_load_formulas_file_not_found PASSED [ 12%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_load_formulas_malformed_json PASSED [ 12%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_load_formulas_valid_file PASSED [ 13%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_match_input_case_insensitive PASSED [ 13%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_match_input_disabled_formula PASSED [ 13%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_match_input_empty_input PASSED [ 13%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_match_input_no_match PASSED [ 13%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_match_input_priority PASSED [ 14%]\ntests/core_ai/formula_engine/test_formula_engine.py::TestFormulaEngine::test_match_input_simple_match PASSED [ 14%]\ntests/core_ai/language_models/test_daily_language_model.py::TestDailyLanguageModel::test_01_initialization PASSED [ 14%]\ntests/core_ai/language_models/test_daily_language_model.py::TestDailyLanguageModel::test_02_recognize_intent_calculate PASSED [ 14%]\ntests/core_ai/language_models/test_daily_language_model.py::TestDailyLanguageModel::test_03_recognize_intent_evaluate_logic PASSED [ 14%]\ntests/core_ai/language_models/test_daily_language_model.py::TestDailyLanguageModel::test_04_recognize_intent_translate_text PASSED [ 15%]\ntests/core_ai/language_models/test_daily_language_model.py::TestDailyLanguageModel::test_05_no_intent_recognized PASSED [ 15%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_01_initialization PASSED [ 15%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_02_simple_entity_extraction FAILED [ 15%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_03_no_entities_extraction PASSED [ 15%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_04_simple_svo_relationship PASSED [ 16%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_05_prep_object_relationship PASSED [ 16%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_06_noun_prep_noun_relationship_of FAILED [ 16%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_07_noun_of_noun_org_has_attribute FAILED [ 16%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_08_noun_of_noun_attribute_of FAILED [ 16%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_08a_entity_is_a_concept PASSED [ 16%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_09_possessive_relationship_entity_to_entity PASSED [ 17%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_10_possessive_relationship_entity_to_concept PASSED [ 17%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_11_matcher_located_in PASSED [ 17%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_12_matcher_works_for PASSED [ 17%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_13_matcher_person_is_ceo_of_org FAILED [ 17%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_14_matcher_person_is_founder_of_org FAILED [ 18%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_15_process_hsp_fact_content_nl FAILED [ 18%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_16_process_hsp_fact_content_semantic_triple_with_mapping FAILED [ 18%]\ntests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_17_process_hsp_fact_content_semantic_triple_no_mapping FAILED [ 18%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_add_and_get_antibody_roundtrip PASSED [ 18%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_add_antibody_success PASSED [ 19%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_get_incident_by_id_found PASSED [ 19%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_get_incident_by_id_not_found PASSED [ 19%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_get_learned_antibodies_filter_by_anomaly_type PASSED [ 19%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_get_learned_antibodies_filter_by_effectiveness PASSED [ 19%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_get_learned_antibodies_no_filters PASSED [ 20%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_by_anomaly_type PASSED [ 20%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_by_min_severity PASSED [ 20%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_by_status PASSED [ 20%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_by_tags_multiple_all_must_match PASSED [ 20%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_by_tags_single PASSED [ 21%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_by_time_window PASSED [ 21%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_combined_filters PASSED [ 21%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_empty_result PASSED [ 21%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_limit_and_sorting PASSED [ 21%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_query_incidents_no_filters PASSED [ 22%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_store_and_get_incident_roundtrip PASSED [ 22%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_store_incident_missing_anomaly_event PASSED [ 22%]\ntests/core_ai/lis/test_ham_lis_cache.py::TestHAMLISCache::test_store_incident_success PASSED [ 22%]\ntests/core_ai/lis/test_tonal_repair_engine.py::TestTonalRepairEngine::test_repair_output PASSED [ 22%]\ntests/core_ai/memory/test_ham_chromadb_integration.py::test_01_store_experience_and_verify_chromadb_entry PASSED [ 23%]\ntests/core_ai/memory/test_ham_chromadb_integration.py::test_02_semantic_search_chromadb_first PASSED [ 23%]\ntests/core_ai/memory/test_ham_chromadb_integration.py::test_03_semantic_search_chromadb_failure_fallback PASSED [ 23%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_01_initialization_and_empty_store PASSED [ 23%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_02_store_and_recall_text_experience PASSED [ 23%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_03_store_and_recall_generic_data SKIPPED [ 24%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_04_persistence SKIPPED [ 24%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_05_recall_non_existent_memory PASSED [ 24%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_06_query_memory_keywords SKIPPED [ 24%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_07_query_memory_data_type SKIPPED [ 24%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_08_query_memory_date_range PASSED [ 25%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_09_empty_text_abstraction SKIPPED [ 25%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_10_encryption_decryption SKIPPED [ 25%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_11_checksum_verification SKIPPED [ 25%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_12_advanced_text_abstraction_placeholders SKIPPED [ 25%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_13_store_experience_simulated_disk_full PASSED [ 26%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_14_store_experience_simulated_lag_warning SKIPPED [ 26%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_15_store_experience_simulated_lag_critical SKIPPED [ 26%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_16_get_current_disk_usage_gb PASSED [ 26%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_17_query_core_memory_return_multiple_candidates PASSED [ 26%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_18_encryption_failure PASSED [ 27%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_19_disk_full_handling PASSED [ 27%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_20_delete_old_experiences PASSED [ 27%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_21_concurrent_access SKIPPED [ 27%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_22_recall_raw_gist PASSED [ 27%]\ntests/core_ai/memory/test_ham_memory_manager.py::test_23_rehydrate_with_relational_context SKIPPED [ 28%]\ntests/core_ai/meta_formulas/test_meta_formulas.py::TestMetaFormulas::test_errx PASSED [ 28%]\ntests/core_ai/meta_formulas/test_meta_formulas.py::TestMetaFormulas::test_meta_formula PASSED [ 28%]\ntests/core_ai/meta_formulas/test_meta_formulas.py::TestMetaFormulas::test_undefined_field PASSED [ 28%]\ntests/core_ai/personality/test_personality_manager.py::TestPersonalityManager::test_01_initialization_default_path PASSED [ 28%]\ntests/core_ai/personality/test_personality_manager.py::TestPersonalityManager::test_02_initialization_custom_path PASSED [ 29%]\ntests/core_ai/personality/test_personality_manager.py::TestPersonalityManager::test_03_load_personality PASSED [ 29%]\ntests/core_ai/personality/test_personality_manager.py::TestPersonalityManager::test_04_load_non_existent_profile PASSED [ 29%]\ntests/core_ai/personality/test_personality_manager.py::TestPersonalityManager::test_05_get_trait PASSED [ 29%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_init FAILED [ 29%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_process_capability_advertisement_new_and_update PASSED [ 30%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_process_capability_advertisement_missing_ids PASSED [ 30%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_get_capability_by_id PASSED [ 30%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_find_capabilities_no_filters PASSED [ 30%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_find_capabilities_by_id PASSED [ 30%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_find_capabilities_by_name PASSED [ 31%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_find_capabilities_by_tags PASSED [ 31%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_find_capabilities_by_min_trust PASSED [ 31%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_find_capabilities_sort_by_trust PASSED [ 31%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_find_capabilities_combined_filters_and_sort PASSED [ 31%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_staleness_checks PASSED [ 32%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_get_capability_by_id_staleness_direct_variant PASSED [ 32%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_get_all_capabilities PASSED [ 32%]\ntests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_get_all_capabilities_async PASSED [ 32%]\ntests/core_ai/test_agent_manager.py::TestAgentManager::test_initialization PASSED [ 32%]\ntests/core_ai/test_agent_manager.py::TestAgentManager::test_launch_agent_already_running PASSED [ 33%]\ntests/core_ai/test_agent_manager.py::TestAgentManager::test_launch_agent_not_found PASSED [ 33%]\ntests/core_ai/test_agent_manager.py::TestAgentManager::test_launch_agent_success PASSED [ 33%]\ntests/core_ai/test_agent_manager.py::TestAgentManager::test_shutdown_agent_not_running PASSED [ 33%]\ntests/core_ai/test_agent_manager.py::TestAgentManager::test_shutdown_agent_success PASSED [ 33%]\ntests/core_ai/test_agent_manager.py::TestAgentManager::test_shutdown_all_agents PASSED [ 33%]\ntests/core_ai/test_crisis_system.py::TestCrisisSystem::test_01_initialization PASSED [ 34%]\ntests/core_ai/test_crisis_system.py::TestCrisisSystem::test_02_assess_normal_input PASSED [ 34%]\ntests/core_ai/test_crisis_system.py::TestCrisisSystem::test_03_assess_crisis_input_escalation PASSED [ 34%]\ntests/core_ai/test_crisis_system.py::TestCrisisSystem::test_04_resolve_crisis PASSED [ 34%]\ntests/core_ai/test_crisis_system.py::TestCrisisSystem::test_05_trigger_protocol PASSED [ 34%]\ntests/core_ai/test_crisis_system.py::TestCrisisSystem::test_06_sentiment_analysis_and_logging PASSED [ 35%]\ntests/core_ai/test_deep_mapper.py::TestDeepMapper::test_map PASSED       [ 35%]\ntests/core_ai/test_deep_mapper.py::TestDeepMapper::test_reverse_map PASSED [ 35%]\ntests/core_ai/test_emotion_system.py::TestEmotionSystem::test_01_initialization PASSED [ 35%]\ntests/core_ai/test_emotion_system.py::TestEmotionSystem::test_02_update_emotion_based_on_input PASSED [ 35%]\ntests/core_ai/test_emotion_system.py::TestEmotionSystem::test_03_get_current_emotion_expression PASSED [ 36%]\ntests/core_ai/test_time_system.py::TestTimeSystem::test_01_initialization PASSED [ 36%]\ntests/core_ai/test_time_system.py::TestTimeSystem::test_02_get_current_time PASSED [ 36%]\ntests/core_ai/test_time_system.py::TestTimeSystem::test_03_get_formatted_current_time PASSED [ 36%]\ntests/core_ai/test_time_system.py::TestTimeSystem::test_04_set_reminder PASSED [ 36%]\ntests/core_ai/test_time_system.py::TestTimeSystem::test_05_check_due_reminders PASSED [ 37%]\ntests/core_ai/test_time_system.py::TestTimeSystem::test_06_get_time_of_day_segment PASSED [ 37%]\ntests/creation/test_creation_engine.py::TestCreationEngine::test_create_model PASSED [ 37%]\ntests/creation/test_creation_engine.py::TestCreationEngine::test_create_tool PASSED [ 37%]\ntests/economy/test_economy_db.py::TestEconomyDB::test_get_user_balance_new_user PASSED [ 37%]\ntests/economy/test_economy_db.py::TestEconomyDB::test_init_db PASSED     [ 38%]\ntests/economy/test_economy_db.py::TestEconomyDB::test_update_user_balance_add PASSED [ 38%]\ntests/economy/test_economy_db.py::TestEconomyDB::test_update_user_balance_debit_insufficient_funds PASSED [ 38%]\ntests/economy/test_economy_db.py::TestEconomyDB::test_update_user_balance_debit_sufficient_funds PASSED [ 38%]\ntests/economy/test_economy_db.py::TestEconomyDB::test_update_user_balance_multiple_updates PASSED [ 38%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_get_balance PASSED [ 39%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_initialization PASSED [ 39%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_process_transaction_insufficient_funds PASSED [ 39%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_process_transaction_missing_data PASSED [ 39%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_process_transaction_success PASSED [ 39%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_update_rules_invalid_allowance PASSED [ 40%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_update_rules_invalid_tax_rate_high PASSED [ 40%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_update_rules_invalid_tax_rate_low PASSED [ 40%]\ntests/economy/test_economy_manager.py::TestEconomyManager::test_update_rules_valid PASSED [ 40%]\ntests/evaluation/test_evaluation_db.py::TestEvaluationDB::test_add_evaluation PASSED [ 40%]\ntests/evaluation/test_evaluation_db.py::TestEvaluationDB::test_get_average_metrics PASSED [ 41%]\ntests/evaluation/test_evaluation_db.py::TestEvaluationDB::test_get_average_metrics_no_data PASSED [ 41%]\ntests/evaluation/test_evaluation_db.py::TestEvaluationDB::test_get_evaluations_by_task_id PASSED [ 41%]\ntests/evaluation/test_evaluation_db.py::TestEvaluationDB::test_init_db PASSED [ 41%]\ntests/evaluation/test_evaluator.py::TestEvaluator::test_evaluate PASSED  [ 41%]\ntests/evaluation/test_task_evaluator.py::TestMetricsCalculator::test_calculate_objective_metrics_failure PASSED [ 42%]\ntests/evaluation/test_task_evaluator.py::TestMetricsCalculator::test_calculate_objective_metrics_success PASSED [ 42%]\ntests/evaluation/test_task_evaluator.py::TestFeedbackAnalyzer::test_analyze_mixed_feedback PASSED [ 42%]\ntests/evaluation/test_task_evaluator.py::TestFeedbackAnalyzer::test_analyze_negative_feedback PASSED [ 42%]\ntests/evaluation/test_task_evaluator.py::TestFeedbackAnalyzer::test_analyze_neutral_feedback PASSED [ 42%]\ntests/evaluation/test_task_evaluator.py::TestFeedbackAnalyzer::test_analyze_positive_feedback PASSED [ 43%]\ntests/evaluation/test_task_evaluator.py::TestFeedbackAnalyzer::test_analyze_usability_feedback PASSED [ 43%]\ntests/evaluation/test_task_evaluator.py::TestTaskExecutionEvaluator::test_evaluate_task_execution_failure PASSED [ 43%]\ntests/evaluation/test_task_evaluator.py::TestTaskExecutionEvaluator::test_evaluate_task_execution_no_expected_output PASSED [ 43%]\ntests/evaluation/test_task_evaluator.py::TestTaskExecutionEvaluator::test_generate_improvements_error PASSED [ 43%]\ntests/evaluation/test_task_evaluator.py::TestTaskExecutionEvaluator::test_generate_improvements_general PASSED [ 44%]\ntests/evaluation/test_task_evaluator.py::TestTaskExecutionEvaluator::test_generate_improvements_performance PASSED [ 44%]\ntests/evaluation/test_task_evaluator.py::TestTaskExecutionEvaluator::test_generate_improvements_quality PASSED [ 44%]\ntests/fragmenta/test_fragmenta_orchestrator.py::TestFragmentaOrchestrator::test_process_complex_task PASSED [ 44%]\ntests/game/test_assets.py::test_asset_loading PASSED                     [ 44%]\ntests/game/test_assets.py::test_specific_assets_loaded PASSED            [ 45%]\ntests/game/test_main.py::test_game_initialization PASSED                 [ 45%]\ntests/game/test_npcs.py::test_npc_creation PASSED                        [ 45%]\ntests/game/test_npcs.py::test_npc_creation_invalid_id PASSED             [ 45%]\ntests/hsp/test_hsp_ack_retry.py::test_scenario_1_successful_ack PASSED   [ 45%]\ntests/hsp/test_hsp_ack_retry.py::test_scenario_2_delayed_ack PASSED      [ 46%]\ntests/hsp/test_hsp_ack_retry.py::test_scenario_3_no_ack_max_retries PASSED [ 46%]\ntests/hsp/test_hsp_ack_retry.py::test_scenario_4_hsp_unavailable_fallback_success PASSED [ 46%]\ntests/hsp/test_hsp_ack_retry.py::test_scenario_5_hsp_unavailable_fallback_failure PASSED [ 46%]\ntests/hsp/test_hsp_connector.py::test_hsp_connector_init PASSED          [ 46%]\ntests/hsp/test_hsp_connector.py::test_hsp_connector_connect_disconnect_mock_mode PASSED [ 47%]\ntests/hsp/test_hsp_connector.py::test_hsp_connector_publish_message FAILED [ 47%]\ntests/hsp/test_hsp_integration.py::TestHSPFactPublishing::test_learning_manager_publishes_fact_via_hsp FAILED [ 47%]\ntests/hsp/test_hsp_integration.py::TestHSPFactConsumption::test_main_ai_consumes_nl_fact_and_updates_kg_check_trust_influence FAILED [ 47%]\ntests/hsp/test_hsp_integration.py::TestHSPFactConsumption::test_main_ai_consumes_structured_fact_updates_kg FAILED [ 47%]\ntests/hsp/test_hsp_integration.py::TestHSPFactConsumption::test_ca_semantic_mapping_for_hsp_structured_fact FAILED [ 48%]\ntests/hsp/test_hsp_integration.py::TestHSPTaskDelegation::test_dm_delegates_task_to_specialist_ai_and_gets_result FAILED [ 48%]\ntests/hsp/test_hsp_integration.py::TestHSPTaskDelegation::test_dm_handles_hsp_task_failure_and_falls_back FAILED [ 48%]\ntests/hsp/test_hsp_simple.py::test_hsp_connector_init PASSED             [ 48%]\ntests/hsp/test_hsp_simple.py::test_publish_fact FAILED                   [ 48%]\ntests/hsp/test_mqtt_broker_startup.py::test_broker_and_connector_startup PASSED [ 49%]\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_complex_project_with_dag FAILED [ 49%]\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_dynamic_agent_launch FAILED [ 49%]\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_failing_subtask FAILED [ 49%]\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_no_dependencies FAILED [ 49%]\ntests/integration/test_atlassian_integration.py::TestAtlassianIntegration::test_configure_atlassian_success PASSED [ 50%]\ntests/integration/test_atlassian_integration.py::TestAtlassianIntegration::test_get_atlassian_status_without_configuration PASSED [ 50%]\ntests/integration/test_atlassian_integration.py::TestAtlassianIntegration::test_get_jira_projects_without_configuration FAILED [ 50%]\ntests/integration/test_atlassian_integration.py::TestAtlassianIntegration::test_create_confluence_page_without_enhanced_bridge FAILED [ 50%]\ntests/integration/test_end_to_end_project_flow.py::test_full_project_flow_with_real_agent FAILED [ 50%]\ntests/integration/test_knowledge_update.py::TestKnowledgeUpdate::test_knowledge_update PASSED [ 50%]\ntests/integration/test_learning_and_trust.py::TestLearningAndTrustIntegration::test_duplicate_fact_increments_corroboration PASSED [ 51%]\ntests/integration/test_learning_and_trust.py::TestLearningAndTrustIntegration::test_fact_from_low_trust_source_is_discarded PASSED [ 51%]\ntests/integration/test_learning_and_trust.py::TestLearningAndTrustIntegration::test_fact_from_high_trust_source_is_accepted PASSED [ 51%]\ntests/integration/test_self_improvement.py::TestSelfImprovement::test_self_improvement PASSED [ 51%]\ntests/integrations/test_atlassian_api.py::TestAtlassianAPI::test_atlassian_config_model PASSED [ 51%]\ntests/integrations/test_atlassian_api.py::TestAtlassianAPI::test_atlassian_cli_bridge_initialization PASSED [ 52%]\ntests/integrations/test_atlassian_api.py::TestAtlassianAPI::test_get_jira_projects PASSED [ 52%]\ntests/integrations/test_atlassian_api.py::TestAtlassianAPI::test_enhanced_atlassian_bridge_initialization FAILED [ 52%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_create_confluence_page PASSED [ 52%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_search_jira_issues PASSED [ 52%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_update_confluence_page PASSED [ 53%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_get_confluence_spaces PASSED [ 53%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_get_jira_projects PASSED [ 53%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_error_handling PASSED [ 53%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_content_formatting PASSED [ 53%]\ntests/integrations/test_atlassian_bridge.py::TestAtlassianBridge::test_jira_field_mapping PASSED [ 54%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_endpoint_config_loading PASSED [ 54%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_successful_primary_endpoint PASSED [ 54%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_fallback_to_backup_endpoint PASSED [ 54%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_all_endpoints_fail PASSED [ 54%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_cache_functionality PASSED [ 55%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_expired_cache PASSED [ 55%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_offline_queue PASSED [ 55%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_offline_queue_processing PASSED [ 55%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_health_monitoring PASSED [ 55%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_force_endpoint_switch PASSED [ 56%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_health_status PASSED [ 56%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_confluence_operations_with_fallback PASSED [ 56%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_jira_operations_with_fallback PASSED [ 56%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_cache_with_get_requests PASSED [ 56%]\ntests/integrations/test_atlassian_bridge_fallback.py::TestAtlassianBridgeFallback::test_offline_mode_with_expired_cache PASSED [ 57%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_agent_initialization PASSED [ 57%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_capability_parameters PASSED [ 57%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_agent_start_stop PASSED [ 57%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_code_analysis_task PASSED [ 57%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_documentation_generation_task PASSED [ 58%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_issue_tracking_task PASSED [ 58%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_task_submission_and_processing PASSED [ 58%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_task_error_handling PASSED [ 58%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_metrics_update PASSED [ 58%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_status_reporting PASSED [ 59%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_task_history PASSED [ 59%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_report_formatting PASSED [ 59%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgent::test_unsupported_capability PASSED [ 59%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgentIntegration::test_full_workflow PASSED [ 59%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgentIntegration::test_real_confluence_integration PASSED [ 60%]\ntests/integrations/test_rovo_dev_agent.py::TestRovoDevAgentIntegration::test_real_jira_integration PASSED [ 60%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_state_persistence PASSED [ 60%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_state_recovery PASSED [ 60%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_task_timeout_handling PASSED [ 60%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_task_retry_mechanism PASSED [ 61%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_degraded_mode_activation PASSED [ 61%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_degraded_mode_exit PASSED [ 61%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_error_rate_monitoring PASSED [ 61%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_retryable_error_detection PASSED [ 61%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_task_error_handling PASSED [ 62%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_recovery_status PASSED [ 62%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_startup_failure_recovery PASSED [ 62%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_health_monitoring_loop PASSED [ 62%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_checkpoint_functionality PASSED [ 62%]\ntests/integrations/test_rovo_dev_agent_recovery.py::TestRovoDevAgentRecovery::test_task_health_monitoring PASSED [ 63%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_connector_initialization PASSED [ 63%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_auth_headers PASSED [ 63%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_context_manager PASSED [ 63%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_authentication_success PASSED [ 63%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_authentication_failure PASSED [ 64%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_make_request_success PASSED [ 64%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_make_request_error PASSED [ 64%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_caching_mechanism PASSED [ 64%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_connection_testing PASSED [ 64%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_connection_testing_with_failures PASSED [ 65%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_user_info_with_caching PASSED [ 65%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_health_check PASSED [ 65%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_session_management PASSED [ 65%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_semaphore_initialization PASSED [ 65%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_concurrent_request_limiting PASSED [ 66%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_base_url_construction PASSED [ 66%]\ntests/integrations/test_rovo_dev_connector.py::TestRovoDevConnector::test_missing_credentials PASSED [ 66%]\ntests/mcp/test_context7_connector.py::TestContext7Config::test_config_creation PASSED [ 66%]\ntests/mcp/test_context7_connector.py::TestContext7Config::test_config_defaults PASSED [ 66%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_connector_initialization PASSED [ 66%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_connect_success PASSED [ 67%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_disconnect PASSED [ 67%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_send_context PASSED [ 67%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_request_context PASSED [ 67%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_collaborate_with_model PASSED [ 67%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_compress_context PASSED [ 68%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_connection_required_error PASSED [ 68%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_capabilities_discovery PASSED [ 68%]\ntests/mcp/test_context7_connector.py::TestContext7MCPConnector::test_unhandled_message_type PASSED [ 68%]\ntests/mcp/test_context7_connector.py::TestUnifiedAIMCPIntegration::test_dialogue_manager_integration PASSED [ 68%]\ntests/mcp/test_context7_connector.py::TestUnifiedAIMCPIntegration::test_ham_memory_integration PASSED [ 69%]\ntests/mcp/test_context7_connector.py::TestUnifiedAIMCPIntegration::test_context_mapping PASSED [ 69%]\ntests/mcp/test_context7_connector.py::TestMCPTypeValidation::test_mcp_message_structure PASSED [ 69%]\ntests/mcp/test_context7_connector.py::TestMCPTypeValidation::test_mcp_response_structure PASSED [ 69%]\ntests/mcp/test_context7_connector.py::TestMCPTypeValidation::test_mcp_capability_structure PASSED [ 69%]\ntests/mcp/test_context7_connector.py::TestContext7Performance::test_concurrent_context_requests PASSED [ 70%]\ntests/mcp/test_context7_connector.py::TestContext7Performance::test_large_context_handling PASSED [ 70%]\ntests/mcp/test_mcp_connector.py::test_mcp_connector_initialization <- ..\\..\\packages\\backend\\tests\\mcp\\test_mcp_connector.py PASSED [ 70%]\ntests/mcp/test_mcp_connector.py::test_connect_and_disconnect <- ..\\..\\packages\\backend\\tests\\mcp\\test_mcp_connector.py PASSED [ 70%]\ntests/mcp/test_mcp_connector.py::test_send_command <- ..\\..\\packages\\backend\\tests\\mcp\\test_mcp_connector.py PASSED [ 70%]\ntests/mcp/test_mcp_connector.py::test_on_message_callback <- ..\\..\\packages\\backend\\tests\\mcp\\test_mcp_connector.py PASSED [ 71%]\ntests/meta/test_adaptive_learning_controller.py::TestPerformanceTracker::test_analyze_trend_degrading PASSED [ 71%]\ntests/meta/test_adaptive_learning_controller.py::TestPerformanceTracker::test_analyze_trend_empty_history PASSED [ 71%]\ntests/meta/test_adaptive_learning_controller.py::TestPerformanceTracker::test_analyze_trend_improving PASSED [ 71%]\ntests/meta/test_adaptive_learning_controller.py::TestPerformanceTracker::test_analyze_trend_stable PASSED [ 71%]\ntests/meta/test_adaptive_learning_controller.py::TestStrategySelector::test_select_degrading_complex_task PASSED [ 72%]\ntests/meta/test_adaptive_learning_controller.py::TestStrategySelector::test_select_degrading_simple_task PASSED [ 72%]\ntests/meta/test_adaptive_learning_controller.py::TestStrategySelector::test_select_improving_trend PASSED [ 72%]\ntests/meta/test_adaptive_learning_controller.py::TestStrategySelector::test_select_stable_high_confidence_simple_task PASSED [ 72%]\ntests/meta/test_adaptive_learning_controller.py::TestStrategySelector::test_select_stable_low_confidence_complex_task PASSED [ 72%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningController::test_adapt_learning_strategy PASSED [ 73%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningController::test_optimize_parameters_degrading_performance PASSED [ 73%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningController::test_optimize_parameters_improving_performance PASSED [ 73%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningController::test_update_strategy_effectiveness_decrease_and_schedule PASSED [ 73%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningController::test_update_strategy_effectiveness_increase PASSED [ 73%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningControllerComplexityAssessment::test_assess_task_complexity_complex_keywords PASSED [ 74%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningControllerComplexityAssessment::test_assess_task_complexity_default PASSED [ 74%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningControllerComplexityAssessment::test_assess_task_complexity_from_context PASSED [ 74%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningControllerComplexityAssessment::test_assess_task_complexity_mixed_keywords_and_context PASSED [ 74%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningControllerComplexityAssessment::test_assess_task_complexity_research_keywords PASSED [ 74%]\ntests/meta/test_adaptive_learning_controller.py::TestAdaptiveLearningControllerComplexityAssessment::test_assess_task_complexity_simple_keywords PASSED [ 75%]\ntests/meta/test_learning_log_db.py::TestLearningLogDB::test_add_log_entry PASSED [ 75%]\ntests/meta/test_learning_log_db.py::TestLearningLogDB::test_get_all_log_entries PASSED [ 75%]\ntests/meta/test_learning_log_db.py::TestLearningLogDB::test_get_all_log_entries_empty PASSED [ 75%]\ntests/meta/test_learning_log_db.py::TestLearningLogDB::test_init_db PASSED [ 75%]\ntests/modules_fragmenta/test_element_layer.py::TestElementLayer::test_01_initialization <- ..\\..\\packages\\backend\\tests\\modules_fragmenta\\test_element_layer.py PASSED [ 76%]\ntests/modules_fragmenta/test_element_layer.py::TestElementLayer::test_02_process_elements_placeholder <- ..\\..\\packages\\backend\\tests\\modules_fragmenta\\test_element_layer.py PASSED [ 76%]\ntests/modules_fragmenta/test_vision_tone_inverter.py::TestVisionToneInverter::test_01_initialization <- ..\\..\\packages\\backend\\tests\\modules_fragmenta\\test_vision_tone_inverter.py PASSED [ 76%]\ntests/modules_fragmenta/test_vision_tone_inverter.py::TestVisionToneInverter::test_02_invert_visual_tone_placeholder <- ..\\..\\packages\\backend\\tests\\modules_fragmenta\\test_vision_tone_inverter.py PASSED [ 76%]\ntests/pet/test_pet_manager.py::TestPetManager::test_get_current_state PASSED [ 76%]\ntests/pet/test_pet_manager.py::TestPetManager::test_handle_interaction_feed PASSED [ 77%]\ntests/pet/test_pet_manager.py::TestPetManager::test_handle_interaction_pet PASSED [ 77%]\ntests/pet/test_pet_manager.py::TestPetManager::test_handle_interaction_play PASSED [ 77%]\ntests/pet/test_pet_manager.py::TestPetManager::test_handle_interaction_rest PASSED [ 77%]\ntests/pet/test_pet_manager.py::TestPetManager::test_handle_interaction_unknown PASSED [ 77%]\ntests/pet/test_pet_manager.py::TestPetManager::test_initialization PASSED [ 78%]\ntests/pet/test_pet_manager.py::TestPetManager::test_update_behavior_invalid_key PASSED [ 78%]\ntests/pet/test_pet_manager.py::TestPetManager::test_update_behavior_invalid_type PASSED [ 78%]\ntests/pet/test_pet_manager.py::TestPetManager::test_update_behavior_valid PASSED [ 78%]\ntests/pet/test_pet_manager.py::TestPetManager::test_update_state_over_time PASSED [ 78%]\ntests/search/test_search_engine.py::TestSearchEngine::test_search <- ..\\..\\packages\\backend\\tests\\search\\test_search_engine.py PASSED [ 79%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_find_element_by_id PASSED [ 79%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_get_action_log_and_clear PASSED [ 79%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_get_virtual_state PASSED [ 79%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_initialization_defaults PASSED [ 79%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_load_and_get_virtual_ui PASSED [ 80%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_keyboard_command_press_keys_with_target PASSED [ 80%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_keyboard_command_special_key_with_target PASSED [ 80%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_keyboard_command_type_string PASSED [ 80%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_keyboard_command_type_string_no_target PASSED [ 80%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_mouse_command_click_simulation PASSED [ 81%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_mouse_command_hover PASSED [ 81%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_mouse_command_move_clamps_coordinates PASSED [ 81%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_mouse_command_move_relative_to_window PASSED [ 81%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_mouse_command_scroll PASSED [ 81%]\ntests/services/test_ai_virtual_input_service.py::TestAIVirtualInputService::test_process_mouse_command_unimplemented_action_logs PASSED [ 82%]\ntests/services/test_audio_service.py::TestAudioService::test_01_initialization_placeholder PASSED [ 82%]\ntests/services/test_audio_service.py::TestAudioService::test_02_speech_to_text_placeholder PASSED [ 82%]\ntests/services/test_audio_service.py::TestAudioService::test_03_text_to_speech_placeholder FAILED [ 82%]\ntests/services/test_audio_service.py::TestAudioService::test_04_speech_to_text_with_sentiment_analysis SKIPPED [ 82%]\ntests/services/test_hot_endpoints.py::test_hot_status_endpoint_basic_structure PASSED [ 83%]\ntests/services/test_llm_interface.py::TestLLMInterface::test_01_initialization_placeholder <- ..\\..\\packages\\backend\\tests\\services\\test_llm_interface.py PASSED [ 83%]\ntests/services/test_llm_interface.py::TestLLMInterface::test_02_generate_response_placeholder <- ..\\..\\packages\\backend\\tests\\services\\test_llm_interface.py PASSED [ 83%]\ntests/services/test_llm_interface.py::TestLLMInterface::test_03_list_models_placeholder <- ..\\..\\packages\\backend\\tests\\services\\test_llm_interface.py PASSED [ 83%]\ntests/services/test_main_api_server.py::test_read_main PASSED            [ 83%]\ntests/services/test_main_api_server.py::test_get_status PASSED           [ 83%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_list_hsp_services_empty PASSED [ 84%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_list_hsp_services_with_advertisements PASSED [ 84%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_request_hsp_task_success PASSED [ 84%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_request_hsp_task_capability_not_found PASSED [ 84%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_get_hsp_task_status_pending PASSED [ 84%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_get_hsp_task_status_completed_from_ham PASSED [ 85%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_get_hsp_task_status_failed_from_ham PASSED [ 85%]\ntests/services/test_main_api_server_hsp.py::TestHSPEndpoints::test_get_hsp_task_status_unknown PASSED [ 85%]\ntests/services/test_node_services.py::TestNodeServicesIntegration::test_placeholder_node_services_integration <- ..\\..\\packages\\backend\\tests\\services\\test_node_services.py PASSED [ 85%]\ntests/services/test_resource_awareness_service.py::TestResourceAwarenessService::test_default_config_path_loading_if_file_exists PASSED [ 85%]\ntests/services/test_resource_awareness_service.py::TestResourceAwarenessService::test_load_incomplete_yaml_falls_back_to_default PASSED [ 86%]\ntests/services/test_resource_awareness_service.py::TestResourceAwarenessService::test_load_malformed_yaml_falls_back_to_default PASSED [ 86%]\ntests/services/test_resource_awareness_service.py::TestResourceAwarenessService::test_load_non_existent_config_falls_back_to_default PASSED [ 86%]\ntests/services/test_resource_awareness_service.py::TestResourceAwarenessService::test_load_valid_config PASSED [ 86%]\ntests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_execution_error_in_tool FAILED [ 86%]\ntests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_non_json_output FAILED [ 87%]\ntests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_stderr_output FAILED [ 87%]\ntests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_successful_execution FAILED [ 87%]\ntests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_timeout_expired FAILED [ 87%]\ntests/services/test_vision_service.py::TestVisionService::test_01_initialization_placeholder PASSED [ 87%]\ntests/services/test_vision_service.py::TestVisionService::test_02_analyze_image PASSED [ 88%]\ntests/services/test_vision_service.py::TestVisionService::test_03_compare_images PASSED [ 88%]\ntests/shared/test_key_manager.py::TestUnifiedKeyManager::test_demo_mode_detection_from_env PASSED [ 88%]\ntests/shared/test_key_manager.py::TestUnifiedKeyManager::test_generate_ham_key_in_demo_mode PASSED [ 88%]\ntests/shared/test_key_manager.py::TestUnifiedKeyManager::test_generate_ham_key_not_in_demo_mode PASSED [ 88%]\ntests/shared/test_key_manager.py::TestUnifiedKeyManager::test_get_key_from_environment PASSED [ 89%]\ntests/shared/test_key_manager.py::TestUnifiedKeyManager::test_get_key_in_demo_mode PASSED [ 89%]\ntests/shared/test_key_manager.py::TestUnifiedKeyManager::test_get_key_not_in_environment PASSED [ 89%]\ntests/shared/test_key_manager.py::TestUnifiedKeyManager::test_not_in_demo_mode PASSED [ 89%]\ntests/shared/utils/test_cleanup_utils.py::TestCleanupUtils::test_cleanup_cache_data PASSED [ 89%]\ntests/shared/utils/test_cleanup_utils.py::TestCleanupUtils::test_cleanup_temp_files PASSED [ 90%]\ntests/temp_async_test.py::test_find_capabilities_no_filters PASSED       [ 90%]\ntests/test_basic.py::test_python_version PASSED                          [ 90%]\ntests/test_basic.py::test_basic_imports PASSED                           [ 90%]\ntests/test_basic.py::test_project_structure PASSED                       [ 90%]\ntests/test_basic.py::test_slow_example PASSED                            [ 91%]\ntests/test_basic.py::test_environment_variables PASSED                   [ 91%]\ntests/test_dependency_manager.py::TestDependencyManager::test_all_dependencies_unavailable PASSED [ 91%]\ntests/test_dependency_manager.py::TestDependencyManager::test_config_file_not_found PASSED [ 91%]\ntests/test_dependency_manager.py::TestDependencyManager::test_dependency_report_generation PASSED [ 91%]\ntests/test_dependency_manager.py::TestDependencyManager::test_fallback_dependency_used PASSED [ 92%]\ntests/test_dependency_manager.py::TestDependencyManager::test_fallbacks_disabled_in_production PASSED [ 92%]\ntests/test_dependency_manager.py::TestDependencyManager::test_import_name_mapping PASSED [ 92%]\ntests/test_dependency_manager.py::TestDependencyManager::test_primary_dependency_available PASSED [ 92%]\ntests/test_hsp_connector.py::test_hsp_connector_init PASSED              [ 92%]\ntests/test_hsp_connector.py::test_hsp_connector_connect_disconnect_mock_mode PASSED [ 93%]\ntests/test_hsp_connector.py::test_hsp_connector_publish_message FAILED   [ 93%]\ntests/test_hsp_connector.py::test_hsp_connector_subscribe_and_receive PASSED [ 93%]\ntests/test_hsp_connector.py::test_hsp_connector_ack_sending FAILED       [ 93%]\ntests/test_hsp_connector.py::test_hsp_connector_on_connect_callback PASSED [ 93%]\ntests/test_hsp_connector.py::test_hsp_connector_on_disconnect_callback PASSED [ 94%]\ntests/test_hsp_connector.py::test_hsp_connector_register_specific_callbacks PASSED [ 94%]\ntests/test_simple.py::test_simple <- ..\\..\\packages\\backend\\tests\\test_simple.py PASSED [ 94%]\ntests/tools/test_code_understanding_tool.py::TestCodeUnderstandingTool::test_describe_tool_found <- ..\\..\\packages\\backend\\tests\\tools\\test_code_understanding_tool.py PASSED [ 94%]\ntests/tools/test_code_understanding_tool.py::TestCodeUnderstandingTool::test_describe_tool_not_found <- ..\\..\\packages\\backend\\tests\\tools\\test_code_understanding_tool.py PASSED [ 94%]\ntests/tools/test_code_understanding_tool.py::TestCodeUnderstandingTool::test_describe_tool_structure_with_no_docstrings_or_params <- ..\\..\\packages\\backend\\tests\\tools\\test_code_understanding_tool.py PASSED [ 95%]\ntests/tools/test_code_understanding_tool.py::TestCodeUnderstandingTool::test_execute_describe_tool_missing_tool_name <- ..\\..\\packages\\backend\\tests\\tools\\test_code_understanding_tool.py PASSED [ 95%]\ntests/tools/test_code_understanding_tool.py::TestCodeUnderstandingTool::test_execute_unknown_action <- ..\\..\\packages\\backend\\tests\\tools\\test_code_understanding_tool.py PASSED [ 95%]\ntests/tools/test_code_understanding_tool.py::TestCodeUnderstandingTool::test_list_tools_no_tools_found <- ..\\..\\packages\\backend\\tests\\tools\\test_code_understanding_tool.py PASSED [ 95%]\ntests/tools/test_code_understanding_tool.py::TestCodeUnderstandingTool::test_list_tools_success <- ..\\..\\packages\\backend\\tests\\tools\\test_code_understanding_tool.py PASSED [ 95%]\ntests/tools/test_logic_model.py::TestLogicModelComponents::test_01_logic_data_generator PASSED [ 96%]\ntests/tools/test_logic_model.py::TestLogicModelComponents::test_02_logic_parser_eval PASSED [ 96%]\ntests/tools/test_logic_model.py::TestLogicModelComponents::test_03_logic_model_nn_structure_and_helpers SKIPPED [ 96%]\ntests/tools/test_logic_model.py::TestLogicModelComponents::test_04_logic_tool_interface PASSED [ 96%]\ntests/tools/test_logic_model.py::TestLogicModelComponents::test_05_tool_dispatcher_logic_routing PASSED [ 96%]\ntests/tools/test_math_model.py::TestMathModelComponents::test_data_generator_csv PASSED [ 97%]\ntests/tools/test_math_model.py::TestMathModelComponents::test_data_generator_json PASSED [ 97%]\ntests/tools/test_math_model.py::TestMathModelComponents::test_extract_arithmetic_problem PASSED [ 97%]\ntests/tools/test_math_model.py::TestMathModelComponents::test_math_tool_calculate_model_unavailable PASSED [ 97%]\ntests/tools/test_math_model.py::TestMathModelComponents::test_model_build_and_char_maps SKIPPED [ 97%]\ntests/tools/test_math_model.py::TestMathModelComponents::test_tool_dispatcher_math_routing PASSED [ 98%]\ntests/tools/test_parameter_extractor.py::TestParameterExtractor::test_download_model_parameters <- ..\\..\\packages\\backend\\tests\\tools\\test_parameter_extractor.py PASSED [ 98%]\ntests/tools/test_parameter_extractor.py::TestParameterExtractor::test_load_parameters_to_model <- ..\\..\\packages\\backend\\tests\\tools\\test_parameter_extractor.py PASSED [ 98%]\ntests/tools/test_parameter_extractor.py::TestParameterExtractor::test_map_parameters <- ..\\..\\packages\\backend\\tests\\tools\\test_parameter_extractor.py PASSED [ 98%]\ntests/tools/test_tool_dispatcher_logging.py::test_tool_dispatcher_action_policy_logged_smoke PASSED [ 98%]\ntests/tools/test_translation_model.py::TestTranslationModelComponents::test_01_load_dictionary <- ..\\..\\packages\\backend\\tests\\tools\\test_translation_model.py PASSED [ 99%]\ntests/tools/test_translation_model.py::TestTranslationModelComponents::test_02_detect_language <- ..\\..\\packages\\backend\\tests\\tools\\test_translation_model.py PASSED [ 99%]\ntests/tools/test_translation_model.py::TestTranslationModelComponents::test_03_translate_function <- ..\\..\\packages\\backend\\tests\\tools\\test_translation_model.py PASSED [ 99%]\ntests/tools/test_translation_model.py::TestTranslationModelComponents::test_04_request_model_upgrade_hook <- ..\\..\\packages\\backend\\tests\\tools\\test_translation_model.py PASSED [ 99%]\ntests/tools/test_translation_model.py::TestTranslationModelComponents::test_05_tool_dispatcher_translation_routing <- ..\\..\\packages\\backend\\tests\\tools\\test_translation_model.py PASSED [ 99%]\ntests/tools/test_translation_model.py::TestTranslationModelComponents::test_06_dictionary_load_failure <- ..\\..\\packages\\backend\\tests\\tools\\test_translation_model.py PASSED [100%]\n\n================================== FAILURES ===================================\n_____ TestLightweightCodeModel.test_get_tool_structure_ambiguous_patterns _____\ntests\\core_ai\\code_understanding\\test_lightweight_code_model.py:270: in test_get_tool_structure_ambiguous_patterns\n    with self.assertLogs(logger='src.core_ai.code_understanding.lightweight_code_model', level='WARNING') as cm:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\_log.py:84: in __exit__\n    self._raiseFailure(\nE   AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\n------------------------------ Captured log call ------------------------------\nWARNING  apps.backend.src.core_ai.code_understanding.lightweight_code_model:lightweight_code_model.py:326 Ambiguous tool name 'ambiguous_pattern' (base: 'ambiguous_pattern'). Found multiple pattern matches in C:\\Users\\catai\\AppData\\Local\\Temp\\tmpbpbd00dm: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\tmpbpbd00dm\\\\ambiguous_pattern_tool.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\tmpbpbd00dm\\\\tool_ambiguous_pattern.py']. Please provide a more specific name or direct path.\n____ TestLightweightCodeModel.test_get_tool_structure_direct_invalid_path _____\ntests\\core_ai\\code_understanding\\test_lightweight_code_model.py:205: in test_get_tool_structure_direct_invalid_path\n    with self.assertLogs(logger='src.core_ai.code_understanding.lightweight_code_model', level='WARNING') as cm:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\_log.py:84: in __exit__\n    self._raiseFailure(\nE   AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\n------------------------------ Captured log call ------------------------------\nWARNING  apps.backend.src.core_ai.code_understanding.lightweight_code_model:lightweight_code_model.py:285 Input 'C:\\Users\\catai\\AppData\\Local\\Temp\\tmpdv_7wcbx\\non_existent_tool.py' appears to be a path but was not found or is not a file.\n__ TestLightweightCodeModel.test_get_tool_structure_invalid_tools_directory ___\ntests\\core_ai\\code_understanding\\test_lightweight_code_model.py:287: in test_get_tool_structure_invalid_tools_directory\n    with self.assertLogs(logger='src.core_ai.code_understanding.lightweight_code_model', level='WARNING') as init_cm:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\_log.py:84: in __exit__\n    self._raiseFailure(\nE   AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\n------------------------------ Captured log call ------------------------------\nWARNING  apps.backend.src.core_ai.code_understanding.lightweight_code_model:lightweight_code_model.py:45 Tools directory 'path_that_does_not_exist_at_all_xyz' does not exist or is not a directory.\n_______ TestLightweightCodeModel.test_get_tool_structure_name_not_found _______\ntests\\core_ai\\code_understanding\\test_lightweight_code_model.py:277: in test_get_tool_structure_name_not_found\n    with self.assertLogs(logger='src.core_ai.code_understanding.lightweight_code_model', level='WARNING') as cm:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\_log.py:84: in __exit__\n    self._raiseFailure(\nE   AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\n------------------------------ Captured log call ------------------------------\nWARNING  apps.backend.src.core_ai.code_understanding.lightweight_code_model:lightweight_code_model.py:336 Could not resolve tool 'completely_non_existent_tool_name' to a Python file in 'C:\\Users\\catai\\AppData\\Local\\Temp\\tmp5pcgajt6' using supported conventions, nor as a direct path.\n_ TestLightweightCodeModel.test_get_tool_structure_path_looks_like_path_but_not_found _\ntests\\core_ai\\code_understanding\\test_lightweight_code_model.py:217: in test_get_tool_structure_path_looks_like_path_but_not_found\n    with self.assertLogs(logger='src.core_ai.code_understanding.lightweight_code_model', level='WARNING') as cm:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\_log.py:84: in __exit__\n    self._raiseFailure(\nE   AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\n------------------------------ Captured log call ------------------------------\nWARNING  apps.backend.src.core_ai.code_understanding.lightweight_code_model:lightweight_code_model.py:285 Input 'some_dir/non_existent_tool.py' appears to be a path but was not found or is not a file.\n_______ TestLightweightCodeModel.test_list_tool_files_non_existent_dir ________\ntests\\core_ai\\code_understanding\\test_lightweight_code_model.py:61: in test_list_tool_files_non_existent_dir\n    with self.assertLogs(logger='src.core_ai.code_understanding.lightweight_code_model', level='WARNING') as cm:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\_log.py:84: in __exit__\n    self._raiseFailure(\nE   AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\n------------------------------ Captured log call ------------------------------\nWARNING  apps.backend.src.core_ai.code_understanding.lightweight_code_model:lightweight_code_model.py:45 Tools directory 'non_existent_dir_for_list_test/' does not exist or is not a directory.\n_________ TestContentAnalyzerModule.test_02_simple_entity_extraction __________\ntests\\core_ai\\learning\\test_content_analyzer_module.py:60: in test_02_simple_entity_extraction\n    self.assertEqual(nx_graph.number_of_nodes(), len(kg_data[\"entities\"]))\nE   AssertionError: 5 != 4\n---------------------------- Captured stdout call -----------------------------\nDEBUG: Created is_a relationship: ent_apple_inc__4af4a2fe --is_a--> ent_concept_company_d39f4b30\nDEBUG: Created is_a relationship: ent_steve_jobs_2b9525db --is_a--> ent_person_cb92cbab\n______ TestContentAnalyzerModule.test_06_noun_prep_noun_relationship_of _______\ntests\\core_ai\\learning\\test_content_analyzer_module.py:204: in test_06_noun_prep_noun_relationship_of\n    self.assertTrue(typed_dict_rel_found, \"Expected 'founder of' type relationship not found between Apple and Steve Jobs.\")\nE   AssertionError: False is not true : Expected 'founder of' type relationship not found between Apple and Steve Jobs.\n---------------------------- Captured stdout call -----------------------------\nDEBUG: Processing PERSON_IS_TITLE_OF_ORG pattern. Start: 1, End: 7\nDEBUG: Pattern span: 'Jobs was a founder of Apple'\nDEBUG: Skipping relationship creation because person_entity=False and org_entity=False\nDEBUG: Created is_a relationship: ent_steve_jobs_1b5aab9f --is_a--> ent_founder_f86a4a2e\n______ TestContentAnalyzerModule.test_07_noun_of_noun_org_has_attribute _______\ntests\\core_ai\\learning\\test_content_analyzer_module.py:312: in test_07_noun_of_noun_org_has_attribute\n    self.assertTrue(found_relationship, \"Expected 'has_ceo' or similar relationship not found between Google and Sundar Pichai.\")\nE   AssertionError: False is not true : Expected 'has_ceo' or similar relationship not found between Google and Sundar Pichai.\n---------------------------- Captured stdout call -----------------------------\nDEBUG: Processing PERSON_IS_TITLE_OF_ORG pattern. Start: 1, End: 7\nDEBUG: Pattern span: 'Pichai is the CEO of Google'\nDEBUG: Skipping relationship creation because person_entity=False and org_entity=False\nDEBUG: Created is_a relationship: ent_sundar_pichai_91160e99 --is_a--> ent_ceo_f766d405\n_________ TestContentAnalyzerModule.test_08_noun_of_noun_attribute_of _________\ntests\\core_ai\\learning\\test_content_analyzer_module.py:408: in test_08_noun_of_noun_attribute_of\n    self.assertTrue(found_has_capital, \"Expected 'has_capital' or similar relationship not found between France and capital.\")\nE   AssertionError: False is not true : Expected 'has_capital' or similar relationship not found between France and capital.\n---------------------------- Captured stdout call -----------------------------\nDEBUG: Created is_a relationship: ent_paris_0f86814a --is_a--> ent_concept_capital_f6f5871c\n_______ TestContentAnalyzerModule.test_13_matcher_person_is_ceo_of_org ________\ntests\\core_ai\\learning\\test_content_analyzer_module.py:766: in test_13_matcher_person_is_ceo_of_org\n    self.assertRelationshipInGraph(kg_data, nx_graph,\ntests\\core_ai\\learning\\test_content_analyzer_module.py:247: in assertRelationshipInGraph\n    self.assertTrue(found_in_kg_direct or (allow_reverse and found_in_kg_reverse),\nE   AssertionError: False is not true : Relationship Microsoft -> Satya Nadella (type: has_ceo) not found in KG relationships. (Allow reverse: False)\n---------------------------- Captured stdout call -----------------------------\nDEBUG: Processing PERSON_IS_TITLE_OF_ORG pattern. Start: 1, End: 6\nDEBUG: Pattern span: 'Nadella is CEO of Microsoft'\nDEBUG: Skipping relationship creation because person_entity=False and org_entity=False\nDEBUG: Created is_a relationship: ent_satya_nadella_52c63aaa --is_a--> ent_ceo_0718178c\n_____ TestContentAnalyzerModule.test_14_matcher_person_is_founder_of_org ______\ntests\\core_ai\\learning\\test_content_analyzer_module.py:790: in test_14_matcher_person_is_founder_of_org\n    self.assertEntityInGraph(\"ExampleCorp\", \"ORG\", kg_data) # Assuming ExampleCorp is tagged as ORG\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests\\core_ai\\learning\\test_content_analyzer_module.py:27: in assertEntityInGraph\n    self.assertTrue(found, msg or f\"Entity '{label}' (type: {entity_type}) not found in graph entities.\")\nE   AssertionError: False is not true : Entity 'ExampleCorp' (type: ORG) not found in graph entities.\n---------------------------- Captured stdout call -----------------------------\nDEBUG: Processing PERSON_IS_TITLE_OF_ORG pattern. Start: 1, End: 6\nDEBUG: Pattern span: 'Doe is Founder of ExampleCorp'\nDEBUG: Skipping relationship creation because person_entity=False and org_entity=False\nDEBUG: Created is_a relationship: ent_jane_doe_681300a0 --is_a--> ent_founder_of_examplecorp_e64cd322\n________ TestContentAnalyzerModule.test_15_process_hsp_fact_content_nl ________\ntests\\core_ai\\learning\\test_content_analyzer_module.py:845: in test_15_process_hsp_fact_content_nl\n    self.assertEqual(self.analyzer.graph.nodes[sirius_node_id][\"hsp_source_info\"][\"origin_fact_id\"], hsp_payload[\"id\"])\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: list indices must be integers or slices, not str\n---------------------------- Captured stdout call -----------------------------\nDEBUG: Created is_a relationship: ent_sirius_ef46ccd8 --is_a--> ent_star_269c41a9\n_ TestContentAnalyzerModule.test_16_process_hsp_fact_content_semantic_triple_with_mapping _\ntests\\core_ai\\learning\\test_content_analyzer_module.py:899: in test_16_process_hsp_fact_content_semantic_triple_with_mapping\n    self.assertEqual(processed_triple_info[\"subject_id\"], expected_s_id) # type: ignore\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AssertionError: 'http://example.org/entity/Paris' != 'cai_instance:ex_Paris'\nE   - http://example.org/entity/Paris\nE   + cai_instance:ex_Paris\n_ TestContentAnalyzerModule.test_17_process_hsp_fact_content_semantic_triple_no_mapping _\ntests\\core_ai\\learning\\test_content_analyzer_module.py:946: in test_17_process_hsp_fact_content_semantic_triple_no_mapping\n    self.assertTrue(processed_triple_info[\"object_id\"].startswith(\"literal_somevalue\")) # type: ignore\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AssertionError: False is not true\n____________________ TestServiceDiscoveryModule.test_init _____________________\ntests\\core_ai\\service_discovery\\test_service_discovery_module.py:31: in test_init\n    assert f\"Staleness threshold: {ServiceDiscoveryModule.DEFAULT_STALENESS_THRESHOLD_SECONDS} seconds\" in caplog.text\nE   AssertionError: assert 'Staleness threshold: 600 seconds' in ''\nE    +  where '' = <_pytest.logging.LogCaptureFixture object at 0x00000271D1CCC1A0>.text\n_____________________ test_hsp_connector_publish_message ______________________\ntests\\hsp\\test_hsp_connector.py:89: in test_hsp_connector_publish_message\n    mock_mqtt_client.publish.assert_awaited_once_with(topic, json.dumps(envelope).encode('utf-8'), qos=1)\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py:2362: in assert_awaited_once_with\n    raise AssertionError(msg)\nE   AssertionError: Expected publish to have been awaited once. Awaited 0 times.\n_____ TestHSPFactPublishing.test_learning_manager_publishes_fact_via_hsp ______\ntests\\hsp\\test_hsp_integration.py:600: in test_learning_manager_publishes_fact_via_hsp\n    assert len(self.received_facts_on_peer) > 0, \"Peer A did not receive any facts.\"\nE   AssertionError: Peer A did not receive any facts.\nE   assert 0 > 0\nE    +  where 0 = len([])\nE    +    where [] = <apps.backend.tests.hsp.test_hsp_integration.TestHSPFactPublishing object at 0x00000271D0289D90>.received_facts_on_peer\n---------------------------- Captured stdout setup ----------------------------\nOntology mapping file not found at D:\\Projects\\Unified-AI-Project\\apps\\backend\\src\\core_ai\\learning\\..\\..\\configs\\ontology_mappings.yaml. Using empty mappings.\nContentAnalyzerModule initialized successfully.\nTrustManager initialized. Default score for new AIs: 0.5\nPersonalityManager: Successfully loaded personality 'miko_base'.\nPersonalityManager initialized. Profiles dir: D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\personality_profiles\nLearningManager initialized for AI ID 'did:hsp:test_ai_main_001'. Min fact store conf: 0.7, share conf: 0.8, HSP store conf: 0.55\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D1A3DD90>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D1A3E450>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nLearningManager: Storing user-derived fact - Type: learned_fact_general_statement, Content: {'subject': 'Berlin', 'relation': 'is_capital_of', 'object': 'Germany'}, Meta: {'record_id': 'lfact_0489e7c94c934603a905fe0247eeb34b', 'timestamp': '2025-09-03T05:54:19.882230', 'user_id': 'test_user_pub', 'session_id': 'test_session_pub', 'source_interaction_ref': 'test_interaction_pub_01', 'fact_type': 'general_statement', 'confidence': 0.99, 'source_text': 'Berlin is the capital of Germany.'}\nLearningManager: Stored fact 'lfact_0489e7c94c934603a905fe0247eeb34b' (HAM ID 'mock_ham_test_1')\nLearningManager: Publishing fact hspfact_did_hsp_test_ai_main_001_2e7f49 to HSP topic 'hsp/knowledge/facts/test_general'\nFinal received facts on peer A: []\n---------------------------- Captured log teardown ----------------------------\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-209' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-211' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\n_ TestHSPFactConsumption.test_main_ai_consumes_nl_fact_and_updates_kg_check_trust_influence _\ntests\\hsp\\test_hsp_integration.py:656: in test_main_ai_consumes_nl_fact_and_updates_kg_check_trust_influence\n    assert len(ham_manager_fixture.memory_store) > 0, \"HAM memory store should not be empty after processing high trust peer fact\"\nE   AssertionError: HAM memory store should not be empty after processing high trust peer fact\nE   assert 0 > 0\nE    +  where 0 = len({})\nE    +    where {} = <apps.backend.tests.hsp.test_hsp_integration.MockHAM object at 0x00000271D1A3EE40>.memory_store\n---------------------------- Captured stdout setup ----------------------------\nTrustManager initialized. Default score for new AIs: 0.5\nPersonalityManager: Successfully loaded personality 'miko_base'.\nPersonalityManager initialized. Profiles dir: D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\personality_profiles\nLearningManager initialized for AI ID 'did:hsp:test_ai_main_001'. Min fact store conf: 0.7, share conf: 0.8, HSP store conf: 0.55\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D3AE1040>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D3AE09E0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D3AE0410>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D3AE20C0>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EB3290>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EB3920>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EB3E90>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D1A80110>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D1A82F00>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nTrustManager: Trust score for 'did:hsp:test_ai_peer_A_002' (scope: general) SET to 0.900.\nHAM memory store contents: {}\n---------------------------- Captured log teardown ----------------------------\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-230' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-232' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-234' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-236' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-241' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-243' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-245' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-247' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-249' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\n___ TestHSPFactConsumption.test_main_ai_consumes_structured_fact_updates_kg ___\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:520: in wait_for\n    return await fut\n           ^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\locks.py:212: in wait\n    await fut\nE   asyncio.exceptions.CancelledError\n\nThe above exception was the direct cause of the following exception:\ntests\\hsp\\test_hsp_integration.py:744: in test_main_ai_consumes_structured_fact_updates_kg\n    await asyncio.wait_for(done_event.wait(), timeout=10.0)\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:519: in wait_for\n    async with timeouts.timeout(timeout):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\timeouts.py:115: in __aexit__\n    raise TimeoutError from exc_val\nE   TimeoutError\n---------------------------- Captured stdout setup ----------------------------\nTrustManager initialized. Default score for new AIs: 0.5\nPersonalityManager: Successfully loaded personality 'miko_base'.\nPersonalityManager initialized. Profiles dir: D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\personality_profiles\nLearningManager initialized for AI ID 'did:hsp:test_ai_main_001'. Min fact store conf: 0.7, share conf: 0.8, HSP store conf: 0.55\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F04B00>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F05130>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F05700>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F05D00>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F06360>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F069F0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F07020>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nTrustManager: Trust score for 'did:hsp:test_ai_peer_A_002' (scope: general) SET to 0.900.\n---------------------------- Captured log teardown ----------------------------\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-273' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-275' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-277' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-279' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-281' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-283' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-285' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\n___ TestHSPFactConsumption.test_ca_semantic_mapping_for_hsp_structured_fact ___\ntests\\hsp\\test_hsp_integration.py:807: in test_ca_semantic_mapping_for_hsp_structured_fact\n    assert len(content_analyzer_module_fixture.graph.nodes()) > 0, \"ContentAnalyzerModule graph was not updated\"\nE   AssertionError: ContentAnalyzerModule graph was not updated\nE   assert 0 > 0\nE    +  where 0 = len(NodeView(()))\nE    +    where NodeView(()) = NodeView(())()\nE    +      where NodeView(()) = <networkx.classes.digraph.DiGraph object at 0x00000271D1B3CFE0>.nodes\nE    +        where <networkx.classes.digraph.DiGraph object at 0x00000271D1B3CFE0> = <apps.backend.src.core_ai.learning.content_analyzer_module.ContentAnalyzerModule object at 0x00000271D1B3D0A0>.graph\n---------------------------- Captured stdout setup ----------------------------\nTrustManager initialized. Default score for new AIs: 0.5\nPersonalityManager: Successfully loaded personality 'miko_base'.\nPersonalityManager initialized. Profiles dir: D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\personality_profiles\nLearningManager initialized for AI ID 'did:hsp:test_ai_main_001'. Min fact store conf: 0.7, share conf: 0.8, HSP store conf: 0.55\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E684D0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EFA0F0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EF9130>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F06D50>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F05880>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F04F50>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F06780>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F05640>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D1B5B170>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nTrustManager: Trust score for 'did:hsp:test_ai_peer_A_002' (scope: general) SET to 0.900.\n---------------------------- Captured log teardown ----------------------------\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-314' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-316' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-318' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-320' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-322' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-324' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-326' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-328' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-330' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\n_ TestHSPTaskDelegation.test_dm_delegates_task_to_specialist_ai_and_gets_result _\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:520: in wait_for\n    return await fut\n           ^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\locks.py:212: in wait\n    await fut\nE   asyncio.exceptions.CancelledError\n\nThe above exception was the direct cause of the following exception:\ntests\\hsp\\test_hsp_integration.py:342: in wait_for_event\n    await asyncio.wait_for(event.wait(), timeout)\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:519: in wait_for\n    async with timeouts.timeout(timeout):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\timeouts.py:115: in __aexit__\n    raise TimeoutError from exc_val\nE   TimeoutError\n\nDuring handling of the above exception, another exception occurred:\ntests\\hsp\\test_hsp_integration.py:985: in test_dm_delegates_task_to_specialist_ai_and_gets_result\n    await wait_for_event(task_received_event, timeout=10.0)\ntests\\hsp\\test_hsp_integration.py:344: in wait_for_event\n    pytest.fail(f\"Event wait timed out after {timeout} seconds\")\nE   Failed: Event wait timed out after 10.0 seconds\n---------------------------- Captured stdout setup ----------------------------\nTrustManager initialized. Default score for new AIs: 0.5\nPersonalityManager: Successfully loaded personality 'miko_base'.\nPersonalityManager initialized. Profiles dir: D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\personality_profiles\nLearningManager initialized for AI ID 'did:hsp:test_ai_main_001'. Min fact store conf: 0.7, share conf: 0.8, HSP store conf: 0.55\nDailyLanguageModel: Initialized with LLMInterface.\nCsvTool initialized.\nImageGenerationTool initialized.\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E941D0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7D0A0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7D6A0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7DCD0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7E300>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7E930>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7EF60>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7F590>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4E7FBC0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52BC230>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52BC860>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nDEBUG: InternalBus.publish_async - Channel: hsp.external.capability_advertisement, Message: {'hsp_envelope_version': '0.1', 'message_id': '1dbb0931-5f21-4684-b964-b03fb083e630', 'correlation_id': None, 'sender_ai_id': 'did:hsp:test_ai_peer_A_002', 'recipient_ai_id': 'all', 'timestamp_sent': '2025-09-02T21:54:39.576702+00:00', 'message_type': 'HSP::CapabilityAdvertisement_v0.1', 'protocol_version': '0.1', 'communication_pattern': 'publish', 'security_parameters': None, 'qos_parameters': {'requires_ack': False, 'priority': 'medium'}, 'routing_info': None, 'payload_schema_uri': 'file:///D:/Projects/Unified-AI-Project/apps/backend/schemas/HSP_CapabilityAdvertisement_v0.1.schema.json', 'payload': {'capability_id': 'advanced_weather_forecast', 'name': 'advanced_weather_forecast', 'description': 'Provides detailed 7-day weather forecasts for any location.', 'ai_id': 'did:hsp:test_ai_peer_A_002', 'input_schema_example': {'type': 'object', 'properties': {'location': {'type': 'string'}}}, 'output_schema_example': {'type': 'object', 'properties': {'forecast': {'type': 'string'}}}, 'version': '1.0', 'availability_status': 'online', 'tags': ['weather', 'forecast']}}\nKnown capabilities in SDM: {'advanced_weather_forecast': ({'capability_id': 'advanced_weather_forecast', 'name': 'advanced_weather_forecast', 'description': 'Provides detailed 7-day weather forecasts for any location.', 'ai_id': 'did:hsp:test_ai_peer_A_002', 'input_schema_example': {'type': 'object', 'properties': {'location': {'type': 'string'}}}, 'output_schema_example': {'type': 'object', 'properties': {'forecast': {'type': 'string'}}}, 'version': '1.0', 'availability_status': 'online', 'tags': ['weather', 'forecast']}, datetime.datetime(2025, 9, 2, 21, 54, 39, 577734, tzinfo=datetime.timezone.utc))}\nFound capabilities: [{'capability_id': 'advanced_weather_forecast', 'name': 'advanced_weather_forecast', 'description': 'Provides detailed 7-day weather forecasts for any location.', 'ai_id': 'did:hsp:test_ai_peer_A_002', 'input_schema_example': {'type': 'object', 'properties': {'location': {'type': 'string'}}}, 'output_schema_example': {'type': 'object', 'properties': {'forecast': {'type': 'string'}}}, 'version': '1.0', 'availability_status': 'online', 'tags': ['weather', 'forecast']}]\n---------------------------- Captured log teardown ----------------------------\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-363' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-365' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-367' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-369' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-371' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-373' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-375' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-377' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-379' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-381' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-383' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\n____ TestHSPTaskDelegation.test_dm_handles_hsp_task_failure_and_falls_back ____\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:520: in wait_for\n    return await fut\n           ^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\locks.py:212: in wait\n    await fut\nE   asyncio.exceptions.CancelledError\n\nThe above exception was the direct cause of the following exception:\ntests\\hsp\\test_hsp_integration.py:342: in wait_for_event\n    await asyncio.wait_for(event.wait(), timeout)\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:519: in wait_for\n    async with timeouts.timeout(timeout):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\timeouts.py:115: in __aexit__\n    raise TimeoutError from exc_val\nE   TimeoutError\n\nDuring handling of the above exception, another exception occurred:\ntests\\hsp\\test_hsp_integration.py:1080: in test_dm_handles_hsp_task_failure_and_falls_back\n    await wait_for_event(task_received_event, timeout=10.0)\ntests\\hsp\\test_hsp_integration.py:344: in wait_for_event\n    pytest.fail(f\"Event wait timed out after {timeout} seconds\")\nE   Failed: Event wait timed out after 10.0 seconds\n---------------------------- Captured stdout setup ----------------------------\nTrustManager initialized. Default score for new AIs: 0.5\nPersonalityManager: Successfully loaded personality 'miko_base'.\nPersonalityManager initialized. Profiles dir: D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\personality_profiles\nLearningManager initialized for AI ID 'did:hsp:test_ai_main_001'. Min fact store conf: 0.7, share conf: 0.8, HSP store conf: 0.55\nDailyLanguageModel: Initialized with LLMInterface.\nCsvTool initialized.\nImageGenerationTool initialized.\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F05BB0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F072F0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EFAC90>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EFAC30>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4EF9250>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52B58E0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52B5BB0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52B62A0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52B68A0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52B6EA0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52B74A0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D52B7AA0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D5294170>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nDEBUG: InternalBus.publish_async - Channel: hsp.external.capability_advertisement, Message: {'hsp_envelope_version': '0.1', 'message_id': 'beff2d49-f0c6-4c52-b91b-333bd7c87fab', 'correlation_id': None, 'sender_ai_id': 'did:hsp:test_ai_peer_A_002', 'recipient_ai_id': 'all', 'timestamp_sent': '2025-09-02T21:54:52.480772+00:00', 'message_type': 'HSP::CapabilityAdvertisement_v0.1', 'protocol_version': '0.1', 'communication_pattern': 'publish', 'security_parameters': None, 'qos_parameters': {'requires_ack': False, 'priority': 'medium'}, 'routing_info': None, 'payload_schema_uri': 'file:///D:/Projects/Unified-AI-Project/apps/backend/schemas/HSP_CapabilityAdvertisement_v0.1.schema.json', 'payload': {'capability_id': 'failing_service_274c4a9f5d2d4d299c5389c6161ea8d3', 'name': 'failing_service', 'description': 'A service that always fails.', 'ai_id': 'did:hsp:test_ai_peer_A_002', 'input_schema_example': {'type': 'object', 'properties': {'query': {'type': 'string'}}}, 'output_schema_example': {'type': 'object', 'properties': {'result': {'type': 'string'}}}, 'version': '1.0', 'availability_status': 'online', 'tags': ['test', 'failing']}}\n------------------------------ Captured log call ------------------------------\nERROR    root:project_coordinator.py:299 [ProjectCoordinator] Failed to parse LLM response as JSON: Expecting value: line 1 column 1 (char 0)\nERROR    root:project_coordinator.py:300 [ProjectCoordinator] Raw LLM output: I couldn't access the failing service, but here's a fallback response.\nWARNING  root:project_coordinator.py:320 [ProjectCoordinator] Falling back to keyword-based decomposition\n---------------------------- Captured log teardown ----------------------------\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-424' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-426' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-428' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-430' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-432' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-434' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-436' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-438' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-440' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-442' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-444' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-446' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\nERROR    asyncio:base_events.py:1833 Task was destroyed but it is pending!\ntask: <Task pending name='Task-448' coro=<IocpProactor.accept.<locals>.accept_coro() running at C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\windows_events.py:566> wait_for=<_OverlappedFuture cancelled>>\n______________________________ test_publish_fact ______________________________\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:520: in wait_for\n    return await fut\n           ^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\locks.py:212: in wait\n    await fut\nE   asyncio.exceptions.CancelledError\n\nThe above exception was the direct cause of the following exception:\ntests\\hsp\\test_hsp_simple.py:120: in test_publish_fact\n    await asyncio.wait_for(received_event.wait(), timeout=15.0) # 进一步增加超时时间\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:519: in wait_for\n    async with timeouts.timeout(timeout):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\timeouts.py:115: in __aexit__\n    raise TimeoutError from exc_val\nE   TimeoutError\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nPublish result: True\nInternal bus subscriptions: {'hsp.internal.fact': [<function test_publish_fact.<locals>.fact_handler at 0x00000271D52D5DA0>]}\nInternal bus has subscriptions attribute: True\nRegistered callbacks: []\nPublished messages in broker: []\nTimeout waiting for fact. Received facts so far: []\nPublished messages in broker: []\nInternal bus subscriptions at timeout: {'hsp.internal.fact': [<function test_publish_fact.<locals>.fact_handler at 0x00000271D52D5DA0>]}\nInternal bus has subscriptions attribute at timeout: True\nRegistered callbacks at timeout: []\n_________ TestAgentCollaboration.test_handle_complex_project_with_dag _________\ntests\\integration\\test_agent_collaboration.py:91: in test_handle_complex_project_with_dag\n    self.assertIn(\"Based on the data summary\", final_response)\nE   AssertionError: 'Based on the data summary' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\n---------------------------- Captured stdout setup ----------------------------\nCore Services: Initializing for AI ID: did:hsp:unified_ai_core_13213b\nCore Services: Hardware probe initialized\nCore Services: Applied standard deployment mode\nCore Services: AI Capability Score: 35.0/100\nCoreServices: Using TempMockHAM.\nPersonalityManager: Successfully loaded personality 'miko_base'.\nPersonalityManager initialized. Profiles dir: D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\personality_profiles\nTrustManager initialized. Default score for new AIs: 0.5\nMCPConnector for did:hsp:unified_ai_core_13213b connecting to localhost:1883\nAIVirtualInputService initialized in 'simulation_only' mode.\n  Initial virtual cursor: (0.5, 0.5)\nMCPConnector connected successfully.\nResourceAwarenessService initialized. Loaded profile: 'StandardAISandbox_v1' from 'D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs/simulated_resources.yaml'\nCore Services: WARNING - HSPConnector for did:hsp:unified_ai_core_13213b failed to connect to localhost:1883\nOntology mapping file not found at D:\\Projects\\Unified-AI-Project\\apps\\backend\\src\\core_ai\\learning\\..\\..\\configs\\ontology_mappings.yaml. Using empty mappings.\nContentAnalyzerModule initialized successfully.\nLearningManager initialized for AI ID 'did:hsp:unified_ai_core_13213b'. Min fact store conf: 0.6, share conf: 0.75, HSP store conf: 0.5\nEmotionSystem initialized. Default emotion: neutral\nTimeSystem initialized.\nFormulaEngine initialized. Attempted to load formulas from D:\\Projects\\Unified-AI-Project\\apps\\backend\\configs\\formula_configs\\default_formulas.json. Loaded 7 formulas.\nDailyLanguageModel: Initialized with LLMInterface.\nCsvTool initialized.\nImageGenerationTool initialized.\nCore Services: All services initialized (or attempted).\n----------------------------- Captured log setup ------------------------------\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\n[did:hsp:unified_ai_core_13213b] LearningManager: Processing project case for user query: 'analyze data.csv and write a marketing slogan'\n[did:hsp:unified_ai_core_13213b] Failed to decode JSON from strategy distillation output. Raw: Mock response (no API key)\n------------------------------ Captured log call ------------------------------\nWARNING  root:project_coordinator.py:241 [ProjectCoordinator] Using mock LLM response. Returning mock subtasks for testing.\n_______ TestAgentCollaboration.test_handle_project_dynamic_agent_launch _______\ntests\\integration\\test_agent_collaboration.py:216: in test_handle_project_dynamic_agent_launch\n    self.assertIn(\"Dynamically launched agent\", final_response)\nE   AssertionError: 'Dynamically launched agent' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\n---------------------------- Captured stdout call -----------------------------\n[did:hsp:unified_ai_core_13213b] LearningManager: Processing project case for user query: 'new agent'\n[did:hsp:unified_ai_core_13213b] Failed to decode JSON from strategy distillation output. Raw: Mock response (no API key)\n------------------------------ Captured log call ------------------------------\nWARNING  root:project_coordinator.py:241 [ProjectCoordinator] Using mock LLM response. Returning mock subtasks for testing.\n_________ TestAgentCollaboration.test_handle_project_failing_subtask __________\ntests\\integration\\test_agent_collaboration.py:170: in test_handle_project_failing_subtask\n    self.assertIn(\"The project failed\", final_response)\nE   AssertionError: 'The project failed' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\n---------------------------- Captured stdout call -----------------------------\n[did:hsp:unified_ai_core_13213b] LearningManager: Processing project case for user query: 'failing task'\n[did:hsp:unified_ai_core_13213b] Failed to decode JSON from strategy distillation output. Raw: Mock response (no API key)\n------------------------------ Captured log call ------------------------------\nWARNING  root:project_coordinator.py:241 [ProjectCoordinator] Using mock LLM response. Returning mock subtasks for testing.\n_________ TestAgentCollaboration.test_handle_project_no_dependencies __________\ntests\\integration\\test_agent_collaboration.py:140: in test_handle_project_no_dependencies\n    self.assertIn(\"Both tasks completed\", final_response)\nE   AssertionError: 'Both tasks completed' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\n---------------------------- Captured stdout call -----------------------------\n[did:hsp:unified_ai_core_13213b] LearningManager: Processing project case for user query: 'two tasks'\n[did:hsp:unified_ai_core_13213b] Failed to decode JSON from strategy distillation output. Raw: Mock response (no API key)\n------------------------------ Captured log call ------------------------------\nWARNING  root:project_coordinator.py:241 [ProjectCoordinator] Using mock LLM response. Returning mock subtasks for testing.\n-------------------------- Captured stdout teardown ---------------------------\nCore Services: Shutting down services...\nCore Services: AgentManager shut down.\nCore Services: HSPConnector disconnected.\nCore Services: LLMInterface closed.\nCore Services: HAM Memory Manager closed.\nMCPConnector disconnected.\nCore Services: MCPConnector disconnected (sync).\nCore Services: Shutdown process complete.\n---------------------------- Captured log teardown ----------------------------\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\nERROR    apps.backend.src.hsp.fallback.fallback_protocols:fallback_protocols.py:655 停止协议 http 失败: 'NoneType' object has no attribute '_stop_serving'\n____ TestAtlassianIntegration.test_get_jira_projects_without_configuration ____\ntests\\integration\\test_atlassian_integration.py:44: in test_get_jira_projects_without_configuration\n    assert response.status_code == 400\nE   assert 500 == 400\nE    +  where 500 = <Response [500 Internal Server Error]>.status_code\n------------------------------ Captured log call ------------------------------\nERROR    apps.backend.src.services.atlassian_api:atlassian_api.py:204 Failed to get Jira projects: 500: [WinError 2] 系統找不到指定的檔案。\n_ TestAtlassianIntegration.test_create_confluence_page_without_enhanced_bridge _\ntests\\integration\\test_atlassian_integration.py:61: in test_create_confluence_page_without_enhanced_bridge\n    assert response.status_code in [400, 500]\nE   assert 200 in [400, 500]\nE    +  where 200 = <Response [200 OK]>.status_code\n___________________ test_full_project_flow_with_real_agent ____________________\ntests\\integration\\test_end_to_end_project_flow.py:329: in test_full_project_flow_with_real_agent\n    assert \"The result is: 15\" in final_response\nE   assert 'The result is: 15' in \"TestCoordinator: Here's the result of your project request:\\n\\nTask failed: Could not find or launch an agent with capability 'data_analysis_v1'.\"\n---------------------------- Captured stdout setup ----------------------------\nTrustManager initialized. Default score for new AIs: 0.5\n----------------------------- Captured log setup ------------------------------\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F5B5C0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F5BAA0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F983B0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F989B0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F98FB0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F995E0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F99C10>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F9A210>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F9A840>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F9AE70>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F9B4A0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4F9BAD0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4FE8140>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4FE8770>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4FE8DA0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4FE93D0>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4FE9A00>\nERROR    asyncio:base_events.py:1833 Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x00000271D4FEA030>\nWARNING  apps.backend.src.hsp.connector:connector.py:1214 No capability provider registered. Cannot re-advertise capabilities.\n---------------------------- Captured stdout call -----------------------------\nTest agent manager script map: {'data_analysis_agent': 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-catai\\\\pytest-216\\\\test_full_project_flow_with_re0\\\\agents\\\\data_analysis_agent.py'}\nLooking for agent 'data_analysis_agent' in script map\nAttempting to launch agent: data_analysis_agent\nLaunch result PID: 3956\nAgent process: <Popen: returncode: None args: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\...>\n---------------------------- Captured stderr call -----------------------------\nTraceback (most recent call last):\n\n  File \"C:\\Users\\catai\\AppData\\Local\\Temp\\pytest-of-catai\\pytest-216\\test_full_project_flow_with_re0\\agents\\data_analysis_agent.py\", line 19, in <module>\n\n    from apps.backend.src.hsp.connector import HSPConnector\n\nModuleNotFoundError: No module named 'apps'\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\catai\\AppData\\Local\\Temp\\pytest-of-catai\\pytest-216\\test_full_project_flow_with_re0\\agents\\data_analysis_agent.py\", line 19, in <module>\n\n    from apps.backend.src.hsp.connector import HSPConnector\n\nModuleNotFoundError: No module named 'apps'\n\n------------------------------ Captured log call ------------------------------\nWARNING  root:agent_manager.py:167 [AgentManager] Agent 'data_analysis_agent' not ready within 10 seconds. Checking all capabilities...\nWARNING  root:agent_manager.py:124 [AgentManager] Agent 'data_analysis_agent' not found or not running.\n_______ TestAtlassianAPI.test_enhanced_atlassian_bridge_initialization ________\ntests\\integrations\\test_atlassian_api.py:68: in test_enhanced_atlassian_bridge_initialization\n    bridge = EnhancedAtlassianBridge(connector=mock_connector)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc\\integrations\\enhanced_atlassian_bridge.py:28: in __init__\n    asyncio.create_task(self._check_demo_mode())\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:417: in create_task\n    loop = events.get_running_loop()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   RuntimeError: no running event loop\n_____________ TestAudioService.test_03_text_to_speech_placeholder _____________\ntests\\services\\test_audio_service.py:36: in test_03_text_to_speech_placeholder\n    self.assertIsNotNone(audio_data)\nE   AssertionError: unexpectedly None\n------------------------------ Captured log call ------------------------------\nWARNING  src.services.audio_service:audio_service.py:168 Real text-to-speech is not implemented. Enable demo mode for testing.\n____________ TestSandboxExecutor.test_run_execution_error_in_tool _____________\ntests\\services\\test_sandbox_executor.py:106: in test_run_execution_error_in_tool\n    self.assertIn(\"Error during sandboxed tool execution: TestException\", error)\nE   AssertionError: 'Error during sandboxed tool execution: TestException' not found in 'Sandbox execution completed with no output.'\n---------------------------- Captured stderr call -----------------------------\n2025-09-03 05:56:10,851 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - ExecutionManager initialized with adaptive monitoring\n2025-09-03 05:56:10,873 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:10,876 - apps.backend.src.core_ai.execution_monitor - INFO - Calculated adaptive timeout: 30s\n2025-09-03 05:56:10,882 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:10,923 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:11,942 - apps.backend.src.core_ai.execution_monitor - WARNING - High CPU usage: 95.3%\n2025-09-03 05:56:11,944 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 89.3%\n2025-09-03 05:56:12,926 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n------------------------------ Captured log call ------------------------------\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:120 ExecutionManager initialized with adaptive monitoring\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:336 Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:160 Calculated adaptive timeout: 30s\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_error\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:236 High CPU usage: 95.3%\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 89.3%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\n________________ TestSandboxExecutor.test_run_non_json_output _________________\ntests\\services\\test_sandbox_executor.py:153: in test_run_non_json_output\n    self.assertIn(\"Sandbox execution produced non-JSON output: This is not JSON\", error)\nE   AssertionError: 'Sandbox execution produced non-JSON output: This is not JSON' not found in 'Sandbox execution completed with no output.'\n---------------------------- Captured stderr call -----------------------------\n2025-09-03 05:56:12,950 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - ExecutionManager initialized with adaptive monitoring\n2025-09-03 05:56:12,961 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:12,961 - apps.backend.src.core_ai.execution_monitor - INFO - Calculated adaptive timeout: 30s\n2025-09-03 05:56:12,961 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:12,968 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:13,967 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 89.2%\n2025-09-03 05:56:14,968 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n------------------------------ Captured log call ------------------------------\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:120 ExecutionManager initialized with adaptive monitoring\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:336 Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:160 Calculated adaptive timeout: 30s\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_nonjson\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 89.2%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\n_________________ TestSandboxExecutor.test_run_stderr_output __________________\ntests\\services\\test_sandbox_executor.py:177: in test_run_stderr_output\n    self.assertIn(\"Sandbox execution error (stderr):\\nCritical Python interpreter error\", error)\nE   AssertionError: 'Sandbox execution error (stderr):\\nCritical Python interpreter error' not found in 'Sandbox execution completed with no output.'\n---------------------------- Captured stderr call -----------------------------\n2025-09-03 05:56:14,997 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - ExecutionManager initialized with adaptive monitoring\n2025-09-03 05:56:15,007 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:15,008 - apps.backend.src.core_ai.execution_monitor - INFO - Calculated adaptive timeout: 30s\n2025-09-03 05:56:15,008 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:15,018 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:16,017 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 89.4%\n2025-09-03 05:56:17,018 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n------------------------------ Captured log call ------------------------------\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:120 ExecutionManager initialized with adaptive monitoring\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:336 Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:160 Calculated adaptive timeout: 30s\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_stderr\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 89.4%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\n______________ TestSandboxExecutor.test_run_successful_execution ______________\ntests\\services\\test_sandbox_executor.py:59: in test_run_successful_execution\n    self.assertIsNone(error)\nE   AssertionError: 'Sandbox execution completed with no output.' is not None\n---------------------------- Captured stderr call -----------------------------\n2025-09-03 05:56:17,041 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - ExecutionManager initialized with adaptive monitoring\n2025-09-03 05:56:17,056 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandboxed_tool.py', 'TestTool', 'test_method', '{\"param1\": \"value1\"}']\n2025-09-03 05:56:17,056 - apps.backend.src.core_ai.execution_monitor - INFO - Calculated adaptive timeout: 30s\n2025-09-03 05:56:17,057 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandboxed_tool.py', 'TestTool', 'test_method', '{\"param1\": \"value1\"}']\n2025-09-03 05:56:17,063 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:18,062 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 89.5%\n2025-09-03 05:56:19,064 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n------------------------------ Captured log call ------------------------------\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:120 ExecutionManager initialized with adaptive monitoring\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:336 Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandboxed_tool.py', 'TestTool', 'test_method', '{\"param1\": \"value1\"}']\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:160 Calculated adaptive timeout: 30s\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir\\\\_sandboxed_tool.py', 'TestTool', 'test_method', '{\"param1\": \"value1\"}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 89.5%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\n________________ TestSandboxExecutor.test_run_timeout_expired _________________\ntests\\services\\test_sandbox_executor.py:128: in test_run_timeout_expired\n    self.assertIn(f\"Sandbox execution timed out after {self.executor.timeout_seconds} seconds.\", error)\nE   AssertionError: 'Sandbox execution timed out after 30 seconds.' not found in 'Sandbox execution completed with no output.'\n---------------------------- Captured stderr call -----------------------------\n2025-09-03 05:56:19,089 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - ExecutionManager initialized with adaptive monitoring\n2025-09-03 05:56:19,106 - apps.backend.src.core_ai.execution_manager.ExecutionManager - INFO - Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:19,108 - apps.backend.src.core_ai.execution_monitor - INFO - Calculated adaptive timeout: 30s\n2025-09-03 05:56:19,108 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:19,115 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:20,115 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 89.7%\n2025-09-03 05:56:21,116 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n2025-09-03 05:56:21,116 - apps.backend.src.core_ai.execution_manager.ExecutionManager - WARNING - Retrying command (attempt 1/3)\n2025-09-03 05:56:26,117 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:26,124 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:27,124 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 89.9%\n2025-09-03 05:56:28,125 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n2025-09-03 05:56:28,126 - apps.backend.src.core_ai.execution_manager.ExecutionManager - WARNING - Retrying command (attempt 2/3)\n2025-09-03 05:56:33,128 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:33,132 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:34,134 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 89.6%\n2025-09-03 05:56:35,134 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n2025-09-03 05:56:35,135 - apps.backend.src.core_ai.execution_manager.ExecutionManager - WARNING - Retrying command (attempt 3/3)\n2025-09-03 05:56:40,136 - apps.backend.src.core_ai.execution_monitor - INFO - Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\n2025-09-03 05:56:40,143 - apps.backend.src.core_ai.execution_monitor - ERROR - Command execution error: [WinError 267] 目錄名稱無效。\n2025-09-03 05:56:41,142 - apps.backend.src.core_ai.execution_monitor - WARNING - High memory usage: 90.1%\n2025-09-03 05:56:42,143 - apps.backend.src.core_ai.execution_monitor - INFO - Command completed: error in 0.00s\n------------------------------ Captured log call ------------------------------\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:120 ExecutionManager initialized with adaptive monitoring\nINFO     apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:336 Executing command: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:160 Calculated adaptive timeout: 30s\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 89.7%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\nWARNING  apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:358 Retrying command (attempt 1/3)\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 89.9%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\nWARNING  apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:358 Retrying command (attempt 2/3)\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 89.6%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\nWARNING  apps.backend.src.core_ai.execution_manager.ExecutionManager:execution_manager.py:358 Retrying command (attempt 3/3)\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:299 Executing command with timeout 30s: ['C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe', '-u', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandbox_runner.py', 'C:\\\\Users\\\\catai\\\\AppData\\\\Local\\\\Temp\\\\fake_temp_dir_timeout\\\\_sandboxed_tool.py', 'ClassName', 'methodName', '{}']\nERROR    apps.backend.src.core_ai.execution_monitor:execution_monitor.py:352 Command execution error: [WinError 267] 目錄名稱無效。\nWARNING  apps.backend.src.core_ai.execution_monitor:execution_monitor.py:239 High memory usage: 90.1%\nINFO     apps.backend.src.core_ai.execution_monitor:execution_monitor.py:373 Command completed: error in 0.00s\n_____________________ test_hsp_connector_publish_message ______________________\ntests\\test_hsp_connector.py:96: in test_hsp_connector_publish_message\n    mock_mqtt_client.publish.assert_called_once()\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py:928: in assert_called_once\n    raise AssertionError(msg)\nE   AssertionError: Expected 'publish' to have been called once. Called 0 times.\n----------------------------- Captured log setup ------------------------------\nINFO     src.hsp.connector:connector.py:67 HSPConnector: Initializing in mock mode.\nDEBUG    src.hsp.connector:connector.py:68 HSPConnector.__init__ - ai_id: test_ai, mock_mode: True\n_______________________ test_hsp_connector_ack_sending ________________________\ntests\\test_hsp_connector.py:213: in test_hsp_connector_ack_sending\n    mock_mqtt_client.publish.assert_called_once()\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py:928: in assert_called_once\n    raise AssertionError(msg)\nE   AssertionError: Expected 'publish' to have been called once. Called 0 times.\n----------------------------- Captured log setup ------------------------------\nINFO     src.hsp.connector:connector.py:67 HSPConnector: Initializing in mock mode.\nDEBUG    src.hsp.connector:connector.py:68 HSPConnector.__init__ - ai_id: test_ai, mock_mode: True\n---------------------------- Captured stdout call -----------------------------\nDEBUG: MessageBridge.handle_external_message - Incoming topic: hsp/test/ack_required, message: {\"hsp_envelope_version\": \"0.1\", \"message_id\": \"msg789\", \"correlation_id\": null, \"sender_ai_id\": \"requester_ai\", \"recipient_ai_id\": \"test_ai\", \"timestamp_sent\": \"2024-07-05T14:00:00Z\", \"message_type\": \"HSP::Fact_v0.1\", \"protocol_version\": \"0.1\", \"communication_pattern\": \"publish\", \"security_parameters\": null, \"qos_parameters\": {\"requires_ack\": true, \"priority\": \"medium\"}, \"routing_info\": null, \"payload_schema_uri\": \"hsp:schema:payload/Fact/0.1\", \"payload\": {\"id\": \"fact789\", \"statement_type\": \"natural_language\", \"statement_nl\": \"ACK me.\", \"source_ai_id\": \"requester_ai\", \"timestamp_created\": \"2024-07-05T14:00:00Z\", \"confidence_score\": 0.7}}\nDEBUG: DataAligner.align_message - Aligned message: {'hsp_envelope_version': '0.1', 'message_id': 'msg789', 'correlation_id': None, 'sender_ai_id': 'requester_ai', 'recipient_ai_id': 'test_ai', 'timestamp_sent': '2024-07-05T14:00:00Z', 'message_type': 'HSP::Fact_v0.1', 'protocol_version': '0.1', 'communication_pattern': 'publish', 'security_parameters': None, 'qos_parameters': {'requires_ack': True, 'priority': 'medium'}, 'routing_info': None, 'payload_schema_uri': 'hsp:schema:payload/Fact/0.1', 'payload': {'id': 'fact789', 'statement_type': 'natural_language', 'statement_nl': 'ACK me.', 'source_ai_id': 'requester_ai', 'timestamp_created': '2024-07-05T14:00:00Z', 'confidence_score': 0.7}}\nDEBUG: MessageBridge.handle_external_message - Publishing to internal bus channel: hsp.external.fact with aligned_message: {'hsp_envelope_version': '0.1', 'message_id': 'msg789', 'correlation_id': None, 'sender_ai_id': 'requester_ai', 'recipient_ai_id': 'test_ai', 'timestamp_sent': '2024-07-05T14:00:00Z', 'message_type': 'HSP::Fact_v0.1', 'protocol_version': '0.1', 'communication_pattern': 'publish', 'security_parameters': None, 'qos_parameters': {'requires_ack': True, 'priority': 'medium'}, 'routing_info': None, 'payload_schema_uri': 'hsp:schema:payload/Fact/0.1', 'payload': {'id': 'fact789', 'statement_type': 'natural_language', 'statement_nl': 'ACK me.', 'source_ai_id': 'requester_ai', 'timestamp_created': '2024-07-05T14:00:00Z', 'confidence_score': 0.7}}\nDEBUG: InternalBus.publish_async - Channel: hsp.external.fact, Message: {'hsp_envelope_version': '0.1', 'message_id': 'msg789', 'correlation_id': None, 'sender_ai_id': 'requester_ai', 'recipient_ai_id': 'test_ai', 'timestamp_sent': '2024-07-05T14:00:00Z', 'message_type': 'HSP::Fact_v0.1', 'protocol_version': '0.1', 'communication_pattern': 'publish', 'security_parameters': None, 'qos_parameters': {'requires_ack': True, 'priority': 'medium'}, 'routing_info': None, 'payload_schema_uri': 'hsp:schema:payload/Fact/0.1', 'payload': {'id': 'fact789', 'statement_type': 'natural_language', 'statement_nl': 'ACK me.', 'source_ai_id': 'requester_ai', 'timestamp_created': '2024-07-05T14:00:00Z', 'confidence_score': 0.7}}\n------------------------------ Captured log call ------------------------------\nDEBUG    src.hsp.connector:connector.py:775 Dispatching fact to 0 callbacks. Message: {'hsp_envelope_version': '0.1', 'message_id': 'msg789', 'correlation_id': None, 'sender_ai_id': 'requester_ai', 'recipient_ai_id': 'test_ai', 'timestamp_sent': '2024-07-05T14:00:00Z', 'message_type': 'HSP::Fact_v0.1', 'protocol_version': '0.1', 'communication_pattern': 'publish', 'security_parameters': None, 'qos_parameters': {'requires_ack': True, 'priority': 'medium'}, 'routing_info': None, 'payload_schema_uri': 'hsp:schema:payload/Fact/0.1', 'payload': {'id': 'fact789', 'statement_type': 'natural_language', 'statement_nl': 'ACK me.', 'source_ai_id': 'requester_ai', 'timestamp_created': '2024-07-05T14:00:00Z', 'confidence_score': 0.7}}\n============================== warnings summary ===============================\nC:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pygame\\pkgdata.py:25\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n    from pkg_resources import resource_stream, resource_exists\n\ntests/core_ai/memory/test_ham_memory_manager.py: 11 warnings\n  D:\\Projects\\Unified-AI-Project\\apps\\backend\\src\\core_ai\\memory\\vector_store.py:123: RuntimeWarning: coroutine 'VectorMemoryStore._schedule_maintenance' was never awaited\n    logger.warning(f\"Error setting up advanced features: {e}\")\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/hsp/test_hsp_simple.py::test_hsp_connector_init\ntests/hsp/test_hsp_simple.py::test_publish_fact\n  D:\\Projects\\Unified-AI-Project\\apps\\backend\\tests\\hsp\\test_hsp_integration.py:73: RuntimeWarning: coroutine 'MockMqttBroker.subscribe' was never awaited\n    self.subscribe(topic, self.clients[client_id])\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_complex_project_with_dag\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_dynamic_agent_launch\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_failing_subtask\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_no_dependencies\n  D:\\Projects\\Unified-AI-Project\\apps\\backend\\src\\core_ai\\learning\\learning_manager.py:240: RuntimeWarning: coroutine 'initialize_services.<locals>.TempMockHAM.store_experience' was never awaited\n    self.ham_memory.store_experience(raw_data=project_case, data_type=\"project_execution_case\", metadata=raw_case_metadata)\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_dynamic_agent_launch\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_failing_subtask\ntests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_no_dependencies\ntests/tools/test_tool_dispatcher_logging.py::test_tool_dispatcher_action_policy_logged_smoke\n  D:\\Projects\\Unified-AI-Project\\apps\\backend\\src\\services\\multi_llm_service.py:1111: RuntimeWarning: This AsyncLimiter instance is being re-used across loops. Please create a new limiter per event loop as re-use can lead to undefined behaviour.\n    async with self.limiters[provider_name]:\n\ntests/integration/test_learning_and_trust.py::TestLearningAndTrustIntegration::test_fact_from_high_trust_source_is_accepted\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py:88: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\n    self._context.run(self._callback, *self._args)\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/services/test_audio_service.py::TestAudioService::test_02_speech_to_text_placeholder\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestAudioService.test_02_speech_to_text_placeholder' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/services/test_llm_interface.py::TestLLMInterface::test_02_generate_response_placeholder\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestLLMInterface.test_02_generate_response_placeholder' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/services/test_llm_interface.py::TestLLMInterface::test_03_list_models_placeholder\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestLLMInterface.test_03_list_models_placeholder' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/services/test_vision_service.py::TestVisionService::test_02_analyze_image\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestVisionService.test_02_analyze_image' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/services/test_vision_service.py::TestVisionService::test_03_compare_images\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestVisionService.test_03_compare_images' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/tools/test_logic_model.py::TestLogicModelComponents::test_05_tool_dispatcher_logic_routing\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestLogicModelComponents.test_05_tool_dispatcher_logic_routing' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/tools/test_math_model.py::TestMathModelComponents::test_math_tool_calculate_model_unavailable\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestMathModelComponents.test_math_tool_calculate_model_unavailable' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/tools/test_math_model.py::TestMathModelComponents::test_tool_dispatcher_math_routing\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestMathModelComponents.test_tool_dispatcher_math_routing' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/tools/test_translation_model.py::TestTranslationModelComponents::test_05_tool_dispatcher_translation_routing\n  C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:589: RuntimeWarning: coroutine 'TestTranslationModelComponents.test_05_tool_dispatcher_translation_routing' was never awaited\n    if method() is not None:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nFAILED tests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_ambiguous_patterns - AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\nFAILED tests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_direct_invalid_path - AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\nFAILED tests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_invalid_tools_directory - AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\nFAILED tests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_name_not_found - AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\nFAILED tests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_get_tool_structure_path_looks_like_path_but_not_found - AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\nFAILED tests/core_ai/code_understanding/test_lightweight_code_model.py::TestLightweightCodeModel::test_list_tool_files_non_existent_dir - AssertionError: no logs of level WARNING or higher triggered on src.core_ai.code_understanding.lightweight_code_model\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_02_simple_entity_extraction - AssertionError: 5 != 4\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_06_noun_prep_noun_relationship_of - AssertionError: False is not true : Expected 'founder of' type relationship not found between Apple and Steve Jobs.\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_07_noun_of_noun_org_has_attribute - AssertionError: False is not true : Expected 'has_ceo' or similar relationship not found between Google and Sundar Pichai.\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_08_noun_of_noun_attribute_of - AssertionError: False is not true : Expected 'has_capital' or similar relationship not found between France and capital.\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_13_matcher_person_is_ceo_of_org - AssertionError: False is not true : Relationship Microsoft -> Satya Nadella (type: has_ceo) not found in KG relationships. (Allow reverse: False)\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_14_matcher_person_is_founder_of_org - AssertionError: False is not true : Entity 'ExampleCorp' (type: ORG) not found in graph entities.\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_15_process_hsp_fact_content_nl - TypeError: list indices must be integers or slices, not str\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_16_process_hsp_fact_content_semantic_triple_with_mapping - AssertionError: 'http://example.org/entity/Paris' != 'cai_instance:ex_Paris'\n- http://example.org/entity/Paris\n+ cai_instance:ex_Paris\nFAILED tests/core_ai/learning/test_content_analyzer_module.py::TestContentAnalyzerModule::test_17_process_hsp_fact_content_semantic_triple_no_mapping - AssertionError: False is not true\nFAILED tests/core_ai/service_discovery/test_service_discovery_module.py::TestServiceDiscoveryModule::test_init - AssertionError: assert 'Staleness threshold: 600 seconds' in ''\n +  where '' = <_pytest.logging.LogCaptureFixture object at 0x00000271D1CCC1A0>.text\nFAILED tests/hsp/test_hsp_connector.py::test_hsp_connector_publish_message - AssertionError: Expected publish to have been awaited once. Awaited 0 times.\nFAILED tests/hsp/test_hsp_integration.py::TestHSPFactPublishing::test_learning_manager_publishes_fact_via_hsp - AssertionError: Peer A did not receive any facts.\nassert 0 > 0\n +  where 0 = len([])\n +    where [] = <apps.backend.tests.hsp.test_hsp_integration.TestHSPFactPublishing object at 0x00000271D0289D90>.received_facts_on_peer\nFAILED tests/hsp/test_hsp_integration.py::TestHSPFactConsumption::test_main_ai_consumes_nl_fact_and_updates_kg_check_trust_influence - AssertionError: HAM memory store should not be empty after processing high trust peer fact\nassert 0 > 0\n +  where 0 = len({})\n +    where {} = <apps.backend.tests.hsp.test_hsp_integration.MockHAM object at 0x00000271D1A3EE40>.memory_store\nFAILED tests/hsp/test_hsp_integration.py::TestHSPFactConsumption::test_main_ai_consumes_structured_fact_updates_kg - TimeoutError\nFAILED tests/hsp/test_hsp_integration.py::TestHSPFactConsumption::test_ca_semantic_mapping_for_hsp_structured_fact - AssertionError: ContentAnalyzerModule graph was not updated\nassert 0 > 0\n +  where 0 = len(NodeView(()))\n +    where NodeView(()) = NodeView(())()\n +      where NodeView(()) = <networkx.classes.digraph.DiGraph object at 0x00000271D1B3CFE0>.nodes\n +        where <networkx.classes.digraph.DiGraph object at 0x00000271D1B3CFE0> = <apps.backend.src.core_ai.learning.content_analyzer_module.ContentAnalyzerModule object at 0x00000271D1B3D0A0>.graph\nFAILED tests/hsp/test_hsp_integration.py::TestHSPTaskDelegation::test_dm_delegates_task_to_specialist_ai_and_gets_result - Failed: Event wait timed out after 10.0 seconds\nFAILED tests/hsp/test_hsp_integration.py::TestHSPTaskDelegation::test_dm_handles_hsp_task_failure_and_falls_back - Failed: Event wait timed out after 10.0 seconds\nFAILED tests/hsp/test_hsp_simple.py::test_publish_fact - TimeoutError\nFAILED tests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_complex_project_with_dag - AssertionError: 'Based on the data summary' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\nFAILED tests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_dynamic_agent_launch - AssertionError: 'Dynamically launched agent' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\nFAILED tests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_failing_subtask - AssertionError: 'The project failed' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\nFAILED tests/integration/test_agent_collaboration.py::TestAgentCollaboration::test_handle_project_no_dependencies - AssertionError: 'Both tasks completed' not found in \"Miko (Base): Here's the result of your project request:\\n\\nMock response (no API key)\"\nFAILED tests/integration/test_atlassian_integration.py::TestAtlassianIntegration::test_get_jira_projects_without_configuration - assert 500 == 400\n +  where 500 = <Response [500 Internal Server Error]>.status_code\nFAILED tests/integration/test_atlassian_integration.py::TestAtlassianIntegration::test_create_confluence_page_without_enhanced_bridge - assert 200 in [400, 500]\n +  where 200 = <Response [200 OK]>.status_code\nFAILED tests/integration/test_end_to_end_project_flow.py::test_full_project_flow_with_real_agent - assert 'The result is: 15' in \"TestCoordinator: Here's the result of your project request:\\n\\nTask failed: Could not find or launch an agent with capability 'data_analysis_v1'.\"\nFAILED tests/integrations/test_atlassian_api.py::TestAtlassianAPI::test_enhanced_atlassian_bridge_initialization - RuntimeError: no running event loop\nFAILED tests/services/test_audio_service.py::TestAudioService::test_03_text_to_speech_placeholder - AssertionError: unexpectedly None\nFAILED tests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_execution_error_in_tool - AssertionError: 'Error during sandboxed tool execution: TestException' not found in 'Sandbox execution completed with no output.'\nFAILED tests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_non_json_output - AssertionError: 'Sandbox execution produced non-JSON output: This is not JSON' not found in 'Sandbox execution completed with no output.'\nFAILED tests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_stderr_output - AssertionError: 'Sandbox execution error (stderr):\\nCritical Python interpreter error' not found in 'Sandbox execution completed with no output.'\nFAILED tests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_successful_execution - AssertionError: 'Sandbox execution completed with no output.' is not None\nFAILED tests/services/test_sandbox_executor.py::TestSandboxExecutor::test_run_timeout_expired - AssertionError: 'Sandbox execution timed out after 30 seconds.' not found in 'Sandbox execution completed with no output.'\nFAILED tests/test_hsp_connector.py::test_hsp_connector_publish_message - AssertionError: Expected 'publish' to have been called once. Called 0 times.\nFAILED tests/test_hsp_connector.py::test_hsp_connector_ack_sending - AssertionError: Expected 'publish' to have been called once. Called 0 times.\n===== 40 failed, 451 passed, 15 skipped, 32 warnings in 321.40s (0:05:21) =====\n",
  "stderr": "C:\\Users\\catai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\_pytest\\unraisableexception.py:33: RuntimeWarning: coroutine 'EnhancedAtlassianBridge._check_demo_mode' was never awaited\n  gc.collect()\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
  "timestamp": "2025-09-03 05:56:56.444366"
}