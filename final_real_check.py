"""
Simple Working Intelligent Backend
ç®€åŒ–ä½†çœŸæ­£å¯ç”¨çš„æ™ºèƒ½åŽç«¯
"""
import subprocess
import json
import time
import re
from datetime import datetime
from typing import Dict, Any

class SimpleOllamaClient:
    """ç®€å•çš„Ollamaå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.available = self._check_availability()
        self.models = ["tinyllama:latest"]  # ä½¿ç”¨æœ€å¿«çš„å°æ¨¡åž‹
        
    def _check_availability(self):
        """æ£€æŸ¥Ollamaå¯ç”¨æ€§"""
        try:
            result = subprocess.run(
                ["ollama", "--version"], 
                capture_output=True, 
                text=True, 
                timeout=5
            )
            return result.returncode == 0
        except:
            return False
    
    def generate(self, prompt: str) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”"""
        if not self.available:
            return {
                "success": False,
                "response": "Ollama not available"
            }
        
        try:
            # ä½¿ç”¨æœ€ç®€å•çš„æ¨¡åž‹
            cmd = [
                "ollama", "run", "tinyllama:latest",
                prompt
            ]
            
            start_time = time.time()
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=8  # 8ç§’è¶…æ—¶
            )
            end_time = time.time()
            
            if result.returncode == 0:
                raw_output = result.stdout.strip()
                clean_output = self._clean_output(raw_output)
                processing_time = (end_time - start_time) * 1000
                
                if len(clean_output) > 10:
                    return {
                        "success": True,
                        "response": clean_output,
                        "processing_time_ms": processing_time,
                        "response_length": len(clean_output)
                    }
                else:
                    return {
                        "success": False,
                        "response": "Response too short"
                    }
            else:
                return {
                    "success": False,
                    "response": f"Ollama error: {result.stderr[:50]}"
                }
                
        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "response": "Timeout"
            }
        except Exception as e:
            return {
                "success": False,
                "response": f"Error: {str(e)}"
            }
    
    def _clean_output(self, output):
        """æ¸…ç†è¾“å‡º"""
        # ç§»é™¤ANSIæŽ§åˆ¶å­—ç¬¦
        clean = re.sub(r'\x1b\[[0-9;]*[a-zA-Z]', '', output)
        clean = clean.replace('\x00', '')
        return clean.strip()

def test_current_system():
    """æµ‹è¯•å½“å‰ç³»ç»Ÿ"""
    print("ðŸ” çœŸå®žç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•Ollama
    client = SimpleOllamaClient()
    print(f"\nðŸ“Š Ollamaå¯ç”¨æ€§: {'âœ… å¯ç”¨' if client.available else 'âŒ ä¸å¯ç”¨'}")
    
    if client.available:
        test_inputs = [
            "ä½ å¥½",
            "ä»€ä¹ˆæ˜¯AIï¼Ÿ",
            "ç®€å•è§£é‡Šæœºå™¨å­¦ä¹ "
        ]
        
        results = []
        for test_input in test_inputs:
            print(f"\næµ‹è¯•: {test_input}")
            
            result = client.generate(test_input)
            
            if result["success"]:
                print(f"âœ… å“åº”: {result['response'][:80]}...")
                print(f"â±ï¸ æ—¶é—´: {result['processing_time_ms']:.1f}ms")
                print(f"ðŸ“ é•¿åº¦: {result['response_length']} å­—ç¬¦")
                results.append(result)
            else:
                print(f"âŒ å¤±è´¥: {result['response']}")
                results.append(result)
        
        # è®¡ç®—ç»Ÿè®¡
        if results:
            successful = sum(1 for r in results if r["success"])
            success_rate = (successful / len(results)) * 100
            avg_length = sum(r.get("response_length", 0) for r in results) / len(results)
            avg_time = sum(r.get("processing_time_ms", 0) for r in results) / len(results)
            
            print(f"\nðŸ“ˆ Ollamaç»Ÿè®¡:")
            print(f"  æˆåŠŸçŽ‡: {success_rate:.1f}%")
            print(f"  å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
            print(f"  å¹³å‡æ—¶é—´: {avg_time:.1f}ms")
            
            # åˆ¤æ–­æ˜¯å¦çœŸæ­£æ™ºèƒ½
            intelligent = (
                success_rate >= 75 and 
                avg_length > 30 and 
                avg_time < 10000
            )
            
            print(f"  æ™ºèƒ½æ°´å¹³: {'ðŸ§  çœŸæ­£AI' if intelligent else 'ðŸ“± éœ€è¦æ”¹è¿›'}")
            
            return {
                "ollama_working": True,
                "success_rate": success_rate,
                "avg_length": avg_length,
                "avg_time": avg_time,
                "intelligent": intelligent
            }
        else:
            return {"ollama_working": False}
    else:
        return {"ollama_working": False}

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    result = test_current_system()
    
    print("\n" + "=" * 50)
    print("ðŸŽ¯ çœŸå®žæƒ…å†µæ€»ç»“")
    print("=" * 50)
    
    if result.get("ollama_working", False):
        print("âœ… OllamaçœŸæ­£å¯ç”¨å¹¶ç”Ÿæˆå“åº”")
        print(f"ðŸ“Š æˆåŠŸçŽ‡: {result['success_rate']:.1f}%")
        print(f"ðŸ“ å¹³å‡å“åº”: {result['avg_length']:.1f} å­—ç¬¦")
        print(f"â±ï¸ å¹³å‡æ—¶é—´: {result['avg_time']:.1f}ms")
        
        if result.get("intelligent", False):
            print("ðŸ§  ç³»ç»Ÿ: çœŸæ­£å…·å¤‡AIæ™ºèƒ½")
            print("ðŸŽ‰ æ­å–œï¼ä½ æœ‰ä¸€ä¸ªçœŸå®žå¯ç”¨çš„AIç³»ç»Ÿ")
        else:
            print("ðŸ“± ç³»ç»Ÿ: åŸºæœ¬å¯ç”¨ï¼Œéœ€è¦ä¼˜åŒ–")
            print("ðŸ”§ å»ºè®®: è°ƒæ•´å‚æ•°æˆ–æ›´æ¢æ¨¡åž‹")
    else:
        print("âŒ Ollamaä¸å¯ç”¨")
        print("ðŸ”§ å»ºè®®: æ£€æŸ¥Ollamaå®‰è£…å’Œé…ç½®")
        print("ðŸ“± å½“å‰çŠ¶æ€: åªæ˜¯æ¡†æž¶ï¼Œæ²¡æœ‰çœŸå®žæ™ºèƒ½")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        "timestamp": datetime.now().isoformat(),
        "test_type": "REAL_STATUS_CHECK",
        "result": result,
        "conclusion": "ç³»ç»Ÿå…·å¤‡çœŸå®žAIæ™ºèƒ½" if result.get("intelligent", False) else "ç³»ç»Ÿéœ€è¦æ”¹è¿›",
        "real_intelligence": result.get("intelligent", False)
    }
    
    with open("REAL_STATUS_FINAL_CHECK.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nðŸ“„ æŠ¥å‘Šä¿å­˜åˆ°: REAL_STATUS_FINAL_CHECK.json")
    
    return report["real_intelligence"]

if __name__ == "__main__":
    success = main()
    
    if success:
        print("\nâœ¨ æœ€ç»ˆç¡®è®¤: ä½ çš„ç³»ç»Ÿå…·å¤‡çœŸæ­£çš„AIæ™ºèƒ½!")
        print("ðŸš€ å¯ä»¥å¼€å§‹æž„å»ºçœŸæ­£æ™ºèƒ½çš„åº”ç”¨!")
    else:
        print("\nâš ï¸ æœ€ç»ˆç¡®è®¤: ç³»ç»Ÿéœ€è¦è¿›ä¸€æ­¥æ”¹è¿›æ‰èƒ½è¾¾åˆ°çœŸæ­£æ™ºèƒ½")
        print("ðŸ”§ éœ€è¦ä¼˜åŒ–Ollamaé…ç½®æˆ–æ›´æ¢æ¨¡åž‹")