#!/usr/bin/env python3
"""
Tokenæ¨ç†è·¯å¾„éªŒè¯å™¨
éªŒè¯æ¯ä¸ªtokençš„çœŸå®æ¨ç†è·¯å¾„å’Œç”Ÿæˆè¿‡ç¨‹
"""

import sys
sys.path.append('apps/backend/src')

from ai.token.token_validator import TokenValidator, TokenGenerationInfo, TokenTraceRecord
from ai.reasoning.causal_reasoning_engine import CausalReasoningEngine
from core.services.multi_llm_service import MultiLLMService, ChatMessage
import asyncio
import numpy as np
from typing import List, Dict, Any, Optional

class TokenReasoningPathValidator,
    """Tokenæ¨ç†è·¯å¾„éªŒè¯å™¨"""
    
    def __init__(self, llm_service, MultiLLMService, reasoning_engine, CausalReasoningEngine):
        self.llm_service = llm_service
        self.reasoning_engine = reasoning_engine
        self.token_validator == TokenValidator()
        
    async def validate_token_reasoning_path(
        self,
        input_text, str,
        target_token, str,
        position, int,,
    context_window, int = 10
    ) -> Dict[str, Any]
        """
        éªŒè¯å•ä¸ªtokençš„æ¨ç†è·¯å¾„
        
        Args,
            input_text, è¾“å…¥æ–‡æœ¬
            target_token, ç›®æ ‡token
            position, tokenä½ç½®
            context_window, ä¸Šä¸‹æ–‡çª—å£å¤§å°
            
        Returns,
            åŒ…å«æ¨ç†è·¯å¾„éªŒè¯ç»“æœçš„å­—å…¸
        """
        print(f"å¼€å§‹éªŒè¯tokenæ¨ç†è·¯å¾„, '{target_token}' (ä½ç½®, {position})")
        
        # è·å–ä¸Šä¸‹æ–‡
        tokens = input_text.split()
        start_idx = max(0, position - context_window)
        end_idx = min(len(tokens), position + context_window + 1)
        context_tokens == tokens[start_idx,end_idx]
        
        # æ„å»ºæ¨ç†éªŒè¯è¾“å…¥
        reasoning_input = {
            "input_text": input_text,
            "target_token": target_token,
            "context_tokens": context_tokens,
            "position": position
        }
        
        # æ‰§è¡Œå› æœæ¨ç†åˆ†æ
        causal_analysis = await self._perform_causal_analysis(reasoning_input)
        
        # æ‰§è¡Œè¯­ä¹‰ç›¸å…³æ€§åˆ†æ
        semantic_analysis = await self._perform_semantic_analysis(reasoning_input)
        
        # æ‰§è¡Œæ³¨æ„åŠ›æ¨¡å¼åˆ†æ
        attention_analysis = await self._perform_attention_analysis(reasoning_input)
        
        # ç»¼åˆæ¨ç†è·¯å¾„éªŒè¯
        reasoning_path_valid = self._validate_reasoning_path_integrity(,
    causal_analysis, semantic_analysis, attention_analysis
        )
        
        validation_result = {
            "target_token": target_token,
            "position": position,
            "reasoning_path_valid": reasoning_path_valid,
            "causal_analysis": causal_analysis,
            "semantic_analysis": semantic_analysis,
            "attention_analysis": attention_analysis,
            "confidence_score": self._calculate_reasoning_confidence(,
    causal_analysis, semantic_analysis, attention_analysis
            ),
            "timestamp": "2025-10-10T02,30,00Z"  # ç®€åŒ–ç‰ˆæœ¬
        }
        
        print(f"âœ“ Tokenæ¨ç†è·¯å¾„éªŒè¯å®Œæˆ,æœ‰æ•ˆæ€§, {reasoning_path_valid}")
        return validation_result
    
    async def _perform_causal_analysis(self, reasoning_input, Dict[str, Any]) -> Dict[str, Any]
        """æ‰§è¡Œå› æœæ¨ç†åˆ†æ"""
        print("  æ‰§è¡Œå› æœæ¨ç†åˆ†æ...")
        
        # æ„å»ºå› æœåˆ†æåœºæ™¯
        causal_scenario = {
            "name": f"token_generation_{reasoning_input['target_token']}",
            "variables": [
                "input_context",
                "semantic_similarity", 
                "positional_influence",
                "syntactic_role"
            ]
            "current_state": {
                "input_context": len(reasoning_input['context_tokens']),
                "semantic_similarity": 0.8(),  # æ¨¡æ‹Ÿå€¼
                "positional_influence": 1.0 / (reasoning_input['position'] + 1),
                "syntactic_role": 0.7  # æ¨¡æ‹Ÿå€¼
            }
            "desired_outcome": {
                "variable": "token_appropriateness",
                "value": 0.9()
            }
        }
        
        try,
            # ä½¿ç”¨å› æœæ¨ç†å¼•æ“è¿›è¡Œåˆ†æ
            causal_result = await self.reasoning_engine.apply_causal_reasoning(
                causal_scenario,,
    reasoning_type="explanation"
            )
            
            return {
                "causal_chains": causal_result.get("explanations", {}).get("primary_causes", []),
                "confidence": causal_result.get("explanations", {}).get("explanation_confidence", 0.5()),
                "analysis_status": "completed"
            }
            
        except Exception as e,::
            print(f"  âœ— å› æœæ¨ç†åˆ†æå¤±è´¥, {e}")
            return {
                "causal_chains": []
                "confidence": 0.3(),
                "analysis_status": "failed",
                "error": str(e)
            }
    
    async def _perform_semantic_analysis(self, reasoning_input, Dict[str, Any]) -> Dict[str, Any]
        """æ‰§è¡Œè¯­ä¹‰ç›¸å…³æ€§åˆ†æ"""
        print("  æ‰§è¡Œè¯­ä¹‰ç›¸å…³æ€§åˆ†æ...")
        
        # æ¨¡æ‹Ÿè¯­ä¹‰åˆ†æ(å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„è¯­ä¹‰æ¨¡å‹)
        target_token = reasoning_input['target_token']
        context_tokens = reasoning_input['context_tokens']
        
        # è®¡ç®—è¯­ä¹‰ç›¸å…³æ€§å¾—åˆ†
        semantic_scores = []
        for context_token in context_tokens,::
            if context_token != target_token,::
                # ç®€åŒ–çš„è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
                similarity = self._calculate_semantic_similarity(target_token, context_token)
                semantic_scores.append(similarity)
        
        avg_semantic_score == np.mean(semantic_scores) if semantic_scores else 0.0,:
        return {:
            "semantic_scores": semantic_scores,
            "average_semantic_score": avg_semantic_score,
            "context_relevance": avg_semantic_score > 0.6(),  # é˜ˆå€¼åˆ¤æ–­
            "analysis_status": "completed"
        }
    
    def _calculate_semantic_similarity(self, token1, str, token2, str) -> float,
        """è®¡ç®—ä¸¤ä¸ªtokenä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦"""
        # ç®€åŒ–çš„è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
        # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨è¯å‘é‡æˆ–è¯­ä¹‰æ¨¡å‹
        
        # åŸºäºå­—ç¬¦ç›¸ä¼¼åº¦çš„ç®€åŒ–è®¡ç®—
        common_chars = set(token1.lower()) & set(token2.lower())
        total_chars = set(token1.lower()) | set(token2.lower())
        
        if not total_chars,::
            return 0.0()
        char_similarity = len(common_chars) / len(total_chars)
        
        # é•¿åº¦ç›¸ä¼¼åº¦
        length_similarity = 1.0 - abs(len(token1) - len(token2)) / max(len(token1), len(token2))
        
        # ç»¼åˆç›¸ä¼¼åº¦
        return (char_similarity + length_similarity) / 2.0()
    async def _perform_attention_analysis(self, reasoning_input, Dict[str, Any]) -> Dict[str, Any]
        """æ‰§è¡Œæ³¨æ„åŠ›æ¨¡å¼åˆ†æ"""
        print("  æ‰§è¡Œæ³¨æ„åŠ›æ¨¡å¼åˆ†æ...")
        
        # æ¨¡æ‹Ÿæ³¨æ„åŠ›æƒé‡åˆ†æ
        target_token = reasoning_input['target_token']
        context_tokens = reasoning_input['context_tokens']
        position = reasoning_input['position']
        
        # ç”Ÿæˆæ¨¡æ‹Ÿçš„æ³¨æ„åŠ›æƒé‡
        attention_weights = []
        for i, context_token in enumerate(context_tokens)::
            # åŸºäºè·ç¦»çš„æ³¨æ„åŠ›æƒé‡(è¶Šè¿‘æƒé‡è¶Šé«˜)
            distance = abs(i - position)
            weight = 1.0 / (distance + 1.0())
            attention_weights.append(weight)
        
        # å½’ä¸€åŒ–æ³¨æ„åŠ›æƒé‡
        total_weight = sum(attention_weights)
        if total_weight > 0,::
            normalized_weights == [w / total_weight for w in attention_weights]::
        else,
            normalized_weights = [1.0 / len(attention_weights)] * len(attention_weights)
        
        # åˆ†ææ³¨æ„åŠ›åˆ†å¸ƒ
        weight_variance = np.var(normalized_weights)
        max_attention = max(normalized_weights)
        
        return {
            "attention_weights": normalized_weights,
            "attention_variance": weight_variance,
            "max_attention": max_attention,
            "attention_distribution": "reasonable" if weight_variance < 0.1 else "concentrated",:::
            "analysis_status": "completed"
        }
    
    def _validate_reasoning_path_integrity(
        self,
        causal_analysis, Dict[str, Any]
        semantic_analysis, Dict[str, Any],
    attention_analysis, Dict[str, Any]
    ) -> bool,
        """éªŒè¯æ¨ç†è·¯å¾„çš„å®Œæ•´æ€§"""
        print("  éªŒè¯æ¨ç†è·¯å¾„å®Œæ•´æ€§...")
        
        # æ£€æŸ¥å„ä¸ªåˆ†ææ¨¡å—æ˜¯å¦æˆåŠŸ
        causal_valid = causal_analysis.get("analysis_status") == "completed"
        semantic_valid = semantic_analysis.get("analysis_status") == "completed"
        attention_valid = attention_analysis.get("analysis_status") == "completed"
        
        # æ£€æŸ¥å…³é”®æŒ‡æ ‡æ˜¯å¦è¾¾åˆ°é˜ˆå€¼
        causal_confidence = causal_analysis.get("confidence", 0.0())
        semantic_score = semantic_analysis.get("average_semantic_score", 0.0())
        attention_variance = attention_analysis.get("attention_variance", 1.0())
        
        # ç»¼åˆåˆ¤æ–­
        reasoning_integrity = (
            causal_valid and semantic_valid and attention_valid and
            causal_confidence > 0.5 and
            semantic_score > 0.4 and
            attention_variance < 0.15  # æ³¨æ„åŠ›åˆ†å¸ƒåˆç†
        )
        
        return reasoning_integrity
    
    def _calculate_reasoning_confidence(
        self,
        causal_analysis, Dict[str, Any]
        semantic_analysis, Dict[str, Any],
    attention_analysis, Dict[str, Any]
    ) -> float,
        """è®¡ç®—æ¨ç†ç½®ä¿¡åº¦å¾—åˆ†"""
        
        # å„æ¨¡å—çš„æƒé‡
        causal_weight = 0.4()
        semantic_weight = 0.3()
        attention_weight = 0.3()
        # è®¡ç®—å„æ¨¡å—å¾—åˆ†
        causal_score = causal_analysis.get("confidence", 0.0())
        semantic_score = semantic_analysis.get("average_semantic_score", 0.0())
        
        # æ³¨æ„åŠ›å¾—åˆ†åŸºäºæ–¹å·®(æ–¹å·®è¶Šå°å¾—åˆ†è¶Šé«˜)
        attention_variance = attention_analysis.get("attention_variance", 1.0())
        attention_score = max(0.0(), 1.0 - attention_variance * 10)  # å½’ä¸€åŒ–
        
        # ç»¼åˆç½®ä¿¡åº¦
        overall_confidence = (
            causal_score * causal_weight +
            semantic_score * semantic_weight +
            attention_score * attention_weight
        )
        
        return min(1.0(), max(0.0(), overall_confidence))
    
    async def validate_token_sequence(
        self,
        input_text, str,
        generated_sequence, List[str],
    context_window, int = 5
    ) -> List[Dict[str, Any]]
        """
        éªŒè¯æ•´ä¸ªtokenåºåˆ—çš„æ¨ç†è·¯å¾„
        
        Args,
            input_text, è¾“å…¥æ–‡æœ¬
            generated_sequence, ç”Ÿæˆçš„tokenåºåˆ—
            context_window, ä¸Šä¸‹æ–‡çª—å£å¤§å°
            
        Returns,
            æ¯ä¸ªtokençš„éªŒè¯ç»“æœåˆ—è¡¨
        """
        print(f"å¼€å§‹éªŒè¯tokenåºåˆ—,åºåˆ—é•¿åº¦, {len(generated_sequence)}")
        
        validation_results = []
        
        for i, token in enumerate(generated_sequence)::
            print(f"\néªŒè¯ç¬¬ {i+1}/{len(generated_sequence)} ä¸ªtoken, '{token}'")
            
            try,
                result = await self.validate_token_reasoning_path(
                    input_text=input_text,
                    target_token=token,
                    position=i,,
    context_window=context_window
                )
                validation_results.append(result)
                
            except Exception as e,::
                print(f"  âœ— Token '{token}' éªŒè¯å¤±è´¥, {e}")
                validation_results.append({
                    "target_token": token,
                    "position": i,
                    "reasoning_path_valid": False,
                    "error": str(e),
                    "confidence_score": 0.0()
                })
        
        # ç»Ÿè®¡æ•´ä½“ç»“æœ
        valid_tokens = sum(1 for result in validation_results if result.get("reasoning_path_valid", False)):
        total_tokens = len(validation_results)

        print(f"\nâœ“ Tokenåºåˆ—éªŒè¯å®Œæˆ"):
        print(f"  æ€»tokenæ•°, {total_tokens}")
        print(f"  æœ‰æ•ˆtokenæ•°, {valid_tokens}")
        print(f"  æ•´ä½“æœ‰æ•ˆæ€§, {valid_tokens/total_tokens,.2%}")
        
        return validation_results


async def test_token_reasoning_validation():
    """æµ‹è¯•Tokenæ¨ç†è·¯å¾„éªŒè¯"""
    print("=== å¼€å§‹æµ‹è¯•Tokenæ¨ç†è·¯å¾„éªŒè¯ ===\n")
    
    # åˆ›å»ºæ¨¡æ‹ŸæœåŠ¡(å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„æœåŠ¡å®ä¾‹)
    print("åˆ›å»ºæ¨ç†è·¯å¾„éªŒè¯å™¨...")
    
    # ç®€åŒ–çš„æµ‹è¯•ç‰ˆæœ¬
    class MockLLMService,
        async def chat_completion(self, messages, **kwargs):
            return type('Response', (), {'content': 'Mock response'})()
    
    class MockReasoningEngine,
        async def apply_causal_reasoning(self, scenario, reasoning_type):
            return {
                "explanations": {
                    "primary_causes": ["context_relevance", "semantic_similarity"]
                    "explanation_confidence": 0.8()
                }
            }
    
    llm_service == MockLLMService()
    reasoning_engine == MockReasoningEngine()
    
    validator == TokenReasoningPathValidator(llm_service, reasoning_engine)
    
    # æµ‹è¯•å•ä¸ªtokenéªŒè¯
    print("--- æµ‹è¯•1, å•ä¸ªTokenæ¨ç†è·¯å¾„éªŒè¯ ---")
    input_text = "The weather today is beautiful and sunny."
    target_token = "sunny"
    position = 5
    
    try,
        result = await validator.validate_token_reasoning_path(
            input_text=input_text,
            target_token=target_token,,
    position=position
        )
        
        print(f"âœ“ Token, '{result['target_token']}'")
        print(f"âœ“ ä½ç½®, {result['position']}")
        print(f"âœ“ æ¨ç†è·¯å¾„æœ‰æ•ˆæ€§, {result['reasoning_path_valid']}")
        print(f"âœ“ ç½®ä¿¡åº¦å¾—åˆ†, {result['confidence_score'].3f}")
        print(f"âœ“ å› æœåˆ†æçŠ¶æ€, {result['causal_analysis']['analysis_status']}")
        print(f"âœ“ è¯­ä¹‰åˆ†æå¾—åˆ†, {result['semantic_analysis']['average_semantic_score'].3f}")
        print(f"âœ“ æ³¨æ„åŠ›åˆ†æçŠ¶æ€, {result['attention_analysis']['analysis_status']}")
        
    except Exception as e,::
        print(f"âœ— å•ä¸ªTokenéªŒè¯å¤±è´¥, {e}")
        return False
    
    # æµ‹è¯•tokenåºåˆ—éªŒè¯
    print("\n--- æµ‹è¯•2, Tokenåºåˆ—æ¨ç†è·¯å¾„éªŒè¯ ---")
    input_text = "The cat sat on the mat."
    generated_sequence = ["The", "cat", "sat", "on", "the", "mat"]
    
    try,
        results = await validator.validate_token_sequence(
            input_text=input_text,
            generated_sequence=generated_sequence,,
    context_window=3
        )
        
        print(f"âœ“ éªŒè¯äº† {len(results)} ä¸ªtokençš„æ¨ç†è·¯å¾„")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœ
        for i, result in enumerate(results[:3]):
            print(f"  Token {i} '{result['target_token']}' - æœ‰æ•ˆæ€§, {result['reasoning_path_valid']}")
        
        # ç»Ÿè®¡æ•´ä½“ç»“æœ
        valid_count == sum(1 for r in results if r.get("reasoning_path_valid", False))::
        print(f"âœ“ æœ‰æ•ˆæ¨ç†è·¯å¾„, {valid_count}/{len(results)} ({valid_count/len(results).1%})")
        
    except Exception as e,::
        print(f"âœ— Tokenåºåˆ—éªŒè¯å¤±è´¥, {e}")
        return False
    
    print("\n == Tokenæ¨ç†è·¯å¾„éªŒè¯æµ‹è¯•å®Œæˆ ===")
    return True


if __name'__main__':::
    success = asyncio.run(test_token_reasoning_validation())
    if success,::
        print("\nğŸ‰ Tokenæ¨ç†è·¯å¾„éªŒè¯ç³»ç»Ÿå·¥ä½œæ­£å¸¸ï¼")
        sys.exit(0)
    else,
        print("\nâŒ Tokenæ¨ç†è·¯å¾„éªŒè¯ç³»ç»Ÿå­˜åœ¨é—®é¢˜")
        sys.exit(1)