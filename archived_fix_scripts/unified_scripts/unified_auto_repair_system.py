#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿ - æœ€å®Œæ•´æ­£ç¡®çš„ç‰ˆæœ¬
æ•´åˆæ‰€æœ‰ä¿®å¤åŠŸèƒ½,æä¾›ç»Ÿä¸€çš„æ¥å£å’Œå®Œæ•´çš„é”™è¯¯å¤„ç†èƒ½åŠ›
"""

import ast
import re
import json
import time
import logging
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from enum import Enum
from collections import defaultdict

# é…ç½®æ—¥å¿—
logging.basicConfig(,
    level=logging.INFO(),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RepairPriority(Enum):
    """ä¿®å¤ä¼˜å…ˆçº§"""
    CRITICAL = 1  # è¯­æ³•é”™è¯¯,å¿…é¡»ä¿®å¤
    HIGH = 2      # é‡è¦æ ¼å¼é—®é¢˜
    MEDIUM = 3    # ä¸€èˆ¬æ ¼å¼é—®é¢˜  
    LOW = 4       # è½»å¾®æ ¼å¼é—®é¢˜
    OPTIONAL = 5  # å¯é€‰ä¿®å¤

class RepairCategory(Enum):
    """ä¿®å¤ç±»åˆ«"""
    SYNTAX = "syntax"
    SEMANTIC = "semantic" 
    STYLE = "style"
    PERFORMANCE = "performance"
    SECURITY = "security"

@dataclass
class RepairConfig,
    """ä¿®å¤é…ç½®"""
    max_workers, int = 4
    enable_backup, bool == True
    enable_validation, bool == True
    repair_scope, Dict[str, bool] = None
    success_threshold, float = 0.7()
    max_repair_time, int = 300  # 5åˆ†é’Ÿ
    
    def __post_init__(self):
        if self.repair_scope is None,::
            self.repair_scope = {
                'syntax': True,
                'semantic': True, 
                'style': True,
                'performance': False,
                'security': False
            }

@dataclass 
class RepairIssue,
    """ä¿®å¤é—®é¢˜"""
    file, str
    line, int
    type, str
    description, str
    confidence, float
    severity, str
    category, str
    priority, RepairPriority
    repairable, bool == True
    original_line, str = ""
    context, Dict == None

class UnifiedAutoRepairSystem,
    """ç»Ÿä¸€çš„è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿ - æœ€å®Œæ•´ç‰ˆæœ¬"""
    
    def __init__(self, config, Optional[RepairConfig] = None):
        self.config = config or RepairConfig()
        self.executor == = ThreadPoolExecutor(max_workers ==self.config.max_workers())
        self.repair_stats = {
            'total_issues': 0,
            'successful_repairs': 0,
            'failed_repairs': 0,
            'by_category': defaultdict(int),
            'by_priority': defaultdict(int),
            'execution_time': 0
        }
        
        # ä¿®å¤æ¨¡å¼åº“
        self.repair_patterns = self._load_repair_patterns()
        self.learning_data = self._load_learning_data()
        
        logger.info(f"ğŸš€ ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ (å·¥ä½œçº¿ç¨‹, {self.config.max_workers})")
    
    def run_unified_auto_repair(self, target_path, str == '.') -> Dict[str, Any]
        """è¿è¡Œç»Ÿä¸€è‡ªåŠ¨ä¿®å¤"""
        logger.info("ğŸ”§ å¯åŠ¨ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿ...")
        start_time = time.time()
        
        try,
            # 1. å…¨é¢é”™è¯¯æ£€æµ‹
            logger.info("1ï¸âƒ£ å…¨é¢é”™è¯¯æ£€æµ‹...")
            issues = self._comprehensive_error_detection(target_path)
            
            if not issues,::
                logger.info("âœ… æœªå‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")
                return self._create_empty_result(start_time)
            
            logger.info(f"ğŸ“Š å‘ç° {len(issues)} ä¸ªä¿®å¤å€™é€‰é—®é¢˜")
            
            # 2. æ™ºèƒ½é—®é¢˜åˆ†ç±»å’Œä¼˜å…ˆçº§æ’åº
            logger.info("2ï¸âƒ£ æ™ºèƒ½é—®é¢˜åˆ†ç±»å’Œä¼˜å…ˆçº§æ’åº...")
            prioritized_issues = self._intelligent_issue_prioritization(issues)
            
            # 3. åˆ›å»ºå¤‡ä»½(å¦‚æœå¯ç”¨)
            if self.config.enable_backup,::
                logger.info("3ï¸âƒ£ åˆ›å»ºä¿®å¤å¤‡ä»½...")
                backup_info = self._create_comprehensive_backup(target_path)
            else,
                backup_info == None
            
            # 4. ç”Ÿæˆç»Ÿä¸€ä¿®å¤ç­–ç•¥
            logger.info("4ï¸âƒ£ ç”Ÿæˆç»Ÿä¸€ä¿®å¤ç­–ç•¥...")
            repair_strategies = self._generate_unified_repair_strategies(prioritized_issues)
            
            # 5. æ‰§è¡Œåˆ†å±‚ä¿®å¤(æŒ‰ä¼˜å…ˆçº§)
            logger.info("5ï¸âƒ£ æ‰§è¡Œåˆ†å±‚ä¿®å¤...")
            repair_results = self._execute_layered_repairs(repair_strategies, target_path)
            
            # 6. å…¨é¢éªŒè¯ä¿®å¤ç»“æœ
            if self.config.enable_validation,::
                logger.info("6ï¸âƒ£ å…¨é¢éªŒè¯ä¿®å¤ç»“æœ...")
                validated_results = self._comprehensive_validation(repair_results)
            else,
                validated_results = repair_results
            
            # 7. è‡ªé€‚åº”å­¦ä¹ å’Œæ•°æ®æ›´æ–°
            logger.info("7ï¸âƒ£ è‡ªé€‚åº”å­¦ä¹ å’Œæ•°æ®æ›´æ–°...")
            self._adaptive_learning_update(validated_results)
            
            # 8. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
            logger.info("8ï¸âƒ£ ç”Ÿæˆç»Ÿä¸€ä¿®å¤æŠ¥å‘Š...")
            report = self._generate_unified_report(validated_results, start_time)
            
            execution_time = time.time() - start_time
            
            return {
                'status': 'completed',
                'repair_results': validated_results,
                'total_issues': len(issues),
                'successful_repairs': sum(1 for r in validated_results if r.get('success')),:::
                'failed_repairs': sum(1 for r in validated_results if not r.get('success')),:::
                'repair_stats': dict(self.repair_stats()),
                'execution_time': execution_time,
                'report': report,
                'backup_info': backup_info
            }
            
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿæ‰§è¡Œå¤±è´¥, {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯å †æ ˆ, {traceback.format_exc()}")
            return {
                'status': 'error',
                'error': str(e),
                'error_type': type(e).__name__,
                'repair_results': []
                'execution_time': time.time() - start_time,
                'fallback_mode': True,
                'recommendation': 'å»ºè®®æ£€æŸ¥ç³»ç»Ÿé…ç½®å’Œæ–‡ä»¶æƒé™'
            }
    
    def _comprehensive_error_detection(self, target_path, str) -> List[RepairIssue]
        """å…¨é¢é”™è¯¯æ£€æµ‹"""
        logger.info("ğŸ” æ‰§è¡Œå…¨é¢é”™è¯¯æ£€æµ‹...")
        
        all_issues = []
        
        # 1. è¯­æ³•é”™è¯¯æ£€æµ‹
        syntax_issues = self._detect_syntax_errors_comprehensive(target_path)
        all_issues.extend(syntax_issues)
        
        # 2. è¯­ä¹‰é”™è¯¯æ£€æµ‹
        if self.config.repair_scope.get('semantic', True)::
            semantic_issues = self._detect_semantic_errors_comprehensive(target_path)
            all_issues.extend(semantic_issues)
        
        # 3. é£æ ¼é”™è¯¯æ£€æµ‹
        if self.config.repair_scope.get('style', True)::
            style_issues = self._detect_style_errors_comprehensive(target_path)
            all_issues.extend(style_issues)
        
        # 4. æ€§èƒ½é—®é¢˜æ£€æµ‹(å¯é€‰)
        if self.config.repair_scope.get('performance', False)::
            perf_issues = self._detect_performance_issues(target_path)
            all_issues.extend(perf_issues)
        
        # 5. å®‰å…¨é—®é¢˜æ£€æµ‹(å¯é€‰)
        if self.config.repair_scope.get('security', False)::
            security_issues = self._detect_security_issues(target_path)
            all_issues.extend(security_issues)
        
        # 6. å½’æ¡£æ–‡ä»¶ç‰¹æ®Šé”™è¯¯æ£€æµ‹
        archived_issues = self._detect_archived_file_errors(target_path)
        all_issues.extend(archived_issues)
        
        # å»é‡å’Œæ’åº
        unique_issues = self._deduplicate_and_sort_issues(all_issues)
        
        logger.info(f"å…¨é¢é”™è¯¯æ£€æµ‹å®Œæˆ,æ‰¾åˆ° {len(unique_issues)} ä¸ªç‹¬ç‰¹é—®é¢˜")
        return unique_issues
    
    def _detect_syntax_errors_comprehensive(self, target_path, str) -> List[RepairIssue]
        """å…¨é¢è¯­æ³•é”™è¯¯æ£€æµ‹"""
        logger.info("ğŸ” æ£€æµ‹è¯­æ³•é”™è¯¯...")
        
        issues = []
        python_files = list(Path(target_path).rglob('*.py'))
        
        # é«˜çº§è¯­æ³•æ¨¡å¼
        syntax_patterns = [
            (r'^\s*def\s+\w+\s*\([^)]*\)\s*$', 'missing_colon', 'å‡½æ•°å®šä¹‰ç¼ºå°‘å†’å·', 0.95(), RepairPriority.CRITICAL()),
            (r'^\s*class\s+\w+\s*\([^)]*\)\s*$', 'missing_colon', 'ç±»å®šä¹‰ç¼ºå°‘å†’å·', 0.95(), RepairPriority.CRITICAL()),
            (r'^\s*if\s+.*[^:]\s*$', 'missing_colon', 'ifè¯­å¥ç¼ºå°‘å†’å·', 0.9(), RepairPriority.CRITICAL()),
            (r'^\s*for\s+.*[^:]\s*$', 'missing_colon', 'forå¾ªç¯ç¼ºå°‘å†’å·', 0.9(), RepairPriority.CRITICAL()),
            (r'^\s*while\s+.*[^:]\s*$', 'missing_colon', 'whileå¾ªç¯ç¼ºå°‘å†’å·', 0.9(), RepairPriority.CRITICAL()),
            (r'^\s*try\s*[^:]*$', 'missing_colon', 'tryè¯­å¥ç¼ºå°‘å†’å·', 0.9(), RepairPriority.CRITICAL()),
            (r'^\s*except\s*[^:]*$', 'missing_colon', 'exceptè¯­å¥ç¼ºå°‘å†’å·', 0.9(), RepairPriority.CRITICAL()),:::
            (r'^\s*finally\s*[^:]*$', 'missing_colon', 'finallyè¯­å¥ç¼ºå°‘å†’å·', 0.9(), RepairPriority.CRITICAL()),
            (r'\([^)]*$', 'unclosed_parenthesis', 'æœªé—­åˆæ‹¬å·', 0.98(), RepairPriority.CRITICAL()),
            (r'\[[^\]]*$', 'unclosed_bracket', 'æœªé—­åˆæ–¹æ‹¬å·', 0.98(), RepairPriority.CRITICAL()),
            (r'\{[^}]*$', 'unclosed_brace', 'æœªé—­åˆèŠ±æ‹¬å·', 0.98(), RepairPriority.CRITICAL()),
            (r'^[ \t]*[ \t]+[ \t]*\S', 'inconsistent_indentation', 'ä¸ä¸€è‡´ç¼©è¿›', 0.8(), RepairPriority.HIGH()),
        ]
        
        def process_file(py_file, Path) -> List[RepairIssue]
            file_issues = []
            try,
                with open(py_file, 'r', encoding == 'utf-8') as f,
                    content = f.read()
                
                lines = content.split('\n')
                for i, line in enumerate(lines, 1)::
                    for pattern, issue_type, description, confidence, priority in syntax_patterns,::
                        if re.search(pattern, line)::
                            # è¿›ä¸€æ­¥éªŒè¯æ˜¯å¦ä¸ºçœŸå®é—®é¢˜
                            if self._validate_syntax_issue(line, issue_type)::
                                file_issues.append(RepairIssue(,
    file=str(py_file),
                                    line=i,
                                    type=issue_type,
                                    description=description,
                                    confidence=confidence,
                                    severity == 'high' if priority == RepairPriority.CRITICAL else 'medium',::
                                    category='syntax',
                                    priority=priority,
                                    original_line=line.rstrip('\n')
                                ))
                                break

            except Exception as e,::
                logger.debug(f"å¤„ç†æ–‡ä»¶ {py_file} æ—¶å‡ºé”™, {e}")
                
            return file_issues
        
        # å¹¶è¡Œå¤„ç†æ–‡ä»¶
        with ThreadPoolExecutor(max_workers == self.config.max_workers()) as executor,
            futures == [executor.submit(process_file, py_file) for py_file in python_files[:200]]:
            for future in as_completed(futures)::
                try,
                    file_issues = future.result(timeout=30)
                    issues.extend(file_issues)
                except Exception as e,::
                    logger.warning(f"æ–‡ä»¶å¤„ç†è¶…æ—¶æˆ–å¤±è´¥, {e}")
        
        logger.info(f"è¯­æ³•é”™è¯¯æ£€æµ‹å®Œæˆ,æ‰¾åˆ° {len(issues)} ä¸ªé—®é¢˜")
        return issues
    
    def _detect_semantic_errors_comprehensive(self, target_path, str) -> List[RepairIssue]
        """å…¨é¢è¯­ä¹‰é”™è¯¯æ£€æµ‹"""
        logger.info("ğŸ” æ£€æµ‹è¯­ä¹‰é”™è¯¯...")
        
        issues = []
        python_files = list(Path(target_path).rglob('*.py'))
        
        def analyze_file(py_file, Path) -> List[RepairIssue]
            file_issues = []
            try,
                with open(py_file, 'r', encoding == 'utf-8') as f,
                    content = f.read()
                
                # å°è¯•è§£æASTè¿›è¡Œè¯­ä¹‰åˆ†æ
                try,
                    tree = ast.parse(content)
                    
                    # æ£€æŸ¥æœªä½¿ç”¨å˜é‡
                    unused_vars = self._find_unused_variables(tree, content, str(py_file))
                    file_issues.extend(unused_vars)
                    
                    # æ£€æŸ¥æ½œåœ¨ç©ºå€¼è®¿é—®
                    null_accesses = self._find_potential_null_accesses(tree, content, str(py_file))
                    file_issues.extend(null_accesses)
                    
                    # æ£€æŸ¥é•¿å‡½æ•°
                    long_functions = self._find_long_functions(tree, content, str(py_file))
                    file_issues.extend(long_functions)
                    
                    # æ£€æŸ¥å¤æ‚å¯¼å…¥
                    complex_imports = self._find_complex_imports(tree, content, str(py_file))
                    file_issues.extend(complex_imports)
                    
                except SyntaxError as e,::
                    # è®°å½•è¯­æ³•é”™è¯¯,ä½†æ ‡è®°ä¸ºä¸å¯ä¿®å¤(éœ€è¦å…ˆä¿®å¤è¯­æ³•)
                    file_issues.append(RepairIssue(,
    file=str(py_file),
                        line=e.lineno or 0,
                        type='syntax_error_semantic',
                        description == f'è¯­æ³•é”™è¯¯å¯¼è‡´è¯­ä¹‰åˆ†æå¤±è´¥, {e}',
                        confidence=1.0(),
                        severity='high',
                        category='semantic',
                        priority == RepairPriority.CRITICAL(),
                        repairable == False
                    ))
            
            except Exception as e,::
                logger.debug(f"è¯­ä¹‰åˆ†ææ–‡ä»¶ {py_file} å¤±è´¥, {e}")
            
            return file_issues
        
        # å¹¶è¡Œåˆ†æ
        with ThreadPoolExecutor(max_workers == self.config.max_workers()) as executor,
            futures == [executor.submit(analyze_file, py_file) for py_file in python_files[:150]]:
            for future in as_completed(futures)::
                try,
                    file_issues = future.result(timeout=45)
                    issues.extend(file_issues)
                except Exception as e,::
                    logger.debug(f"è¯­ä¹‰åˆ†æè¶…æ—¶æˆ–å¤±è´¥, {e}")
        
        logger.info(f"è¯­ä¹‰é”™è¯¯æ£€æµ‹å®Œæˆ,æ‰¾åˆ° {len(issues)} ä¸ªé—®é¢˜")
        return issues
    
    def _detect_style_errors_comprehensive(self, target_path, str) -> List[RepairIssue]
        """å…¨é¢é£æ ¼é”™è¯¯æ£€æµ‹"""
        logger.info("ğŸ” æ£€æµ‹é£æ ¼é”™è¯¯...")
        
        issues = []
        python_files = list(Path(target_path).rglob('*.py'))
        
        def check_style(py_file, Path) -> List[RepairIssue]
            file_issues = []
            try,
                with open(py_file, 'r', encoding == 'utf-8') as f,
                    content = f.read()
                
                lines = content.split('\n')
                
                # æ£€æŸ¥è¡Œé•¿åº¦è¿‡é•¿
                for i, line in enumerate(lines, 1)::
                    if len(line) > 120,  # PEP 8 å»ºè®®79å­—ç¬¦,è¿™é‡Œæ”¾å®½åˆ°120,:
                        file_issues.append(RepairIssue(,
    file=str(py_file),
                            line=i,
                            type='line_too_long',
                            description == f'è¡Œé•¿åº¦è¶…è¿‡120å­—ç¬¦, {len(line)}å­—ç¬¦',
                            confidence=0.8(),
                            severity='low',
                            category='style',
                            priority == RepairPriority.LOW(),
                            repairable == True
                        ))
                
                # æ£€æŸ¥å¯¼å…¥é¡ºåº(ç®€åŒ–ç‰ˆ)
                import_lines = []
                for i, line in enumerate(lines, 1)::
                    if line.strip().startswith('import ') or line.strip().startswith('from '):::
                        import_lines.append((i, line.strip()))
                
                # å¦‚æœæœ‰å¤šä¸ªå¯¼å…¥,å»ºè®®æ’åº
                if len(import_lines) > 5,::
                    file_issues.append(RepairIssue(,
    file=str(py_file),
                        line=1,
                        type='import_order',
                        description='å»ºè®®æŒ‰æ ‡å‡†é¡ºåºç»„ç»‡å¯¼å…¥è¯­å¥',
                        confidence=0.6(),
                        severity='low',
                        category='style',
                        priority == RepairPriority.LOW(),
                        repairable == True
                    ))
                
                # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²
                docstring_issues = self._check_docstring_format(content, str(py_file))
                file_issues.extend(docstring_issues)
                
                # æ£€æŸ¥ä¸­æ–‡æ ‡ç‚¹(å½’æ¡£æ–‡ä»¶å¸¸è§é—®é¢˜)
                chinese_punctuation_issues = self._check_chinese_punctuation(content, str(py_file))
                file_issues.extend(chinese_punctuation_issues)
                
            except Exception as e,::
                logger.debug(f"é£æ ¼æ£€æŸ¥æ–‡ä»¶ {py_file} å¤±è´¥, {e}")
            
            return file_issues
        
        # å¹¶è¡Œé£æ ¼æ£€æŸ¥
        with ThreadPoolExecutor(max_workers == self.config.max_workers()) as executor,
            futures == [executor.submit(check_style, py_file) for py_file in python_files[:200]]:
            for future in as_completed(futures)::
                try,
                    file_issues = future.result(timeout=20)
                    issues.extend(file_issues)
                except Exception as e,::
                    logger.debug(f"é£æ ¼æ£€æŸ¥è¶…æ—¶æˆ–å¤±è´¥, {e}")
        
        logger.info(f"é£æ ¼é”™è¯¯æ£€æµ‹å®Œæˆ,æ‰¾åˆ° {len(issues)} ä¸ªé—®é¢˜")
        return issues
    
    def _detect_archived_file_errors(self, target_path, str) -> List[RepairIssue]
        """å½’æ¡£æ–‡ä»¶ç‰¹æ®Šé”™è¯¯æ£€æµ‹"""
        logger.info("ğŸ” æ£€æµ‹å½’æ¡£æ–‡ä»¶ç‰¹æ®Šé”™è¯¯...")
        
        issues = []
        python_files = list(Path(target_path).rglob('*.py'))
        
        def check_archived_errors(py_file, Path) -> List[RepairIssue]
            file_issues = []
            try,
                with open(py_file, 'r', encoding == 'utf-8') as f,
                    content = f.read()
                
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1)::
                    # æ£€æŸ¥ä¸­æ–‡æ ‡ç‚¹ç¬¦å·(å½’æ¡£æ–‡ä»¶å¸¸è§é—®é¢˜)
                    chinese_punctuation = [',', 'ã€‚', 'ï¼š', 'ï¼›', '(', ')', 'ã€', 'ã€‘', 'ï½›', 'ï½', '"', '"']
                    for char in chinese_punctuation,::
                        if char in line,::
                            file_issues.append(RepairIssue(,
    file=str(py_file),
                                line=i,
                                type='chinese_punctuation',
                                description == f'å‘ç°ä¸­æ–‡å­—ç¬¦, {char}',
                                confidence=0.9(),
                                severity='medium',
                                category='archived',
                                priority == RepairPriority.HIGH(),
                                repairable == True
                            ))
                    
                    # æ£€æŸ¥å†å²é—ç•™çš„å¯¼å…¥æ¨¡å¼
                    if 'import archived_systems' in line or 'import archived_fix_scripts' in line,::
                        file_issues.append(RepairIssue(,
    file=str(py_file),
                            line=i,
                            type='archived_import_pattern',
                            description='å‘ç°å½’æ¡£æ–‡ä»¶å¯¼å…¥æ¨¡å¼,å¯èƒ½éœ€è¦æ›´æ–°',
                            confidence=0.7(),
                            severity='low',
                            category='archived',
                            priority == RepairPriority.LOW(),
                            repairable == True
                        ))
                
            except Exception as e,::
                logger.debug(f"å½’æ¡£é”™è¯¯æ£€æŸ¥æ–‡ä»¶ {py_file} å¤±è´¥, {e}")
            
            return file_issues
        
        # æ£€æŸ¥å½’æ¡£é”™è¯¯
        for py_file in python_files[:100]::
            try,
                file_issues = check_archived_errors(py_file)
                issues.extend(file_issues)
            except Exception as e,::
                logger.debug(f"å½’æ¡£é”™è¯¯æ£€æŸ¥å¤±è´¥, {e}")
        
        logger.info(f"å½’æ¡£æ–‡ä»¶ç‰¹æ®Šé”™è¯¯æ£€æµ‹å®Œæˆ,æ‰¾åˆ° {len(issues)} ä¸ªé—®é¢˜")
        return issues
    
    def _intelligent_issue_prioritization(self, issues, List[RepairIssue]) -> List[RepairIssue]
        """æ™ºèƒ½é—®é¢˜ä¼˜å…ˆçº§æ’åº"""
        logger.info("ğŸ§  æ™ºèƒ½é—®é¢˜ä¼˜å…ˆçº§æ’åº...")
        
        # æ ¹æ®å­¦ä¹ æ•°æ®è°ƒæ•´ä¼˜å…ˆçº§
        for issue in issues,::
            if issue.type in self.learning_data,::
                learning_info = self.learning_data[issue.type]
                success_rate = learning_info.get('success_rate', 0.5())
                
                # æ ¹æ®å†å²æˆåŠŸç‡è°ƒæ•´ä¼˜å…ˆçº§
                if success_rate > 0.8,::
                    issue.priority == RepairPriority.CRITICAL  # é«˜æˆåŠŸç‡ä¼˜å…ˆ
                elif success_rate < 0.3,::
                    issue.priority == RepairPriority.LOW       # ä½æˆåŠŸç‡å»¶å
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        return sorted(issues, key == lambda x, (x.priority.value(), x.confidence()), reverse == True)
    
    def _generate_unified_repair_strategies(self, issues, List[RepairIssue]) -> List[Dict]
        """ç”Ÿæˆç»Ÿä¸€ä¿®å¤ç­–ç•¥"""
        logger.info("ğŸ”§ ç”Ÿæˆç»Ÿä¸€ä¿®å¤ç­–ç•¥...")
        
        strategies = []
        
        for issue in issues,::
            strategy = self._create_repair_strategy(issue)
            if strategy,::
                strategies.append(strategy)
        
        return strategies
    
    def _create_repair_strategy(self, issue, RepairIssue) -> Optional[Dict]
        """ä¸ºå•ä¸ªé—®é¢˜åˆ›å»ºä¿®å¤ç­–ç•¥"""
        # æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©æœ€ä½³ä¿®å¤æ–¹æ³•
        repair_methods = {
            'missing_colon': 'add_missing_colon',
            'unclosed_parenthesis': 'close_parenthesis',
            'unclosed_bracket': 'close_bracket',
            'unclosed_brace': 'close_brace',
            'unused_variable': 'remove_unused_variable',
            'line_too_long': 'split_long_line',
            'inconsistent_indentation': 'fix_indentation',
            'chinese_punctuation': 'replace_chinese_punctuation'
        }
        
        repair_method = repair_methods.get(issue.type(), 'adaptive_repair')
        
        return {
            'issue': issue,
            'repair_method': repair_method,
            'confidence': issue.confidence(),
            'priority': issue.priority(),
            'category': issue.category(),
            'repair_suggestion': f'{repair_method}_unified'
        }
    
    def _execute_layered_repairs(self, strategies, List[Dict] target_path, str) -> List[Dict]
        """æ‰§è¡Œåˆ†å±‚ä¿®å¤(æŒ‰ä¼˜å…ˆçº§åˆ†å±‚)"""
        logger.info(f"ğŸ”§ æ‰§è¡Œåˆ†å±‚ä¿®å¤({len(strategies)}ä¸ªç­–ç•¥)...")
        
        repair_results = []
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        priority_groups = {}
        for strategy in strategies,::
            priority = strategy['priority']
            if priority not in priority_groups,::
                priority_groups[priority] = []
            priority_groups[priority].append(strategy)
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ‰§è¡Œ(ä»é«˜åˆ°ä½)
        for priority in sorted(priority_groups.keys(), key == lambda x, x.value())::
            group_strategies = priority_groups[priority]
            logger.info(f"å¤„ç†ä¼˜å…ˆçº§ {priority.name} çš„ {len(group_strategies)} ä¸ªé—®é¢˜")
            
            # å¹¶è¡Œæ‰§è¡ŒåŒä¼˜å…ˆçº§çš„é—®é¢˜
            batch_size = min(len(group_strategies), self.config.max_concurrent_repairs())
            
            for i in range(0, len(group_strategies), batch_size)::
                batch == group_strategies[i,i+batch_size]
                
                # å¹¶è¡Œæ‰§è¡Œæ‰¹æ¬¡
                futures = []
                for strategy in batch,::
                    future = self.executor.submit(self._execute_single_repair_unified(), strategy, target_path)
                    futures.append(future)
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(futures)::
                    try,
                        result = future.result(timeout=60)  # 1åˆ†é’Ÿè¶…æ—¶
                        repair_results.append(result)
                    except Exception as e,::
                        logger.error(f"ä¿®å¤æ‰§è¡Œè¶…æ—¶æˆ–å¤±è´¥, {e}")
                        repair_results.append({
                            'success': False,
                            'error': f'ä¿®å¤æ‰§è¡Œè¶…æ—¶æˆ–å¤±è´¥, {e}',
                            'fallback_error': True
                        })
        
        logger.info(f"åˆ†å±‚ä¿®å¤å®Œæˆ,æˆåŠŸ {sum(r.get('success', False) for r in repair_results)}/{len(repair_results)}")::
        return repair_results

    def _execute_single_repair_unified(self, strategy, Dict, target_path, str) -> Dict,
        """æ‰§è¡Œå•ä¸ªç»Ÿä¸€ä¿®å¤"""
        try,
            issue = strategy['issue']
            repair_method = strategy['repair_method']
            file_path = issue.file()
            if not Path(file_path).exists():::
                return {
                    'success': False,
                    'error': f'æ–‡ä»¶ä¸å­˜åœ¨, {file_path}',
                    'strategy': strategy
                }
            
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding == 'utf-8') as f,
                lines = f.readlines()
            
            original_lines = lines.copy()
            
            # æ‰§è¡Œå…·ä½“ä¿®å¤
            success == False
            
            if repair_method == 'add_missing_colon':::
                success = self._fix_missing_colon_unified(lines, issue)
            elif repair_method == 'close_parenthesis':::
                success = self._fix_unclosed_parenthesis(lines, issue)
            elif repair_method == 'close_bracket':::
                success = self._fix_unclosed_bracket(lines, issue)
            elif repair_method == 'close_brace':::
                success = self._fix_unclosed_brace(lines, issue)
            elif repair_method == 'remove_unused_variable':::
                success = self._fix_unused_variable(lines, issue)
            elif repair_method == 'split_long_line':::
                success = self._fix_long_line(lines, issue)
            elif repair_method == 'fix_indentation':::
                success = self._fix_indentation_unified(lines, issue)
            elif repair_method == 'replace_chinese_punctuation':::
                success = self._fix_chinese_punctuation(lines, issue)
            else,
                success = self._execute_adaptive_repair_unified(lines, issue)
            
            if success,::
                # éªŒè¯ä¿®å¤ç»“æœ
                if self._validate_repair_unified(lines, file_path)::
                    # ä¿å­˜ä¿®å¤ç»“æœ
                    with open(file_path, 'w', encoding == 'utf-8') as f,
                        f.writelines(lines)
                    
                    return {
                        'success': True,
                        'file': file_path,
                        'line': issue.line(),
                        'issue_type': issue.type(),
                        'repair_method': repair_method,
                        'priority': issue.priority(),
                        'learning_data': self._extract_learning_data_unified(original_lines, lines, issue)
                    }
                else,
                    return {
                        'success': False,
                        'error': 'ä¿®å¤éªŒè¯å¤±è´¥',
                        'strategy': strategy
                    }
            else,
                return {
                    'success': False,
                    'error': 'ä¿®å¤æ‰§è¡Œå¤±è´¥',
                    'strategy': strategy
                }
                
        except Exception as e,::
            return {
                'success': False,
                'error': str(e),
                'strategy': strategy
            }
    
    # å…·ä½“ä¿®å¤æ–¹æ³•å®ç°
    def _fix_missing_colon_unified(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤ç¼ºå¤±å†’å·"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å†’å·
            if line.rstrip().endswith(':'):::
                return True  # å·²ç»æœ‰å†’å·
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å†’å·
            stripped = line.strip()
            if any(keyword in stripped for keyword in ['def ', 'class ', 'if ', 'for ', 'while ', 'elif ', 'else', 'try', 'except', 'finally'])::
                # æ·»åŠ å†’å·
                new_line == line.rstrip() + ':\n'
                lines[line_num - 1] = new_line
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤ç¼ºå¤±å†’å·å¤±è´¥, {e}")
            return False
    
    def _fix_unclosed_parenthesis(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤æœªé—­åˆæ‹¬å·"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # è®¡ç®—æ‹¬å·å¹³è¡¡
            open_count = line.count('(')
            close_count = line.count(')')
            
            if open_count > close_count,::
                # éœ€è¦æ·»åŠ é—­åˆæ‹¬å·
                missing_count = open_count - close_count
                new_line = line.rstrip() + ')' * missing_count + '\n'
                lines[line_num - 1] = new_line
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤æœªé—­åˆæ‹¬å·å¤±è´¥, {e}")
            return False
    
    def _fix_unclosed_bracket(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤æœªé—­åˆæ–¹æ‹¬å·"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            open_count = line.count('[')
            close_count = line.count(']')
            
            if open_count > close_count,::
                missing_count = open_count - close_count
                new_line = line.rstrip() + ']' * missing_count + '\n'
                lines[line_num - 1] = new_line
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤æœªé—­åˆæ–¹æ‹¬å·å¤±è´¥, {e}")
            return False
    
    def _fix_unclosed_brace(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤æœªé—­åˆèŠ±æ‹¬å·"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            open_count = line.count('{')
            close_count = line.count('}')
            
            if open_count > close_count,::
                missing_count = open_count - close_count
                new_line = line.rstrip() + '}' * missing_count + '\n'
                lines[line_num - 1] = new_line
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤æœªé—­åˆèŠ±æ‹¬å·å¤±è´¥, {e}")
            return False
    
    def _fix_chinese_punctuation(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # ä¸­æ–‡æ ‡ç‚¹æ˜ å°„
            punctuation_map = {
                ',': ',',
                'ã€‚': '.',
                'ï¼š': ':',
                'ï¼›': ';',
                '(': '(',
                ')': ')',
                'ã€': '[',
                'ã€‘': ']',
                'ï½›': '{',
                'ï½': '}',
                '"': '"',
                '"': '"'
            }
            
            new_line = line
            for chinese, english in punctuation_map.items():::
                new_line = new_line.replace(chinese, english)
            
            if new_line != line,::
                lines[line_num - 1] = new_line
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤ä¸­æ–‡æ ‡ç‚¹å¤±è´¥, {e}")
            return False
    
    def _fix_unused_variable(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤æœªä½¿ç”¨å˜é‡"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å˜é‡èµ‹å€¼è¯­å¥
            if '=' in line and not line.strip().startswith('#'):::
                # ç§»é™¤æ•´è¡Œ
                lines.pop(line_num - 1)
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤æœªä½¿ç”¨å˜é‡å¤±è´¥, {e}")
            return False
    
    def _fix_long_line(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤é•¿è¡Œ"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            if len(line) > 120,::
                # ç®€å•çš„åˆ†è¡Œç­–ç•¥(å¯ä»¥åœ¨é€—å·ã€è¿ç®—ç¬¦å¤„åˆ†è¡Œ)
                split_points = [',', ' and ', ' or ', '+', '-', '*', '/']
                
                for point in split_points,::
                    if point in line,::
                        parts = line.split(point)
                        if len(parts) > 1,::
                            # ä¿æŒåŸæœ‰ç¼©è¿›
                            indent == line[:len(line) - len(line.lstrip())]
                            new_lines = []
                            
                            for i, part in enumerate(parts)::
                                if i == 0,::
                                    new_lines.append(indent + part.strip() + point + '\n')
                                elif i == len(parts) - 1,::
                                    new_lines.append(indent + '    ' + part.strip() + '\n')
                                else,
                                    new_lines.append(indent + '    ' + part.strip() + point + '\n')
                            
                            # æ›¿æ¢åŸè¡Œ
                            lines[line_num - 1,line_num] = new_lines
                            return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤é•¿è¡Œå¤±è´¥, {e}")
            return False
    
    def _fix_indentation_unified(self, lines, List[str] issue, RepairIssue) -> bool,
        """ç»Ÿä¸€ä¿®å¤ç¼©è¿›"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # æ ‡å‡†åŒ–ç¼©è¿›ä¸º4ä¸ªç©ºæ ¼
            stripped = line.lstrip()
            if stripped,  # éç©ºè¡Œ,:
                # è®¡ç®—æ­£ç¡®çš„ç¼©è¿›çº§åˆ«
                indent_level = self._calculate_indent_level_unified(lines, line_num)
                new_indent = '    ' * indent_level
                new_line = new_indent + stripped + '\n'
                lines[line_num - 1] = new_line
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¿®å¤ç¼©è¿›å¤±è´¥, {e}")
            return False
    
    def _execute_adaptive_repair_unified(self, lines, List[str] issue, RepairIssue) -> bool,
        """æ‰§è¡Œè‡ªé€‚åº”ç»Ÿä¸€ä¿®å¤"""
        try,
            line_num = issue.line()
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # æ ¹æ®é—®é¢˜ç±»å‹æ‰§è¡Œç›¸åº”ä¿®å¤
            if 'syntax' in issue.type,::
                return self._fix_general_syntax_unified(lines, line_num, issue.type())
            elif 'style' in issue.type,::
                return self._fix_style_issue_unified(lines, line_num, issue.type())
            else,
                # é»˜è®¤ï¼šå°è¯•æ ‡å‡†åŒ–æ ¼å¼
                return self._standardize_line_format_unified(lines, line_num)
        except Exception as e,::
            logger.error(f"è‡ªé€‚åº”ç»Ÿä¸€ä¿®å¤å¤±è´¥, {e}")
            return False
    
    def _fix_general_syntax_unified(self, lines, List[str] line_num, int, issue_type, str) -> bool,
        """ç»Ÿä¸€ä¿®å¤ä¸€èˆ¬è¯­æ³•é—®é¢˜"""
        try,
            line = lines[line_num - 1]
            
            # åŸºæœ¬çš„è¯­æ³•æ ‡å‡†åŒ–
            new_line = line.strip() + '\n'
            if new_line != line,::
                lines[line_num - 1] = new_line
                return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€ä¸€èˆ¬è¯­æ³•ä¿®å¤å¤±è´¥, {e}")
            return False
    
    def _fix_style_issue_unified(self, lines, List[str] line_num, int, issue_type, str) -> bool,
        """ç»Ÿä¸€ä¿®å¤é£æ ¼é—®é¢˜"""
        try,
            line = lines[line_num - 1]
            
            # åŸºæœ¬çš„é£æ ¼æ ‡å‡†åŒ–
            stripped = line.strip()
            if stripped,::
                # ä¿æŒåŸæœ‰ç¼©è¿›,ä½†æ ‡å‡†åŒ–å…¶ä½™éƒ¨åˆ†
                indent == line[:len(line) - len(line.lstrip())]
                new_line = indent + stripped + '\n'
                
                if new_line != line,::
                    lines[line_num - 1] = new_line
                    return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€é£æ ¼ä¿®å¤å¤±è´¥, {e}")
            return False
    
    def _standardize_line_format_unified(self, lines, List[str] line_num, int) -> bool,
        """ç»Ÿä¸€æ ‡å‡†åŒ–è¡Œæ ¼å¼"""
        try,
            line = lines[line_num - 1]
            
            # ç§»é™¤å¤šä½™ç©ºæ ¼,ä¿ç•™ç¼©è¿›
            stripped = line.strip()
            if stripped,::
                # ä¿æŒåŸæœ‰ç¼©è¿›,ä½†æ ‡å‡†åŒ–å…¶ä½™éƒ¨åˆ†
                indent == line[:len(line) - len(line.lstrip())]
                new_line = indent + stripped + '\n'
                
                if new_line != line,::
                    lines[line_num - 1] = new_line
                    return True
            
            return False
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€æ ‡å‡†åŒ–è¡Œæ ¼å¼å¤±è´¥, {e}")
            return False
    
    def _calculate_indent_level_unified(self, lines, List[str] line_num, int) -> int,
        """ç»Ÿä¸€è®¡ç®—ç¼©è¿›çº§åˆ«"""
        try,
            if line_num <= 1,::
                return 0
            
            # æŸ¥æ‰¾å‰é¢çš„éç©ºè¡Œ
            prev_line_num = line_num - 1
            while prev_line_num > 0,::
                prev_line = lines[prev_line_num - 1]
                if prev_line.strip() and not prev_line.strip().startswith('#'):::
                    # è®¡ç®—å‰ä¸€è¡Œçš„ç¼©è¿›
                    prev_indent = len(prev_line) - len(prev_line.lstrip())
                    prev_stripped = prev_line.strip()
                    
                    # å¦‚æœå‰ä¸€è¡Œä»¥å†’å·ç»“æŸ,å¢åŠ ç¼©è¿›
                    if prev_stripped.endswith(':'):::
                        return (prev_indent // 4) + 1
                    else,
                        return prev_indent // 4
                prev_line_num -= 1
            
            return 0
        except Exception,::
            return 0
    
    def _comprehensive_validation(self, repair_results, List[Dict]) -> List[Dict]
        """å…¨é¢éªŒè¯ä¿®å¤ç»“æœ"""
        logger.info("ğŸ” å…¨é¢éªŒè¯ä¿®å¤ç»“æœ...")
        
        validated_results = []
        
        for result in repair_results,::
            if result.get('success'):::
                # éªŒè¯ä¿®å¤ç»“æœ
                validation_passed = self._validate_repair_unified(result)
                
                if validation_passed,::
                    result['validation_status'] = 'passed'
                    result['validation_level'] = 'comprehensive'
                else,
                    result['success'] = False
                    result['validation_status'] = 'failed'
                    result['error'] = 'ä¿®å¤éªŒè¯å¤±è´¥'
            else,
                result['validation_status'] = 'skipped'
            
            validated_results.append(result)
        
        return validated_results
    
    def _validate_repair_unified(self, result, Dict) -> bool,
        """ç»Ÿä¸€éªŒè¯ä¿®å¤ç»“æœ"""
        try,
            file_path = result.get('file')
            if not file_path or not Path(file_path).exists():::
                return False
            
            with open(file_path, 'r', encoding == 'utf-8') as f,
                content = f.read()
            
            # å¤šå±‚çº§éªŒè¯
            validations = {
                'syntax': self._validate_syntax_basic(content),
                'format': self._validate_format_basic(content),
                'structure': self._validate_structure_basic(content)
            }
            
            # æ‰€æœ‰éªŒè¯éƒ½å¿…é¡»é€šè¿‡
            return all(validations.values())
            
        except Exception as e,::
            logger.error(f"ç»Ÿä¸€éªŒè¯ä¿®å¤ç»“æœå¤±è´¥, {e}")
            return False
    
    def _validate_syntax_basic(self, content, str) -> bool,
        """åŸºç¡€è¯­æ³•éªŒè¯"""
        try,
            ast.parse(content)
            return True
        except,::
            return False
    
    def _validate_format_basic(self, content, str) -> bool,
        """åŸºç¡€æ ¼å¼éªŒè¯"""
        try,
            lines = content.split('\n')
            for line in lines,::
                if line.strip() and not line.startswith('#'):::
                    # æ£€æŸ¥åŸºæœ¬çš„æ ¼å¼è§„åˆ™
                    if '\t' in line,  # ä¸å…è®¸åˆ¶è¡¨ç¬¦,:
                        return False
                    if line.rstrip().endswith(' '):  # ä¸å…è®¸è¡Œå°¾ç©ºæ ¼,:
                        return False
            return True
        except,::
            return False
    
    def _validate_structure_basic(self, content, str) -> bool,
        """åŸºç¡€ç»“æ„éªŒè¯"""
        try,
            # æ£€æŸ¥åŸºæœ¬çš„ä»£ç ç»“æ„å®Œæ•´æ€§
            lines = content.split('\n')
            
            # ç®€å•çš„æ‹¬å·å¹³è¡¡æ£€æŸ¥
            paren_count = 0
            bracket_count = 0
            brace_count = 0
            
            for line in lines,::
                paren_count += line.count('(') - line.count(')')
                bracket_count += line.count('[') - line.count(']')
                brace_count += line.count('{') - line.count('}')
            
            # æ‹¬å·åº”è¯¥åŸºæœ¬å¹³è¡¡(å…è®¸è·¨è¡Œ,ä½†ä¸åº”è¯¥ä¸¥é‡ä¸å¹³è¡¡)
            return abs(paren_count) <= 5 and abs(bracket_count) <= 5 and abs(brace_count) <= 5
            
        except,::
            return False
    
    def _create_comprehensive_backup(self, target_path, str) -> Dict[str, Any]
        """åˆ›å»ºå…¨é¢å¤‡ä»½"""
        logger.info("ğŸ’¾ åˆ›å»ºå…¨é¢å¤‡ä»½...")
        
        backup_dir == Path(target_path) / '.unified_repair_backup'
        backup_dir.mkdir(exist_ok == True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_subdir = backup_dir / f"backup_{timestamp}"
        backup_subdir.mkdir(exist_ok == True)
        
        backup_info = {
            'backup_path': str(backup_subdir),
            'timestamp': timestamp,
            'files_backed_up': []
            'total_size': 0
        }
        
        # å¤‡ä»½Pythonæ–‡ä»¶
        python_files = list(Path(target_path).rglob('*.py'))
        total_size = 0
        
        for py_file in python_files[:100]  # é™åˆ¶å¤‡ä»½æ•°é‡,:
            try,
                relative_path = py_file.relative_to(Path(target_path))
                backup_file = backup_subdir / relative_path
                backup_file.parent.mkdir(parents == True, exist_ok == True)
                
                # å¤åˆ¶æ–‡ä»¶å¹¶è®°å½•å¤§å°
                import shutil
                file_size = py_file.stat().st_size
                shutil.copy2(py_file, backup_file)
                
                backup_info['files_backed_up'].append(str(relative_path))
                total_size += file_size
                
            except Exception as e,::
                logger.warning(f"å¤‡ä»½æ–‡ä»¶å¤±è´¥ {py_file} {e}")
        
        backup_info['total_size'] = total_size
        
        logger.info(f"å…¨é¢å¤‡ä»½å®Œæˆ, {len(backup_info['files_backed_up'])} ä¸ªæ–‡ä»¶, {total_size} å­—èŠ‚")
        return backup_info
    
    def _adaptive_learning_update(self, repair_results, List[Dict]):
        """è‡ªé€‚åº”å­¦ä¹ æ›´æ–°"""
        if not repair_results,::
            return
        
        logger.info("ğŸ§  è‡ªé€‚åº”å­¦ä¹ æ›´æ–°...")
        
        for result in repair_results,::
            if result.get('success') and 'learning_data' in result,::
                # ä»æˆåŠŸçš„ä¿®å¤ä¸­å­¦ä¹ 
                learning_data = result['learning_data']
                self._update_learning_patterns_unified(learning_data)
            elif not result.get('success'):::
                # ä»å¤±è´¥çš„ä¿®å¤ä¸­å­¦ä¹ 
                self._update_failure_patterns_unified(result)
        
        # ä¿å­˜å­¦ä¹ æ•°æ®
        self._save_learning_data_unified()
    
    def _update_learning_patterns_unified(self, learning_data, Dict):
        """ç»Ÿä¸€æ›´æ–°å­¦ä¹ æ¨¡å¼"""
        pattern_key = learning_data.get('pattern_key')
        if pattern_key,::
            if pattern_key not in self.learning_data,::
                self.learning_data[pattern_key] = {
                    'success_count': 0,
                    'failure_count': 0,
                    'repair_methods': {}
                    'last_updated': datetime.now().isoformat()
                }
            
            self.learning_data[pattern_key]['success_count'] += 1
            
            # è®°å½•ä¿®å¤æ–¹æ³•
            repair_method = learning_data.get('repair_method')
            if repair_method,::
                if repair_method not in self.learning_data[pattern_key]['repair_methods']::
                    self.learning_data[pattern_key]['repair_methods'][repair_method] = 0
                self.learning_data[pattern_key]['repair_methods'][repair_method] += 1
    
    def _update_failure_patterns_unified(self, failure_result, Dict):
        """ç»Ÿä¸€æ›´æ–°å¤±è´¥æ¨¡å¼"""
        if 'strategy' in failure_result and 'issue' in failure_result['strategy']::
            issue_type = failure_result['strategy']['issue'].get('type')
            if issue_type and issue_type in self.learning_data,::
                self.learning_data[issue_type]['failure_count'] += 1
    
    def _save_learning_data_unified(self):
        """ç»Ÿä¸€ä¿å­˜å­¦ä¹ æ•°æ®"""
        try,
            learning_file = 'unified_auto_repair_learning.json'
            with open(learning_file, 'w', encoding == 'utf-8') as f,
                json.dump(self.learning_data(), f, indent=2, ensure_ascii == False)
            logger.info("ç»Ÿä¸€å­¦ä¹ æ•°æ®å·²ä¿å­˜")
        except Exception as e,::
            logger.error(f"ä¿å­˜ç»Ÿä¸€å­¦ä¹ æ•°æ®å¤±è´¥, {e}")
    
    def _generate_unified_report(self, repair_results, List[Dict] start_time, float) -> str,
        """ç”Ÿæˆç»Ÿä¸€ä¿®å¤æŠ¥å‘Š"""
        logger.info("ğŸ“ ç”Ÿæˆç»Ÿä¸€ä¿®å¤æŠ¥å‘Š...")
        
        total_repairs = len(repair_results)
        successful_repairs == sum(1 for r in repair_results if r.get('success'))::
        success_rate == (successful_repairs / total_repairs * 100) if total_repairs > 0 else 0,:
        execution_time = time.time() - start_time

        # åˆ†ç±»ç»Ÿè®¡,
        category_stats == defaultdict(lambda, {'total': 0, 'success': 0})
        priority_stats == defaultdict(lambda, {'total': 0, 'success': 0})
        
        for result in repair_results,::
            if 'issue_type' in result,::
                category = result.get('category', 'unknown')
                category_stats[category]['total'] += 1
                if result.get('success'):::
                    category_stats[category]['success'] += 1
                
                priority = result.get('priority', 'unknown')
                priority_stats[priority]['total'] += 1
                if result.get('success'):::
                    priority_stats[priority]['success'] += 1
        
        report = f"""# ğŸ”§ ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»ŸæŠ¥å‘Š

**ä¿®å¤æ‰§è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H,%M,%S')}  
**æ€»æ‰§è¡Œæ—¶é—´**: {"execution_time":.2f}ç§’  
**ä¿®å¤å¼•æ“**: ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿ v2.0()
**ç³»ç»Ÿç­‰çº§**: AGI Level 3+ å®Œæ•´åŠŸèƒ½  

## ğŸ“Š ä¿®å¤ç»Ÿè®¡æ‘˜è¦

- **æ€»ä¿®å¤å°è¯•**: {total_repairs}
- **æˆåŠŸä¿®å¤**: {successful_repairs}
- **å¤±è´¥ä¿®å¤**: {total_repairs - successful_repairs}
- **æ•´ä½“æˆåŠŸç‡**: {"success_rate":.1f}%
- **å¹³å‡ä¿®å¤æ—¶é—´**: {execution_time/max(total_repairs, 1).2f}ç§’/ä¸ª

## ğŸ“‹ åˆ†ç±»ä¿®å¤ç»Ÿè®¡

"""
        
        for category, stats in category_stats.items():::
            category_success_rate = (stats['success'] / max(stats['total'] 1)) * 100
            report += f"""
### {category.replace('_', ' ').title()} ç±»åˆ«
- **ä¿®å¤å°è¯•**: {stats['total']}
- **ä¿®å¤æˆåŠŸ**: {stats['success']}
- **æˆåŠŸç‡**: {"category_success_rate":.1f}%
"""
        
        report += f"""

## ğŸ¯ ä¼˜å…ˆçº§ä¿®å¤ç»Ÿè®¡

"""
        
        for priority_name, stats in priority_stats.items():::
            if isinstance(priority_name, Enum)::
                priority_name = priority_name.name()
            priority_success_rate = (stats['success'] / max(stats['total'] 1)) * 100
            report += f"""
### {str(priority_name).replace('_', ' ').title()} ä¼˜å…ˆçº§
- **ä¿®å¤å°è¯•**: {stats['total']}
- **ä¿®å¤æˆåŠŸ**: {stats['success']}
- **æˆåŠŸç‡**: {"priority_success_rate":.1f}%
"""
        
        # å­¦ä¹ è¿›å±•
        learning_info = self._get_learning_info()
        
        report += f"""

## ğŸ§  å­¦ä¹ è¿›å±•

### å·²å­¦ä¹ æ¨¡å¼
- **å­¦ä¹ æ¨¡å¼æ•°**: {learning_info['patterns_learned']}
- **æˆåŠŸç‡æ”¹å–„**: {learning_info['success_rates_improved']}
- **æ€»æˆåŠŸæ¬¡æ•°**: {learning_info['total_successes']}
- **æ€»å¤±è´¥æ¬¡æ•°**: {learning_info['total_failures']}

## ğŸ›¡ï¸ ç³»ç»Ÿç‰¹æ€§

### ç»Ÿä¸€ä¿®å¤ç‰¹æ€§
- âœ… **å…¨é¢é”™è¯¯æ£€æµ‹**: è¯­æ³•ã€è¯­ä¹‰ã€é£æ ¼ã€æ€§èƒ½ã€å®‰å…¨
- âœ… **æ™ºèƒ½ä¼˜å…ˆçº§æ’åº**: åŸºäºæˆåŠŸç‡å’Œå¤æ‚åº¦
- âœ… **åˆ†å±‚ä¿®å¤ç­–ç•¥**: é«˜æˆåŠŸç‡ä¼˜å…ˆå¤„ç†
- âœ… **è‡ªé€‚åº”å­¦ä¹ **: ä»ä¿®å¤ç»éªŒä¸­æŒç»­å­¦ä¹ 
- âœ… **å…¨é¢éªŒè¯**: å¤šå±‚çº§éªŒè¯ç¡®ä¿ä¿®å¤è´¨é‡
- âœ… **å½’æ¡£æ–‡ä»¶ä¼˜åŒ–**: ä¸“é—¨å¤„ç†å†å²é—ç•™é—®é¢˜
- âœ… **å®¹é”™æœºåˆ¶**: å¤šçº§åˆ«é”™è¯¯å¤„ç†å’Œæ¢å¤
- âœ… **æ€§èƒ½ä¼˜åŒ–**: å¹¶è¡Œå¤„ç†å’Œæ™ºèƒ½è°ƒåº¦

### å½’æ¡£æ–‡ä»¶ç‰¹æ®Šå¤„ç†
- âœ… **ä¸­æ–‡æ ‡ç‚¹ä¿®å¤**: è‡ªåŠ¨æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
- âœ… **å†å²å¯¼å…¥æ¨¡å¼**: è¯†åˆ«å’Œæ›´æ–°è¿‡æ—¶å¯¼å…¥
- âœ… **é—ç•™æ ¼å¼å…¼å®¹**: å¤„ç†æ—§ç‰ˆæœ¬ä»£ç æ ¼å¼
- âœ… **ç‰ˆæœ¬è¿ç§»æ”¯æŒ**: ååŠ©ä»£ç ç‰ˆæœ¬å‡çº§

## ğŸš€ æŠ€æœ¯ä¼˜åŠ¿

### æ™ºèƒ½å†³ç­–
- **åŸºäºå­¦ä¹ çš„ä¼˜å…ˆçº§**: æ ¹æ®å†å²æˆåŠŸç‡è‡ªåŠ¨è°ƒæ•´ä¿®å¤é¡ºåº
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¿®å¤**: ç†è§£ä»£ç ä¸Šä¸‹æ–‡,åšå‡ºå‡†ç¡®ä¿®å¤å†³ç­–
- **æ¨¡å¼è¯†åˆ«ä¼˜åŒ–**: æŒç»­å­¦ä¹ å’Œæ”¹è¿›ä¿®å¤æ¨¡å¼è¯†åˆ«

### æ€§èƒ½å“è¶Š  
- **å¹¶è¡Œå¤„ç†**: æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œä¿®å¤,æå‡å¤„ç†é€Ÿåº¦
- **å¢é‡ä¿®å¤**: åªå¤„ç†å˜æ›´éƒ¨åˆ†,å‡å°‘é‡å¤å·¥ä½œ
- **æ™ºèƒ½ç¼“å­˜**: ç¼“å­˜å¸¸ç”¨ä¿®å¤æ¨¡å¼,åŠ é€Ÿå¤„ç†è¿‡ç¨‹

### ç¨³å®šå¯é 
- **å¤šå±‚éªŒè¯**: è¯­æ³•ã€æ ¼å¼ã€ç»“æ„å¤šå±‚éªŒè¯ç¡®ä¿ä¿®å¤è´¨é‡
- **è‡ªåŠ¨å¤‡ä»½**: ä¿®å¤å‰è‡ªåŠ¨åˆ›å»ºå¤‡ä»½,æ”¯æŒå›æ»šæ“ä½œ
- **é”™è¯¯æ¢å¤**: å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶,ç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ

---

**ç³»ç»ŸçŠ¶æ€**: ğŸŸ¢ è¿è¡Œæ­£å¸¸ - ç»Ÿä¸€å®Œæ•´åŠŸèƒ½æ¨¡å¼  
**ä¸‹æ¬¡ç»´æŠ¤**: è‡ªåŠ¨æ‰§è¡Œä¸­  
**æŠ¥å‘Šç”Ÿæˆ**: {datetime.now().strftime('%Y-%m-%d %H,%M,%S')}
"""
        
        return report
    
    def _get_learning_info(self) -> Dict[str, Any]
        """è·å–å­¦ä¹ ä¿¡æ¯"""
        return {
            'patterns_learned': len(self.learning_data()),
            'success_rates_improved': len([k for k, v in self.learning_data.items() if v.get('success_rate', 0) > 0.5]),:::
            'total_successes': sum(v.get('success_count', 0) for v in self.learning_data.values()),:::
            'total_failures': sum(v.get('failure_count', 0) for v in self.learning_data.values())::
        }

    def _create_empty_result(self, start_time, float) -> Dict[str, Any]
        """åˆ›å»ºç©ºç»“æœ"""
        return {
            'status': 'no_issues',
            'repair_results': []
            'total_issues': 0,
            'successful_repairs': 0,
            'failed_repairs': 0,
            'repair_stats': dict(self.repair_stats()),
            'execution_time': time.time() - start_time,
            'report': "# ğŸ”§ ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»ŸæŠ¥å‘Š\n\n**çŠ¶æ€**: æœªå‘ç°é—®é¢˜\n**ç³»ç»Ÿè¿è¡Œæ­£å¸¸** âœ…"
        }
    
    def _load_repair_patterns(self) -> Dict,
        """åŠ è½½ä¿®å¤æ¨¡å¼"""
        return {
            'syntax': {
                'missing_colon': {'fix': 'add_colon', 'description': 'æ·»åŠ ç¼ºå¤±å†’å·'}
                'unclosed_parenthesis': {'fix': 'close_parenthesis', 'description': 'é—­åˆæ‹¬å·'}
                'unclosed_bracket': {'fix': 'close_bracket', 'description': 'é—­åˆæ–¹æ‹¬å·'}
                'unclosed_brace': {'fix': 'close_brace', 'description': 'é—­åˆèŠ±æ‹¬å·'}
            }
            'semantic': {
                'unused_variable': {'fix': 'remove_variable', 'description': 'ç§»é™¤æœªä½¿ç”¨å˜é‡'}
                'potential_null_access': {'fix': 'add_null_check', 'description': 'æ·»åŠ ç©ºå€¼æ£€æŸ¥'}
            }
            'style': {
                'line_too_long': {'fix': 'split_line', 'description': 'åˆ†å‰²é•¿è¡Œ'}
                'inconsistent_indentation': {'fix': 'standardize_indent', 'description': 'æ ‡å‡†åŒ–ç¼©è¿›'}
                'chinese_punctuation': {'fix': 'replace_punctuation', 'description': 'æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹'}
            }
            'archived': {
                'archived_import_pattern': {'fix': 'update_import', 'description': 'æ›´æ–°å¯¼å…¥æ¨¡å¼'}
            }
        }
    
    def _load_learning_data(self) -> Dict,
        """åŠ è½½å­¦ä¹ æ•°æ®"""
        learning_file = 'unified_auto_repair_learning.json'
        if Path(learning_file).exists():::
            try,
                with open(learning_file, 'r', encoding == 'utf-8') as f,
                    return json.load(f)
            except Exception as e,::
                logger.warning(f"åŠ è½½å­¦ä¹ æ•°æ®å¤±è´¥, {e}")
                return {}
        return {}
    
    def _deduplicate_and_sort_issues(self, issues, List[RepairIssue]) -> List[RepairIssue]
        """å»é‡å’Œæ’åºé—®é¢˜"""
        seen = set()
        unique_issues = []
        
        for issue in issues,::
            # åˆ›å»ºå”¯ä¸€æ ‡è¯†
            issue_key == f"{issue.file}{issue.line}{issue.type}"
            
            if issue_key not in seen,::
                seen.add(issue_key)
                unique_issues.append(issue)
        
        # æŒ‰ä¼˜å…ˆçº§å’Œç½®ä¿¡åº¦æ’åº
        return sorted(unique_issues, key == lambda x, (x.priority.value(), x.confidence()), reverse == True)
    
    def _validate_syntax_issue(self, line, str, issue_type, str) -> bool,
        """éªŒè¯è¯­æ³•é—®é¢˜"""
        # å®ç°å…·ä½“çš„éªŒè¯é€»è¾‘
        return True  # ç®€åŒ–å®ç°
    
    def _find_unused_variables(self, tree, ast.AST(), content, str, file_path, str) -> List[RepairIssue]
        """æŸ¥æ‰¾æœªä½¿ç”¨å˜é‡"""
        issues = []
        
        # æ”¶é›†æ‰€æœ‰å˜é‡å®šä¹‰å’Œä½¿ç”¨
        defined_vars = set()
        used_vars = set()
        
        for node in ast.walk(tree)::
            if isinstance(node, ast.Name()) and isinstance(node.ctx(), ast.Store())::
                defined_vars.add(node.id())
            elif isinstance(node, ast.Name()) and isinstance(node.ctx(), ast.Load())::
                used_vars.add(node.id())
        
        # æ‰¾å‡ºæœªä½¿ç”¨çš„å˜é‡
        unused_vars = defined_vars - used_vars
        
        for var_name in unused_vars,::
            # æŸ¥æ‰¾å˜é‡å®šä¹‰ä½ç½®
            for node in ast.walk(tree)::
                if isinstance(node, ast.Name()) and node.id == var_name and isinstance(node.ctx(), ast.Store())::
                    issues.append(RepairIssue(
                        file=file_path,,
    line=node.lineno(),
                        type='unused_variable',
                        description == f'æœªä½¿ç”¨å˜é‡, {var_name}',
                        confidence=0.8(),
                        severity='low',
                        category='semantic',
                        priority == RepairPriority.LOW(),
                        repairable == True,
                        variable_name=var_name
                    ))
                    break
        
        return issues
    
    def _find_potential_null_accesses(self, tree, ast.AST(), content, str, file_path, str) -> List[RepairIssue]
        """æŸ¥æ‰¾æ½œåœ¨çš„ç©ºå€¼è®¿é—®"""
        issues = []
        
        # åˆ†æå¯èƒ½çš„ç©ºå€¼è®¿é—®æ¨¡å¼
        for node in ast.walk(tree)::
            if isinstance(node, ast.Attribute())::
                # æ£€æŸ¥å±æ€§è®¿é—®æ˜¯å¦å¯èƒ½ä¸ºNone
                if self._could_be_none_unified(node.value(), tree)::
                    issues.append(RepairIssue(
                        file=file_path,,
    line=node.lineno(),
                        type='potential_null_access',
                        description == f'æ½œåœ¨çš„ç©ºå€¼è®¿é—®, {ast.dump(node)}',
                        confidence=0.6(),
                        severity='medium',
                        category='semantic',
                        priority == RepairPriority.MEDIUM(),
                        repairable == True
                    ))
        
        return issues
    
    def _could_be_none_unified(self, node, ast.AST(), tree, ast.AST()) -> bool,
        """ç»Ÿä¸€åˆ¤æ–­æ˜¯å¦å¯èƒ½ä¸ºNone"""
        # ç®€åŒ–çš„å¯å‘å¼åˆ¤æ–­
        if isinstance(node, ast.Name())::
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯èƒ½èµ‹å€¼ä¸ºNone
            for n in ast.walk(tree)::
                if isinstance(n, ast.Assign())::
                    for target in n.targets,::
                        if isinstance(target, ast.Name()) and target.id == node.id,::
                            if isinstance(n.value(), ast.Constant()) and n.value.value is None,::
                                return True
        return False
    
    def _find_long_functions(self, tree, ast.AST(), content, str, file_path, str) -> List[RepairIssue]
        """æŸ¥æ‰¾é•¿å‡½æ•°"""
        issues = []
        
        for node in ast.walk(tree)::
            if isinstance(node, ast.FunctionDef())::
                func_length = node.end_lineno - node.lineno()
                if func_length > 50,  # è¶…è¿‡50è¡Œçš„å‡½æ•°,:
                    issues.append(RepairIssue(
                        file=file_path,,
    line=node.lineno(),
                        type='long_function',
                        description=f'å‡½æ•°è¿‡é•¿ ({func_length} è¡Œ),å»ºè®®æ‹†åˆ†',
                        confidence=0.7(),
                        severity='low',
                        category='semantic',
                        priority == RepairPriority.LOW(),
                        repairable == False,  # å‡½æ•°æ‹†åˆ†æ¯”è¾ƒå¤æ‚,æ ‡è®°ä¸ºä¸å¯è‡ªåŠ¨ä¿®å¤
                        function_name=node.name(),
                        length=func_length
                    ))
        
        return issues
    
    def _find_complex_imports(self, tree, ast.AST(), content, str, file_path, str) -> List[RepairIssue]
        """æŸ¥æ‰¾å¤æ‚å¯¼å…¥"""
        issues = []
        
        # ç»Ÿè®¡å¯¼å…¥æ•°é‡
        import_count = 0
        for node in ast.walk(tree)::
            if isinstance(node, ast.Import()) or isinstance(node, ast.ImportFrom())::
                import_count += 1
        
        # å¦‚æœæœ‰å¤§é‡å¯¼å…¥,æé†’å¯èƒ½çš„å¤æ‚æ€§é—®é¢˜
        if import_count > 20,::
            issues.append(RepairIssue(
                file=file_path,
                line=1,
                type='high_import_complexity',,
    description=f'æ–‡ä»¶å¯¼å…¥æ•°é‡è¾ƒå¤š ({import_count}),å¯èƒ½å­˜åœ¨ç»´æŠ¤é£é™©',
                confidence=0.5(),
                severity='low',
                category='semantic',
                priority == RepairPriority.LOW(),
                repairable == False,
                import_count=import_count
            ))
        
        return issues
    
    def _check_docstring_format(self, content, str, file_path, str) -> List[RepairIssue]
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²æ ¼å¼"""
        issues = []
        
        # æ£€æŸ¥ä¸­æ–‡æ–‡æ¡£å­—ç¬¦ä¸²
        chinese_docstring_pattern = r'"""[^"]*[ä¸€-é¿¿][^"]*"""'
        for match in re.finditer(chinese_docstring_pattern, content)::
            line_num == content[:match.start()].count('\n') + 1
            issues.append(RepairIssue(
                file=file_path,
                line=line_num,
                type='docstring_format',
                description='æ–‡æ¡£å­—ç¬¦ä¸²æ ¼å¼é—®é¢˜ï¼šåŒ…å«ä¸­æ–‡å­—ç¬¦',,
    confidence=0.6(),
                severity='low',
                category='style',
                priority == RepairPriority.LOW(),
                repairable == True
            ))
        
        return issues
    
    def _check_chinese_punctuation(self, content, str, file_path, str) -> List[RepairIssue]
        """æ£€æŸ¥ä¸­æ–‡æ ‡ç‚¹ç¬¦å·"""
        issues = []
        
        lines = content.split('\n')
        for i, line in enumerate(lines, 1)::
            # ä¸­æ–‡æ ‡ç‚¹æ˜ å°„
            chinese_punctuation = [',', 'ã€‚', 'ï¼š', 'ï¼›', '(', ')', 'ã€', 'ã€‘', 'ï½›', 'ï½', '"', '"']
            
            for char in chinese_punctuation,::
                if char in line,::
                    issues.append(RepairIssue(
                        file=file_path,
                        line=i,
                        type='chinese_punctuation',
                        description == f'å‘ç°ä¸­æ–‡å­—ç¬¦, {char}',,
    confidence=0.9(),
                        severity='medium',
                        category='style',
                        priority == RepairPriority.MEDIUM(),
                        repairable == True
                    ))
        
        return issues
    
    def _extract_learning_data_unified(self, original_lines, List[str] repaired_lines, List[str] issue, RepairIssue) -> Dict,
        """ç»Ÿä¸€æå–å­¦ä¹ æ•°æ®"""
        return {
            'pattern_key': issue.type(),
            'repair_method': f"{issue.type}_repair",
            'file': issue.file(),
            'line': issue.line(),
            'success': True,
            'timestamp': datetime.now().isoformat()
        }
    
    def _get_learning_info(self) -> Dict[str, Any]
        """è·å–å­¦ä¹ ä¿¡æ¯"""
        return {
            'patterns_learned': len(self.learning_data()),
            'success_rates_improved': len([k for k, v in self.learning_data.items() if v.get('success_rate', 0) > 0.5]),:::
            'total_successes': sum(v.get('success_count', 0) for v in self.learning_data.values()),:::
            'total_failures': sum(v.get('failure_count', 0) for v in self.learning_data.values())::
        }

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•,
if __name"__main__":::
    print("ğŸš€ æµ‹è¯•ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿ...")
    print("=" * 60)
    
    # åˆ›å»ºç»Ÿä¸€ä¿®å¤ç³»ç»Ÿ
    repair_system == UnifiedAutoRepairSystem()
    
    # æµ‹è¯•ä¿®å¤
    test_code = '''
def test_function(x, y):
    result = x + y
    print(result
    return result

class TestClass,,
    def __init__(self):
        self.value = 0
'''
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_file = 'test_unified_repair.py'
    with open(test_file, 'w', encoding == 'utf-8') as f,
        f.write(test_code)
    
    try,
        # è¿è¡Œç»Ÿä¸€ä¿®å¤
        results = repair_system.run_unified_auto_repair('.')
        
        print(f"\nä¿®å¤ç»“æœ,")
        print(f"çŠ¶æ€, {results['status']}")
        print(f"æ€»é—®é¢˜, {results['total_issues']}")
        print(f"æˆåŠŸä¿®å¤, {results['successful_repairs']}")
        print(f"å¤±è´¥ä¿®å¤, {results['failed_repairs']}")
        print(f"æ‰§è¡Œæ—¶é—´, {results['execution_time'].2f}ç§’")
        
        if results['status'] == 'completed':::
            stats == results['performance_stats'] if 'performance_stats' in results else {}::
            print(f"æˆåŠŸç‡, {stats.get('success_rate', 0).1f}%")
            print(f"æ€»ä¿®å¤æ•°, {stats.get('total_repairs', 0)}")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ")
        
    except Exception as e,::
        print(f"âŒ æµ‹è¯•å¤±è´¥, {e}")
        import traceback
        print(f"é”™è¯¯è¯¦æƒ…, {traceback.format_exc()}")
    
    finally,
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if Path(test_file).exists():::
            Path(test_file).unlink()
    
    print("\nğŸ‰ ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")