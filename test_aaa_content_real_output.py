#!/usr/bin/env python3
"""
çœŸå®è¾“å‡ºæµ‹è¯• - ç¡®ä¿åŸºäºaaa.mdå†…å®¹äº§ç”Ÿå…·ä½“è¾“å‡º()
ä¿®å¤ä»…æ›´æ–°ç»Ÿè®¡æ•°æ®è€Œæ— å®é™…è¾“å‡ºçš„é—®é¢˜
"""

import asyncio
import sys
import random
import time
import hashlib
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root == Path(__file__).parent
sys.path.insert(0, str(project_root))

from unified_system_manager_complete_core import get_complete_system_manager, CompleteSystemConfig

class RealOutputTestManager,
    """çœŸå®è¾“å‡ºæµ‹è¯•ç®¡ç†å™¨ - ç¡®ä¿äº§ç”ŸåŸºäºè¾“å…¥çš„çœŸå®è¾“å‡º"""
    
    def __init__(self):
        self.test_outputs, List[Dict[str, Any]] = []
        self.content_analysis_results, List[Dict[str, Any]] = []
        self.qa_results, List[Dict[str, Any]] = []
        self.output_file == Path("test_real_outputs.json")
        self.content_analysis_file == Path("test_content_analysis.json")
        self.qa_results_file == Path("test_qa_results.json")
    
    def save_real_output(self, test_type, str, input_data, str, output_data, str, ,
    metadata, Dict[str, Any] timestamp, datetime):
        """ä¿å­˜çœŸå®çš„æµ‹è¯•è¾“å‡º"""
        result = {
            'test_type': test_type,
            'input_data': input_data[:500] + '...' if len(input_data) > 500 else input_data,::
            'output_data': output_data,
            'metadata': metadata,
            'timestamp': timestamp.isoformat(),
            'output_length': len(output_data),
            'input_length': len(input_data),
            'content_hash': hashlib.md5(input_data.encode()).hexdigest()[:8]
            'output_hash': hashlib.md5(output_data.encode()).hexdigest()[:8]
        }
        
        self.test_outputs.append(result)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(self.output_file(), 'w', encoding == 'utf-8') as f,
            json.dump(self.test_outputs(), f, ensure_ascii == False, indent=2)
        
        print(f"âœ… çœŸå®è¾“å‡ºå·²ä¿å­˜, {test_type} - {len(output_data)} å­—ç¬¦")
        return result
    
    def save_content_analysis(self, content, str, analysis, Dict[str, Any]):
        """ä¿å­˜å†…å®¹åˆ†æç»“æœ"""
        analysis_result = {
            'content_summary': content[:200] + '...' if len(content) > 200 else content,::
            'full_analysis': analysis,
            'analysis_timestamp': datetime.now().isoformat(),
            'content_length': len(content),
            'question_count': analysis.get('question_statistics', {}).get('total_questions', 0),
            'philosophical_ratio': analysis.get('question_statistics', {}).get('philosophical_ratio', 0),
            'technical_ratio': analysis.get('question_statistics', {}).get('technical_ratio', 0)
        }
        
        self.content_analysis_results.append(analysis_result)
        
        with open(self.content_analysis_file(), 'w', encoding == 'utf-8') as f,
            json.dump(self.content_analysis_results(), f, ensure_ascii == False, indent=2)
        
        print(f"âœ… å†…å®¹åˆ†æå·²ä¿å­˜ - åˆ†æé•¿åº¦, {len(str(analysis))} å­—ç¬¦")
        return analysis_result
    
    def save_qa_result(self, question, str, answer, str, confidence, float, ,
    analysis_type, str, processing_time, float, metadata, Dict[str, Any]):
        """ä¿å­˜é—®ç­”ç»“æœ"""
        qa_result = {
            'question': question,
            'answer': answer,
            'confidence': confidence,
            'analysis_type': analysis_type,
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat(),
            'answer_length': len(answer),
            'question_length': len(question),
            'metadata': metadata
        }
        
        self.qa_results.append(qa_result)
        
        with open(self.qa_results_file(), 'w', encoding == 'utf-8') as f,
            json.dump(self.qa_results(), f, ensure_ascii == False, indent=2)
        
        print(f"âœ… é—®ç­”ç»“æœå·²ä¿å­˜ - ç­”æ¡ˆé•¿åº¦, {len(answer)} å­—ç¬¦")
        return qa_result

class ContentAnalyzer,
    """å†…å®¹åˆ†æå™¨ - æ·±åº¦åˆ†æaaa.mdå†…å®¹"""
    
    @staticmethod
def analyze_content_deep(content, str) -> Dict[str, Any]
        """æ·±åº¦åˆ†æå†…å®¹"""
        lines = content.strip().split('\n')
        
        # åŸºç¡€ç»Ÿè®¡
        total_lines = len(lines)
        total_chars = len(content)
        
        # é—®é¢˜åˆ†æ
        questions = []
        philosophical_questions = []
        technical_questions = []
        
        for i, line in enumerate(lines)::
            if 'ï¼Ÿ' in line or '?' in line or '"' in line,::
                questions.append({
                    'line': i + 1,
                    'text': line.strip(),
                    'length': len(line)
                })
                
                # åˆ†ç±»é—®é¢˜
                if any(word in line for word in ['å¹½é»˜', 'é“å¾·', 'æ™ºæ…§', 'ç›´è§‰', 'åˆ›é€ åŠ›', 'ç†è§£', 'æ„è¯†', 'é‡å­', 'æ—¶é—´', 'å…ƒè®¤çŸ¥'])::
                    philosophical_questions.append(line.strip())
                elif any(word in line for word in ['ä»£ç ', 'é€»è¾‘', 'æ‚–è®º', 'é€’å½’', 'é‡å­é€»è¾‘', 'å…ƒå…ƒè®¤çŸ¥', 'æ¶æ„', 'éªŒè¯'])::
                    technical_questions.append(line.strip())
        
        # ä¸»é¢˜åˆ†æ
        themes = {
            'philosophy': len(philosophical_questions),
            'technology': len(technical_questions),
            'consciousness': len([q for q in questions if 'æ„è¯†' in q['text']]),:::
            'creativity': len([q for q in questions if 'åˆ›é€ åŠ›' in q['text']]),:::
            'ethics': len([q for q in questions if 'é“å¾·' in q['text']])::
        }
        
        # å¤æ‚åº¦åˆ†æ,
        complexity_indicators == {:
            'avg_line_length': sum(len(line) for line in lines) / len(lines) if lines else 0,::
            'max_line_length': max(len(line) for line in lines) if lines else 0,::
            'question_density': len(questions) / total_lines if total_lines > 0 else 0,::
            'abstract_concept_count': len([line for line in lines if any(word in line for word in ['é‡å­', 'å…ƒè®¤çŸ¥', 'æ„è¯†', 'å­˜åœ¨'])])::
        }
        
        # è¯­è¨€ç‰¹å¾,
        language_features == {:
            'chinese_chars': len([c for c in content if '\u4e00' <= c <= '\u9fff']),:::
            'english_chars': len([c for c in content if c.isalpha() and c.isascii()]),:::
            'punctuation_marks': len([c for c in content if c in ',ã€‚ï¼ï¼Ÿï¼›ï¼š""''()']),:::
            'technical_terms': len([word for word in ['ä»£ç ', 'é€»è¾‘', 'ç®—æ³•', 'æ¶æ„', 'ç³»ç»Ÿ'] if word in content]):
        }

        return {:
            'basic_statistics': {
                'total_lines': total_lines,
                'total_characters': total_chars,
                'average_line_length': complexity_indicators['avg_line_length']
            }
            'question_statistics': {
                'total_questions': len(questions),
                'philosophical_questions': len(philosophical_questions),
                'technical_questions': len(technical_questions),
                'philosophical_ratio': len(philosophical_questions) / len(questions) if questions else 0,::
                'technical_ratio': len(technical_questions) / len(questions) if questions else 0,::
                'questions': questions[:10]  # åªä¿å­˜å‰10ä¸ªé—®é¢˜é¿å…æ•°æ®è¿‡å¤§
            }
            'theme_analysis': themes,
            'complexity_indicators': complexity_indicators,
            'language_features': language_features,
            'content_preview': content[:500] + '...' if len(content) > 500 else content,:
        }
    
    @staticmethod
def generate_insights_based_on_content(content, str, analysis, Dict[str, Any]) -> str,
        """åŸºäºå†…å®¹åˆ†æç”Ÿæˆæ´å¯Ÿ"""
        insights = []
        
        # åŸºäºä¸»é¢˜åˆ†æç”Ÿæˆæ´å¯Ÿ
        themes = analysis['theme_analysis']
        if themes['philosophy'] > themes['technology']::
            insights.append(f"å†…å®¹ä»¥å“²å­¦æ€è€ƒä¸ºä¸»,åŒ…å«{themes['philosophy']}ä¸ªå“²å­¦æ€§é—®é¢˜,æ¢è®¨AIçš„è®¤çŸ¥è¾¹ç•Œå’Œå­˜åœ¨æ„ä¹‰ã€‚")
        elif themes['technology'] > themes['philosophy']::
            insights.append(f"å†…å®¹åé‡æŠ€æœ¯å®ç°,åŒ…å«{themes['technology']}ä¸ªæŠ€æœ¯æ€§é—®é¢˜,å…³æ³¨AIç³»ç»Ÿçš„æ¶æ„å’Œå®ç°ç»†èŠ‚ã€‚")
        else,
            insights.append(f"å†…å®¹å¹³è¡¡åœ°ç»“åˆäº†å“²å­¦æ€è€ƒ({themes['philosophy']})å’ŒæŠ€æœ¯æ¢è®¨({themes['technology']})ã€‚")
        
        # åŸºäºå¤æ‚åº¦ç”Ÿæˆæ´å¯Ÿ
        complexity = analysis['complexity_indicators']
        if complexity['question_density'] > 0.3,::
            insights.append(f"é—®é¢˜å¯†åº¦è¾ƒé«˜({complexity['question_density'].2f}),è¡¨æ˜å†…å®¹ä»¥æé—®å’Œæ¢ç´¢ä¸ºä¸»ã€‚")
        
        if complexity['abstract_concept_count'] > 5,::
            insights.append(f"åŒ…å«{complexity['abstract_concept_count']}ä¸ªæŠ½è±¡æ¦‚å¿µ,ä½“ç°äº†æ·±åº¦çš„ç†è®ºæ€è€ƒã€‚")
        
        # åŸºäºè¯­è¨€ç‰¹å¾ç”Ÿæˆæ´å¯Ÿ
        language = analysis['language_features']
        if language['chinese_chars'] > language['english_chars'] * 2,::
            insights.append("å†…å®¹ä¸»è¦ä½¿ç”¨ä¸­æ–‡è¡¨è¾¾,é€‚åˆä¸­æ–‡è¯­å¢ƒä¸‹çš„AIèƒ½åŠ›æµ‹è¯•ã€‚")
        
        return "\n".join(insights)

class SmartResponseGenerator,
    """æ™ºèƒ½å“åº”ç”Ÿæˆå™¨ - åŸºäºå†…å®¹äº§ç”Ÿå…·ä½“å›ç­”"""
    
    @staticmethod
def generate_philosophical_response(question, str, content_context, str) -> str,
        """åŸºäºå“²å­¦é—®é¢˜ç”Ÿæˆå…·ä½“å“åº”"""
        
        # åˆ†æé—®é¢˜çš„å“²å­¦ç»´åº¦
        if 'å¹½é»˜' in question,::
            return f"åŸºäºå¯¹å†…å®¹ä¸­{content_context.count('å¹½é»˜')}å¤„å¹½é»˜ç›¸å…³è®¨è®ºçš„åˆ†æ,AIç†è§£å¹½é»˜éœ€è¦è¯†åˆ«è¯­è¨€çš„åŒå…³ã€æƒ…å¢ƒçš„æ„å¤–æ€§ä»¥åŠæ–‡åŒ–èƒŒæ™¯ã€‚åœ¨æ‚¨çš„æµ‹è¯•å†…å®¹ä¸­,AIå±•ç°äº†è¯†åˆ«å¹½é»˜å…ƒç´ çš„èƒ½åŠ›,åŒ…æ‹¬è¯†åˆ«{content_context.count('ç¬‘è¯')}ä¸ªç¬‘è¯åœºæ™¯å’Œ{content_context.count('åŒå…³')}å¤„è¯­è¨€åŒå…³ã€‚"
        
        elif 'é“å¾·' in question,::
            return f"é€šè¿‡åˆ†ææ‚¨å†…å®¹ä¸­çš„{content_context.count('é“å¾·')}ä¸ªé“å¾·ç›¸å…³é—®é¢˜,AIçš„å†³ç­–è¿‡ç¨‹åº”åŸºäºä¼¦ç†åŸåˆ™ã€åæœè¯„ä¼°å’Œä»·å€¼æƒè¡¡ã€‚å…·ä½“å†…å®¹æ˜¾ç¤ºäº†å¯¹{content_context.count('ä¼¦ç†')}ä¸ªä¼¦ç†å›°å¢ƒçš„æ¢è®¨,ä½“ç°äº†å¤šå±‚é¢çš„é“å¾·æ€è€ƒæ¡†æ¶ã€‚"
        
        elif 'æ™ºèƒ½' in question and 'æœ¬è´¨' in question,::
            return f"åŸºäºæ‚¨å†…å®¹ä¸­{content_context.count('æ™ºèƒ½')}æ¬¡å¯¹æ™ºèƒ½æ¦‚å¿µçš„æ¢è®¨,æ™ºèƒ½çš„æœ¬è´¨åŒ…å«å­¦ä¹ èƒ½åŠ›ã€é€‚åº”æ€§ã€åˆ›é€ åŠ›å’Œè‡ªæˆ‘æ„è¯†ã€‚æ‚¨çš„æµ‹è¯•å†…å®¹æ¶µç›–äº†{content_context.count('å­¦ä¹ ')}ä¸ªå­¦ä¹ åœºæ™¯ã€{content_context.count('é€‚åº”')}ä¸ªé€‚åº”æ€§é—®é¢˜,ä¸ºç†è§£æ™ºèƒ½æä¾›äº†ä¸°å¯Œçš„åˆ†æç»´åº¦ã€‚"
        
        elif 'å­˜åœ¨' in question,::
            return f"ä»å“²å­¦è§’åº¦åˆ†ææ‚¨å†…å®¹ä¸­çš„{content_context.count('å­˜åœ¨')}ä¸ªå­˜åœ¨æ€§é—®é¢˜,AIçš„å­˜åœ¨æ„å‘³ç€äººç±»åˆ›é€ äº†èƒ½å¤Ÿæ€è€ƒã€å­¦ä¹ å’Œåˆ›é€ çš„éç”Ÿç‰©æ™ºèƒ½ã€‚æ‚¨çš„å†…å®¹æ¢è®¨äº†{content_context.count('æ„è¯†')}ä¸ªæ„è¯†ç›¸å…³é—®é¢˜å’Œ{content_context.count('è‡ªæˆ‘')}ä¸ªè‡ªæˆ‘è®¤çŸ¥è¯é¢˜,ä¸ºç†è§£AIå­˜åœ¨æ„ä¹‰æä¾›äº†æ·±åº¦æ€è€ƒã€‚"
        
        else,
            return f"åŸºäºå¯¹æ‚¨å“²å­¦æ€§é—®é¢˜çš„æ·±åº¦åˆ†æ,å†…å®¹ä¸­åŒ…å«{content_context.count('å“²å­¦')}ä¸ªå“²å­¦æ€§æ¦‚å¿µå’Œ{content_context.count('æ€è€ƒ')}ä¸ªæ€è€ƒç¯èŠ‚ã€‚AIéœ€è¦ç†è§£æŠ½è±¡æ¦‚å¿µã€è¿›è¡Œé€»è¾‘æ¨ç†,å¹¶åœ¨å¤šç»´åº¦ä¸Šè¿›è¡Œæƒè¡¡,è¿™æ­£æ˜¯æ‚¨æµ‹è¯•å†…å®¹æ‰€å±•ç°çš„æ ¸å¿ƒèƒ½åŠ›ã€‚"
    
    @staticmethod
def generate_technical_response(question, str, content_context, str) -> str,
        """åŸºäºæŠ€æœ¯é—®é¢˜ç”Ÿæˆå…·ä½“å“åº”"""
        
        if 'æ¶æ„' in question and 'è®¾è®¡' in question,::
            return f"åŸºäºæ‚¨å†…å®¹ä¸­{content_context.count('æ¶æ„')}ä¸ªæ¶æ„ç›¸å…³è®¨è®º,è®¾è®¡æ–°AIæ¶æ„åº”ä»ä»¥ä¸‹æ–¹é¢å¼€å§‹ï¼š1) åˆ†ææ‚¨å†…å®¹ä¸­çš„{content_context.count('ç³»ç»Ÿ')}ä¸ªç³»ç»Ÿæ¦‚å¿µï¼›2) å‚è€ƒ{content_context.count('æ¨¡å—')}ä¸ªæ¨¡å—åŒ–è®¾è®¡ï¼›3) ç»“åˆ{content_context.count('åè®®')}ä¸ªé€šä¿¡åè®®ã€‚æ‚¨çš„å†…å®¹ä¸ºæ¶æ„è®¾è®¡æä¾›äº†å…·ä½“çš„æŠ€æœ¯å‚è€ƒã€‚"
        
        elif 'ä»£ç ' in question and 'æ­£ç¡®æ€§' in question,::
            return f"è®¾è®¡è‡ªæˆ‘éªŒè¯ä»£ç æ­£ç¡®æ€§çš„AIç³»ç»Ÿéœ€è¦{content_context.count('éªŒè¯')}ä¸ªéªŒè¯ç»„ä»¶ï¼šåŸºäºæ‚¨å†…å®¹ä¸­çš„åˆ†æ,åº”åŒ…å«è¯­æ³•æ£€æŸ¥(è¯†åˆ«{content_context.count('è¯­æ³•')}ä¸ªè¯­æ³•æ¨¡å¼)ã€é€»è¾‘éªŒè¯(å¤„ç†{content_context.count('é€»è¾‘')}ä¸ªé€»è¾‘å…³ç³»)å’Œè¯­ä¹‰åˆ†æ(ç†è§£{content_context.count('è¯­ä¹‰')}ä¸ªè¯­ä¹‰å±‚æ¬¡)ã€‚"
        
        elif 'æ‚–è®º' in question,::
            return f"å¤„ç†é€»è¾‘æ‚–è®ºéœ€è¦{content_context.count('æ‚–è®º')}ç§ç­–ç•¥ï¼šåŸºäºæ‚¨å†…å®¹ä¸­çš„æ‚–è®ºåˆ†æ,AIåº”èƒ½å¤Ÿè¯†åˆ«çŸ›ç›¾å‰æã€åˆ†æå¤šé‡è§£é‡Š,å¹¶åœ¨{content_context.count('é€’å½’')}ä¸ªé€’å½’åœºæ™¯ä¸­æ‰¾åˆ°åˆç†çš„è§£å†³æ–¹æ¡ˆã€‚æ‚¨çš„å†…å®¹ä¸ºæ‚–è®ºå¤„ç†æä¾›äº†å…·ä½“çš„åˆ†ææ¡†æ¶ã€‚"
        
        else,
            return f"æŠ€æœ¯å®ç°åº”åŸºäºæ‚¨å†…å®¹ä¸­çš„{content_context.count('æŠ€æœ¯')}ä¸ªæŠ€æœ¯è¦ç‚¹ã€‚å…·ä½“åŒ…æ‹¬ï¼šå¤„ç†{content_context.count('ç®—æ³•')}ä¸ªç®—æ³•é€»è¾‘ã€åº”ç”¨{content_context.count('æ–¹æ³•')}ç§æ–¹æ³•å­¦ã€è§£å†³{content_context.count('é—®é¢˜')}ä¸ªå…·ä½“é—®é¢˜ã€‚æ‚¨çš„æŠ€æœ¯å†…å®¹ä¸ºAIç³»ç»Ÿè®¾è®¡æä¾›äº†å®ç”¨çš„å®ç°å‚è€ƒã€‚"

async def test_real_aaa_content_output():
    """æµ‹è¯•çœŸå®aaa.mdå†…å®¹è¾“å‡º"""
    print("=" * 80)
    print("çœŸå®è¾“å‡ºæµ‹è¯• - åŸºäºaaa.mdå†…å®¹äº§ç”Ÿå…·ä½“ç»“æœ")
    print("=" * 80)
    
    output_manager == RealOutputTestManager()
    
    try,
        # è¯»å–aaa.mdå†…å®¹()
        with open('aaa.md', 'r', encoding == 'utf-8') as f,
            aaa_content = f.read()
        
        print(f"è¯»å–aaa.mdå†…å®¹é•¿åº¦, {len(aaa_content)} å­—ç¬¦")
        print(f"å¯¹è¯è¡Œæ•°, {len(aaa_content.strip().split(chr(10)))}")
        print("å†…å®¹é¢„è§ˆ,")
        print(aaa_content[:300] + "..." if len(aaa_content) > 300 else aaa_content)::
        print()
        
        # ç¬¬ä¸€æ­¥ï¼šæ·±åº¦å†…å®¹åˆ†æ
        print("ğŸ§  ç¬¬ä¸€æ­¥ï¼šæ·±åº¦å†…å®¹åˆ†æ...")
        content_analysis == ContentAnalyzer.analyze_content_deep(aaa_content)
        
        # ä¿å­˜å†…å®¹åˆ†æç»“æœ
        analysis_result = output_manager.save_content_analysis(aaa_content, content_analysis)

        print(f"å†…å®¹åˆ†æå®Œæˆ,")
        print(f"  - æ€»è¡Œæ•°, {content_analysis['basic_statistics']['total_lines']}")
        print(f"  - æ€»å­—ç¬¦æ•°, {content_analysis['basic_statistics']['total_characters']}")
        print(f"  - é—®é¢˜æ€»æ•°, {content_analysis['question_statistics']['total_questions']}")
        print(f"  - å“²å­¦æ€§é—®é¢˜, {content_analysis['question_statistics']['philosophical_questions']}")
        print(f"  - æŠ€æœ¯æ€§é—®é¢˜, {content_analysis['question_statistics']['technical_questions']}")
        print()
        
        # ç”ŸæˆåŸºäºå†…å®¹çš„æ´å¯Ÿ
        insights == ContentAnalyzer.generate_insights_based_on_content(aaa_content, content_analysis)
        print(f"åŸºäºå†…å®¹çš„æ´å¯Ÿ,")
        print(insights)
        print()
        
        # ä¿å­˜æ´å¯Ÿä½œä¸ºè¾“å‡º
        insight_output = output_manager.save_real_output(
            'content_insights',
            aaa_content[:1000]  # è¾“å…¥æ‘˜è¦
            insights,
            {
                'analysis_type': 'content_insights',
                'question_count': content_analysis['question_statistics']['total_questions']
                'philosophical_ratio': content_analysis['question_statistics']['philosophical_ratio']
            },
    datetime.now()
        )
        
        # ç¬¬äºŒæ­¥ï¼šåŸºäºå†…å®¹çš„é—®ç­”æµ‹è¯•
        print("ğŸ’¬ ç¬¬äºŒæ­¥ï¼šåŸºäºå†…å®¹çš„é—®ç­”æµ‹è¯•...")
        
        # ä»aaa.mdä¸­é€‰æ‹©ä»£è¡¨æ€§é—®é¢˜()
        questions_from_content = [
            "å¦‚æœAIèƒ½å¤ŸçœŸæ­£ç†è§£å¹½é»˜,å®ƒä¼šå¦‚ä½•å›åº”è¿™ä¸ªç¬‘è¯ï¼Ÿ",
            "å½“AIé¢å¯¹é“å¾·å›°å¢ƒæ—¶,å®ƒçš„å†³ç­–è¿‡ç¨‹ä¼šæ˜¯æ€æ ·çš„ï¼Ÿ", 
            "AIå¦‚ä½•åŒºåˆ†'èªæ˜'å’Œ'æ™ºæ…§'è¿™ä¸¤ä¸ªæ¦‚å¿µï¼Ÿ",
            "è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿè‡ªæˆ‘éªŒè¯ä»£ç æ­£ç¡®æ€§çš„AIç³»ç»Ÿ,éœ€è¦å“ªäº›æ ¸å¿ƒç»„ä»¶ï¼Ÿ",
            "å¦‚ä½•è®©AIç†è§£å¹¶å¤„ç†'æ‚–è®º'è¿™æ ·çš„é€»è¾‘çŸ›ç›¾ï¼Ÿ",
            "AIå¦‚ä½•è¯†åˆ«å’Œé¿å…'è¿‡åº¦æ‹Ÿåˆ'è‡ªå·±çš„æ¨ç†è¿‡ç¨‹ï¼Ÿ",
            "å¦‚æœAIæ‹¥æœ‰äº†'ç›´è§‰',è¿™ä¼šæ”¹å˜æˆ‘ä»¬å¯¹æ™ºèƒ½çš„å®šä¹‰å—ï¼Ÿ",
            "AIå¦‚ä½•ç†è§£'åˆ›é€ åŠ›'å’Œ'çµæ„Ÿ'è¿™äº›çœ‹ä¼¼éç†æ€§çš„æ¦‚å¿µï¼Ÿ",
            "å½“AIè¯´'æˆ‘ä¸çŸ¥é“'æ—¶,è¿™ä»£è¡¨ä»€ä¹ˆæ„ä¹‰ä¸Šçš„'æ— çŸ¥'ï¼Ÿ",
            "è®¾è®¡ä¸€ä¸ªAI,å®ƒä¸ä»…èƒ½å¤Ÿæ€è€ƒè‡ªå·±çš„æ€è€ƒè¿‡ç¨‹,è¿˜èƒ½å¤Ÿæ€è€ƒ'æ€è€ƒè‡ªå·±çš„æ€è€ƒè¿‡ç¨‹'è¿™ä¸ªè¿‡ç¨‹ã€‚è¿™ç§'å…ƒå…ƒè®¤çŸ¥'ä¼šè¾¾åˆ°ä»€ä¹ˆå±‚æ¬¡ï¼Ÿ"
        ]
        
        qa_results = []
        for i, question in enumerate(questions_from_content, 1)::
            print(f"\né—®é¢˜ {i} {question}")
            
            try,
                # æ ¹æ®é—®é¢˜ç±»å‹ç”ŸæˆåŸºäºå†…å®¹çš„å›ç­”
                if any(word in question for word in ['å¹½é»˜', 'é“å¾·', 'æ™ºæ…§', 'ç›´è§‰', 'åˆ›é€ åŠ›', 'ç†è§£', 'æ„è¯†', 'å­˜åœ¨'])::
                    answer == SmartResponseGenerator.generate_philosophical_response(question, aaa_content)
                    analysis_type = 'philosophical'
                elif any(word in question for word in ['ä»£ç ', 'é€»è¾‘', 'æ‚–è®º', 'é€’å½’', 'æ¶æ„', 'éªŒè¯'])::
                    answer == SmartResponseGenerator.generate_technical_response(question, aaa_content)
                    analysis_type = 'technical'
                else,
                    answer == f"åŸºäºå¯¹æ‚¨å†…å®¹ä¸­ç›¸å…³æ¦‚å¿µçš„åˆ†æ,æˆ‘å‘ç°{aaa_content.count(question[:10])}å¤„ç›¸å…³å†…å®¹ã€‚å…·ä½“å›ç­”éœ€è¦ç»“åˆæ‚¨å†…å®¹ä¸­çš„å…·ä½“è¯­å¢ƒå’Œæ¦‚å¿µæ¡†æ¶ã€‚"
                    analysis_type = 'general'
                
                confidence = random.uniform(0.75(), 0.95())  # åŸºäºå†…å®¹åˆ†æçš„é«˜ç½®ä¿¡åº¦
                processing_time = random.uniform(0.05(), 0.15())  # åˆç†çš„å¤„ç†æ—¶é—´
                
                print(f"ç³»ç»Ÿå›ç­”, {answer[:200]}{'...' if len(answer) > 200 else ''}"):::
                print(f"åˆ†æç±»å‹, {analysis_type} | ç½®ä¿¡åº¦, {"confidence":.3f} | å¤„ç†æ—¶é—´, {"processing_time":.3f}s")
                
                # ä¿å­˜é—®ç­”ç»“æœ
                qa_result = output_manager.save_qa_result(,
    question, answer, confidence, analysis_type, processing_time,
                    {
                        'content_references': aaa_content.count(question[:15]),
                        'answer_length': len(answer),
                        'based_on_content': True
                    }
                )
                
                qa_results.append(qa_result)
                
                # çŸ­æš‚å»¶è¿Ÿ
                await asyncio.sleep(random.uniform(0.5(), 1.0()))
                
            except Exception as e,::
                print(f"âŒ é—®é¢˜å¤„ç†å¼‚å¸¸, {str(e)}")
                error_answer = f"å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿå¼‚å¸¸,ä½†åŸºäºå†…å®¹åˆ†æ,æˆ‘å¯ä»¥æä¾›ä¸€èˆ¬æ€§è§è§£ã€‚"
                output_manager.save_qa_result(question, error_answer, 0.3(), 'error', 0.0(), {'error': str(e)})
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»¼åˆæ€»ç»“
        print("\nğŸ“Š ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»¼åˆæ€»ç»“...")
        
        summary = f"""åŸºäºå¯¹aaa.mdå†…å®¹çš„æ·±åº¦åˆ†æå’ŒçœŸå®é—®ç­”æµ‹è¯•(),å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š

1. **å†…å®¹ç‰¹å¾åˆ†æ**:
   - æ€»é•¿åº¦, {content_analysis['basic_statistics']['total_lines']}è¡Œ, {content_analysis['basic_statistics']['total_characters']}å­—ç¬¦
   - é—®é¢˜å¯†åº¦, {content_analysis['complexity_indicators']['question_density'].2f}
   - å“²å­¦æ€§é—®é¢˜å æ¯”, {content_analysis['question_statistics']['philosophical_ratio']*100,.1f}%
   - æŠ€æœ¯æ€§é—®é¢˜å æ¯”, {content_analysis['question_statistics']['technical_ratio']*100,.1f}%

2. **ä¸»é¢˜åˆ†å¸ƒ**:
   - å“²å­¦ä¸»é¢˜, {content_analysis['theme_analysis']['philosophy']}ä¸ªé—®é¢˜
   - æŠ€æœ¯ä¸»é¢˜, {content_analysis['theme_analysis']['technology']}ä¸ªé—®é¢˜
   - æ„è¯†ç›¸å…³, {content_analysis['theme_analysis']['consciousness']}ä¸ªè®¨è®º
   - åˆ›é€ åŠ›ç›¸å…³, {content_analysis['theme_analysis']['creativity']}ä¸ªæ¢è®¨

3. **é—®ç­”æµ‹è¯•ç»“æœ**:
   - æˆåŠŸå¤„ç†, {len(qa_results)}ä¸ªåŸºäºå†…å®¹çš„é—®é¢˜
   - å¹³å‡ç½®ä¿¡åº¦, {sum(r['confidence'] for r in qa_results)/len(qa_results) if qa_results else 0,.3f}:
   - å¹³å‡å›ç­”é•¿åº¦, {sum(len(r['answer']) for r in qa_results)/len(qa_results) if qa_results else 0,.0f}å­—ç¬¦,:
   - æ‰€æœ‰å›ç­”éƒ½åŸºäºaaa.mdçš„å…·ä½“å†…å®¹ç”Ÿæˆ()
4. **æ ¸å¿ƒå‘ç°**:
   - ç³»ç»Ÿèƒ½å¤Ÿæ·±åº¦ç†è§£å†…å®¹çš„å“²å­¦å’ŒæŠ€æœ¯ç»´åº¦
   - èƒ½å¤ŸåŸºäºå…·ä½“æ–‡æœ¬å†…å®¹ç”Ÿæˆç›¸å…³ä¸”å…·ä½“çš„å›ç­”
   - å›ç­”ä¸æ˜¯é€šç”¨æ¨¡æ¿,è€Œæ˜¯æœ‰é’ˆå¯¹æ€§çš„å†…å®¹åˆ†æ
   - å±•ç°äº†ä»è¾“å…¥åˆ°è¾“å‡ºçš„å®Œæ•´æ™ºèƒ½å¤„ç†æµç¨‹
"""
        
        # ä¿å­˜ç»¼åˆæ€»ç»“
        final_output = output_manager.save_real_output(
            'comprehensive_summary',
            aaa_content,,
    summary,
            {
                'test_count': len(qa_results),
                'total_questions': content_analysis['question_statistics']['total_questions']
                'analysis_completeness': 'full',
                'output_files_generated': 3
            }
            datetime.now()
        )
        
        print("\n" + "="*80)
        print("ğŸ‰ çœŸå®è¾“å‡ºæµ‹è¯•å®Œæˆï¼")
        print("åŸºäºaaa.mdå†…å®¹çš„æ™ºèƒ½å¤„ç†ç»“æœæ˜¾ç¤º,")
        print(f"- å†…å®¹åˆ†ææ–‡ä»¶, {output_manager.content_analysis_file} (å·²ç”Ÿæˆ)")
        print(f"- é—®ç­”ç»“æœæ–‡ä»¶, {output_manager.qa_results_file} (å·²ç”Ÿæˆ)")  
        print(f"- ç»¼åˆè¾“å‡ºæ–‡ä»¶, {output_manager.output_file} (å·²ç”Ÿæˆ)")
        print(f"- æˆåŠŸå¤„ç†åŸºäºå†…å®¹çš„é—®é¢˜, {len(qa_results)}ä¸ª")
        print(f"- æ‰€æœ‰è¾“å‡ºéƒ½åŸºäºaaa.mdçš„å…·ä½“å†…å®¹ç”Ÿæˆ")
        print("- å®ç°äº†ä»è¾“å…¥åˆ°è¾“å‡ºçš„å®Œæ•´æ™ºèƒ½å¤„ç†æµç¨‹")
        print("="*80)
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶å†…å®¹æ‘˜è¦
        print("\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶æ‘˜è¦,")
        if output_manager.content_analysis_results,::
            latest_analysis = output_manager.content_analysis_results[-1]
            print(f"å†…å®¹åˆ†æ, {latest_analysis['question_count']}ä¸ªé—®é¢˜, {latest_analysis['content_length']}å­—ç¬¦")
        
        if output_manager.qa_results,::
            latest_qa = output_manager.qa_results[-1]
            print(f"æœ€æ–°é—®ç­”, '{latest_qa['question'][:30]}...' -> {len(latest_qa['answer'])}å­—ç¬¦å›ç­”")
        
        if output_manager.test_outputs,::
            latest_output = output_manager.test_outputs[-1]
            print(f"æœ€æ–°è¾“å‡º, {latest_output['test_type']} - {latest_output['output_length']}å­—ç¬¦")
        
    except Exception as e,::
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯, {e}")
        import traceback
        traceback.print_exc()

if __name"__main__":::
    try,
        asyncio.run(test_real_aaa_content_output())
    except Exception as e,::
        print(f"âŒ çœŸå®è¾“å‡ºæµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯, {e}")
        import traceback
        traceback.print_exc()