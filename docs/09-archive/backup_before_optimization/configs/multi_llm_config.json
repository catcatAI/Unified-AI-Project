{
  "default_model": "gpt-4",
  "models": {
    "gpt-4": {
      "provider": "openai",
      "model_name": "gpt-4",
      "api_key_env": "OPENAI_API_KEY",
      "max_tokens": 8192,
      "temperature": 0.7,
      "top_p": 1.0,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "timeout": 60,
      "enabled": true,
      "cost_per_1k_tokens": 0.03,
      "context_window": 8192
    },
    "gpt-3.5-turbo": {
      "provider": "openai",
      "model_name": "gpt-3.5-turbo",
      "api_key_env": "OPENAI_API_KEY",
      "max_tokens": 4096,
      "temperature": 0.7,
      "top_p": 1.0,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "timeout": 60,
      "enabled": true,
      "cost_per_1k_tokens": 0.002,
      "context_window": 4096
    },
    "claude-3-opus": {
      "provider": "anthropic",
      "model_name": "claude-3-opus-20240229",
      "api_key_env": "ANTHROPIC_API_KEY",
      "max_tokens": 4096,
      "temperature": 0.7,
      "timeout": 60,
      "enabled": true,
      "cost_per_1k_tokens": 0.015,
      "context_window": 200000
    },
    "claude-3-sonnet": {
      "provider": "anthropic",
      "model_name": "claude-3-sonnet-20240229",
      "api_key_env": "ANTHROPIC_API_KEY",
      "max_tokens": 4096,
      "temperature": 0.7,
      "timeout": 60,
      "enabled": true,
      "cost_per_1k_tokens": 0.003,
      "context_window": 200000
    },
    "claude-3-haiku": {
      "provider": "anthropic",
      "model_name": "claude-3-haiku-20240307",
      "api_key_env": "ANTHROPIC_API_KEY",
      "max_tokens": 4096,
      "temperature": 0.7,
      "timeout": 60,
      "enabled": true,
      "cost_per_1k_tokens": 0.00025,
      "context_window": 200000
    },
    "gemini-pro": {
      "provider": "google",
      "model_name": "gemini-pro",
      "api_key_env": "GEMINI_API_KEY",
      "max_tokens": 8192,
      "temperature": 0.7,
      "top_p": 1.0,
      "timeout": 60,
      "enabled": true,
      "cost_per_1k_tokens": 0.0005,
      "context_window": 32768
    },
    "gemini-pro-vision": {
      "provider": "google",
      "model_name": "gemini-pro-vision",
      "api_key_env": "GEMINI_API_KEY",
      "max_tokens": 4096,
      "temperature": 0.7,
      "timeout": 60,
      "enabled": true,
      "cost_per_1k_tokens": 0.0005,
      "context_window": 16384
    },
    "llama2-7b": {
      "provider": "ollama",
      "model_name": "llama2:7b",
      "base_url": "http://localhost:11434",
      "max_tokens": 4096,
      "temperature": 0.7,
      "top_p": 1.0,
      "timeout": 120,
      "enabled": true,
      "cost_per_1k_tokens": 0.0,
      "context_window": 4096
    },
    "llama2-13b": {
      "provider": "ollama",
      "model_name": "llama2:13b",
      "base_url": "http://localhost:11434",
      "max_tokens": 4096,
      "temperature": 0.7,
      "top_p": 1.0,
      "timeout": 180,
      "enabled": true,
      "cost_per_1k_tokens": 0.0,
      "context_window": 4096
    },
    "codellama": {
      "provider": "ollama",
      "model_name": "codellama:7b",
      "base_url": "http://localhost:11434",
      "max_tokens": 4096,
      "temperature": 0.1,
      "top_p": 1.0,
      "timeout": 120,
      "enabled": true,
      "cost_per_1k_tokens": 0.0,
      "context_window": 16384
    },
    "mistral-7b": {
      "provider": "ollama",
      "model_name": "mistral:7b",
      "base_url": "http://localhost:11434",
      "max_tokens": 4096,
      "temperature": 0.7,
      "top_p": 1.0,
      "timeout": 120,
      "enabled": true,
      "cost_per_1k_tokens": 0.0,
      "context_window": 8192
    },
    "azure-gpt-4": {
      "provider": "azure_openai",
      "model_name": "gpt-4",
      "api_key_env": "AZURE_OPENAI_API_KEY",
      "base_url": "https://your-resource.openai.azure.com/",
      "deployment_name": "gpt-4",
      "api_version": "2023-12-01-preview",
      "max_tokens": 8192,
      "temperature": 0.7,
      "timeout": 60,
      "enabled": false,
      "cost_per_1k_tokens": 0.03,
      "context_window": 8192
    },
    "cohere-command": {
      "provider": "cohere",
      "model_name": "command",
      "api_key_env": "COHERE_API_KEY",
      "max_tokens": 4096,
      "temperature": 0.7,
      "timeout": 60,
      "enabled": false,
      "cost_per_1k_tokens": 0.0015,
      "context_window": 4096
    },
    "huggingface-llama": {
      "provider": "huggingface",
      "model_name": "meta-llama/Llama-2-7b-chat-hf",
      "api_key_env": "HUGGINGFACE_API_KEY",
      "base_url": "https://api-inference.huggingface.co/models/",
      "max_tokens": 4096,
      "temperature": 0.7,
      "timeout": 60,
      "enabled": false,
      "cost_per_1k_tokens": 0.0,
      "context_window": 4096
    }
  },
  "fallback_chain": [
    "gpt-4",
    "claude-3-sonnet",
    "gemini-pro",
    "llama2-7b"
  ],
  "load_balancing": {
    "enabled": true,
    "strategy": "round_robin",
    "health_check_interval": 300
  },
  "rate_limiting": {
    "enabled": true,
    "requests_per_minute": {
      "openai": 60,
      "anthropic": 50,
      "google": 60,
      "ollama": 1000
    }
  }
}