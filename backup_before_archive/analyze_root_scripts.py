#!/usr/bin/env python3
"""
åˆ†ææ ¹ç›®å½•Pythonè„šæœ¬çš„åˆ†ç±»å’Œå¤„ç†å»ºè®®
ç¡®å®šå“ªäº›éœ€è¦å½’æ¡£ã€å“ªäº›å¯ä»¥èåˆã€å“ªäº›å¯ä»¥ä¿ç•™
"""

import os
import re
import ast
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple

class RootScriptAnalyzer:
    """æ ¹ç›®å½•è„šæœ¬åˆ†æå™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.root_scripts = list(self.project_root.glob("*.py"))
        
        # åˆ†ç±»å®šä¹‰
        self.system_scripts = {  # ç³»ç»Ÿå¿…éœ€è„šæœ¬
            'COMPLEXITY_ASSESSMENT_SYSTEM.py',
            'quick_complexity_check.py', 
            'enforce_no_simple_fixes.py',
            'quick_verify.py',
            'verify_progress.py'
        }
        
        self.simple_fix_patterns = [  # ç®€å•ä¿®å¤è„šæœ¬æ¨¡å¼
            r'fix_.*\.py$',
            r'check_.*\.py$', 
            r'.*fix.*\.py$',
            r'.*repair.*\.py$',
            r'syntax.*\.py$',
            r'.*checker.*\.py$'
        ]
        
    def analyze_all_scripts(self) -> Dict:
        """åˆ†ææ‰€æœ‰æ ¹ç›®å½•è„šæœ¬"""
        print("ğŸ” å¼€å§‹åˆ†ææ ¹ç›®å½•Pythonè„šæœ¬...")
        print(f"ğŸ“Š å‘ç° {len(self.root_scripts)} ä¸ªPythonè„šæœ¬")
        print()
        
        categories = {
            'system_essential': [],      # ç³»ç»Ÿå¿…éœ€ - ä¿ç•™
            'simple_fix_scripts': [],    # ç®€å•ä¿®å¤ - å½’æ¡£
            'fusion_candidates': [],     # å¯èåˆ - é›†æˆåˆ°ç»Ÿä¸€ç³»ç»Ÿ
            'utility_scripts': [],       # å·¥å…·è„šæœ¬ - è¯„ä¼°ä¿ç•™
            'obsolete_scripts': [],      # åºŸå¼ƒè„šæœ¬ - å½’æ¡£
            'unknown_scripts': []        # æœªçŸ¥ç±»å‹ - éœ€è¦åˆ†æ
        }
        
        for script_path in self.root_scripts:
            script_name = script_path.name
            
            # è·³è¿‡ç³»ç»Ÿå¿…éœ€è„šæœ¬
            if script_name in self.system_scripts:
                categories['system_essential'].append(script_name)
                continue
                
            # åˆ†æè„šæœ¬å†…å®¹å’Œç‰¹å¾
            analysis = self._analyze_script_content(script_path)
            
            # åˆ†ç±»åˆ¤æ–­
            category = self._categorize_script(script_name, analysis)
            categories[category].append({
                'name': script_name,
                'analysis': analysis
            })
        
        return categories
        
    def _analyze_script_content(self, script_path: Path) -> Dict:
        """åˆ†æå•ä¸ªè„šæœ¬çš„å†…å®¹å’Œç‰¹å¾"""
        try:
            with open(script_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                
            lines = content.split('\n')
            
            # åŸºæœ¬ç»Ÿè®¡
            analysis = {
                'total_lines': len(lines),
                'code_lines': len([l for l in lines if l.strip() and not l.strip().startswith('#')]),
                'has_main': '__main__' in content,
                'has_functions': len(re.findall(r'^def\s+', content, re.MULTILINE)),
                'has_classes': len(re.findall(r'^class\s+', content, re.MULTILINE)),
                'has_imports': len(re.findall(r'^(import|from)\s+', content, re.MULTILINE)),
                'file_size': script_path.stat().st_size,
                'modified_time': script_path.stat().st_mtime
            }
            
            # åŠŸèƒ½åˆ†æ
            analysis['functionality'] = self._identify_functionality(content)
            analysis['complexity'] = self._assess_complexity(content)
            analysis['unified_system_compatible'] = self._check_unified_system_compatible(content)
            
            return analysis
            
        except Exception as e:
            return {
                'error': str(e),
                'total_lines': 0,
                'file_size': 0
            }
            
    def _identify_functionality(self, content: str) -> List[str]:
        """è¯†åˆ«è„šæœ¬åŠŸèƒ½ç±»å‹"""
        functionality = []
        
        content_lower = content.lower()
        
        # ä¿®å¤ç›¸å…³åŠŸèƒ½
        if any(keyword in content_lower for keyword in ['fix', 'repair', 'correct']):
            functionality.append('repair')
            
        # æ£€æŸ¥ç›¸å…³åŠŸèƒ½  
        if any(keyword in content_lower for keyword in ['check', 'verify', 'validate']):
            functionality.append('check')
            
        # è¯­æ³•ç›¸å…³
        if any(keyword in content_lower for keyword in ['syntax', 'indent', 'ast']):
            functionality.append('syntax')
            
        # åˆ†æç›¸å…³
        if any(keyword in content_lower for keyword in ['analyze', 'analysis', 'scan']):
            functionality.append('analysis')
            
        # ç³»ç»Ÿç›¸å…³
        if any(keyword in content_lower for keyword in ['system', 'unified', 'comprehensive']):
            functionality.append('system')
            
        # å·¥å…·ç›¸å…³
        if any(keyword in content_lower for keyword in ['utility', 'tool', 'helper']):
            functionality.append('utility')
            
        return functionality
        
    def _assess_complexity(self, content: str) -> str:
        """è¯„ä¼°è„šæœ¬å¤æ‚åº¦"""
        lines = content.split('\n')
        code_lines = len([l for l in lines if l.strip() and not l.strip().startswith('#')])
        
        if code_lines < 50:
            return "simple"
        elif code_lines < 200:
            return "medium"
        elif code_lines < 500:
            return "complex"
        else:
            return "mega"
            
    def _check_unified_system_compatible(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ç»Ÿä¸€è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿå…¼å®¹"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»Ÿä¸€çš„é”™è¯¯å¤„ç†ã€æ—¥å¿—ã€é…ç½®ç­‰
        has_proper_structure = all([
            'def ' in content,  # æœ‰å‡½æ•°å®šä¹‰
            'import' in content,  # æœ‰å¯¼å…¥
            len(content.split('\n')) > 20  # ä¸æ˜¯å¤ªç®€å•
        ])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸è‰¯åšæ³•
        has_bad_practices = any([
            'subprocess.run(' in content and 'python' in content,  # è°ƒç”¨å…¶ä»–Pythonè„šæœ¬
            'subprocess' in content and 'python' in content,
            'glob(' in content and '*.py' in content,  # æ‰¹é‡å¤„ç†Pythonæ–‡ä»¶
            're.sub(' in content and '.*' in content,  # ç®€å•çš„å…¨å±€æ›¿æ¢
        ], shell=False, check=True)
        
        return has_proper_structure and not has_bad_practices
        
    def _categorize_script(self, script_name: str, analysis: Dict) -> str:
        """åˆ†ç±»è„šæœ¬"""
        if 'error' in analysis:
            return 'obsolete_scripts'
            
        functionality = analysis.get('functionality', [])
        complexity = analysis.get('complexity', 'simple')
        is_compatible = analysis.get('unified_system_compatible', False)
        
        # ç®€å•ä¿®å¤è„šæœ¬è¯†åˆ«
        is_simple_fix = (
            any(re.match(pattern, script_name) for pattern in self.simple_fix_patterns) and
            complexity == 'simple' and
            not is_compatible
        )
        
        if is_simple_fix:
            return 'simple_fix_scripts'
            
        # èåˆå€™é€‰è¯†åˆ«
        if ('repair' in functionality or 'syntax' in functionality) and is_compatible:
            return 'fusion_candidates'
            
        # å·¥å…·è„šæœ¬è¯†åˆ«
        if 'utility' in functionality or 'tool' in functionality:
            return 'utility_scripts'
            
        # åºŸå¼ƒè„šæœ¬è¯†åˆ«
        if complexity == 'simple' and len(functionality) <= 1:
            return 'obsolete_scripts'
            
        return 'unknown_scripts'
        
    def generate_recommendations(self, categories: Dict) -> List[str]:
        """ç”Ÿæˆå¤„ç†å»ºè®®"""
        recommendations = []
        
        # ç³»ç»Ÿå¿…éœ€è„šæœ¬ - ä¿ç•™
        if categories['system_essential']:
            recommendations.append(f"âœ… ç³»ç»Ÿå¿…éœ€è„šæœ¬ï¼ˆä¿ç•™ï¼‰: {len(categories['system_essential'])}ä¸ª")
            for script in categories['system_essential']:
                recommendations.append(f"   - {script}: ä¿ç•™ï¼Œç³»ç»Ÿè¿è¡Œå¿…éœ€")
                
        # ç®€å•ä¿®å¤è„šæœ¬ - å½’æ¡£
        if categories['simple_fix_scripts']:
            recommendations.append(f"ğŸš¨ ç®€å•ä¿®å¤è„šæœ¬ï¼ˆå¿…é¡»å½’æ¡£ï¼‰: {len(categories['simple_fix_scripts'])}ä¸ª")
            for script_info in categories['simple_fix_scripts']:
                script = script_info['name']
                complexity = script_info['analysis']['complexity']
                recommendations.append(f"   - {script}: å½’æ¡£åˆ°archived_fix_scripts/ï¼Œè§„åˆ™ç®€é™‹ï¼Œå¤æ‚åº¦{complexity}")
                
        # å¯èåˆè„šæœ¬ - é›†æˆåˆ°ç»Ÿä¸€ç³»ç»Ÿ
        if categories['fusion_candidates']:
            recommendations.append(f"ğŸ”„ å¯èåˆè„šæœ¬ï¼ˆé›†æˆåˆ°ç»Ÿä¸€ç³»ç»Ÿï¼‰: {len(categories['fusion_candidates'])}ä¸ª")
            for script_info in categories['fusion_candidates']:
                script = script_info['name']
                functionality = script_info['analysis']['functionality']
                recommendations.append(f"   - {script}: èåˆåˆ°unified_auto_fix_system/modules/ï¼ŒåŠŸèƒ½:{',
                '.join(functionality)}")
                
        # å·¥å…·è„šæœ¬ - è¯„ä¼°ä¿ç•™
        if categories['utility_scripts']:
            recommendations.append(f"ğŸ› ï¸ å·¥å…·è„šæœ¬ï¼ˆè¯„ä¼°ä¿ç•™ï¼‰: {len(categories['utility_scripts'])}ä¸ª")
            for script_info in categories['utility_scripts']:
                script = script_info['name']
                lines = script_info['analysis']['total_lines']
                recommendations.append(f"   - {script}: è¯„ä¼°æ˜¯å¦ä¿ç•™ï¼Œ{lines}è¡Œ")
                
        # åºŸå¼ƒè„šæœ¬ - å½’æ¡£
        if categories['obsolete_scripts']:
            recommendations.append(f"ğŸ—‘ï¸ åºŸå¼ƒè„šæœ¬ï¼ˆå½’æ¡£ï¼‰: {len(categories['obsolete_scripts'])}ä¸ª")
            for script_info in categories['obsolete_scripts']:
                script = script_info['name']
                lines = script_info['analysis']['total_lines']
                recommendations.append(f"   - {script}: å½’æ¡£åˆ°archived_fix_scripts/ï¼Œè¿‡äºç®€å•({lines}è¡Œ)")
                
        return recommendations
        
    def print_analysis_report(self, categories: Dict, recommendations: List[str]):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ” æ ¹ç›®å½•Pythonè„šæœ¬åˆ†ææŠ¥å‘Š")
        print("="*80)
        print(f"åˆ†ææ—¶é—´: {datetime.now()}")
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root.absolute()}")
        print()
        
        # åˆ†ç±»ç»Ÿè®¡
        print("ğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
        total_analyzed = sum(len(scripts) for scripts in categories.values())
        
        for category, scripts in categories.items():
            if scripts:
                category_names = {
                    'system_essential': 'ç³»ç»Ÿå¿…éœ€è„šæœ¬',
                    'simple_fix_scripts': 'ç®€å•ä¿®å¤è„šæœ¬',
                    'fusion_candidates': 'å¯èåˆè„šæœ¬',
                    'utility_scripts': 'å·¥å…·è„šæœ¬',
                    'obsolete_scripts': 'åºŸå¼ƒè„šæœ¬',
                    'unknown_scripts': 'æœªçŸ¥è„šæœ¬'
                }
                print(f"  {category_names.get(category, category)}: {len(scripts)}ä¸ª")
        
        print(f"  ğŸ“ˆ æ€»è®¡åˆ†æ: {total_analyzed}ä¸ªè„šæœ¬")
        print()
        
        # è¯¦ç»†å»ºè®®
        print("ğŸ¯ å¤„ç†å»ºè®®:")
        for rec in recommendations:
            print(f"  {rec}")
        
        print("\n" + "="*80)
        
        # è¿”å›å…³é”®ç»Ÿè®¡
        simple_fix_count = len(categories['simple_fix_scripts'])
        fusion_count = len(categories['fusion_candidates'])
        obsolete_count = len(categories['obsolete_scripts'])
        
        return {
            'simple_fix_scripts': simple_fix_count,
            'fusion_candidates': fusion_count, 
            'obsolete_scripts': obsolete_count,
            'total_analyzed': total_analyzed
        }


def main():
    """ä¸»å‡½æ•°"""
    analyzer = RootScriptAnalyzer()
    
    # åˆ†ææ‰€æœ‰è„šæœ¬
    categories = analyzer.analyze_all_scripts()
    
    # ç”Ÿæˆå»ºè®®
    recommendations = analyzer.generate_recommendations(categories)
    
    # æ‰“å°æŠ¥å‘Š
    stats = analyzer.print_analysis_report(categories, recommendations)
    
    print(f"\nğŸ¯ å…³é”®å‘ç°:")
    print(f"  ğŸš¨ éœ€è¦å½’æ¡£çš„ç®€å•ä¿®å¤è„šæœ¬: {stats['simple_fix_scripts']}ä¸ª")
    print(f"  ğŸ”„ å¯èåˆåˆ°ç»Ÿä¸€ç³»ç»Ÿçš„è„šæœ¬: {stats['fusion_candidates']}ä¸ª") 
    print(f"  ğŸ—‘ï¸ éœ€è¦å½’æ¡£çš„åºŸå¼ƒè„šæœ¬: {stats['obsolete_scripts']}ä¸ª")
    
    # æ€»ä½“å»ºè®®
    print(f"\nğŸ“‹ æ€»ä½“å»ºè®®:")
    if stats['simple_fix_scripts'] > 0:
        print(f"  âš ï¸  å‘ç°{stats['simple_fix_scripts']}ä¸ªç®€å•ä¿®å¤è„šæœ¬ï¼Œå»ºè®®ç«‹å³å½’æ¡£")
        
    if stats['fusion_candidates'] > 0:
        print(f"  ğŸ”„ å‘ç°{stats['fusion_candidates']}ä¸ªå¯èåˆè„šæœ¬ï¼Œå»ºè®®é›†æˆåˆ°ç»Ÿä¸€ä¿®å¤ç³»ç»Ÿ")
        
    if stats['obsolete_scripts'] > 0:
        print(f"  ğŸ§¹ å‘ç°{stats['obsolete_scripts']}ä¸ªåºŸå¼ƒè„šæœ¬ï¼Œå»ºè®®å½’æ¡£æ¸…ç†")
        
    print(f"\nğŸ’¡ å»ºè®®ä¼˜å…ˆçº§:")
    print(f"  1. ğŸš¨ ç«‹å³å½’æ¡£ç®€å•ä¿®å¤è„šæœ¬ï¼ˆé˜²æ­¢ç»§ç»­ä½¿ç”¨ï¼‰")
    print(f"  2. ğŸ”„ é€æ­¥èåˆæœ‰ç”¨è„šæœ¬åˆ°ç»Ÿä¸€ç³»ç»Ÿ")
    print(f"  3. ğŸ§¹ æ¸…ç†å½’æ¡£åºŸå¼ƒè„šæœ¬ï¼ˆä¿æŒæ•´æ´ï¼‰")


if __name__ == "__main__":
    main()