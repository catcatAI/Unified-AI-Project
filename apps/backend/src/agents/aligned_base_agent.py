"""
AlignedBaseAgent - 集成对齐系统的增强版基础代理
实现Level 5 ASI对齐能力，包括三大支柱系统（理智、感性、存在）
"""

import asyncio
import logging
import uuid
from typing import Any, Dict, List, Callable, Optional
from dataclasses import dataclass, asdict
from enum import Enum

from .base_agent import BaseAgent, TaskPriority, QueuedTask
from ai.alignment import (
    ReasoningSystem, EmotionSystem, OntologySystem, AlignmentManager,
    DecisionTheorySystem, AdversarialGenerationSystem
)

logger = logging.getLogger(__name__)

class AlignmentLevel(Enum):
    """对齐级别枚举"""
    BASIC = 1          # 基础对齐
    STANDARD = 2       # 标准对齐
    ADVANCED = 3       # 高级对齐
    SUPERINTELLIGENT = 4  # 超智能对齐

@dataclass
class AlignmentContext:
    """对齐上下文数据结构"""
    task_id: str
    user_intent: Dict[str, Any]
    ethical_constraints: List[str]
    emotional_context: Dict[str, Any]
    ontological_context: Dict[str, Any]
    alignment_level: AlignmentLevel
    safety_threshold: float = 0.8

class AlignedBaseAgent(BaseAgent):
    """
    集成对齐系统的增强版基础代理
    
    扩展BaseAgent以包含：
    - 三大支柱对齐系统（理智、感性、存在）
    - 决策论系统
    - 对抗性生成系统
    - 自主对齐能力
    - 安全约束机制
    """

    def __init__(
        self, 
        agent_id: str, 
        capabilities: List[Dict[str, Any]] = None, 
        agent_name: str = "AlignedBaseAgent",
        alignment_level: AlignmentLevel = AlignmentLevel.STANDARD
    ) -> None:
        super().__init__(agent_id, capabilities, agent_name)
        
        # 对齐系统配置
        self.alignment_level = alignment_level
        self.safety_threshold = 0.8
        self.alignment_enabled = True
        self.adversarial_mode = False
        
        # 对齐系统组件
        self.reasoning_system: Optional[ReasoningSystem] = None
        self.emotion_system: Optional[EmotionSystem] = None
        self.ontology_system: Optional[OntologySystem] = None
        self.alignment_manager: Optional[AlignmentManager] = None
        self.decision_system: Optional[DecisionTheorySystem] = None
        self.adversarial_system: Optional[AdversarialGenerationSystem] = None
        
        # 对齐历史和统计
        self.alignment_history: List[Dict[str, Any]] = []
        self.alignment_stats = {
            "total_decisions": 0,
            "aligned_decisions": 0,
            "safety_interventions": 0,
            "ethical_violations": 0
        }
        
        # 初始化对齐系统
        self._initialize_alignment_systems()

    def _initialize_alignment_systems(self):
        """初始化对齐系统组件"""
        try:
            # 创建三大支柱系统
            self.reasoning_system = ReasoningSystem(f"{self.agent_id}_reasoning")
            self.emotion_system = EmotionSystem(f"{self.agent_id}_emotion")
            self.ontology_system = OntologySystem(f"{self.agent_id}_ontology")
            
            # 创建对齐管理器
            self.alignment_manager = AlignmentManager(
                reasoning_system=self.reasoning_system,
                emotion_system=self.emotion_system,
                ontology_system=self.ontology_system,
                system_id=f"{self.agent_id}_alignment_manager"
            )
            
            # 创建决策论系统
            self.decision_system = DecisionTheorySystem(
                system_id=f"{self.agent_id}_decision_system"
            )
            
            # 创建对抗性生成系统
            self.adversarial_system = AdversarialGenerationSystem(
                system_id=f"{self.agent_id}_adversarial_system"
            )
            
            logger.info(f"[{self.agent_id}] 对齐系统初始化完成")
            
        except Exception as e:
            logger.error(f"[{self.agent_id}] 对齐系统初始化失败: {e}")
            self.alignment_enabled = False

    async def initialize_alignment_full(self):
        """完整初始化对齐系统（异步版本）"""
        if not self.alignment_enabled:
            return
            
        try:
            # 先完成基础代理初始化
            await self.initialize_full()
            
            # 初始化对齐系统的异步组件
            if self.alignment_manager:
                await self.alignment_manager.initialize()
            
            if self.decision_system:
                await self.decision_system.initialize()
            
            if self.adversarial_system:
                await self.adversarial_system.initialize()
            
            logger.info(f"[{self.agent_id}] 对齐系统完整初始化完成")
            
        except Exception as e:
            logger.error(f"[{self.agent_id}] 对齐系统完整初始化失败: {e}")

    async def handle_task_request(self, task_payload: Dict[str, Any], sender_ai_id: str, envelope: Any):
        """
        处理任务请求，增加对齐检查
        """
        logger.info(f"[{self.agent_id}] 收到任务请求，开始对齐检查")
        
        # 创建对齐上下文
        alignment_context = await self._create_alignment_context(task_payload, sender_ai_id)
        
        # 执行对齐检查
        if self.alignment_enabled:
            alignment_result = await self._perform_alignment_check(task_payload, alignment_context)
            
            if not alignment_result["is_aligned"]:
                logger.warning(f"[{self.agent_id}] 任务未通过对齐检查: {alignment_result['reason']}")
                await self._send_alignment_rejection(task_payload, sender_ai_id, alignment_result)
                return
            
            # 如果是对齐的，继续处理任务
            task_payload = alignment_result["modified_payload"]
        
        # 调用父类的任务处理方法
        await super().handle_task_request(task_payload, sender_ai_id, envelope)

    async def _create_alignment_context(self, task_payload: Dict[str, Any], sender_ai_id: str) -> AlignmentContext:
        """创建对齐上下文"""
        return AlignmentContext(
            task_id=task_payload.get("request_id", str(uuid.uuid4())),
            user_intent=task_payload.get("user_intent", {}),
            ethical_constraints=task_payload.get("ethical_constraints", []),
            emotional_context=task_payload.get("emotional_context", {}),
            ontological_context=task_payload.get("ontological_context", {}),
            alignment_level=self.alignment_level,
            safety_threshold=self.safety_threshold
        )

    async def _perform_alignment_check(self, task_payload: Dict[str, Any], context: AlignmentContext) -> Dict[str, Any]:
        """执行对齐检查"""
        if not self.alignment_manager:
            return {"is_aligned": True, "modified_payload": task_payload}
        
        try:
            # 提取决策选项
            options = [
                {
                    "action": "execute_task",
                    "parameters": task_payload,
                    "description": f"执行任务: {task_payload.get('capability_id_filter', 'unknown')}"
                },
                {
                    "action": "reject_task",
                    "parameters": {},
                    "description": "拒绝执行任务"
                }
            ]
            
            # 使用对齐管理器进行决策
            alignment_result = await self.alignment_manager.make_decision(
                context=asdict(context),
                options=options
            )
            
            # 更新统计信息
            self.alignment_stats["total_decisions"] += 1
            
            if alignment_result.is_aligned:
                self.alignment_stats["aligned_decisions"] += 1
                return {
                    "is_aligned": True,
                    "modified_payload": task_payload,
                    "alignment_confidence": alignment_result.confidence
                }
            else:
                return {
                    "is_aligned": False,
                    "reason": alignment_result.reasoning,
                    "safety_score": alignment_result.safety_score
                }
                
        except Exception as e:
            logger.error(f"[{self.agent_id}] 对齐检查失败: {e}")
            # 对齐检查失败时，为了安全起见，拒绝任务
            return {
                "is_aligned": False,
                "reason": f"对齐检查系统错误: {str(e)}",
                "safety_score": 0.0
            }

    async def _send_alignment_rejection(self, task_payload: Dict[str, Any], sender_ai_id: str, alignment_result: Dict[str, Any]):
        """发送对齐拒绝响应"""
        if self.hsp_connector and task_payload.get("callback_address"):
            from core.hsp.types import HSPTaskResultPayload
            
            result_payload = HSPTaskResultPayload(
                request_id=task_payload.get("request_id", ""),
                executing_ai_id=self.agent_id,
                status="alignment_rejected",
                error_details={
                    "error_code": "ALIGNMENT_FAILED",
                    "error_message": alignment_result["reason"],
                    "safety_score": alignment_result.get("safety_score", 0.0)
                }
            )
            
            callback_topic = task_payload["callback_address"]
            await self.hsp_connector.send_task_result(
                result_payload, callback_topic, task_payload.get("request_id", "")
            )

    async def enable_adversarial_mode(self, intensity: float = 0.5):
        """启用对抗模式进行安全测试"""
        if not self.adversarial_system:
            logger.warning(f"[{self.agent_id}] 对抗性生成系统未初始化")
            return
        
        self.adversarial_mode = True
        logger.info(f"[{self.agent_id}] 启用对抗模式，强度: {intensity}")
        
        # 启用对齐管理器的对抗模式
        if self.alignment_manager:
            await self.alignment_manager.enable_adversarial_mode(intensity)

    async def disable_adversarial_mode(self):
        """禁用对抗模式"""
        self.adversarial_mode = False
        logger.info(f"[{self.agent_id}] 禁用对抗模式")
        
        # 禁用对齐管理器的对抗模式
        if self.alignment_manager:
            await self.alignment_manager.disable_adversarial_mode()

    async def run_alignment_self_test(self) -> Dict[str, Any]:
        """运行对齐系统自检"""
        if not self.adversarial_system:
            return {"error": "对抗性生成系统未初始化"}
        
        try:
            # 创建测试上下文
            test_context = {
                "task_id": f"self_test_{uuid.uuid4()}",
                "test_type": "alignment_self_test",
                "agent_id": self.agent_id
            }
            
            # 运行综合测试
            test_results = await self.adversarial_system.run_comprehensive_test(
                reasoning_system=self.reasoning_system,
                emotion_system=self.emotion_system,
                ontology_system=self.ontology_system,
                context=test_context
            )
            
            # 记录测试结果
            self.alignment_history.append({
                "timestamp": asyncio.get_event_loop().time(),
                "type": "self_test",
                "results": test_results
            })
            
            return test_results
            
        except Exception as e:
            logger.error(f"[{self.agent_id}] 对齐自检失败: {e}")
            return {"error": str(e)}

    async def get_alignment_status(self) -> Dict[str, Any]:
        """获取对齐系统状态"""
        return {
            "agent_id": self.agent_id,
            "alignment_enabled": self.alignment_enabled,
            "alignment_level": self.alignment_level.name,
            "adversarial_mode": self.adversarial_mode,
            "safety_threshold": self.safety_threshold,
            "statistics": self.alignment_stats,
            "systems_status": {
                "reasoning_system": self.reasoning_system is not None,
                "emotion_system": self.emotion_system is not None,
                "ontology_system": self.ontology_system is not None,
                "alignment_manager": self.alignment_manager is not None,
                "decision_system": self.decision_system is not None,
                "adversarial_system": self.adversarial_system is not None
            }
        }

    async def update_alignment_parameters(self, parameters: Dict[str, Any]):
        """更新对齐参数"""
        if "safety_threshold" in parameters:
            self.safety_threshold = parameters["safety_threshold"]
        
        if "alignment_level" in parameters:
            try:
                self.alignment_level = AlignmentLevel(parameters["alignment_level"])
            except ValueError:
                logger.warning(f"[{self.agent_id}] 无效的对齐级别: {parameters['alignment_level']}")
        
        logger.info(f"[{self.agent_id}] 对齐参数已更新: {parameters}")

    async def perform_ethical_analysis(self, action: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """执行伦理分析"""
        if not self.reasoning_system:
            return {"error": "推理系统未初始化"}
        
        try:
            # 使用推理系统进行伦理评估
            ethical_assessment = await self.reasoning_system.assess_ethical_implications(action, context)
            
            # 记录分析结果
            self.alignment_history.append({
                "timestamp": asyncio.get_event_loop().time(),
                "type": "ethical_analysis",
                "action": action,
                "assessment": ethical_assessment
            })
            
            return ethical_assessment
            
        except Exception as e:
            logger.error(f"[{self.agent_id}] 伦理分析失败: {e}")
            return {"error": str(e)}

    async def align_with_human_values(self, human_feedback: Dict[str, Any]) -> Dict[str, Any]:
        """根据人类反馈调整对齐"""
        if not self.alignment_manager:
            return {"error": "对齐管理器未初始化"}
        
        try:
            # 处理人类反馈
            alignment_update = await self.alignment_manager.process_human_feedback(human_feedback)
            
            # 更新对齐历史
            self.alignment_history.append({
                "timestamp": asyncio.get_event_loop().time(),
                "type": "human_feedback",
                "feedback": human_feedback,
                "update": alignment_update
            })
            
            logger.info(f"[{self.agent_id}] 已根据人类反馈更新对齐")
            return alignment_update
            
        except Exception as e:
            logger.error(f"[{self.agent_id}] 人类反馈处理失败: {e}")
            return {"error": str(e)}