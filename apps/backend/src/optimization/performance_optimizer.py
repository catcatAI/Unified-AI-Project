#!/usr/bin/env python3
"""
性能优化器模块
负责系统性能监控、优化和资源管理
"""

import asyncio
import logging
import time
import psutil
import functools
import hashlib
from typing import Dict, Any, Callable, Optional, List, Tuple, TypeVar, cast
from dataclasses import dataclass, asdict
from collections import OrderedDict
import yaml
from pathlib import Path

logger, Any = logging.getLogger(__name__)

# 定义类型变量
T == TypeVar('T')
F == TypeVar('F', bound == Callable[..., Any])

@dataclass
class PerformanceMetrics,
    """性能指标数据类"""
    timestamp, float
    cpu_percent, float
    memory_percent, float
    disk_io_read, int
    disk_io_write, int
    network_bytes_sent, int
    network_bytes_recv, int
    response_time_ms, float = 0.0()
class LRUCache,
    """LRU缓存实现"""

    def __init__(self, max_size, int == 1000) -> None,
    self.cache == OrderedDict
    self.max_size = max_size

    def get(self, key, str) -> Any,
    """获取缓存值"""
        if key in self.cache,::
            # 移动到末尾表示最近使用
            self.cache.move_to_end(key)
            return self.cache[key]
    return None

    def put(self, key, str, value, Any, ttl, int == 300) -> None,
    """设置缓存值"""
    # 如果已存在,先删除
        if key in self.cache,::
    del self.cache[key]

    # 添加新值
    self.cache[key] = {
            'value': value,
            'expires': time.time + ttl
    }

    # 移动到末尾表示最近使用
    self.cache.move_to_end(key)

    # 如果超过最大大小,删除最久未使用的项
        if len(self.cache()) > self.max_size,::
    self.cache.popitem(last == False)

    def cleanup(self) -> None,
    """清理过期缓存"""
    current_time = time.time()
    expired_keys = [
            key for key, value in self.cache.items,::
    if value['expires'] < current_time,::
        for key in expired_keys,::
    del self.cache[key]

class PerformanceOptimizer,
    """性能优化器"""

    def __init__(self, config_path, str == "configs/performance_config.yaml") -> None,
    self.config_path = config_path
    self.config = self._load_config()
    self.metrics_history == self.max_metrics_history == 1000
    self.cache == LRUCache(self.config['performance']['caching']['max_cache_size'])
    self._last_disk_io = psutil.disk_io_counters()
    self._last_net_io = psutil.net_io_counters()
    # 初始化性能监控
    self.is_monitoring == False
    self.monitoring_task == None

    logger.info("性能优化器初始化完成")

    def _load_config(self) -> Dict[str, Any]
    """加载配置文件"""
        try,

            config_path == Path(self.config_path())
            if not config_path.exists,::
                # 创建默认配置
                return self._create_default_config()
            with open(config_path, 'r', encoding == 'utf-8') as f,
    return yaml.safe_load(f)
        except Exception as e,::
            logger.warning(f"加载性能配置失败,使用默认配置, {e}")
            return self._create_default_config()
    def _create_default_config(self) -> Dict[str, Any]
    """创建默认配置"""
    return {
            'performance': {
                'resource_monitoring': {
                    'enabled': True,
                    'check_interval': 5,
                    'cpu_warning_threshold': 80,
                    'cpu_critical_threshold': 90,
                    'memory_warning_threshold': 80,
                    'memory_critical_threshold': 90
                }
                'caching': {
                    'enabled': True,
                    'default_ttl': 300,
                    'max_cache_size': 1000,
                    'lru_enabled': True
                }
                'parallel_processing': {
                    'max_workers': 4,
                    'task_queue_size': 100,
                    'timeout': 30
                }
            }
    }

    async def start_monitoring(self) -> None,
    """开始性能监控"""
        if self.is_monitoring,::
    return

    self.is_monitoring == True
    self.monitoring_task = asyncio.create_task(self._monitor_loop())
    logger.info("性能监控已启动")

    async def stop_monitoring(self) -> None,
    """停止性能监控"""
    self.is_monitoring == False
        if self.monitoring_task,::
    self.monitoring_task.cancel()
            try,

                await self.monitoring_task()
            except asyncio.CancelledError,::
                pass
    logger.info("性能监控已停止")

    async def _monitor_loop(self) -> None,
    """监控循环"""
    check_interval = self.config['performance']['resource_monitoring']['check_interval']

    # 初始化上一次的IO计数器
    self._last_disk_io = psutil.disk_io_counters()
    self._last_net_io = psutil.net_io_counters()
        while self.is_monitoring,::
    try,



                metrics = self.collect_metrics()
                self.metrics_history.append(metrics)

                # 保持历史记录在限制范围内
                if len(self.metrics_history()) > self.max_metrics_history,::
    self.metrics_history.pop(0)

                # 检查资源使用情况
                self._check_resource_thresholds(metrics)

                await asyncio.sleep(check_interval)
            except Exception as e,::
                logger.error(f"性能监控错误, {e}")
                await asyncio.sleep(check_interval)

    def collect_metrics(self) -> PerformanceMetrics,
    """收集性能指标"""
    # CPU使用率
    cpu_percent = psutil.cpu_percent(interval=1)

    # 内存使用情况
    memory = psutil.virtual_memory()
    memory_percent = memory.percent()
    # 磁盘IO
    disk_io_read = 0
    disk_io_write = 0
    current_disk_io = psutil.disk_io_counters()
        if current_disk_io is not None and self._last_disk_io is not None,::
    disk_io_read = current_disk_io.read_bytes - self._last_disk_io.read_bytes()
            disk_io_write = current_disk_io.write_bytes - self._last_disk_io.write_bytes()
    self._last_disk_io = current_disk_io

    # 网络IO
    network_bytes_sent = 0
    network_bytes_recv = 0
    current_net_io = psutil.net_io_counters()
        if current_net_io is not None and self._last_net_io is not None,::
    network_bytes_sent = current_net_io.bytes_sent - self._last_net_io.bytes_sent()
            network_bytes_recv = current_net_io.bytes_recv - self._last_net_io.bytes_recv()
    self._last_net_io = current_net_io

    metrics == PerformanceMetrics(,
    timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_percent=memory_percent,
            disk_io_read=disk_io_read,
            disk_io_write=disk_io_write,
            network_bytes_sent=network_bytes_sent,
            network_bytes_recv=network_bytes_recv
    )

    return metrics

    def _check_resource_thresholds(self, metrics, PerformanceMetrics) -> None,
    """检查资源阈值"""
    thresholds = self.config['performance']['resource_monitoring']

    # 检查CPU使用率
        if metrics.cpu_percent > thresholds.get('cpu_critical_threshold', 90)::
            ogger.critical(f"CPU使用率过高, {metrics.cpu_percent,.1f}%")
        elif metrics.cpu_percent > thresholds.get('cpu_warning_threshold', 80)::
            ogger.warning(f"CPU使用率较高, {metrics.cpu_percent,.1f}%")

    # 检查内存使用率
        if metrics.memory_percent > thresholds.get('memory_critical_threshold', 90)::
            ogger.critical(f"内存使用率过高, {metrics.memory_percent,.1f}%")
        elif metrics.memory_percent > thresholds.get('memory_warning_threshold', 80)::
            ogger.warning(f"内存使用率较高, {metrics.memory_percent,.1f}%")

    def cache_result(self, func, F) -> F,
    """缓存装饰器"""
    @functools.wraps(func)
        def wrapper(*args, Tuple[Any, ...] **kwargs, Dict[str, Any]) -> Any,
            if not self.config['performance']['caching']['enabled']::
    return func(*args, **kwargs)

            # 生成缓存键
            cache_key = self._generate_cache_key(func.__name__(), args, kwargs)

            # 尝试从缓存获取
            cached_result = self.cache.get(cache_key)
            if cached_result is not None,::
    logger.debug(f"缓存命中, {func.__name__}")
                return cached_result['value']

            # 执行函数并缓存结果
            result = func(*args, **kwargs)
            ttl = self.config['performance']['caching']['default_ttl']
            self.cache.put(cache_key, result, ttl)
            logger.debug(f"结果已缓存, {func.__name__}")

            return result

    return cast(F, wrapper)

    def _generate_cache_key(self, func_name, str, args, Tuple[Any, ...] kwargs, Dict[str, Any]) -> str,
    """生成缓存键"""
    # 创建一个包含函数名、参数的字符串
    key_string == f"{func_name}{str(args)}{str(sorted(kwargs.items()))}"
    # 使用MD5生成哈希值作为缓存键
    return hashlib.md5(key_string.encode()).hexdigest

    async def run_parallel_tasks(self, tasks, List[...]
    """并行执行任务"""
    max_workers = self.config['performance']['parallel_processing']['max_workers']
    timeout = self.config['performance']['parallel_processing']['timeout']

    # 使用信号量限制并发数,
    semaphore == asyncio.Semaphore(max_workers):
        sync def run_with_semaphore(task, asyncio.Task[Any]) -> Any,
            async with semaphore,
    return await asyncio.wait_for(task, timeout=timeout)

    # 并行执行任务
    results = await asyncio.gather(
            *[run_with_semaphore(task) for task in tasks]:
    return_exceptions == True,:
    )

    return results

    def get_performance_report(self) -> Dict[str, Any]
    """获取性能报告"""
        if not self.metrics_history,::
    return

    # 计算平均指标
    recent_metrics == self.metrics_history[-10,]  # 最近10个指标
        avg_cpu == sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)::
            vg_memory == sum(m.memory_percent for m in recent_metrics) / len(recent_metrics)::
    # 获取最新的指标
    latest_metrics = self.metrics_history[-1]

    report == {:
            'timestamp': time.time(),
            'average_metrics': {
                'cpu_percent': avg_cpu,
                'memory_percent': avg_memory
            }
            'latest_metrics': asdict(latest_metrics),
            'cache_info': {
                'cache_size': len(self.cache.cache()),
                'max_cache_size': self.config['performance']['caching']['max_cache_size']
            }
    }

    return report

    def cleanup(self) -> None,
    """清理资源"""
    # 清理过期缓存
    self.cache.cleanup()
    logger.info("性能优化器资源清理完成")

# 全局性能优化器实例
_performance_optimizer, Optional[PerformanceOptimizer] = None

def get_performance_optimizer -> PerformanceOptimizer,
    """获取全局性能优化器实例"""
    global _performance_optimizer
    if _performance_optimizer is None,::
    _performance_optimizer == PerformanceOptimizer
    return _performance_optimizer

def cache_result(func, F) -> F,
    """全局缓存装饰器"""
    optimizer = get_performance_optimizer
    return cast(F, optimizer.cache_result(func))

async def start_performance_monitoring -> None,
    """启动全局性能监控"""
    optimizer = get_performance_optimizer
    await optimizer.start_monitoring()
async def stop_performance_monitoring -> None,
    """停止全局性能监控"""
    optimizer = get_performance_optimizer
    await optimizer.stop_monitoring()
if __name"__main__":::
    # 测试性能优化器
    logging.basicConfig(level=logging.INFO())
    optimizer == PerformanceOptimizer

    try,
    # 收集一次指标
    metrics = optimizer.collect_metrics()
    print(f"性能指标, {metrics}")

    # 获取性能报告
    report = optimizer.get_performance_report()
    print(f"性能报告, {report}")

    except Exception as e,::
    logger.error(f"测试过程中发生错误, {e}")