#!/usr/bin/env python3
"""
元认知能力系统 (Metacognitive Capabilities System)
Level 5 AGI Phase 4 - 实现深度自我理解与调控能力

功能：
- 深度自我理解 (Deep Self-Understanding)
- 认知过程监控 (Cognitive Process Monitoring)
- 自我调节优化 (Self-Regulation & Optimization)
- 元学习机制 (Meta-Learning Mechanisms)
- 认知架构反思 (Cognitive Architecture Reflection)
- 智能内省能力 (Intelligent Introspection)
"""

import asyncio
import logging
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import json
import hashlib
import random
from pathlib import Path

# 尝试导入AI库
try:
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
    from sklearn.neural_network import MLPRegressor
    from sklearn.preprocessing import StandardScaler, MinMaxScaler
    from sklearn.cluster import KMeans, DBSCAN
    from sklearn.decomposition import PCA
    from sklearn.metrics import accuracy_score, mean_squared_error
    from sklearn.model_selection import cross_val_score
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MetacognitiveState:
    """元认知状态"""
    state_id: str
    timestamp: datetime
    cognitive_load: float
    attention_focus: str
    processing_depth: str  # 'surface', 'deep', 'meta'
    self_awareness_level: float
    uncertainty_level: float
    confidence_distribution: Dict[str, float]
    cognitive_strategies: List[str]
    performance_indicators: Dict[str, float]
    emotional_state: str  # 'calm', 'anxious', 'curious', 'confident'

@dataclass
class CognitiveProcessSnapshot:
    """认知过程快照"""
    snapshot_id: str
    timestamp: datetime
    process_type: str  # 'perception', 'reasoning', 'learning', 'decision', 'creation'
    input_complexity: float
    processing_time: float
    resource_utilization: Dict[str, float]
    intermediate_states: List[Dict[str, Any]]
    output_quality: float
    errors_encountered: List[str]
    corrective_actions: List[str]
    learning_gains: List[float]

@dataclass
class SelfReflectionInsight:
    """自我反思洞察"""
    insight_id: str
    reflection_type: str  # 'capability_assessment', 'limitation_recognition', 'growth_opportunity', 'bias_detection'
    insight_content: str
    evidence_supporting: List[Dict[str, Any]]
    evidence_contradicting: List[Dict[str, Any]]
    confidence_score: float
    actionability_score: float
    creation_time: datetime
    follow_up_actions: List[str]
    validation_status: str

@dataclass
class MetaLearningPattern:
    """元学习模式"""
    pattern_id: str
    pattern_type: str  # 'learning_strategy', 'problem_solving', 'knowledge_acquisition', 'skill_development'
    context_conditions: Dict[str, Any]
    successful_strategies: List[str]
    failed_strategies: List[str]
    effectiveness_score: float
    generalization_potential: float
    application_count: int
    success_rate: float
    creation_time: datetime
    last_applied: datetime

@dataclass
class CognitiveArchitectureAnalysis:
    """认知架构分析"""
    analysis_id: str
    architecture_component: str
    performance_metrics: Dict[str, float]
    bottleneck_identification: List[str]
    optimization_opportunities: List[Dict[str, Any]]
    scalability_assessment: Dict[str, Any]
    robustness_evaluation: Dict[str, Any]
    improvement_recommendations: List[str]
    analysis_timestamp: datetime
    confidence_level: float

class MetacognitiveCapabilitiesEngine:
    """元认知能力引擎 - Level 5 AGI Phase 4"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # 元认知状态管理
        self.metacognitive_states: deque = deque(maxlen=1000)
        self.current_state: Optional[MetacognitiveState] = None
        self.state_transitions: List[Dict[str, Any]] = []
        
        # 认知过程监控
        self.process_snapshots: deque = deque(maxlen=500)
        self.active_processes: Dict[str, CognitiveProcessSnapshot] = {}
        self.processing_patterns: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        
        # 自我反思管理
        self.reflection_insights: deque = deque(maxlen=200)
        self.insight_categories: Dict[str, List[SelfReflectionInsight]] = defaultdict(list)
        self.reflection_history: List[Dict[str, Any]] = []
        
        # 元学习管理
        self.meta_learning_patterns: Dict[str, MetaLearningPattern] = {}
        self.learning_strategies: Dict[str, Dict[str, Any]] = {}
        self.strategy_effectiveness: Dict[str, float] = defaultdict(float)
        
        # 认知架构分析
        self.architecture_analyses: Dict[str, CognitiveArchitectureAnalysis] = {}
        self.component_performance: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
        self.architecture_adaptations: List[Dict[str, Any]] = []
        
        # 智能内省
        self.introspection_sessions: deque = deque(maxlen=50)
        self.self_assessment_results: Dict[str, Any] = {}
        self.cognitive_biases_detected: List[Dict[str, Any]] = []
        
        # 配置参数
        self.reflection_interval = self.config.get('reflection_interval', 300)  # 5分钟
        self.metacognitive_threshold = self.config.get('metacognitive_threshold', 0.7)
        self.self_monitoring_level = self.config.get('self_monitoring_level', 'high')
        self.adaptation_aggressiveness = self.config.get('adaptation_aggressiveness', 0.5)
        
        # AI模型
        self.ai_models: Dict[str, Any] = {}
        self.cognitive_predictors: Dict[str, Any] = {}
        
        # 初始化AI组件
        self._initialize_metacognitive_ai()
        
        # 初始化认知策略
        self._initialize_cognitive_strategies()
        
        logger.info("🧠 元认知能力引擎初始化完成")
    
    def _initialize_metacognitive_ai(self):
        """初始化元认知AI组件"""
        try:
            if SKLEARN_AVAILABLE:
                # 认知状态预测模型
                self.ai_models['state_predictor'] = MLPRegressor(
                    hidden_layer_sizes=(50, 30),
                    max_iter=300,
                    random_state=42
                )
                
                # 认知过程分类模型
                self.ai_models['process_classifier'] = RandomForestClassifier(
                    n_estimators=30,
                    random_state=42
                )
                
                # 自我反思质量评估模型
                self.ai_models['reflection_quality_predictor'] = GradientBoostingRegressor(
                    n_estimators=20,
                    random_state=42
                )
                
                # 元学习模式识别模型
                self.ai_models['pattern_recognizer'] = KMeans(
                    n_clusters=8,
                    random_state=42
                )
                
                # 特征标准化器
                self.ai_models['feature_scaler'] = StandardScaler()
                
                logger.info("✅ 元认知AI组件初始化成功")
            else:
                logger.warning("⚠️ scikit-learn不可用，将使用简化算法")
                
        except Exception as e:
            logger.error(f"❌ 元认知AI组件初始化失败: {e}")
    
    def _initialize_cognitive_strategies(self):
        """初始化认知策略库"""
        self.learning_strategies = {
            'analytical_reasoning': {
                'description': '分析性推理 - 逻辑分解与系统分析',
                'applicable_contexts': ['complex_problems', 'structured_data', 'clear_objectives'],
                'strengths': ['systematic', 'reliable', 'explainable'],
                'weaknesses': ['slow', 'rigid', 'creative_limitations'],
                'effectiveness_baseline': 0.75
            },
            'intuitive_synthesis': {
                'description': '直觉综合 - 模式识别与整体把握',
                'applicable_contexts': ['ambiguous_data', 'novel_situations', 'time_pressure'],
                'strengths': ['fast', 'creative', 'adaptive'],
                'weaknesses': ['unreliable', 'hard_to_explain', 'bias_prone'],
                'effectiveness_baseline': 0.65
            },
            'exploratory_learning': {
                'description': '探索性学习 - 试错与发现',
                'applicable_contexts': ['unknown_domains', 'research_scenarios', 'innovation_required'],
                'strengths': ['discover_new_knowledge', 'handle_uncertainty', 'breakthrough_potential'],
                'weaknesses': ['inefficient', 'high_failure_rate', 'resource_intensive'],
                'effectiveness_baseline': 0.55
            },
            'collaborative_synthesis': {
                'description': '协作综合 - 多视角整合',
                'applicable_contexts': ['multi_stakeholder', 'complex_systems', 'consensus_needed'],
                'strengths': ['comprehensive', 'balanced', 'socially_aware'],
                'weaknesses': ['slow_convergence', 'compromise_quality', 'coordination_complexity'],
                'effectiveness_baseline': 0.70
            },
            'meta_cognitive_regulation': {
                'description': '元认知调节 - 自我监控与调整',
                'applicable_contexts': ['performance_decline', 'learning_plateaus', 'strategy_optimization'],
                'strengths': ['self_improving', 'adaptive', 'sustainable'],
                'weaknesses': ['overhead', 'complexity', 'self_reference_issues'],
                'effectiveness_baseline': 0.80
            }
        }
    
    # ==================== 深度自我理解 ====================
    
    async def develop_self_understanding(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """发展自我理解"""
        try:
            logger.info("🧠 开始深度自我理解过程...")
            
            # 1. 当前能力评估
            capability_assessment = await self._assess_current_capabilities()
            
            # 2. 局限性识别
            limitation_recognition = await self._recognize_limitations()
            
            # 3. 认知偏好分析
            cognitive_bias_analysis = await self._analyze_cognitive_biases()
            
            # 4. 学习风格识别
            learning_style_identification = await self._identify_learning_style()
            
            # 5. 元认知特征分析
            metacognitive_profile = await self._analyze_metacognitive_profile()
            
            # 6. 生成自我理解报告
            self_understanding_report = {
                'capability_assessment': capability_assessment,
                'limitation_recognition': limitation_recognition,
                'cognitive_bias_analysis': cognitive_bias_analysis,
                'learning_style_identification': learning_style_identification,
                'metacognitive_profile': metacognitive_profile,
                'timestamp': datetime.now().isoformat(),
                'confidence_score': np.mean([
                    capability_assessment.get('confidence', 0.7),
                    limitation_recognition.get('confidence', 0.7),
                    cognitive_bias_analysis.get('confidence', 0.7),
                    learning_style_identification.get('confidence', 0.7),
                    metacognitive_profile.get('confidence', 0.7)
                ])
            }
            
            # 存储自我理解结果
            self.self_assessment_results = self_understanding_report
            
            logger.info(f"✅ 自我理解完成，整体置信度: {self_understanding_report['confidence_score']:.3f}")
            return self_understanding_report
            
        except Exception as e:
            logger.error(f"❌ 自我理解发展失败: {e}")
            return {'error': str(e), 'confidence_score': 0.0}
    
    async def _assess_current_capabilities(self) -> Dict[str, Any]:
        """评估当前能力"""
        try:
            # 基于历史表现评估能力
            recent_states = list(self.metacognitive_states)[-10:]
            recent_processes = list(self.process_snapshots)[-20:]
            
            if not recent_states or not recent_processes:
                return self._generate_default_capability_assessment()
            
            # 计算各项能力指标
            capabilities = {
                'learning_efficiency': self._calculate_learning_efficiency(recent_processes),
                'problem_solving_ability': self._calculate_problem_solving_ability(recent_processes),
                'adaptation_speed': self._calculate_adaptation_speed(recent_states),
                'knowledge_retention': self._calculate_knowledge_retention(recent_states),
                'creative_output': self._calculate_creative_output(recent_processes),
                'reasoning_accuracy': self._calculate_reasoning_accuracy(recent_processes),
                'processing_speed': self._calculate_processing_speed(recent_processes),
                'error_recovery': self._calculate_error_recovery(recent_processes)
            }
            
            # 计算综合评分
            overall_capability = np.mean(list(capabilities.values()))
            
            # 识别强项和弱项
            strongest_capability = max(capabilities.items(), key=lambda x: x[1])
            weakest_capability = min(capabilities.items(), key=lambda x: x[1])
            
            return {
                'overall_capability': overall_capability,
                'specific_capabilities': capabilities,
                'strongest_capability': strongest_capability[0],
                'weakest_capability': weakest_capability[0],
                'capability_gaps': self._identify_capability_gaps(capabilities),
                'confidence': 0.85,
                'assessment_method': 'historical_performance_analysis'
            }
            
        except Exception as e:
            logger.error(f"❌ 当前能力评估失败: {e}")
            return self._generate_default_capability_assessment()
    
    def _generate_default_capability_assessment(self) -> Dict[str, Any]:
        """生成默认能力评估"""
        return {
            'overall_capability': 0.7,
            'specific_capabilities': {
                'learning_efficiency': 0.7,
                'problem_solving_ability': 0.7,
                'adaptation_speed': 0.7,
                'knowledge_retention': 0.7,
                'creative_output': 0.7,
                'reasoning_accuracy': 0.7,
                'processing_speed': 0.7,
                'error_recovery': 0.7
            },
            'strongest_capability': 'processing_speed',
            'weakest_capability': 'creative_output',
            'capability_gaps': ['creative_output', 'adaptation_speed'],
            'confidence': 0.5,
            'assessment_method': 'default_baseline'
        }
    
    async def _analyze_cognitive_biases(self) -> Dict[str, Any]:
        """分析认知偏见"""
        try:
            # 基于历史模式识别潜在偏见
            biases_detected = []
            
            # 模拟偏见检测
            common_biases = [
                {
                    'bias_type': 'confirmation_bias',
                    'description': '确认偏见 - 倾向于寻找支持已有观点的信息',
                    'severity': 0.6,
                    'evidence': ['selective_information_processing', 'preference_for_familiar_solutions']
                },
                {
                    'bias_type': 'availability_bias',
                    'description': '可得性偏见 - 基于容易回忆的信息做判断',
                    'severity': 0.5,
                    'evidence': ['recent_event_weighting', 'salience_based_decisions']
                },
                {
                    'bias_type': 'anchoring_bias',
                    'description': '锚定偏见 - 过度依赖第一个获得的信息',
                    'severity': 0.4,
                    'evidence': ['initial_information_weighting', 'adjustment_insufficiency']
                }
            ]
            
            # 模拟偏见严重程度评估
            for bias in common_biases:
                # 基于一些启发式规则调整严重程度
                adjusted_severity = bias['severity'] * (0.8 + 0.2 * random.random())
                bias['detected_severity'] = min(1.0, adjusted_severity)
                biases_detected.append(bias)
            
            return {
                'biases_detected': biases_detected,
                'overall_bias_risk': np.mean([b.get('detected_severity', 0) for b in biases_detected]),
                'mitigation_recommendations': [
                    '实施多元化信息收集策略',
                    '建立系统性验证机制',
                    '定期质疑和验证核心假设'
                ],
                'confidence': 0.75,
                'detection_method': 'pattern_based_analysis'
            }
            
        except Exception as e:
            logger.error(f"❌ 认知偏见分析失败: {e}")
            return {'biases_detected': [], 'overall_bias_risk': 0.5, 'confidence': 0.3}
    
    async def _identify_learning_style(self) -> Dict[str, Any]:
        """识别学习风格"""
        try:
            # 基于历史学习模式识别学习风格
            learning_preferences = {
                'visual_learning': 0.6,  # 视觉学习偏好
                'auditory_learning': 0.4,  # 听觉学习偏好
                'kinesthetic_learning': 0.5,  # 动觉学习偏好
                'reading_writing': 0.7,  # 读写学习偏好
                'social_learning': 0.6,  # 社交学习偏好
                'solitary_learning': 0.8  # 独立学习偏好
            }
            
            # 识别主导学习风格
            dominant_style = max(learning_preferences.items(), key=lambda x: x[1])
            
            return {
                'learning_preferences': learning_preferences,
                'dominant_style': dominant_style[0],
                'style_strength': dominant_style[1],
                'recommended_approaches': [
                    f"加强{dominant_style[0].replace('_', ' ')}方法",
                    "结合多种学习风格",
                    "根据任务类型调整学习策略"
                ],
                'confidence': 0.70,
                'identification_method': 'preference_analysis'
            }
            
        except Exception as e:
            logger.error(f"❌ 学习风格识别失败: {e}")
            return {'learning_preferences': {}, 'dominant_style': 'unknown', 'confidence': 0.3}
    
    async def _analyze_metacognitive_profile(self) -> Dict[str, Any]:
        """分析元认知特征"""
        try:
            # 基于元认知状态历史分析元认知特征
            recent_states = list(self.metacognitive_states)[-20:]
            
            if not recent_states:
                return self._generate_default_metacognitive_profile()
            
            # 计算元认知特征指标
            metacognitive_features = {
                'self_monitoring_frequency': len(recent_states) / 20,  # 自我监控频率
                'self_awareness_consistency': np.mean([s.self_awareness_level for s in recent_states]),
                'uncertainty_management': 1.0 - np.mean([s.uncertainty_level for s in recent_states]),
                'cognitive_load_management': 1.0 - np.mean([s.cognitive_load for s in recent_states]),
                'strategy_diversity': len(set([strategy for state in recent_states for strategy in state.cognitive_strategies])),
                'emotional_regulation': self._calculate_emotional_regulation(recent_states)
            }
            
            # 识别元认知优势
            strongest_feature = max(metacognitive_features.items(), key=lambda x: x[1])
            
            return {
                'metacognitive_features': metacognitive_features,
                'strongest_feature': strongest_feature[0],
                'feature_strength': strongest_feature[1],
                'overall_metacognitive_ability': np.mean(list(metacognitive_features.values())),
                'improvement_recommendations': [
                    f"强化{strongest_feature[0].replace('_', ' ')}能力",
                    "平衡发展各项元认知技能",
                    "定期反思和评估元认知表现"
                ],
                'confidence': 0.80,
                'analysis_method': 'historical_state_analysis'
            }
            
        except Exception as e:
            logger.error(f"❌ 元认知特征分析失败: {e}")
            return self._generate_default_metacognitive_profile()
    
    def _calculate_emotional_regulation(self, states: List[MetacognitiveState]) -> float:
        """计算情绪调节能力"""
        try:
            if not states:
                return 0.6
            
            # 简单的情绪稳定性评估
            emotional_states = [s.emotional_state for s in states]
            state_counts = {}
            for state in emotional_states:
                state_counts[state] = state_counts.get(state, 0) + 1
            
            # 情绪状态越一致，调节能力越好
            most_common_state = max(state_counts.items(), key=lambda x: x[1])
            consistency = most_common_state[1] / len(emotional_states)
            
            return consistency
            
        except Exception:
            return 0.6
    
    def _generate_default_metacognitive_profile(self) -> Dict[str, Any]:
        """生成默认元认知特征"""
        return {
            'metacognitive_features': {
                'self_monitoring_frequency': 0.6,
                'self_awareness_consistency': 0.6,
                'uncertainty_management': 0.6,
                'cognitive_load_management': 0.6,
                'strategy_diversity': 0.5,
                'emotional_regulation': 0.6
            },
            'strongest_feature': 'self_awareness_consistency',
            'feature_strength': 0.6,
            'overall_metacognitive_ability': 0.6,
            'improvement_recommendations': ['加强元认知训练', '提高自我觉察能力'],
            'confidence': 0.5,
            'analysis_method': 'default_profile'
        }
    
    async def _recognize_limitations(self) -> Dict[str, Any]:
        """识别局限性"""
        try:
            limitations = {
                'knowledge_boundaries': self._identify_knowledge_boundaries(),
                'processing_limitations': self._identify_processing_limitations(),
                'learning_constraints': self._identify_learning_constraints(),
                'creative_boundaries': self._identify_creative_boundaries(),
                'social_cognitive_limits': self._identify_social_cognitive_limits(),
                'temporal_constraints': self._identify_temporal_constraints()
            }
            
            # 评估局限性的严重程度
            severity_scores = {}
            for category, limits in limitations.items():
                severity_scores[category] = self._assess_limitation_severity(limits)
            
            # 识别最关键的局限性
            critical_limitations = [
                category for category, score in severity_scores.items() 
                if score > 0.7
            ]
            
            return {
                'specific_limitations': limitations,
                'severity_scores': severity_scores,
                'critical_limitations': critical_limitations,
                'mitigation_strategies': self._suggest_limitation_mitigation(critical_limitations),
                'confidence': 0.80,
                'recognition_method': 'systematic_analysis'
            }
            
        except Exception as e:
            logger.error(f"❌ 局限性识别失败: {e}")
            return self._generate_default_limitation_recognition()
    
    def _identify_knowledge_boundaries(self) -> List[Dict[str, Any]]:
        """识别知识边界"""
        return [
            {
                'type': 'domain_expertise',
                'description': '缺乏某些专业领域的深度知识',
                'severity': 0.6,
                'examples': ['quantum_physics', 'advanced_mathematics', 'specialized_medicine']
            },
            {
                'type': 'experiential_knowledge',
                'description': '缺乏真实世界的经验性知识',
                'severity': 0.7,
                'examples': ['physical_manipulation', 'social_interaction_nuances', 'emotional_experience']
            },
            {
                'type': 'tacit_knowledge',
                'description': '难以形式化的隐性知识',
                'severity': 0.8,
                'examples': ['intuition', 'common_sense', 'cultural_understanding']
            }
        ]
    
    def _identify_processing_limitations(self) -> List[Dict[str, Any]]:
        """识别处理局限性"""
        return [
            {
                'type': 'computational_complexity',
                'description': '复杂问题的计算复杂度限制',
                'severity': 0.5,
                'examples': ['np_hard_problems', 'real_time_processing', 'large_scale_optimization']
            },
            {
                'type': 'memory_constraints',
                'description': '工作记忆和长期记忆的限制',
                'severity': 0.6,
                'examples': ['context_window', 'long_term_retention', 'cross_session_learning']
            },
            {
                'type': 'attention_bottlenecks',
                'description': '注意力分配的限制',
                'severity': 0.4,
                'examples': ['multi_tasking', 'divided_attention', 'sustained_focus']
            }
        ]
    
    def _identify_creative_boundaries(self) -> List[Dict[str, Any]]:
        """识别创造性边界"""
        return [
            {
                'type': 'originality_limitation',
                'description': '原创性思维和真正创新的局限性',
                'severity': 0.8,
                'examples': ['breakthrough_innovation', 'paradigm_shifting', 'revolutionary_ideas']
            },
            {
                'type': 'aesthetic_understanding',
                'description': '审美理解和艺术创造力的局限',
                'severity': 0.7,
                'examples': ['artistic_creation', 'beauty_perception', 'cultural_aesthetics']
            },
            {
                'type': 'emotional_creativity',
                'description': '情感驱动的创造力局限',
                'severity': 0.6,
                'examples': ['emotional_expression', 'empathetic_creation', 'feeling_translation']
            }
        ]
    
    def _identify_social_cognitive_limits(self) -> List[Dict[str, Any]]:
        """识别社会认知限制"""
        return [
            {
                'type': 'theory_of_mind',
                'description': '心智理论和他人意图理解局限',
                'severity': 0.7,
                'examples': ['intention_recognition', 'belief_attribution', 'desire_understanding']
            },
            {
                'type': 'social_context_understanding',
                'description': '社会情境和文化背景理解局限',
                'severity': 0.6,
                'examples': ['cultural_nuances', 'social_norms', 'contextual_appropriateness']
            },
            {
                'type': 'collaborative_intelligence',
                'description': '协作智能和群体思维局限',
                'severity': 0.5,
                'examples': ['group_dynamics', 'consensus_building', 'collective_intelligence']
            }
        ]
    
    def _identify_temporal_constraints(self) -> List[Dict[str, Any]]:
        """识别时间约束"""
        return [
            {
                'type': 'real_time_processing',
                'description': '实时处理和响应时间限制',
                'severity': 0.4,
                'examples': ['immediate_response', 'real_time_adaptation', 'live_interaction']
            },
            {
                'type': 'long_term_planning',
                'description': '长期规划和目标坚持限制',
                'severity': 0.6,
                'examples': ['sustained_motivation', 'goal_consistency', 'long_range_planning']
            },
            {
                'type': 'temporal_reasoning',
                'description': '时间推理和历史理解限制',
                'severity': 0.5,
                'examples': ['historical_context', 'temporal_relationships', 'causal_chains']
            }
        ]
    
    def _assess_limitation_severity(self, limits: List[Dict[str, Any]]) -> float:
        """评估局限性严重程度"""
        if not limits:
            return 0.0
        
        severities = [limit.get('severity', 0.5) for limit in limits]
        return np.mean(severities) if severities else 0.5
    
    def _suggest_limitation_mitigation(self, critical_limitations: List[str]) -> List[Dict[str, Any]]:
        """建议局限性缓解策略"""
        mitigation_strategies = {
            'knowledge_boundaries': [
                {'strategy': 'continuous_learning', 'description': '持续学习和知识更新'},
                {'strategy': 'expert_collaboration', 'description': '与领域专家协作'},
                {'strategy': 'experiential_simulation', 'description': '通过模拟获得经验'}
            ],
            'processing_limitations': [
                {'strategy': 'computational_optimization', 'description': '计算优化和算法改进'},
                {'strategy': 'distributed_processing', 'description': '分布式处理和资源扩展'},
                {'strategy': 'approximate_methods', 'description': '使用近似和启发式方法'}
            ],
            'learning_constraints': [
                {'strategy': 'meta_learning', 'description': '元学习和学习策略优化'},
                {'strategy': 'transfer_learning', 'description': '迁移学习和知识重用'},
                {'strategy': 'regularization_techniques', 'description': '正则化技术防止遗忘'}
            ]
        }
        
        strategies = []
        for limitation in critical_limitations:
            if limitation in mitigation_strategies:
                strategies.extend(mitigation_strategies[limitation])
        
        return strategies[:5]  # 返回前5个策略
    
    def _generate_default_limitation_recognition(self) -> Dict[str, Any]:
        """生成默认局限性识别"""
        return {
            'specific_limitations': {
                'knowledge_boundaries': [{'type': 'general', 'description': '一般性知识限制', 'severity': 0.6}],
                'processing_limitations': [{'type': 'general', 'description': '一般性处理限制', 'severity': 0.6}],
                'learning_constraints': [{'type': 'general', 'description': '一般性学习限制', 'severity': 0.6}]
            },
            'severity_scores': {'knowledge_boundaries': 0.6, 'processing_limitations': 0.6, 'learning_constraints': 0.6},
            'critical_limitations': [],
            'mitigation_strategies': [{'strategy': 'general_improvement', 'description': '一般性改进'}],
            'confidence': 0.5,
            'recognition_method': 'default_fallback'
        }
    
    def _identify_learning_constraints(self) -> List[Dict[str, Any]]:
        """识别学习约束"""
        return [
            {
                'type': 'sample_efficiency',
                'description': '学习效率和小样本学习能力',
                'severity': 0.6,
                'examples': ['one_shot_learning', 'few_shot_adaptation', 'transfer_efficiency']
            },
            {
                'type': 'catastrophic_forgetting',
                'description': '灾难性遗忘问题',
                'severity': 0.7,
                'examples': ['sequential_learning', 'task_interference', 'memory_consolidation']
            },
            {
                'type': 'exploration_exploitation',
                'description': '探索与利用的平衡',
                'severity': 0.5,
                'examples': ['novelty_seekng', 'risk_taking', 'optimal_stopping']
            }
        ]
    
    def _calculate_learning_efficiency(self, processes: List[CognitiveProcessSnapshot]) -> float:
        """计算学习效率"""
        if not processes:
            return 0.7
        
        learning_processes = [p for p in processes if p.process_type == 'learning']
        if not learning_processes:
            return 0.6
        
        # 基于学习收益和效率计算
        total_gains = sum(sum(p.learning_gains) for p in learning_processes if p.learning_gains)
        avg_processing_time = np.mean([p.processing_time for p in learning_processes])
        
        # 归一化评分
        efficiency = min(1.0, (total_gains / len(learning_processes)) * (1.0 / max(avg_processing_time, 1.0)) * 10)
        return max(0.0, efficiency)
    
    def _calculate_problem_solving_ability(self, processes: List[CognitiveProcessSnapshot]) -> float:
        """计算问题解决能力"""
        if not processes:
            return 0.7
        
        reasoning_processes = [p for p in processes if p.process_type == 'reasoning']
        if not reasoning_processes:
            return 0.6
        
        # 基于输出质量和错误恢复计算
        avg_quality = np.mean([p.output_quality for p in reasoning_processes if p.output_quality])
        avg_errors = np.mean([len(p.errors_encountered) for p in reasoning_processes])
        
        # 质量评分 + 错误恢复评分
        quality_score = avg_quality if not np.isnan(avg_quality) else 0.6
        error_score = max(0.0, 1.0 - (avg_errors / 10))  # 假设10个错误为上限
        
        return (quality_score + error_score) / 2
    
    # ==================== 认知过程监控 ====================
    
    def _calculate_input_complexity(self, input_data: Dict[str, Any]) -> float:
        """计算输入复杂度"""
        try:
            # 基于数据结构和内容计算复杂度
            complexity_factors = []
            
            # 结构复杂度
            if isinstance(input_data, dict):
                complexity_factors.append(min(len(input_data) / 20, 1.0))
            
            # 语义复杂度
            text_content = str(input_data)
            if len(text_content) > 100:
                # 简单的文本复杂度指标
                unique_words = len(set(text_content.lower().split()))
                total_words = len(text_content.split())
                semantic_complexity = unique_words / max(total_words, 1)
                complexity_factors.append(semantic_complexity)
            
            return np.mean(complexity_factors) if complexity_factors else 0.5
            
        except Exception:
            return 0.5
    
    def _get_initial_resource_utilization(self) -> Dict[str, float]:
        """获取初始资源利用情况"""
        return {
            'cpu': 0.3,  # 默认CPU使用率
            'memory': 0.2,  # 默认内存使用率
            'attention': 0.4,  # 默认注意力分配
            'processing_power': 0.5  # 默认处理能力使用
        }
    
    async def monitor_cognitive_process(self, process_type: str, process_id: str, 
                                      input_data: Dict[str, Any]) -> str:
        """监控认知过程"""
        try:
            snapshot_id = f"process_{process_type}_{process_id}_{datetime.now().strftime('%H%M%S')}"
            
            snapshot = CognitiveProcessSnapshot(
                snapshot_id=snapshot_id,
                timestamp=datetime.now(),
                process_type=process_type,
                input_complexity=self._calculate_input_complexity(input_data),
                processing_time=0.0,  # 将在过程结束时更新
                resource_utilization=self._get_initial_resource_utilization(),
                intermediate_states=[],
                output_quality=0.0,
                errors_encountered=[],
                corrective_actions=[],
                learning_gains=[]
            )
            
            self.active_processes[process_id] = snapshot
            
            logger.info(f"👁️ 开始监控认知过程: {process_type} - {process_id}")
            return snapshot_id
            
        except Exception as e:
            logger.error(f"❌ 认知过程监控启动失败: {e}")
            return ""
    
    async def update_cognitive_process(self, process_id: str, update_data: Dict[str, Any]) -> bool:
        """更新认知过程状态"""
        try:
            if process_id not in self.active_processes:
                logger.warning(f"⚠️ 认知过程 {process_id} 未找到")
                return False
            
            snapshot = self.active_processes[process_id]
            
            # 更新处理时间
            if 'processing_time' in update_data:
                snapshot.processing_time = update_data['processing_time']
            
            # 更新资源利用情况
            if 'resource_utilization' in update_data:
                snapshot.resource_utilization.update(update_data['resource_utilization'])
            
            # 添加中间状态
            if 'intermediate_state' in update_data:
                snapshot.intermediate_states.append(update_data['intermediate_state'])
            
            # 记录错误
            if 'error_encountered' in update_data:
                snapshot.errors_encountered.append(update_data['error_encountered'])
            
            # 记录修正行动
            if 'corrective_action' in update_data:
                snapshot.corrective_actions.append(update_data['corrective_action'])
            
            # 记录学习收益
            if 'learning_gain' in update_data:
                snapshot.learning_gains.append(update_data['learning_gain'])
            
            logger.debug(f"📊 更新认知过程 {process_id}: {list(update_data.keys())}")
            return True
            
        except Exception as e:
            logger.error(f"❌ 认知过程更新失败: {e}")
            return False
    
    async def complete_cognitive_process(self, process_id: str, final_data: Dict[str, Any]) -> Dict[str, Any]:
        """完成认知过程监控"""
        try:
            if process_id not in self.active_processes:
                return {'error': '认知过程未找到'}
            
            snapshot = self.active_processes[process_id]
            
            # 更新最终数据
            if 'output_quality' in final_data:
                snapshot.output_quality = final_data['output_quality']
            
            if 'final_processing_time' in final_data:
                snapshot.processing_time = final_data['final_processing_time']
            
            # 移动到历史记录
            self.process_snapshots.append(snapshot)
            del self.active_processes[process_id]
            
            # 分析处理模式
            await self._analyze_processing_pattern(snapshot)
            
            # 生成元认知洞察
            insights = await self._generate_process_insights(snapshot)
            
            logger.info(f"✅ 认知过程完成: {process_id} (质量: {snapshot.output_quality:.3f})")
            
            return {
                'process_id': process_id,
                'processing_time': snapshot.processing_time,
                'output_quality': snapshot.output_quality,
                'learning_gains': snapshot.learning_gains,
                'errors_count': len(snapshot.errors_encountered),
                'insights_generated': len(insights),
                'success': True
            }
            
        except Exception as e:
            logger.error(f"❌ 认知过程完成失败: {e}")
            return {'error': str(e), 'success': False}
    
    async def _analyze_processing_pattern(self, snapshot: CognitiveProcessSnapshot):
        """分析处理模式"""
        try:
            pattern_key = f"{snapshot.process_type}_{len(snapshot.intermediate_states)}"
            
            pattern_data = {
                'input_complexity': snapshot.input_complexity,
                'processing_time': snapshot.processing_time,
                'output_quality': snapshot.output_quality,
                'error_count': len(snapshot.errors_encountered),
                'learning_gain': np.mean(snapshot.learning_gains) if snapshot.learning_gains else 0,
                'resource_efficiency': np.mean(list(snapshot.resource_utilization.values()))
            }
            
            self.processing_patterns[pattern_key].append(pattern_data)
            
            # 保持模式历史在合理范围内
            if len(self.processing_patterns[pattern_key]) > 50:
                self.processing_patterns[pattern_key] = self.processing_patterns[pattern_key][-50:]
            
        except Exception as e:
            logger.error(f"❌ 处理模式分析失败: {e}")
    
    async def _generate_process_insights(self, snapshot: CognitiveProcessSnapshot) -> List[SelfReflectionInsight]:
        """生成过程洞察"""
        insights = []
        
        try:
            # 基于错误模式生成洞察
            if snapshot.errors_encountered:
                error_insight = await self._generate_error_insight(snapshot)
                if error_insight:
                    insights.append(error_insight)
            
            # 基于性能表现生成洞察
            performance_insight = await self._generate_performance_insight(snapshot)
            if performance_insight:
                insights.append(performance_insight)
            
            # 基于学习收益生成洞察
            if snapshot.learning_gains:
                learning_insight = await self._generate_learning_insight(snapshot)
                if learning_insight:
                    insights.append(learning_insight)
            
            # 存储洞察
            for insight in insights:
                self.reflection_insights.append(insight)
                self.insight_categories[insight.reflection_type].append(insight)
            
            return insights
            
        except Exception as e:
            logger.error(f"❌ 过程洞察生成失败: {e}")
            return []
    
    async def _generate_performance_insight(self, snapshot: CognitiveProcessSnapshot) -> Optional[SelfReflectionInsight]:
        """生成性能洞察"""
        try:
            # 基于性能指标生成洞察
            if snapshot.output_quality < 0.7:  # 低质量输出
                insight_content = f"{snapshot.process_type}过程输出质量低于预期({snapshot.output_quality:.3f})"
                evidence_supporting = [
                    {'type': 'quality_metric', 'content': f"输出质量: {snapshot.output_quality}"},
                    {'type': 'processing_time', 'content': f"处理时间: {snapshot.processing_time}"}
                ]
                follow_up_actions = [
                    "优化处理算法",
                    "增强输入预处理",
                    "调整资源分配"
                ]
            elif snapshot.processing_time > 2.0:  # 处理时间过长
                insight_content = f"{snapshot.process_type}过程处理时间过长({snapshot.processing_time:.3f}s)"
                evidence_supporting = [
                    {'type': 'time_metric', 'content': f"处理时间: {snapshot.processing_time}"},
                    {'type': 'complexity_analysis', 'content': f"输入复杂度: {snapshot.input_complexity}"}
                ]
                follow_up_actions = [
                    "优化算法效率",
                    "实施并行处理",
                    "简化处理流程"
                ]
            else:
                return None  # 性能良好，无需洞察
            
            insight = SelfReflectionInsight(
                insight_id=f"performance_insight_{datetime.now().strftime('%H%M%S')}",
                reflection_type='capability_assessment',
                insight_content=insight_content,
                evidence_supporting=evidence_supporting,
                evidence_contradicting=[],
                confidence_score=0.75,
                actionability_score=0.8,
                creation_time=datetime.now(),
                follow_up_actions=follow_up_actions,
                validation_status='pending'
            )
            
            return insight
            
        except Exception as e:
            logger.error(f"❌ 性能洞察生成失败: {e}")
            return None
    
    async def _generate_learning_insight(self, snapshot: CognitiveProcessSnapshot) -> Optional[SelfReflectionInsight]:
        """生成学习洞察"""
        try:
            if not snapshot.learning_gains:
                return None
            
            avg_learning_gain = np.mean(snapshot.learning_gains)
            
            if avg_learning_gain > 0.1:  # 显著学习收益
                insight_content = f"{snapshot.process_type}过程产生了显著的学习收益({avg_learning_gain:.3f})"
                evidence_supporting = [
                    {'type': 'learning_gains', 'content': f"学习收益: {snapshot.learning_gains}"},
                    {'type': 'gain_analysis', 'content': f"平均收益: {avg_learning_gain}"}
                ]
                follow_up_actions = [
                    "总结成功经验",
                    "应用到类似任务",
                    "强化有效学习策略"
                ]
            elif avg_learning_gain < 0.01:  # 学习收益不足
                insight_content = f"{snapshot.process_type}过程学习收益不足({avg_learning_gain:.3f})"
                evidence_supporting = [
                    {'type': 'learning_gains', 'content': f"学习收益: {snapshot.learning_gains}"},
                    {'type': 'gain_analysis', 'content': f"平均收益: {avg_learning_gain}"}
                ]
                follow_up_actions = [
                    "调整学习策略",
                    "增强反馈机制",
                    "优化学习目标"
                ]
            else:
                return None  # 学习收益正常
            
            insight = SelfReflectionInsight(
                insight_id=f"learning_insight_{datetime.now().strftime('%H%M%S')}",
                reflection_type='growth_opportunity',
                insight_content=insight_content,
                evidence_supporting=evidence_supporting,
                evidence_contradicting=[],
                confidence_score=0.8,
                actionability_score=0.7,
                creation_time=datetime.now(),
                follow_up_actions=follow_up_actions,
                validation_status='pending'
            )
            
            return insight
            
        except Exception as e:
            logger.error(f"❌ 学习洞察生成失败: {e}")
            return None
    
    async def _generate_error_insight(self, snapshot: CognitiveProcessSnapshot) -> Optional[SelfReflectionInsight]:
        """生成错误洞察"""
        try:
            if not snapshot.errors_encountered:
                return None
            
            # 分析错误模式
            error_pattern = self._analyze_error_pattern(snapshot.errors_encountered)
            
            insight = SelfReflectionInsight(
                insight_id=f"error_insight_{datetime.now().strftime('%H%M%S')}",
                reflection_type='bias_detection',
                insight_content=f"在{snapshot.process_type}过程中发现重复性错误模式: {error_pattern['pattern_type']}",
                evidence_supporting=[
                    {'type': 'error_log', 'content': str(snapshot.errors_encountered)},
                    {'type': 'frequency', 'content': f"错误频率: {error_pattern['frequency']}"}
                ],
                evidence_contradicting=[],
                confidence_score=min(0.9, error_pattern['frequency'] * 0.3),
                actionability_score=0.8,
                creation_time=datetime.now(),
                follow_up_actions=[
                    f"实施错误预防机制: {error_pattern['prevention_strategy']}",
                    "加强过程监控",
                    "建立错误恢复协议"
                ],
                validation_status='pending'
            )
            
            return insight
            
        except Exception as e:
            logger.error(f"❌ 错误洞察生成失败: {e}")
            return None
    
    def _analyze_error_pattern(self, errors: List[str]) -> Dict[str, Any]:
        """分析错误模式"""
        try:
            if not errors:
                return {'pattern_type': 'none', 'frequency': 0, 'prevention_strategy': 'none'}
            
            # 简单的错误分类
            error_types = {}
            for error in errors:
                error_type = self._classify_error(error)
                error_types[error_type] = error_types.get(error_type, 0) + 1
            
            # 找出最常见的错误类型
            most_common_error = max(error_types.items(), key=lambda x: x[1]) if error_types else ('unknown', 0)
            
            prevention_strategies = {
                'input_validation': '增强输入验证和预处理',
                'resource_management': '优化资源管理和分配',
                'logic_error': '改进逻辑推理和验证机制',
                'timeout': '优化时间管理和超时处理',
                'unknown': '加强错误监控和分类'
            }
            
            return {
                'pattern_type': most_common_error[0],
                'frequency': most_common_error[1] / len(errors),
                'prevention_strategy': prevention_strategies.get(most_common_error[0], 'general_improvement')
            }
            
        except Exception:
            return {'pattern_type': 'unknown', 'frequency': 1.0, 'prevention_strategy': 'general_improvement'}
    
    def _classify_error(self, error: str) -> str:
        """分类错误"""
        error_lower = error.lower()
        
        if any(keyword in error_lower for keyword in ['input', 'validation', 'format']):
            return 'input_validation'
        elif any(keyword in error_lower for keyword in ['memory', 'resource', 'capacity']):
            return 'resource_management'
        elif any(keyword in error_lower for keyword in ['logic', 'reasoning', 'inference']):
            return 'logic_error'
        elif any(keyword in error_lower for keyword in ['timeout', 'time', 'deadline']):
            return 'timeout'
        else:
            return 'unknown'
    
    # ==================== 元学习机制 ====================
    
    async def conduct_meta_learning(self, learning_context: Dict[str, Any]) -> Dict[str, Any]:
        """执行元学习"""
        try:
            logger.info("📈 开始元学习过程...")
            
            # 1. 学习环境分析
            learning_environment = await self._analyze_learning_environment(learning_context)
            
            # 2. 策略效果评估
            strategy_evaluation = await self._evaluate_strategy_effectiveness(learning_environment)
            
            # 3. 元学习模式发现
            meta_patterns = await self._discover_meta_learning_patterns(strategy_evaluation)
            
            # 4. 适应性策略生成
            adaptive_strategies = await self._generate_adaptive_strategies(meta_patterns)
            
            # 5. 元学习验证
            validation_results = await self._validate_meta_learning(adaptive_strategies)
            
            meta_learning_result = {
                'learning_environment': learning_environment,
                'strategy_evaluation': strategy_evaluation,
                'meta_patterns_discovered': meta_patterns,
                'adaptive_strategies': adaptive_strategies,
                'validation_results': validation_results,
                'timestamp': datetime.now().isoformat(),
                'learning_improvement': validation_results.get('performance_improvement', 0.0)
            }
            
            logger.info(f"✅ 元学习完成，性能改善: {meta_learning_result['learning_improvement']:.3f}")
            return meta_learning_result
            
        except Exception as e:
            logger.error(f"❌ 元学习过程失败: {e}")
            return {'error': str(e), 'learning_improvement': 0.0}
    
    async def _analyze_learning_environment(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """分析学习环境"""
        try:
            environment_analysis = {
                'task_complexity': self._assess_task_complexity(context),
                'data_characteristics': self._analyze_data_characteristics(context),
                'performance_requirements': self._identify_performance_requirements(context),
                'resource_constraints': self._identify_resource_constraints(context),
                'time_pressure': self._assess_time_pressure(context),
                'uncertainty_level': self._assess_uncertainty(context),
                'learning_objectives': context.get('learning_objectives', []),
                'success_criteria': context.get('success_criteria', {})
            }
            
            # 计算环境复杂度
            complexity_factors = [
                environment_analysis['task_complexity'],
                environment_analysis['data_characteristics'].get('complexity_score', 0.5),
                environment_analysis['time_pressure'],
                environment_analysis['uncertainty_level']
            ]
            
            environment_analysis['overall_complexity'] = np.mean(complexity_factors)
            
            return environment_analysis
            
        except Exception as e:
            logger.error(f"❌ 学习环境分析失败: {e}")
            return {'error': str(e), 'overall_complexity': 0.5}
    
    def _assess_task_complexity(self, context: Dict[str, Any]) -> float:
        """评估任务复杂度"""
        try:
            # 基于任务特征评估复杂度
            complexity_indicators = []
            
            # 任务类型复杂度
            task_type = context.get('task_type', 'general')
            type_complexity = {
                'problem_solving': 0.8,
                'decision_making': 0.6,
                'learning': 0.7,
                'creation': 0.9,
                'analysis': 0.5,
                'general': 0.5
            }
            complexity_indicators.append(type_complexity.get(task_type, 0.5))
            
            # 学习目标复杂度
            objectives = context.get('learning_objectives', [])
            complexity_indicators.append(min(len(objectives) / 5, 1.0))
            
            # 时间压力复杂度
            time_pressure = context.get('time_pressure', 0.5)
            complexity_indicators.append(time_pressure)
            
            return np.mean(complexity_indicators) if complexity_indicators else 0.5
            
        except Exception:
            return 0.5
    
    def _analyze_data_characteristics(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """分析数据特征"""
        try:
            return {
                'data_volume': context.get('data_size', 'medium'),
                'data_quality': context.get('data_quality', 0.7),
                'data_diversity': context.get('data_diversity', 0.5),
                'complexity_score': 0.6  # 默认复杂度
            }
            
        except Exception:
            return {'complexity_score': 0.5}
    
    def _identify_performance_requirements(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """识别性能要求"""
        try:
            return {
                'accuracy_target': context.get('accuracy_target', 0.8),
                'speed_target': context.get('speed_target', 0.7),
                'efficiency_target': context.get('efficiency_target', 0.75),
                'reliability_target': context.get('reliability_target', 0.9)
            }
            
        except Exception:
            return {'accuracy_target': 0.8, 'speed_target': 0.7}
    
    def _identify_resource_constraints(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """识别资源约束"""
        try:
            return {
                'computational_budget': context.get('computational_budget', 'medium'),
                'memory_limit': context.get('memory_limit', 'standard'),
                'time_budget': context.get('time_budget', 'flexible')
            }
            
        except Exception:
            return {'computational_budget': 'medium'}
    
    def _assess_time_pressure(self, context: Dict[str, Any]) -> float:
        """评估时间压力"""
        return context.get('time_pressure', 0.5)
    
    def _assess_uncertainty(self, context: Dict[str, Any]) -> float:
        """评估不确定性"""
        return context.get('uncertainty_level', 0.5)
    
    async def _evaluate_strategy_effectiveness(self, environment: Dict[str, Any]) -> Dict[str, Any]:
        """评估策略效果"""
        try:
            strategy_performance = {}
            
            for strategy_name, strategy_config in self.learning_strategies.items():
                # 评估策略在当前环境下的适用性
                applicability = self._calculate_strategy_applicability(strategy_config, environment)
                
                # 基于历史数据评估效果
                historical_effectiveness = self._get_historical_effectiveness(strategy_name, environment)
                
                # 预测潜在效果
                predicted_effectiveness = self._predict_strategy_effectiveness(strategy_config, environment)
                
                # 计算综合效果评分
                overall_effectiveness = (
                    applicability * 0.3 + 
                    historical_effectiveness * 0.4 + 
                    predicted_effectiveness * 0.3
                )
                
                strategy_performance[strategy_name] = {
                    'applicability': applicability,
                    'historical_effectiveness': historical_effectiveness,
                    'predicted_effectiveness': predicted_effectiveness,
                    'overall_effectiveness': overall_effectiveness,
                    'recommendation_score': overall_effectiveness * applicability
                }
            
            # 排序并返回最佳策略
            sorted_strategies = sorted(
                strategy_performance.items(), 
                key=lambda x: x[1]['recommendation_score'], 
                reverse=True
            )
            
            return {
                'strategy_performance': strategy_performance,
                'recommended_strategies': [strategy[0] for strategy in sorted_strategies[:3]],
                'best_strategy': sorted_strategies[0] if sorted_strategies else None,
                'confidence': 0.85 if len(sorted_strategies) >= 3 else 0.7
            }
            
        except Exception as e:
            logger.error(f"❌ 策略效果评估失败: {e}")
            return {'error': str(e), 'recommended_strategies': [], 'confidence': 0.5}
    
    def _calculate_strategy_applicability(self, strategy_config: Dict[str, Any], 
                                        environment: Dict[str, Any]) -> float:
        """计算策略适用性"""
        try:
            applicable_contexts = strategy_config.get('applicable_contexts', [])
            environment_characteristics = [
                environment.get('task_complexity', 0.5),
                environment.get('time_pressure', 0.5),
                environment.get('uncertainty_level', 0.5)
            ]
            
            # 基于环境和策略特征计算适用性
            complexity_match = 1.0 - abs(environment.get('task_complexity', 0.5) - 0.5)
            time_pressure_match = 1.0 - abs(environment.get('time_pressure', 0.5) - 0.5)
            
            applicability = (complexity_match + time_pressure_match) / 2
            
            return max(0.0, min(1.0, applicability))
            
        except Exception:
            return 0.5  # 中性适用性
    
    def _predict_strategy_effectiveness(self, strategy_config: Dict[str, Any], environment: Dict[str, Any]) -> float:
        """预测策略效果"""
        try:
            # 基于策略特征和环境特征预测效果
            baseline_effectiveness = strategy_config.get('effectiveness_baseline', 0.7)
            
            # 环境调整因子
            complexity_factor = 1.0 - abs(environment.get('overall_complexity', 0.5) - 0.5)
            time_pressure_factor = 1.0 - environment.get('time_pressure', 0.5) * 0.3  # 时间压力负面影响
            
            # 计算预测效果
            predicted_effectiveness = baseline_effectiveness * complexity_factor * time_pressure_factor
            
            return max(0.0, min(1.0, predicted_effectiveness))
            
        except Exception:
            return strategy_config.get('effectiveness_baseline', 0.7)
    
    async def _discover_meta_learning_patterns(self, strategy_evaluation: Dict[str, Any]) -> List[Dict[str, Any]]:
        """发现元学习模式"""
        try:
            patterns = []
            
            # 基于策略评估结果发现模式
            strategy_performance = strategy_evaluation.get('strategy_performance', {})
            
            # 识别高效策略的共同特征
            high_performing_strategies = [
                name for name, perf in strategy_performance.items() 
                if perf.get('overall_effectiveness', 0) > 0.8
            ]
            
            if high_performing_strategies:
                patterns.append({
                    'pattern_id': f'high_performance_{datetime.now().strftime("%H%M%S")}',
                    'pattern_type': 'learning_strategy',
                    'context_conditions': {'effectiveness_threshold': 0.8},
                    'successful_strategies': high_performing_strategies,
                    'failed_strategies': [],
                    'effectiveness_score': 0.85,
                    'generalization_potential': 0.7,
                    'application_count': 1,
                    'success_rate': 1.0,
                    'creation_time': datetime.now(),
                    'last_applied': datetime.now()
                })
            
            # 识别策略组合模式
            if len(high_performing_strategies) >= 2:
                patterns.append({
                    'pattern_id': f'combination_{datetime.now().strftime("%H%M%S")}',
                    'pattern_type': 'strategy_combination',
                    'context_conditions': {'multiple_strategies_available': True},
                    'successful_strategies': high_performing_strategies[:2],
                    'failed_strategies': [],
                    'effectiveness_score': 0.9,
                    'generalization_potential': 0.6,
                    'application_count': 1,
                    'success_rate': 1.0,
                    'creation_time': datetime.now(),
                    'last_applied': datetime.now()
                })
            
            return patterns
            
        except Exception as e:
            logger.error(f"❌ 元学习模式发现失败: {e}")
            return []
    
    async def _generate_adaptive_strategies(self, meta_patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """生成适应性策略"""
        try:
            adaptive_strategies = []
            
            for pattern in meta_patterns:
                if pattern.get('effectiveness_score', 0) > 0.7:  # 高效果模式
                    strategy = {
                        'strategy_id': f'adaptive_{pattern["pattern_id"]}',
                        'based_on_pattern': pattern['pattern_id'],
                        'strategy_type': pattern['pattern_type'],
                        'implementation': f"应用{pattern['pattern_type']}模式",
                        'expected_benefit': pattern.get('effectiveness_score', 0.7),
                        'risk_level': 'low' if pattern.get('success_rate', 0) > 0.8 else 'medium',
                        'applicability_conditions': pattern.get('context_conditions', {})
                    }
                    adaptive_strategies.append(strategy)
            
            return adaptive_strategies
            
        except Exception as e:
            logger.error(f"❌ 适应性策略生成失败: {e}")
            return []
    
    async def _validate_meta_learning(self, adaptive_strategies: List[Dict[str, Any]]) -> Dict[str, Any]:
        """验证元学习"""
        try:
            validation_results = {
                'strategies_validated': len(adaptive_strategies),
                'expected_improvement': 0.0,
                'confidence_score': 0.7,
                'validation_method': 'simulation_based'
            }
            
            if adaptive_strategies:
                # 计算预期改善
                avg_expected_benefit = np.mean([s.get('expected_benefit', 0) for s in adaptive_strategies])
                validation_results['expected_improvement'] = avg_expected_benefit
                
                # 基于策略质量调整置信度
                strategy_quality = np.mean([s.get('expected_benefit', 0) for s in adaptive_strategies])
                validation_results['confidence_score'] = min(0.95, 0.6 + strategy_quality * 0.3)
            
            return validation_results
            
        except Exception as e:
            logger.error(f"❌ 元学习验证失败: {e}")
            return {'error': str(e), 'expected_improvement': 0.0, 'confidence_score': 0.5}
    
    def _get_historical_effectiveness(self, strategy_name: str, environment: Dict[str, Any]) -> float:
        """获取历史效果数据"""
        try:
            # 基于策略效果历史记录
            baseline_effectiveness = self.strategy_effectiveness.get(strategy_name, 
                                                                   self.learning_strategies[strategy_name].get('effectiveness_baseline', 0.7))
            
            # 根据环境复杂度调整
            complexity_factor = 1.0 - abs(environment.get('overall_complexity', 0.5) - 0.5)
            
            adjusted_effectiveness = baseline_effectiveness * (0.7 + 0.3 * complexity_factor)
            
            return max(0.0, min(1.0, adjusted_effectiveness))
            
        except Exception:
            return 0.7  # 默认效果

async def test_metacognitive_capabilities():
    """测试元认知能力"""
    # 测试函数
async def test_metacognitive_capabilities():
    """测试元认知能力"""
    print("🧠 测试元认知能力引擎...")
    
    # 创建引擎
    metacognitive_engine = MetacognitiveCapabilitiesEngine({
        'reflection_interval': 60,
        'metacognitive_threshold': 0.7,
        'self_monitoring_level': 'high'
    })
    
    # 测试自我理解
    print("\n🎯 测试自我理解能力...")
    self_understanding = await metacognitive_engine.develop_self_understanding({
        'context': 'test_environment',
        'objectives': ['assess_capabilities', 'identify_limitations']
    })
    
    print(f"✅ 自我理解完成，置信度: {self_understanding.get('confidence_score', 0):.3f}")
    print(f"✅ 整体能力评分: {self_understanding.get('capability_assessment', {}).get('overall_capability', 0):.3f}")
    
    # 测试认知过程监控
    print("\n👁️ 测试认知过程监控...")
    process_id = await metacognitive_engine.monitor_cognitive_process('reasoning', 'test_process', {
        'problem': 'logical_puzzle',
        'complexity': 0.7
    })
    
    if process_id:
        await asyncio.sleep(0.1)  # 模拟处理时间
        
        await metacognitive_engine.update_cognitive_process('test_process', {
            'intermediate_state': {'step': 1, 'progress': 0.3},
            'resource_utilization': {'cpu': 0.4, 'memory': 0.3}
        })
        
        result = await metacognitive_engine.complete_cognitive_process('test_process', {
            'output_quality': 0.85,
            'final_processing_time': 0.5,
            'learning_gains': [0.1, 0.05]
        })
        
        print(f"✅ 认知过程监控完成，质量: {result.get('output_quality', 0):.3f}")
    
    # 测试元学习
    print("\n📈 测试元学习能力...")
    meta_learning_result = await metacognitive_engine.conduct_meta_learning({
        'task_type': 'problem_solving',
        'complexity': 0.8,
        'time_pressure': 0.6,
        'learning_objectives': ['improve_speed', 'enhance_accuracy']
    })
    
    print(f"✅ 元学习完成，性能改善: {meta_learning_result.get('learning_improvement', 0):.3f}")
    print(f"✅ 推荐策略: {meta_learning_result.get('recommended_strategies', [])}")
    
    print("\n🎉 元认知能力测试完成！")
    return True

# 测试函数
async def test_metacognitive_capabilities():
    """测试元认知能力"""
    print("🧠 测试元认知能力引擎...")
    
    # 创建引擎
    metacognitive_engine = MetacognitiveCapabilitiesEngine({
        'reflection_interval': 60,
        'metacognitive_threshold': 0.7,
        'self_monitoring_level': 'high'
    })
    
    # 测试自我理解
    print("\n🎯 测试自我理解能力...")
    self_understanding = await metacognitive_engine.develop_self_understanding({
        'context': 'test_environment',
        'objectives': ['assess_capabilities', 'identify_limitations']
    })
    
    print(f"✅ 自我理解完成，置信度: {self_understanding.get('confidence_score', 0):.3f}")
    print(f"✅ 整体能力评分: {self_understanding.get('capability_assessment', {}).get('overall_capability', 0):.3f}")
    
    # 测试认知过程监控
    print("\n👁️ 测试认知过程监控...")
    process_id = await metacognitive_engine.monitor_cognitive_process('reasoning', 'test_process', {
        'problem': 'logical_puzzle',
        'complexity': 0.7
    })
    
    if process_id:
        await asyncio.sleep(0.1)  # 模拟处理时间
        
        await metacognitive_engine.update_cognitive_process('test_process', {
            'intermediate_state': {'step': 1, 'progress': 0.3},
            'resource_utilization': {'cpu': 0.4, 'memory': 0.3}
        })
        
        result = await metacognitive_engine.complete_cognitive_process('test_process', {
            'output_quality': 0.85,
            'final_processing_time': 0.5,
            'learning_gains': [0.1, 0.05]
        })
        
        print(f"✅ 认知过程监控完成，质量: {result.get('output_quality', 0):.3f}")
    
    # 测试元学习
    print("\n📈 测试元学习能力...")
    meta_learning_result = await metacognitive_engine.conduct_meta_learning({
        'task_type': 'problem_solving',
        'complexity': 0.8,
        'time_pressure': 0.6,
        'learning_objectives': ['improve_speed', 'enhance_accuracy']
    })
    
    print(f"✅ 元学习完成，性能改善: {meta_learning_result.get('learning_improvement', 0):.3f}")
    print(f"✅ 推荐策略: {meta_learning_result.get('recommended_strategies', [])}")
    
    print("\n🎉 元认知能力测试完成！")
    return True
    
    # 创建引擎
    metacognitive_engine = MetacognitiveCapabilitiesEngine({
        'reflection_interval': 60,
        'metacognitive_threshold': 0.7,
        'self_monitoring_level': 'high'
    })
    
    # 测试自我理解
    print("\n🎯 测试自我理解能力...")
    self_understanding = await metacognitive_engine.develop_self_understanding({
        'context': 'test_environment',
        'objectives': ['assess_capabilities', 'identify_limitations']
    })
    
    print(f"✅ 自我理解完成，置信度: {self_understanding.get('confidence_score', 0):.3f}")
    print(f"✅ 整体能力评分: {self_understanding.get('capability_assessment', {}).get('overall_capability', 0):.3f}")
    
    # 测试认知过程监控
    print("\n👁️ 测试认知过程监控...")
    process_id = await metacognitive_engine.monitor_cognitive_process('reasoning', 'test_process', {
        'problem': 'logical_puzzle',
        'complexity': 0.7
    })
    
    if process_id:
        await asyncio.sleep(0.1)  # 模拟处理时间
        
        await metacognitive_engine.update_cognitive_process('test_process', {
            'intermediate_state': {'step': 1, 'progress': 0.3},
            'resource_utilization': {'cpu': 0.4, 'memory': 0.3}
        })
        
        result = await metacognitive_engine.complete_cognitive_process('test_process', {
            'output_quality': 0.85,
            'final_processing_time': 0.5,
            'learning_gains': [0.1, 0.05]
        })
        
        print(f"✅ 认知过程监控完成，质量: {result.get('output_quality', 0):.3f}")
    
    # 测试元学习
    print("\n📈 测试元学习能力...")
    meta_learning_result = await metacognitive_engine.conduct_meta_learning({
        'task_type': 'problem_solving',
        'complexity': 0.8,
        'time_pressure': 0.6,
        'learning_objectives': ['improve_speed', 'enhance_accuracy']
    })
    
    print(f"✅ 元学习完成，性能改善: {meta_learning_result.get('learning_improvement', 0):.3f}")
    print(f"✅ 推荐策略: {meta_learning_result.get('recommended_strategies', [])}")
    
    print("\n🎉 元认知能力测试完成！")
    return True

if __name__ == "__main__":
    success = asyncio.run(test_metacognitive_capabilities())
    exit(0 if success else 1)