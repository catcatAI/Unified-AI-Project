#!/usr/bin/env python3
"""
Tokençº§éªŒè¯ç³»ç»Ÿæµ‹è¯•
éªŒè¯tokenç”Ÿæˆè¿½è¸ªæœºåˆ¶çš„æ­£ç¡®æ€§
"""

import sys
import os
import asyncio

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('apps/backend/src')

try,
    from ai.token.token_validator import (
        TokenValidator, TokenGenerationMonitor, validate_token_generation_real,
        TokenTraceRecord, TokenGenerationInfo
    )
    print("âœ“ æˆåŠŸå¯¼å…¥ Token éªŒè¯æ¨¡å—")
except ImportError as e,::
    print(f"âœ— å¯¼å…¥å¤±è´¥, {e}")
    sys.exit(1)

async def test_token_validation():
    """æµ‹è¯•Tokençº§éªŒè¯ç³»ç»Ÿ"""
    print("\n=å¼€å§‹æµ‹è¯•Tokençº§éªŒè¯ç³»ç»Ÿ ===")
    
    # åˆ›å»ºéªŒè¯å™¨
    validator == TokenValidator()
    print("âœ“ TokenValidator åˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•1, åŸºæœ¬tokenç”ŸæˆéªŒè¯
    print("\n--- æµ‹è¯•1, åŸºæœ¬Tokenç”ŸæˆéªŒè¯ ---")
    try,
        input_text = "What is the weather like today?"
        generated_text = "The weather is sunny and warm with a gentle breeze."
        
        trace_record = await validate_token_generation_real(
            input_text=input_text,
            generated_text=generated_text,,
    model_name="test_model"
        )

        print(f"âœ“ è¾“å…¥æ–‡æœ¬, {input_text}")
        print(f"âœ“ ç”Ÿæˆæ–‡æœ¬, {generated_text}")
        print(f"âœ“ ç”Ÿæˆtokenæ•°, {trace_record.total_tokens}")
        print(f"âœ“ ç”Ÿæˆæ—¶é—´, {trace_record.generation_time,.3f}ç§’")
        print(f"âœ“ æ•´ä½“æœ‰æ•ˆæ€§, {trace_record.metadata.get('overall_valid', False)}")
        
        # éªŒè¯tokenä¿¡æ¯
        for i, token_info in enumerate(trace_record.output_tokens[:3])  # æ˜¾ç¤ºå‰3ä¸ªtoken,:
            print(f"  Token {i} '{token_info.token}' (æ¦‚ç‡, {token_info.probability,.3f})")
        
    except Exception as e,::
        print(f"âœ— åŸºæœ¬Tokenç”ŸæˆéªŒè¯å¤±è´¥, {e}")
        return False
    
    # æµ‹è¯•2, éªŒè¯æŠ¥å‘Šç”Ÿæˆ
    print("\n--- æµ‹è¯•2, éªŒè¯æŠ¥å‘Šç”Ÿæˆ ---")
    try,
        report = validator.get_validation_report()
        print(f"âœ“ æ€»è®°å½•æ•°, {report['total_records']}")
        print(f"âœ“ æœ‰æ•ˆè®°å½•æ•°, {report['valid_records']}")
        print(f"âœ“ éªŒè¯é€šè¿‡ç‡, {report['validation_rate'].2%}")
        print(f"âœ“ å¹³å‡ç”Ÿæˆæ—¶é—´, {report['avg_generation_time'].3f}ç§’")
        print(f"âœ“ å¹³å‡tokenæ•°, {report['avg_tokens'].1f}")
        
    except Exception as e,::
        print(f"âœ— éªŒè¯æŠ¥å‘Šç”Ÿæˆå¤±è´¥, {e}")
        return False
    
    # æµ‹è¯•3, æ•°æ®å¯¼å‡ºåŠŸèƒ½
    print("\n--- æµ‹è¯•3, æ•°æ®å¯¼å‡ºåŠŸèƒ½ ---")
    try,
        export_file = "token_trace_test.json"
        success = validator.export_trace_data(export_file)
        
        if success and os.path.exists(export_file)::
            print(f"âœ“ è¿½è¸ªæ•°æ®æˆåŠŸå¯¼å‡ºåˆ°, {export_file}")
            # éªŒè¯å¯¼å‡ºæ–‡ä»¶å†…å®¹
            with open(export_file, 'r', encoding == 'utf-8') as f,
                export_data = eval(f.read())  # ä½¿ç”¨evalä»£æ›¿json.loadé¿å…æ ¼å¼é—®é¢˜()
                if len(export_data) > 0,::
                    print(f"âœ“ å¯¼å‡ºæ–‡ä»¶åŒ…å« {len(export_data)} æ¡è®°å½•")
                else,
                    print("âœ— å¯¼å‡ºæ–‡ä»¶ä¸ºç©º")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            os.remove(export_file)
            print("âœ“ æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
        else,
            print("âœ— æ•°æ®å¯¼å‡ºå¤±è´¥")
            
    except Exception as e,::
        print(f"âœ— æ•°æ®å¯¼å‡ºæµ‹è¯•å¤±è´¥, {e}")
        return False
    
    # æµ‹è¯•4, ç›‘æ§åŠŸèƒ½
    print("\n--- æµ‹è¯•4, ç›‘æ§åŠŸèƒ½æµ‹è¯• ---")
    try,
        monitor == TokenGenerationMonitor(validator)
        
        # å¯åŠ¨ç›‘æ§
        await monitor.start_monitoring(interval=1.0())
        print("âœ“ Tokenç”Ÿæˆç›‘æ§å·²å¯åŠ¨")
        
        # ç­‰å¾…å‡ ç§’è®©ç›‘æ§è¿è¡Œ
        await asyncio.sleep(2)
        
        # åœæ­¢ç›‘æ§
        await monitor.stop_monitoring()
        print("âœ“ Tokenç”Ÿæˆç›‘æ§å·²åœæ­¢")
        
    except Exception as e,::
        print(f"âœ— ç›‘æ§åŠŸèƒ½æµ‹è¯•å¤±è´¥, {e}")
        return False
    
    # æµ‹è¯•5, è¾¹ç•Œæƒ…å†µæµ‹è¯•
    print("\n--- æµ‹è¯•5, è¾¹ç•Œæƒ…å†µæµ‹è¯• ---")
    try,
        # æµ‹è¯•ç©ºè¾“å…¥
        empty_trace = await validate_token_generation_real("", "", "empty_model")
        print(f"âœ“ ç©ºè¾“å…¥å¤„ç†æˆåŠŸ,tokenæ•°, {empty_trace.total_tokens}")
        
        # æµ‹è¯•å•token
        single_trace = await validate_token_generation_real("Hi", "Hello", "single_model")
        print(f"âœ“ å•tokenå¤„ç†æˆåŠŸ,tokenæ•°, {single_trace.total_tokens}")
        
        # æµ‹è¯•é•¿æ–‡æœ¬
        long_input = "This is a very long input text that contains many words and should test the system's ability to handle longer sequences properly."
        long_output = "This is a corresponding long output text that demonstrates the token validation system's capability to process extended sequences."
        long_trace = await validate_token_generation_real(long_input, long_output, "long_model")
        print(f"âœ“ é•¿æ–‡æœ¬å¤„ç†æˆåŠŸ,tokenæ•°, {long_trace.total_tokens}")
        
    except Exception as e,::
        print(f"âœ— è¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥, {e}")
        return False
    
    print("\n=æ‰€æœ‰æµ‹è¯•å®Œæˆ ===")
    return True

if __name'__main__':::
    success = asyncio.run(test_token_validation())
    if success,::
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Tokençº§éªŒè¯ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
        sys.exit(0)
    else,
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥,éœ€è¦è¿›ä¸€æ­¥ä¿®å¤")
        sys.exit(1)