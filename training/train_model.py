#!/usr/bin/env python3
"""
Unified AI Project - æ¨¡å‹è®­ç»ƒè„šæœ¬
æ”¯æŒä½¿ç”¨é¢„è®¾é…ç½®è¿›è¡Œè®­ç»ƒ
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
backend_path = project_root / "apps" / "backend"
sys.path.insert(0, str(backend_path))
sys.path.insert(0, str(backend_path / "src"))

# å¯¼å…¥è·¯å¾„é…ç½®æ¨¡å—
try:
    from src.path_config import (
        PROJECT_ROOT, 
        DATA_DIR, 
        TRAINING_DIR, 
        MODELS_DIR, 
        CHECKPOINTS_DIR, 
        get_data_path, 
        get_training_config_path, 
        resolve_path
    )
except ImportError:
    # å¦‚æœè·¯å¾„é…ç½®æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„å¤„ç†
    PROJECT_ROOT = project_root
    DATA_DIR = PROJECT_ROOT / "data"
    TRAINING_DIR = PROJECT_ROOT / "training"
    MODELS_DIR = TRAINING_DIR / "models"
    CHECKPOINTS_DIR = TRAINING_DIR / "checkpoints"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, config_path=None, preset_path=None):
        self.project_root = PROJECT_ROOT
        self.training_dir = TRAINING_DIR
        self.data_dir = DATA_DIR
        self.config_path = config_path or get_training_config_path("training_config.json")
        self.preset_path = preset_path or get_training_config_path("training_preset.json")
        self.config = {}
        self.preset = {}
        
        # åŠ è½½é…ç½®
        self.load_config()
        self.load_preset()
    
    def load_config(self):
        """åŠ è½½è®­ç»ƒé…ç½®"""
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
                logger.info(f"âœ… åŠ è½½è®­ç»ƒé…ç½®: {self.config_path}")
            except Exception as e:
                logger.error(f"âŒ åŠ è½½è®­ç»ƒé…ç½®å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ è®­ç»ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
    
    def load_preset(self):
        """åŠ è½½é¢„è®¾é…ç½®"""
        if self.preset_path.exists():
            try:
                with open(self.preset_path, 'r', encoding='utf-8') as f:
                    self.preset = json.load(f)
                logger.info(f"âœ… åŠ è½½é¢„è®¾é…ç½®: {self.preset_path}")
            except Exception as e:
                logger.error(f"âŒ åŠ è½½é¢„è®¾é…ç½®å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ é¢„è®¾é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.preset_path}")
    
    def resolve_data_path(self, path_str):
        """è§£ææ•°æ®è·¯å¾„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„"""
        return resolve_path(path_str)
    
    def get_preset_scenario(self, scenario_name):
        """è·å–é¢„è®¾åœºæ™¯é…ç½®"""
        if not self.preset:
            logger.error("âŒ é¢„è®¾é…ç½®æœªåŠ è½½")
            return None
            
        scenarios = self.preset.get('training_scenarios', {})
        scenario = scenarios.get(scenario_name)
        
        if not scenario:
            logger.error(f"âŒ æœªæ‰¾åˆ°é¢„è®¾åœºæ™¯: {scenario_name}")
            return None
            
        logger.info(f"âœ… ä½¿ç”¨é¢„è®¾åœºæ™¯: {scenario_name}")
        logger.info(f"ğŸ“ åœºæ™¯æè¿°: {scenario.get('description', 'æ— æè¿°')}")
        return scenario
    
    def train_with_preset(self, scenario_name):
        """ä½¿ç”¨é¢„è®¾é…ç½®è¿›è¡Œè®­ç»ƒ"""
        logger.info(f"ğŸš€ å¼€å§‹ä½¿ç”¨é¢„è®¾é…ç½®è®­ç»ƒ: {scenario_name}")
        
        scenario = self.get_preset_scenario(scenario_name)
        if not scenario:
            return False
        
        # æ˜¾ç¤ºè®­ç»ƒå‚æ•°
        logger.info("ğŸ“Š è®­ç»ƒå‚æ•°:")
        logger.info(f"  æ•°æ®é›†: {', '.join(scenario.get('datasets', []))}")
        logger.info(f"  è®­ç»ƒè½®æ•°: {scenario.get('epochs', 10)}")
        logger.info(f"  æ‰¹æ¬¡å¤§å°: {scenario.get('batch_size', 16)}")
        logger.info(f"  ç›®æ ‡æ¨¡å‹: {', '.join(scenario.get('target_models', []))}")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)
        MODELS_DIR.mkdir(parents=True, exist_ok=True)
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        logger.info("ğŸ”„ å¼€å§‹è®­ç»ƒè¿‡ç¨‹...")
        epochs = scenario.get('epochs', 10)
        
        for epoch in range(1, epochs + 1):
            # æ¨¡æ‹Ÿè®­ç»ƒè¿›åº¦
            progress = (epoch / epochs) * 100
            logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}%")
            
            # æ¨¡æ‹Ÿä¿å­˜æ£€æŸ¥ç‚¹
            if epoch % 5 == 0 or epoch == epochs:
                checkpoint_path = CHECKPOINTS_DIR / f"epoch_{epoch}.ckpt"
                # åˆ›å»ºä¸€ä¸ªç©ºçš„æ£€æŸ¥ç‚¹æ–‡ä»¶ä½œä¸ºç¤ºä¾‹
                with open(checkpoint_path, 'w') as f:
                    f.write(f"Checkpoint for epoch {epoch}\n")
                logger.info(f"  ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path.name}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        model_filename = f"{scenario_name}_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
        model_path = MODELS_DIR / model_filename
        # åˆ›å»ºä¸€ä¸ªç©ºçš„æ¨¡å‹æ–‡ä»¶ä½œä¸ºç¤ºä¾‹
        with open(model_path, 'w') as f:
            f.write(f"Model trained with preset: {scenario_name}\n")
            f.write(f"Epochs: {epochs}\n")
            f.write(f"Batch size: {scenario.get('batch_size', 16)}\n")
        logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
        
        # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
        self.generate_training_report(scenario_name, scenario)
        
        return True
    
    def train_with_default_config(self):
        """ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œè®­ç»ƒ"""
        logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ")
        
        if not self.config:
            logger.error("âŒ æœªæ‰¾åˆ°è®­ç»ƒé…ç½®")
            return False
        
        # æ˜¾ç¤ºè®­ç»ƒå‚æ•°
        training_config = self.config.get('training', {})
        logger.info("ğŸ“Š è®­ç»ƒå‚æ•°:")
        logger.info(f"  æ‰¹æ¬¡å¤§å°: {training_config.get('batch_size', 16)}")
        logger.info(f"  è®­ç»ƒè½®æ•°: {training_config.get('epochs', 10)}")
        logger.info(f"  å­¦ä¹ ç‡: {training_config.get('learning_rate', 0.001)}")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)
        MODELS_DIR.mkdir(parents=True, exist_ok=True)
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        epochs = training_config.get('epochs', 10)
        for epoch in range(1, epochs + 1):
            progress = (epoch / epochs) * 100
            logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}%")
            
            if epoch % 5 == 0 or epoch == epochs:
                checkpoint_path = CHECKPOINTS_DIR / f"epoch_{epoch}.ckpt"
                # åˆ›å»ºä¸€ä¸ªç©ºçš„æ£€æŸ¥ç‚¹æ–‡ä»¶ä½œä¸ºç¤ºä¾‹
                with open(checkpoint_path, 'w') as f:
                    f.write(f"Checkpoint for epoch {epoch}\n")
                logger.info(f"  ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path.name}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        model_filename = f"default_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
        model_path = MODELS_DIR / model_filename
        # åˆ›å»ºä¸€ä¸ªç©ºçš„æ¨¡å‹æ–‡ä»¶ä½œä¸ºç¤ºä¾‹
        with open(model_path, 'w') as f:
            f.write("Model trained with default config\n")
            f.write(f"Epochs: {epochs}\n")
            f.write(f"Batch size: {training_config.get('batch_size', 16)}\n")
        logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
        
        return True
    
    def generate_training_report(self, scenario_name, scenario):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        report = f"""# è®­ç»ƒæŠ¥å‘Š

## è®­ç»ƒä¿¡æ¯
- è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ä½¿ç”¨åœºæ™¯: {scenario_name}
- åœºæ™¯æè¿°: {scenario.get('description', 'æ— æè¿°')}

## è®­ç»ƒå‚æ•°
- æ•°æ®é›†: {', '.join(scenario.get('datasets', []))}
- è®­ç»ƒè½®æ•°: {scenario.get('epochs', 10)}
- æ‰¹æ¬¡å¤§å°: {scenario.get('batch_size', 16)}
- ç›®æ ‡æ¨¡å‹: {', '.join(scenario.get('target_models', []))}

## æ•°æ®é›†çŠ¶æ€
"""
        
        # æ·»åŠ æ•°æ®é›†ä¿¡æ¯
        data_config_path = DATA_DIR / "data_config.json"
        if data_config_path.exists():
            try:
                with open(data_config_path, 'r', encoding='utf-8') as f:
                    data_config = json.load(f)
                total_samples = data_config.get('total_samples', {})
                for data_type, count in total_samples.items():
                    report += f"- {data_type}: {count} ä¸ªæ ·æœ¬\n"
            except Exception as e:
                logger.error(f"âŒ è¯»å–æ•°æ®é…ç½®å¤±è´¥: {e}")
        
        report += f"""
## è®­ç»ƒç»“æœ
- æœ€ç»ˆæ¨¡å‹: å·²ä¿å­˜
- æ£€æŸ¥ç‚¹: å·²ä¿å­˜
- è®­ç»ƒçŠ¶æ€: å®Œæˆ

## ä¸‹ä¸€æ­¥å»ºè®®
1. è¯„ä¼°æ¨¡å‹æ€§èƒ½
2. æ ¹æ®éœ€è¦è°ƒæ•´è¶…å‚æ•°
3. ä½¿ç”¨æ›´å¤šæ•°æ®è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒ
"""
        
        report_path = self.training_dir / "reports" / f"training_report_{scenario_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“„ è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Unified AI Project æ¨¡å‹è®­ç»ƒè„šæœ¬')
    parser.add_argument('--preset', type=str, help='ä½¿ç”¨é¢„è®¾é…ç½®è¿›è¡Œè®­ç»ƒ (quick_start, comprehensive_training, vision_focus, audio_focus)')
    parser.add_argument('--config', type=str, help='æŒ‡å®šè®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--preset-config', type=str, help='æŒ‡å®šé¢„è®¾é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    print("ğŸš€ Unified-AI-Project æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = ModelTrainer(
        config_path=args.config,
        preset_path=args.preset_config
    )
    
    # æ ¹æ®å‚æ•°å†³å®šè®­ç»ƒæ–¹å¼
    if args.preset:
        # ä½¿ç”¨é¢„è®¾é…ç½®è®­ç»ƒ
        success = trainer.train_with_preset(args.preset)
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
        success = trainer.train_with_default_config()
    
    if success:
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print("è¯·æŸ¥çœ‹è®­ç»ƒç›®å½•ä¸­çš„æ¨¡å‹å’ŒæŠ¥å‘Šæ–‡ä»¶")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ä¿¡æ¯")
        sys.exit(1)

if __name__ == "__main__":
    main()