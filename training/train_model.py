#!/usr/bin/env python3
"""
æ¨¡å‹è®­ç»ƒè„šæœ¬
æ”¯æŒå¤šç§é¢„è®¾è®­ç»ƒåœºæ™¯å’Œåä½œå¼è®­ç»ƒ
"""

import os
import sys
import shutil
from pathlib import Path
from datetime import datetime
import json
import time
import random

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from training.error_handling_framework import ErrorHandler, ErrorContext, global_error_handler
from training.enhanced_checkpoint_manager import EnhancedCheckpointManager, global_checkpoint_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(TRAINING_DIR / 'training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å®šä¹‰é¡¹ç›®ç›®å½•
PROJECT_ROOT = project_root
DATA_DIR = PROJECT_ROOT / "data"
TRAINING_DIR = PROJECT_ROOT / "training"
MODELS_DIR = TRAINING_DIR / "models"
CHECKPOINTS_DIR = TRAINING_DIR / "checkpoints"

class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, project_root: str = ".", config_path: str = None, preset_path: str = None):
        self.project_root = Path(project_root)
        self.training_dir = TRAINING_DIR
        self.data_dir = DATA_DIR
        # ä½¿ç”¨è®­ç»ƒç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶
        default_config_path = TRAINING_DIR / "configs" / "training_config.json"
        default_preset_path = TRAINING_DIR / "configs" / "training_preset.json"
        self.config_path = Path(config_path) if config_path else default_config_path
        self.preset_path = Path(preset_path) if preset_path else default_preset_path
        self.config = {}
        self.preset = {}
        self.checkpoint_file = None
        self.is_paused = False
        self.tensorflow_available = self._check_tensorflow_availability()
        self.gpu_available = self._check_gpu_availability()
        self.distributed_training_enabled = False
        self.error_handler = global_error_handler  # é”™è¯¯å¤„ç†å™¨
        self.checkpoint_manager = global_checkpoint_manager  # å¢å¼ºçš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨
        
        # åŠ è½½é…ç½®
        self.load_config()
        self.load_preset()
    
    def _check_tensorflow_availability(self):
        """æ£€æŸ¥TensorFlowæ˜¯å¦å¯ç”¨"""
        context = ErrorContext("ModelTrainer", "_check_tensorflow_availability")
        try:
            import tensorflow as tf
            logger.info("âœ… TensorFlowå¯ç”¨")
            return True
        except ImportError:
            self.error_handler.handle_error(Exception("TensorFlow not available"), context, ErrorRecoveryStrategy.FALLBACK)
            logger.warning("âš ï¸ TensorFlowä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ")
            return False
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.warning(f"âš ï¸ æ£€æŸ¥TensorFlowå¯ç”¨æ€§æ—¶å‡ºé”™: {e}")
            return False
    
    def _check_gpu_availability(self):
        """æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨"""
        context = ErrorContext("ModelTrainer", "_check_gpu_availability")
        try:
            import tensorflow as tf
            
            # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„TensorFlow
            gpus = []
            if hasattr(tf, 'config'):
                if hasattr(tf.config, 'list_physical_devices'):
                    gpus = tf.config.list_physical_devices('GPU')
                elif hasattr(tf.config, 'experimental') and hasattr(tf.config.experimental, 'list_physical_devices'):
                    gpus = tf.config.experimental.list_physical_devices('GPU')
            elif hasattr(tf, 'test') and hasattr(tf.test, 'is_gpu_available'):
                # æ›´è€ç‰ˆæœ¬çš„TensorFlow
                return tf.test.is_gpu_available()
            
            # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°GPU
            if gpus:
                logger.info(f"âœ… GPUå¯ç”¨: {len(gpus)} ä¸ªè®¾å¤‡")
                return True
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯é›†æˆæ˜¾å¡ç¯å¢ƒ
                # åœ¨é›†æˆæ˜¾å¡ä¸Šï¼ŒTensorFlowå¯èƒ½ä¸ä¼šè‡ªåŠ¨æ£€æµ‹åˆ°GPUï¼Œä½†æˆ‘ä»¬ä»ç„¶å¯ä»¥å°è¯•ä½¿ç”¨å®ƒ
                try:
                    # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æœ‰GPUè®¾å¤‡ï¼ˆå³ä½¿TensorFlowæ²¡æœ‰æ£€æµ‹åˆ°ï¼‰
                    import platform
                    system = platform.system().lower()
                    
                    if system == "windows":
                        # Windowsç³»ç»Ÿä½¿ç”¨WMIæ£€æŸ¥
                        import subprocess
                        import json
                        
                        result = subprocess.run([
                            "powershell.exe", 
                            "Get-WmiObject -Class Win32_VideoController | Select-Object Name, AdapterRAM | ConvertTo-Json"
                        ], capture_output=True, text=True, timeout=10)
                        
                        if result.returncode == 0 and result.stdout.strip():
                            gpu_data = json.loads(result.stdout)
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰GPUè®¾å¤‡
                            if isinstance(gpu_data, list) and len(gpu_data) > 0:
                                # æœ‰GPUè®¾å¤‡ï¼Œå³ä½¿TensorFlowæ²¡æœ‰æ£€æµ‹åˆ°ï¼Œä¹Ÿè®¤ä¸ºGPU"å¯ç”¨"ï¼ˆå¯ä»¥å°è¯•ä½¿ç”¨ï¼‰
                                logger.info("â„¹ï¸  æ£€æµ‹åˆ°ç³»ç»ŸGPUè®¾å¤‡ï¼Œä½†TensorFlowæœªè¯†åˆ«ï¼Œå°†å°è¯•ä½¿ç”¨CPUè®­ç»ƒ")
                                return False  # TensorFlowæ— æ³•ä½¿ç”¨GPU
                            elif isinstance(gpu_data, dict):
                                logger.info("â„¹ï¸  æ£€æµ‹åˆ°ç³»ç»ŸGPUè®¾å¤‡ï¼Œä½†TensorFlowæœªè¯†åˆ«ï¼Œå°†å°è¯•ä½¿ç”¨CPUè®­ç»ƒ")
                                return False  # TensorFlowæ— æ³•ä½¿ç”¨GPU
                    
                    # å¦‚æœæ— æ³•ç¡®å®šæˆ–æ²¡æœ‰æ£€æµ‹åˆ°GPUè®¾å¤‡
                    logger.info("â„¹ï¸ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
                    return False
                except Exception as e:
                    logger.info(f"â„¹ï¸ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡æˆ–æ— æ³•ç¡®å®šGPUçŠ¶æ€: {e}ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
                    return False
        except ImportError:
            self.error_handler.handle_error(Exception("TensorFlow not available"), context, ErrorRecoveryStrategy.FALLBACK)
            logger.warning("âš ï¸ TensorFlowä¸å¯ç”¨ï¼Œæ— æ³•æ£€æµ‹GPU")
            return False
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.warning(f"âš ï¸ æ£€æµ‹GPUæ—¶å‡ºé”™: {e}")
            return False
    
    def _setup_distributed_training(self):
        """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
        context = ErrorContext("ModelTrainer", "_setup_distributed_training")
        try:
            import tensorflow as tf
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šGPU
            gpus = tf.config.list_physical_devices('GPU')
            if len(gpus) > 1:
                logger.info(f"ğŸ”„ è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼Œä½¿ç”¨ {len(gpus)} ä¸ªGPU")
                
                # åˆ›å»ºåˆ†å¸ƒå¼ç­–ç•¥
                strategy = tf.distribute.MirroredStrategy()
                logger.info(f"âœ… åˆ†å¸ƒå¼ç­–ç•¥åˆ›å»ºæˆåŠŸ: {strategy.num_replicas_in_sync} ä¸ªå‰¯æœ¬")
                
                self.distributed_training_enabled = True
                return strategy
            elif len(gpus) == 1:
                logger.info("ğŸ”„ è®¾ç½®å•GPUè®­ç»ƒç¯å¢ƒ")
                # è®¾ç½®GPUå†…å­˜å¢é•¿
                tf.config.experimental.set_memory_growth(gpus[0], True)
                self.distributed_training_enabled = True
                return None
            else:
                logger.info("â„¹ï¸ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
                self.distributed_training_enabled = False
                return None
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.error(f"âŒ è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒæ—¶å‡ºé”™: {e}")
            self.distributed_training_enabled = False
            return None
    
    def _configure_gpu_memory(self):
        """é…ç½®GPUå†…å­˜ä½¿ç”¨"""
        context = ErrorContext("ModelTrainer", "_configure_gpu_memory")
        try:
            import tensorflow as tf
            gpus = tf.config.list_physical_devices('GPU')
            
            if gpus:
                # è®¾ç½®GPUå†…å­˜å¢é•¿
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                
                logger.info(f"âœ… GPUå†…å­˜é…ç½®å®Œæˆ: {len(gpus)} ä¸ªè®¾å¤‡")
                return True
            else:
                logger.info("â„¹ï¸ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡")
                return False
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.error(f"âŒ é…ç½®GPUå†…å­˜æ—¶å‡ºé”™: {e}")
            return False
    
    def load_config(self):
        """åŠ è½½è®­ç»ƒé…ç½®"""
        context = ErrorContext("ModelTrainer", "load_config")
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
                logger.info(f"âœ… åŠ è½½è®­ç»ƒé…ç½®: {self.config_path}")
            except Exception as e:
                self.error_handler.handle_error(e, context)
                logger.error(f"âŒ åŠ è½½è®­ç»ƒé…ç½®å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ è®­ç»ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
    
    def load_preset(self):
        """åŠ è½½é¢„è®¾é…ç½®"""
        context = ErrorContext("ModelTrainer", "load_preset")
        if self.preset_path.exists():
            try:
                with open(self.preset_path, 'r', encoding='utf-8') as f:
                    self.preset = json.load(f)
                logger.info(f"âœ… åŠ è½½é¢„è®¾é…ç½®: {self.preset_path}")
            except Exception as e:
                self.error_handler.handle_error(e, context)
                logger.error(f"âŒ åŠ è½½é¢„è®¾é…ç½®å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ é¢„è®¾é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.preset_path}")
    
    def resolve_data_path(self, path_str):
        """è§£ææ•°æ®è·¯å¾„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„"""
        context = ErrorContext("ModelTrainer", "resolve_data_path")
        try:
            return resolve_path(path_str)
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.error(f"âŒ è§£ææ•°æ®è·¯å¾„å¤±è´¥: {path_str} - {e}")
            return None
    
    def get_preset_scenario(self, scenario_name):
        """è·å–é¢„è®¾åœºæ™¯é…ç½®"""
        context = ErrorContext("ModelTrainer", "get_preset_scenario", {"scenario_name": scenario_name})
        try:
            if not self.preset:
                logger.error("âŒ é¢„è®¾é…ç½®æœªåŠ è½½")
                return None
                
            scenarios = self.preset.get('training_scenarios', {})
            scenario = scenarios.get(scenario_name)
            
            if not scenario:
                logger.error(f"âŒ æœªæ‰¾åˆ°é¢„è®¾åœºæ™¯: {scenario_name}")
                return None
                
            logger.info(f"âœ… ä½¿ç”¨é¢„è®¾åœºæ™¯: {scenario_name}")
            logger.info(f"ğŸ“ åœºæ™¯æè¿°: {scenario.get('description', 'æ— æè¿°')}")
            return scenario
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.error(f"âŒ è·å–é¢„è®¾åœºæ™¯å¤±è´¥: {scenario_name} - {e}")
            return None
    
    def check_disk_space(self, min_space_gb=5):
        """æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³"""
        context = ErrorContext("ModelTrainer", "check_disk_space")
        try:
            disk_usage = shutil.disk_usage(str(self.project_root))
            free_space_gb = disk_usage.free / (1024**3)
            
            if free_space_gb < min_space_gb:
                logger.warning(f"âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³: å‰©ä½™ {free_space_gb:.2f} GB, æœ€å°‘éœ€è¦ {min_space_gb} GB")
                return False
            else:
                logger.info(f"âœ… ç£ç›˜ç©ºé—´å……è¶³: å‰©ä½™ {free_space_gb:.2f} GB")
                return True
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.error(f"âŒ æ£€æŸ¥ç£ç›˜ç©ºé—´å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶å‡è®¾ç©ºé—´å……è¶³
    
    def save_checkpoint(self, epoch, model_state=None):
        """ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰"""
        context = ErrorContext("ModelTrainer", "save_checkpoint", {"epoch": epoch})
        try:
            # å‡†å¤‡æ£€æŸ¥ç‚¹çŠ¶æ€
            checkpoint_state = {
                "epoch": epoch,
                "timestamp": datetime.now().isoformat(),
                "model_state": model_state if model_state else {},
                "metrics": {},  # å¦‚æœæœ‰çš„è¯ï¼Œå¯ä»¥æ·»åŠ å½“å‰çš„è®­ç»ƒæŒ‡æ ‡
                "config": {
                    "batch_size": 16,  # é»˜è®¤å€¼ï¼Œå®é™…åº”è¯¥ä»é…ç½®ä¸­è·å–
                    "learning_rate": 0.001  # é»˜è®¤å€¼ï¼Œå®é™…åº”è¯¥ä»é…ç½®ä¸­è·å–
                }
            }
            
            # ä½¿ç”¨å¢å¼ºçš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint_id = self.checkpoint_manager.save_checkpoint(checkpoint_state, "main_training", "epoch")
            
            if checkpoint_id:
                checkpoint_path = CHECKPOINTS_DIR / f"epoch_{epoch}_checkpoint.json"
                self.checkpoint_file = checkpoint_path
                logger.info(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path.name}")
                return True
            else:
                logger.error("âŒ ä½¿ç”¨å¢å¼ºæ£€æŸ¥ç‚¹ç®¡ç†å™¨ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥")
                return False
                
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.error(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return False

    def load_checkpoint(self, checkpoint_path=None):
        """åŠ è½½è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰"""
        context = ErrorContext("ModelTrainer", "load_checkpoint")
        try:
            # ä½¿ç”¨å¢å¼ºçš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨åŠ è½½æ£€æŸ¥ç‚¹
            if not checkpoint_path and self.checkpoint_file:
                checkpoint_path = self.checkpoint_file
            elif not checkpoint_path:
                # æŸ¥æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹æ–‡ä»¶
                checkpoint_files = list(CHECKPOINTS_DIR.glob("*_checkpoint.json"))
                if not checkpoint_files:
                    logger.info("ğŸ” æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")
                    return None
                checkpoint_path = max(checkpoint_files, key=os.path.getctime)
            
            if not checkpoint_path or not Path(checkpoint_path).exists():
                logger.info("ğŸ” æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")
                return None
            
            # ä½¿ç”¨å¢å¼ºçš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint_data = self.checkpoint_manager.load_checkpoint(task_id="main_training")
            
            if checkpoint_data:
                logger.info(f"âœ… åŠ è½½æ£€æŸ¥ç‚¹: {Path(checkpoint_path).name}")
                return checkpoint_data
            else:
                logger.error("âŒ ä½¿ç”¨å¢å¼ºæ£€æŸ¥ç‚¹ç®¡ç†å™¨åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥")
                return None
                
        except Exception as e:
            self.error_handler.handle_error(e, context)
            logger.error(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return None
    
    def simulate_training_step(self, epoch, batch_size=16, scenario_name="default"):
        """æ¨¡æ‹Ÿä¸€ä¸ªè®­ç»ƒæ­¥éª¤ï¼ˆå®é™…é¡¹ç›®ä¸­è¿™é‡Œä¼šæ˜¯çœŸæ­£çš„è®­ç»ƒä»£ç ï¼‰"""
        # æ¨¡æ‹Ÿæ›´çœŸå®çš„è®­ç»ƒæ—¶é—´
        # å¯¹äºæ—©æœŸepochï¼Œè®­ç»ƒæ—¶é—´è¾ƒçŸ­ï¼›å¯¹äºåæœŸepochï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿
        base_time = 0.05  # åŸºç¡€æ—¶é—´
        epoch_factor = min(1.0, epoch / 20.0)  # epochå› å­ï¼Œæœ€å¤šå¢åŠ åˆ°åŸæ¥çš„2å€
        batch_factor = batch_size / 16.0  # æ‰¹æ¬¡å¤§å°å› å­
        
        # è®¡ç®—å®é™…ç¡çœ æ—¶é—´
        sleep_time = base_time * (1 + epoch_factor) * batch_factor
        time.sleep(min(0.5, sleep_time))  # æœ€å¤šç¡çœ 0.5ç§’ï¼Œé¿å…å¤ªæ…¢
        
        # æ¨¡æ‹Ÿè®­ç»ƒæŸå¤±ï¼ˆæ›´çœŸå®çš„æŸå¤±ä¸‹é™æ›²çº¿ï¼‰
        # ä½¿ç”¨æŒ‡æ•°è¡°å‡å‡½æ•°æ¨¡æ‹ŸæŸå¤±ä¸‹é™
        initial_loss = 2.0
        decay_rate = 0.05
        noise = random.uniform(-0.05, 0.05)
        loss = initial_loss * (0.8 ** (epoch * decay_rate)) + noise
        loss = max(0.01, loss)  # ç¡®ä¿æŸå¤±ä¸ä¼šé™åˆ°0ä»¥ä¸‹
        
        # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
        max_accuracy = 0.98
        accuracy = min(max_accuracy, (epoch / 100) * max_accuracy + random.uniform(-0.02, 0.02))
        accuracy = max(0, accuracy)
        
        # æ›´æ–°è®­ç»ƒç›‘æ§å™¨
        metrics = {
            "loss": loss,
            "accuracy": accuracy
        }
        
        if training_monitor:
            progress = (epoch / 100) * 100  # å‡è®¾æœ€å¤š100ä¸ªepoch
            training_monitor.update_progress(scenario_name, epoch, progress, metrics)
        
        return metrics
    
    def _train_math_model(self, scenario):
        """è®­ç»ƒæ•°å­¦æ¨¡å‹"""
        if not self.tensorflow_available:
            logger.error("âŒ TensorFlowä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒæ•°å­¦æ¨¡å‹")
            return False
        
        try:
            logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ•°å­¦æ¨¡å‹...")
            # ä½¿ç”¨å­è¿›ç¨‹è°ƒç”¨çœŸå®çš„è®­ç»ƒè„šæœ¬
            math_model_script = self.project_root / "apps" / "backend" / "src" / "tools" / "math_model" / "train.py"
            if not math_model_script.exists():
                logger.error(f"âŒ æ•°å­¦æ¨¡å‹è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: {math_model_script}")
                return False
            
            # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå¹¶è¿è¡Œè®­ç»ƒè„šæœ¬
            venv_python = self.project_root / "apps" / "backend" / "venv" / "Scripts" / "python.exe"
            if venv_python.exists():
                cmd = [str(venv_python), str(math_model_script)]
            else:
                cmd = [sys.executable, str(math_model_script)]
            
            result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info("âœ… æ•°å­¦æ¨¡å‹è®­ç»ƒå®Œæˆ")
                logger.info(f"è®­ç»ƒè¾“å‡º: {result.stdout}")
                return True
            else:
                logger.error(f"âŒ æ•°å­¦æ¨¡å‹è®­ç»ƒå¤±è´¥: {result.stderr}")
                return False
        except Exception as e:
            logger.error(f"âŒ æ•°å­¦æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_logic_model(self, scenario):
        """è®­ç»ƒé€»è¾‘æ¨¡å‹"""
        if not self.tensorflow_available:
            logger.error("âŒ TensorFlowä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒé€»è¾‘æ¨¡å‹")
            return False
        
        try:
            logger.info("ğŸš€ å¼€å§‹è®­ç»ƒé€»è¾‘æ¨¡å‹...")
            # ä½¿ç”¨å­è¿›ç¨‹è°ƒç”¨çœŸå®çš„è®­ç»ƒè„šæœ¬
            logic_model_script = self.project_root / "apps" / "backend" / "src" / "tools" / "logic_model" / "train_logic_model.py"
            if not logic_model_script.exists():
                logger.error(f"âŒ é€»è¾‘æ¨¡å‹è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: {logic_model_script}")
                return False
            
            # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå¹¶è¿è¡Œè®­ç»ƒè„šæœ¬
            venv_python = self.project_root / "apps" / "backend" / "venv" / "Scripts" / "python.exe"
            if venv_python.exists():
                cmd = [str(venv_python), str(logic_model_script)]
            else:
                cmd = [sys.executable, str(logic_model_script)]
            
            result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info("âœ… é€»è¾‘æ¨¡å‹è®­ç»ƒå®Œæˆ")
                logger.info(f"è®­ç»ƒè¾“å‡º: {result.stdout}")
                return True
            else:
                logger.error(f"âŒ é€»è¾‘æ¨¡å‹è®­ç»ƒå¤±è´¥: {result.stderr}")
                return False
        except Exception as e:
            logger.error(f"âŒ é€»è¾‘æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_concept_models(self, scenario):
        """è®­ç»ƒæ¦‚å¿µæ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ¦‚å¿µæ¨¡å‹...")
        
        # å¯¼å…¥æ¦‚å¿µæ¨¡å‹
        try:
            sys.path.append(str(self.project_root / "apps" / "backend" / "src"))
            from core_ai.concept_models.environment_simulator import EnvironmentSimulator
            from core_ai.concept_models.causal_reasoning_engine import CausalReasoningEngine
            from core_ai.concept_models.adaptive_learning_controller import AdaptiveLearningController
            from core_ai.concept_models.alpha_deep_model import AlphaDeepModel
            from core_ai.concept_models.unified_symbolic_space import UnifiedSymbolicSpace
            
            logger.info("âœ… æ¦‚å¿µæ¨¡å‹å¯¼å…¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ æ¦‚å¿µæ¨¡å‹å¯¼å…¥å¤±è´¥: {e}")
            return False
        
        # è·å–è®­ç»ƒå‚æ•°
        epochs = scenario.get('epochs', 10)
        batch_size = scenario.get('batch_size', 16)
        checkpoint_interval = scenario.get('checkpoint_interval', 5)
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        try:
            for epoch in range(1, epochs + 1):
                # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                epoch_metrics = self.simulate_training_step(epoch, batch_size)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f}")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if epoch % checkpoint_interval == 0 or epoch == epochs:
                    self.save_checkpoint(epoch, epoch_metrics)
            
            # ä¿å­˜æ¨¡å‹
            model_filename = f"concept_models_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            model_path = MODELS_DIR / model_filename
            
            model_info = {
                "model_type": "concept_models",
                "training_date": datetime.now().isoformat(),
                "epochs": epochs,
                "batch_size": batch_size,
                "final_metrics": epoch_metrics
            }
            
            with open(model_path, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… æ¦‚å¿µæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ æ¦‚å¿µæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_environment_simulator(self, scenario):
        """è®­ç»ƒç¯å¢ƒæ¨¡æ‹Ÿå™¨"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒç¯å¢ƒæ¨¡æ‹Ÿå™¨...")
        # è¿™é‡Œåº”è¯¥æ˜¯ç¯å¢ƒæ¨¡æ‹Ÿå™¨çš„å®é™…è®­ç»ƒä»£ç 
        # ä¸ºç¤ºä¾‹èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ
        return self._simulate_training(scenario)
    
    def _train_causal_reasoning(self, scenario):
        """è®­ç»ƒå› æœæ¨ç†å¼•æ“"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒå› æœæ¨ç†å¼•æ“...")
        # è¿™é‡Œåº”è¯¥æ˜¯å› æœæ¨ç†å¼•æ“çš„å®é™…è®­ç»ƒä»£ç 
        # ä¸ºç¤ºä¾‹èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ
        return self._simulate_training(scenario)
    
    def _train_adaptive_learning(self, scenario):
        """è®­ç»ƒè‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒè‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨...")
        # è¿™é‡Œåº”è¯¥æ˜¯è‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨çš„å®é™…è®­ç»ƒä»£ç 
        # ä¸ºç¤ºä¾‹èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ
        return self._simulate_training(scenario)
    
    def _train_alpha_deep_model(self, scenario):
        """è®­ç»ƒAlphaæ·±åº¦æ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒAlphaæ·±åº¦æ¨¡å‹...")
        # è¿™é‡Œåº”è¯¥æ˜¯Alphaæ·±åº¦æ¨¡å‹çš„å®é™…è®­ç»ƒä»£ç 
        # ä¸ºç¤ºä¾‹èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ
        return self._simulate_training(scenario)
    
    def _train_code_model(self, scenario):
        """è®­ç»ƒä»£ç æ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒä»£ç æ¨¡å‹...")
        
        # è·å–è®­ç»ƒå‚æ•°
        epochs = scenario.get('epochs', 10)
        batch_size = scenario.get('batch_size', 16)
        checkpoint_interval = scenario.get('checkpoint_interval', 5)
        
        # æ¨¡æ‹Ÿä»£ç æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
        try:
            for epoch in range(1, epochs + 1):
                # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                epoch_metrics = self.simulate_training_step(epoch, batch_size)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f}")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if epoch % checkpoint_interval == 0 or epoch == epochs:
                    self.save_checkpoint(epoch, epoch_metrics)
            
            # ä¿å­˜æ¨¡å‹
            model_filename = f"code_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            model_path = MODELS_DIR / model_filename
            
            model_info = {
                "model_type": "code_model",
                "training_date": datetime.now().isoformat(),
                "epochs": epochs,
                "batch_size": batch_size,
                "final_metrics": epoch_metrics
            }
            
            with open(model_path, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… ä»£ç æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ ä»£ç æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_data_analysis_model(self, scenario):
        """è®­ç»ƒæ•°æ®åˆ†ææ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ•°æ®åˆ†ææ¨¡å‹...")
        
        # è·å–è®­ç»ƒå‚æ•°
        epochs = scenario.get('epochs', 10)
        batch_size = scenario.get('batch_size', 16)
        checkpoint_interval = scenario.get('checkpoint_interval', 5)
        
        # æ¨¡æ‹Ÿæ•°æ®åˆ†ææ¨¡å‹è®­ç»ƒè¿‡ç¨‹
        try:
            for epoch in range(1, epochs + 1):
                # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                epoch_metrics = self.simulate_training_step(epoch, batch_size)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f}")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if epoch % checkpoint_interval == 0 or epoch == epochs:
                    self.save_checkpoint(epoch, epoch_metrics)
            
            # ä¿å­˜æ¨¡å‹
            model_filename = f"data_analysis_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            model_path = MODELS_DIR / model_filename
            
            model_info = {
                "model_type": "data_analysis_model",
                "training_date": datetime.now().isoformat(),
                "epochs": epochs,
                "batch_size": batch_size,
                "final_metrics": epoch_metrics
            }
            
            with open(model_path, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… æ•°æ®åˆ†ææ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åˆ†ææ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_collaboratively(self, scenario):
        """æ‰§è¡Œåä½œå¼è®­ç»ƒ"""
        logger.info("ğŸ”„ å¼€å§‹åä½œå¼è®­ç»ƒ...")
        
        try:
            # å¯¼å…¥åä½œå¼è®­ç»ƒç®¡ç†å™¨
            # ä¿®å¤å¯¼å…¥é—®é¢˜
            import sys
            from pathlib import Path
            # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
            project_root = Path(__file__).parent.parent
            sys.path.insert(0, str(project_root))
            
            from training.collaborative_training_manager import CollaborativeTrainingManager
            
            # åˆå§‹åŒ–åä½œå¼è®­ç»ƒç®¡ç†å™¨
            manager = CollaborativeTrainingManager()
            
            # æ³¨å†Œæ‰€æœ‰å¯ç”¨æ¨¡å‹
            self._register_all_models(manager)
            
            # å¼€å§‹åä½œå¼è®­ç»ƒ
            success = manager.start_collaborative_training(scenario)
            
            if success:
                logger.info("âœ… åä½œå¼è®­ç»ƒå®Œæˆ")
                return True
            else:
                logger.error("âŒ åä½œå¼è®­ç»ƒå¤±è´¥")
                return False
                
        except ImportError as e:
            logger.error(f"âŒ æ— æ³•å¯¼å…¥åä½œå¼è®­ç»ƒç®¡ç†å™¨: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ åä½œå¼è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _register_all_models(self, manager):
        """æ³¨å†Œæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        # æ³¨å†Œæ¦‚å¿µæ¨¡å‹
        try:
            from apps.backend.src.core_ai.concept_models.environment_simulator import EnvironmentSimulator
            manager.register_model("environment_simulator", EnvironmentSimulator())
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•æ³¨å†Œç¯å¢ƒæ¨¡æ‹Ÿå™¨: {e}")
        
        try:
            from apps.backend.src.core_ai.concept_models.causal_reasoning_engine import CausalReasoningEngine
            manager.register_model("causal_reasoning_engine", CausalReasoningEngine())
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•æ³¨å†Œå› æœæ¨ç†å¼•æ“: {e}")
        
        try:
            from apps.backend.src.core_ai.concept_models.adaptive_learning_controller import AdaptiveLearningController
            manager.register_model("adaptive_learning_controller", AdaptiveLearningController())
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•æ³¨å†Œè‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨: {e}")
        
        try:
            from apps.backend.src.core_ai.concept_models.alpha_deep_model import AlphaDeepModel
            manager.register_model("alpha_deep_model", AlphaDeepModel())
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•æ³¨å†ŒAlphaæ·±åº¦æ¨¡å‹: {e}")
        
        # æ³¨å†Œå…¶ä»–æ¨¡å‹
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šæ¨¡å‹çš„æ³¨å†Œ
        logger.info("âœ… æ¨¡å‹æ³¨å†Œå®Œæˆ")

    def _simulate_training(self, scenario):
        """æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹"""
        # è·å–è®­ç»ƒå‚æ•°
        epochs = scenario.get('epochs', 10)
        batch_size = scenario.get('batch_size', 16)
        checkpoint_interval = scenario.get('checkpoint_interval', 5)
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        try:
            for epoch in range(1, epochs + 1):
                # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                epoch_metrics = self.simulate_training_step(epoch, batch_size)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f}")
                
                # æ¨¡æ‹Ÿä¿å­˜æ£€æŸ¥ç‚¹
                if epoch % checkpoint_interval == 0 or epoch == epochs:
                    self.save_checkpoint(epoch, epoch_metrics)
            
            return True
        except Exception as e:
            logger.error(f"âŒ æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_with_gpu(self, scenario):
        """ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒï¼ˆå¢å¼ºå®¹é”™ç‰ˆæœ¬ï¼‰"""
        logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨GPUè®­ç»ƒ...")
        
        try:
            import tensorflow as tf
            
            # é…ç½®GPU
            self._configure_gpu_memory()
            
            # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
            strategy = self._setup_distributed_training()
            
            # è·å–è®­ç»ƒå‚æ•°
            epochs = scenario.get('epochs', 10)
            batch_size = scenario.get('batch_size', 16)
            checkpoint_interval = scenario.get('checkpoint_interval', 5)
            
            # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹ä»¥æ”¯æŒä»ä¸­æ–­å¤„ç»§ç»­
            start_epoch = 1
            checkpoint_data = self.load_checkpoint()
            if checkpoint_data:
                start_epoch = checkpoint_data.get('epoch', 0) + 1
                logger.info(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒï¼Œèµ·å§‹è½®æ•°: {start_epoch}")
            
            # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
            try:
                for epoch in range(start_epoch, epochs + 1):
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
                    if self.is_paused:
                        logger.info("â¸ï¸ è®­ç»ƒå·²æš‚åœ")
                        self.save_checkpoint(epoch)
                        return False
                    
                    # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                    epoch_metrics = self.simulate_training_step(epoch, batch_size)
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (epoch / epochs) * 100
                    logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f}")
                    
                    # ä½¿ç”¨å¢å¼ºçš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨å†³å®šæ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹
                    checkpoint_decision = self.checkpoint_manager.should_save_checkpoint(
                        epoch, 
                        epoch_metrics, 
                        "main_training"
                    )
                    
                    if checkpoint_decision['should_save']:
                        logger.info(f"ğŸ’¾ æ ¹æ®ç­–ç•¥ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_decision['reasons']}")
                        self.save_checkpoint(epoch, epoch_metrics)
                    elif epoch % checkpoint_interval == 0 or epoch == epochs:
                        # ä¿æŒåŸæœ‰çš„æ£€æŸ¥ç‚¹é—´éš”é€»è¾‘ä½œä¸ºåå¤‡
                        self.save_checkpoint(epoch, epoch_metrics)
                
                return True
            except Exception as e:
                logger.error(f"âŒ æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                return False
            
        except Exception as e:
            logger.error(f"âŒ GPUè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _simulate_training_with_gpu(self, scenario):
        """æ¨¡æ‹ŸGPUè®­ç»ƒè¿‡ç¨‹"""
        # è·å–è®­ç»ƒå‚æ•°
        epochs = scenario.get('epochs', 10)
        batch_size = scenario.get('batch_size', 16)
        checkpoint_interval = scenario.get('checkpoint_interval', 5)
        
        # æ¨¡æ‹ŸGPUè®­ç»ƒè¿‡ç¨‹
        try:
            for epoch in range(1, epochs + 1):
                # æ¨¡æ‹ŸGPUè®­ç»ƒæ­¥éª¤
                # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šæ˜¯çœŸæ­£çš„GPUè®­ç»ƒä»£ç 
                time.sleep(0.05)  # æ¨¡æ‹ŸGPUè®­ç»ƒæ—¶é—´
                
                # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡ï¼ˆGPUè®­ç»ƒé€šå¸¸æ›´å¿«ä¸”æ›´å‡†ç¡®ï¼‰
                epoch_metrics = {
                    "loss": max(0.001, 2.0 * (0.8 ** (epoch * 0.1)) + random.uniform(-0.02, 0.02)),
                    "accuracy": min(0.99, (epoch / epochs) * 0.95 + random.uniform(-0.01, 0.01))
                }
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f} (GPUåŠ é€Ÿ)")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if epoch % checkpoint_interval == 0 or epoch == epochs:
                    self.save_checkpoint(epoch, epoch_metrics)
            
            return True
        except Exception as e:
            logger.error(f"âŒ GPUæ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_distributed(self, scenario):
        """æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒ"""
        logger.info("ğŸ”„ å¼€å§‹åˆ†å¸ƒå¼è®­ç»ƒ...")
        
        try:
            import tensorflow as tf
            
            # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ
            strategy = self._setup_distributed_training()
            
            if not strategy:
                logger.warning("âš ï¸ æ— æ³•è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼Œå›é€€åˆ°å•è®¾å¤‡è®­ç»ƒ")
                return self._train_with_gpu(scenario)
            
            # åœ¨åˆ†å¸ƒå¼ç­–ç•¥èŒƒå›´å†…æ‰§è¡Œè®­ç»ƒ
            with strategy.scope():
                logger.info("ğŸ”„ åœ¨åˆ†å¸ƒå¼ç­–ç•¥èŒƒå›´å†…æ‰§è¡Œè®­ç»ƒ")
                # è¿™é‡Œä¼šæ˜¯å®é™…çš„åˆ†å¸ƒå¼è®­ç»ƒä»£ç 
                # ä¸ºç¤ºä¾‹èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ
                success = self._simulate_distributed_training(scenario)
            
            return success
        except Exception as e:
            logger.error(f"âŒ åˆ†å¸ƒå¼è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _simulate_distributed_training(self, scenario):
        """æ¨¡æ‹Ÿåˆ†å¸ƒå¼è®­ç»ƒè¿‡ç¨‹ï¼ˆå¢å¼ºå®¹é”™ç‰ˆæœ¬ï¼‰"""
        # è·å–è®­ç»ƒå‚æ•°
        epochs = scenario.get('epochs', 10)
        batch_size = scenario.get('batch_size', 16)
        checkpoint_interval = scenario.get('checkpoint_interval', 5)
        
        # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹ä»¥æ”¯æŒä»ä¸­æ–­å¤„ç»§ç»­
        start_epoch = 1
        checkpoint_data = self.load_checkpoint()
        if checkpoint_data:
            start_epoch = checkpoint_data.get('epoch', 0) + 1
            logger.info(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹ç»§ç»­åˆ†å¸ƒå¼è®­ç»ƒï¼Œèµ·å§‹è½®æ•°: {start_epoch}")
        
        # æ¨¡æ‹Ÿåˆ†å¸ƒå¼è®­ç»ƒè¿‡ç¨‹ï¼ˆé€šå¸¸æ›´å¿«ï¼‰
        try:
            for epoch in range(start_epoch, epochs + 1):
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
                if self.is_paused:
                    logger.info("â¸ï¸ åˆ†å¸ƒå¼è®­ç»ƒå·²æš‚åœ")
                    self.save_checkpoint(epoch)
                    return False
                
                # æ¨¡æ‹Ÿåˆ†å¸ƒå¼è®­ç»ƒæ­¥éª¤
                time.sleep(0.03)  # æ¨¡æ‹Ÿåˆ†å¸ƒå¼è®­ç»ƒæ—¶é—´ï¼ˆæ›´å¿«ï¼‰
                
                # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡ï¼ˆåˆ†å¸ƒå¼è®­ç»ƒé€šå¸¸æ›´ç¨³å®šï¼‰
                epoch_metrics = {
                    "loss": max(0.0005, 2.0 * (0.75 ** (epoch * 0.12)) + random.uniform(-0.01, 0.01)),
                    "accuracy": min(0.995, (epoch / epochs) * 0.96 + random.uniform(-0.005, 0.005))
                }
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f} (åˆ†å¸ƒå¼è®­ç»ƒ)")
                
                # ä½¿ç”¨å¢å¼ºçš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨å†³å®šæ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹
                checkpoint_decision = self.checkpoint_manager.should_save_checkpoint(
                    epoch, 
                    epoch_metrics, 
                    "distributed_training"
                )
                
                if checkpoint_decision['should_save']:
                    logger.info(f"ğŸ’¾ æ ¹æ®ç­–ç•¥ä¿å­˜åˆ†å¸ƒå¼è®­ç»ƒæ£€æŸ¥ç‚¹: {checkpoint_decision['reasons']}")
                    self.save_checkpoint(epoch, epoch_metrics)
                elif epoch % checkpoint_interval == 0 or epoch == epochs:
                    # ä¿æŒåŸæœ‰çš„æ£€æŸ¥ç‚¹é—´éš”é€»è¾‘ä½œä¸ºåå¤‡
                    self.save_checkpoint(epoch, epoch_metrics)
            
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ†å¸ƒå¼æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def train(self, scenario_name: str = None, scenario: Dict[str, Any] = None):
        """æ‰§è¡Œè®­ç»ƒï¼ˆå¢å¼ºå®¹é”™ç‰ˆæœ¬ï¼‰"""
        logger.info(f"ğŸš€ å¼€å§‹ä½¿ç”¨é¢„è®¾é…ç½®è®­ç»ƒ: {scenario_name}")
        
        if scenario_name:
            scenario = self.get_preset_scenario(scenario_name)
            if not scenario:
                return False
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨GPUè®­ç»ƒ
        use_gpu = scenario.get('use_gpu', self.gpu_available)
        
        # æ£€æŸ¥ç¡¬ä»¶é…ç½®ä¸­çš„é›†æˆæ˜¾å¡æ”¯æŒ
        integrated_graphics_support = self.config.get('hardware_configuration', {}).get('integrated_graphics_support', False)
        minimum_vram_gb = self.config.get('hardware_configuration', {}).get('minimum_vram_gb_for_integrated', 1)
        
        # å¦‚æœå¯ç”¨äº†é›†æˆæ˜¾å¡æ”¯æŒï¼Œå³ä½¿æ²¡æœ‰æ£€æµ‹åˆ°ä¸“ç”¨GPUï¼Œä¹Ÿå¯ä»¥å°è¯•ä½¿ç”¨GPUè®­ç»ƒ
        if use_gpu and (self.gpu_available or integrated_graphics_support):
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ˜¾å­˜ï¼ˆå¯¹äºé›†æˆæ˜¾å¡è¦æ±‚è¾ƒä½ï¼‰
            if self.gpu_available or (integrated_graphics_support and self._check_system_gpu_memory() >= minimum_vram_gb):
                logger.info("ğŸ–¥ï¸  å¯ç”¨GPUè®­ç»ƒ")
                return self._train_with_gpu(scenario)
            else:
                logger.info("âš ï¸  æ˜¾å­˜ä¸è¶³ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
                # ç»§ç»­æ‰§è¡ŒCPUè®­ç»ƒé€»è¾‘
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
        use_distributed = scenario.get('distributed_training', False)
        if use_distributed and self.gpu_available:
            logger.info("ğŸ”„ å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ")
            return self._train_distributed(scenario)
        
        # åº”ç”¨é›†æˆæ˜¾å¡ä¼˜åŒ–ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        if integrated_graphics_optimizer and integrated_graphics_optimizer.is_integrated_graphics_system():
            logger.info("ğŸ”§ åº”ç”¨é›†æˆæ˜¾å¡ä¼˜åŒ–")
            optimization_results = integrated_graphics_optimizer.apply_all_optimizations()
            logger.info(f"é›†æˆæ˜¾å¡ä¼˜åŒ–ç»“æœ: {optimization_results}")
            
            # æ ¹æ®ä¼˜åŒ–ç»“æœè°ƒæ•´è®­ç»ƒå‚æ•°
            if 'optimizations_applied' in optimization_results:
                # è°ƒæ•´æ‰¹å¤„ç†å¤§å°
                original_batch_size = scenario.get('batch_size', 16)
                adjusted_batch_size = integrated_graphics_optimizer.adjust_batch_size_for_integrated_graphics(original_batch_size)
                scenario['batch_size'] = adjusted_batch_size
                logger.info(f"æ‰¹å¤„ç†å¤§å°ä» {original_batch_size} è°ƒæ•´ä¸º {adjusted_batch_size}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®è®­ç»ƒåœºæ™¯
        target_models = scenario.get('target_models', [])
        if 'math_model' in target_models:
            return self._train_math_model(scenario)
        elif 'logic_model' in target_models:
            return self._train_logic_model(scenario)
        elif 'concept_models' in target_models:
            return self._train_concept_models(scenario)
        elif 'environment_simulator' in target_models:
            return self._train_environment_simulator(scenario)
        elif 'causal_reasoning_engine' in target_models:
            return self._train_causal_reasoning(scenario)
        elif 'adaptive_learning_controller' in target_models:
            return self._train_adaptive_learning(scenario)
        elif 'alpha_deep_model' in target_models:
            return self._train_alpha_deep_model(scenario)
        elif 'code_model' in target_models:
            return self._train_code_model(scenario)
        elif 'data_analysis_model' in target_models:
            return self._train_data_analysis_model(scenario)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åä½œå¼è®­ç»ƒ
        if scenario.get('enable_collaborative_training', False):
            return self._train_collaboratively(scenario)
        
        # æ˜¾ç¤ºè®­ç»ƒå‚æ•°
        logger.info("ğŸ“Š è®­ç»ƒå‚æ•°:")
        logger.info(f"  æ•°æ®é›†: {', '.join(scenario.get('datasets', []))}")
        logger.info(f"  è®­ç»ƒè½®æ•°: {scenario.get('epochs', 10)}")
        logger.info(f"  æ‰¹æ¬¡å¤§å°: {scenario.get('batch_size', 16)}")
        logger.info(f"  ç›®æ ‡æ¨¡å‹: {', '.join(scenario.get('target_models', []))}")
        logger.info(f"  ä½¿ç”¨GPU: {use_gpu}")
        logger.info(f"  åˆ†å¸ƒå¼è®­ç»ƒ: {use_distributed}")
        
        # æ£€æŸ¥è‡ªåŠ¨æš‚åœè®¾ç½®
        auto_pause_on_low_disk = scenario.get('auto_pause_on_low_disk', False)
        min_disk_space_gb = scenario.get('min_disk_space_gb', 5)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)
        MODELS_DIR.mkdir(parents=True, exist_ok=True)
        
        # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹ä»¥æ”¯æŒä»ä¸­æ–­å¤„ç»§ç»­
        start_epoch = 1
        checkpoint_data = self.load_checkpoint()
        if checkpoint_data:
            start_epoch = checkpoint_data.get('epoch', 0) + 1
            logger.info(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒï¼Œèµ·å§‹è½®æ•°: {start_epoch}")
        
        # è·å–è®­ç»ƒå‚æ•°
        epochs = scenario.get('epochs', 10)
        batch_size = scenario.get('batch_size', 16)
        checkpoint_interval = scenario.get('checkpoint_interval', 5)
        
        try:
            # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ï¼ˆå®é™…é¡¹ç›®ä¸­è¿™é‡Œä¼šæ˜¯çœŸæ­£çš„è®­ç»ƒå¾ªç¯ï¼‰
            logger.info("ğŸ”„ å¼€å§‹è®­ç»ƒè¿‡ç¨‹...")
            
            for epoch in range(start_epoch, epochs + 1):
                # æ£€æŸ¥ç£ç›˜ç©ºé—´
                if auto_pause_on_low_disk and not self.check_disk_space(min_disk_space_gb):
                    logger.warning("â¸ï¸ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè‡ªåŠ¨æš‚åœè®­ç»ƒ")
                    self.save_checkpoint(epoch)
                    self.is_paused = True
                    return False
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœï¼ˆæ¨¡æ‹Ÿç”¨æˆ·ä¸­æ–­ï¼‰
                if self.is_paused:
                    logger.info("â¸ï¸ è®­ç»ƒå·²æš‚åœ")
                    self.save_checkpoint(epoch)
                    return False
                
                # æ¨¡æ‹Ÿä¸€ä¸ªepochçš„è®­ç»ƒï¼ˆå®é™…é¡¹ç›®ä¸­è¿™é‡Œä¼šæ˜¯å¤šä¸ªbatchçš„è®­ç»ƒï¼‰
                epoch_metrics = self.simulate_training_step(epoch, batch_size, scenario_name)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f}")
                
                # æ¨¡æ‹Ÿä¿å­˜æ£€æŸ¥ç‚¹
                if epoch % checkpoint_interval == 0 or epoch == epochs:
                    self.save_checkpoint(epoch, epoch_metrics)
                
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            model_filename = f"{scenario_name}_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
            model_path = MODELS_DIR / model_filename
            
            # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ¨¡å‹æ–‡ä»¶ï¼ˆå®é™…é¡¹ç›®ä¸­è¿™é‡Œä¼šä¿å­˜çœŸæ­£çš„æ¨¡å‹ï¼‰
            model_info = {
                "model_name": scenario_name,
                "training_date": datetime.now().isoformat(),
                "epochs": epochs,
                "batch_size": batch_size,
                "final_metrics": epoch_metrics,
                "datasets": scenario.get('datasets', []),
                "use_gpu": use_gpu,
                "distributed_training": use_distributed
            }
            
            with open(model_path, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
            
            # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
            self.generate_training_report(scenario_name, scenario, model_info)
            
            return True
            
        except KeyboardInterrupt:
            logger.info("â¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
            self.save_checkpoint(epoch, epoch_metrics)
            return False
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.save_checkpoint(epoch, epoch_metrics)
            return False
    
    def train_with_default_config(self):
        """ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œè®­ç»ƒ"""
        logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ")
        
        if not self.config:
            logger.error("âŒ æœªæ‰¾åˆ°è®­ç»ƒé…ç½®")
            return False
        
        # æ˜¾ç¤ºè®­ç»ƒå‚æ•°
        training_config = self.config.get('training', {})
        logger.info("ğŸ“Š è®­ç»ƒå‚æ•°:")
        logger.info(f"  æ‰¹æ¬¡å¤§å°: {training_config.get('batch_size', 16)}")
        logger.info(f"  è®­ç»ƒè½®æ•°: {training_config.get('epochs', 10)}")
        logger.info(f"  å­¦ä¹ ç‡: {training_config.get('learning_rate', 0.001)}")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)
        MODELS_DIR.mkdir(parents=True, exist_ok=True)
        
        # è·å–è®­ç»ƒå‚æ•°
        epochs = training_config.get('epochs', 10)
        batch_size = training_config.get('batch_size', 16)
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        try:
            logger.info("ğŸ”„ å¼€å§‹è®­ç»ƒè¿‡ç¨‹...")
            for epoch in range(1, epochs + 1):
                # æ¨¡æ‹Ÿä¸€ä¸ªepochçš„è®­ç»ƒ
                epoch_metrics = self.simulate_training_step(epoch, batch_size)
                
                progress = (epoch / epochs) * 100
                logger.info(f"  Epoch {epoch}/{epochs} - è¿›åº¦: {progress:.1f}% - Loss: {epoch_metrics['loss']:.4f} - Accuracy: {epoch_metrics['accuracy']:.4f}")
                
                if epoch % 5 == 0 or epoch == epochs:
                    checkpoint_path = CHECKPOINTS_DIR / f"epoch_{epoch}.ckpt"
                    # åˆ›å»ºä¸€ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶
                    with open(checkpoint_path, 'w') as f:
                        f.write(f"Checkpoint for epoch {epoch}\nLoss: {epoch_metrics['loss']}\nAccuracy: {epoch_metrics['accuracy']}\n")
                    logger.info(f"  ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path.name}")
            
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            model_filename = f"default_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
            model_path = MODELS_DIR / model_filename
            
            # åˆ›å»ºæ¨¡å‹æ–‡ä»¶
            with open(model_path, 'w') as f:
                f.write("Default model trained with default config\n")
                f.write(f"Epochs: {epochs}\n")
                f.write(f"Batch size: {batch_size}\n")
            logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def generate_training_report(self, scenario_name, scenario, model_info=None):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        report = f"""# è®­ç»ƒæŠ¥å‘Š

## è®­ç»ƒä¿¡æ¯
- è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ä½¿ç”¨åœºæ™¯: {scenario_name}
- åœºæ™¯æè¿°: {scenario.get('description', 'æ— æè¿°')}

## è®­ç»ƒå‚æ•°
- æ•°æ®é›†: {', '.join(scenario.get('datasets', []))}
- è®­ç»ƒè½®æ•°: {scenario.get('epochs', 10)}
- æ‰¹æ¬¡å¤§å°: {scenario.get('batch_size', 16)}
- ç›®æ ‡æ¨¡å‹: {', '.join(scenario.get('target_models', []))}

## æ•°æ®é›†çŠ¶æ€
"""
        
        # æ·»åŠ æ•°æ®é›†ä¿¡æ¯
        data_config_path = DATA_DIR / "data_config.json"
        if data_config_path.exists():
            try:
                with open(data_config_path, 'r', encoding='utf-8') as f:
                    data_config = json.load(f)
                total_samples = data_config.get('total_samples', {})
                for data_type, count in total_samples.items():
                    report += f"- {data_type}: {count} ä¸ªæ ·æœ¬\n"
            except Exception as e:
                logger.error(f"âŒ è¯»å–æ•°æ®é…ç½®å¤±è´¥: {e}")
        
        report += f"""

## è®­ç»ƒç»“æœ
- æœ€ç»ˆæ¨¡å‹: å·²ä¿å­˜
- æ£€æŸ¥ç‚¹: å·²ä¿å­˜
- è®­ç»ƒçŠ¶æ€: å®Œæˆ

## æ¨¡å‹ä¿¡æ¯
"""
        
        if model_info:
            report += f"""- æ¨¡å‹åç§°: {model_info.get('model_name', 'N/A')}
- è®­ç»ƒæ—¥æœŸ: {model_info.get('training_date', 'N/A')}
- æœ€ç»ˆæŸå¤±: {model_info.get('final_metrics', {}).get('loss', 'N/A')}
- æœ€ç»ˆå‡†ç¡®ç‡: {model_info.get('final_metrics', {}).get('accuracy', 'N/A')}
"""
        
        report += f"""

## ä¸‹ä¸€æ­¥å»ºè®®
1. è¯„ä¼°æ¨¡å‹æ€§èƒ½
2. æ ¹æ®éœ€è¦è°ƒæ•´è¶…å‚æ•°
3. ä½¿ç”¨æ›´å¤šæ•°æ®è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒ

## æ¨¡å‹æ–‡ä»¶å…³è”ä¿¡æ¯
- æ¨¡å‹æ–‡ä»¶è·¯å¾„: {MODELS_DIR}
- æ£€æŸ¥ç‚¹è·¯å¾„: {CHECKPOINTS_DIR}
- é¡¹ç›®æ ¹ç›®å½•: {self.project_root}
- æ¨¡å‹ä¸é¡¹ç›®å…³è”: é€šè¿‡é¡¹ç›®è·¯å¾„é…ç½®å’Œè®­ç»ƒé…ç½®æ–‡ä»¶å»ºç«‹å…³è”
"""

        report_path = self.training_dir / "reports" / f"training_report_{scenario_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“„ è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def pause_training(self):
        """æš‚åœè®­ç»ƒ"""
        self.is_paused = True
        logger.info("â¸ï¸ è®­ç»ƒæš‚åœè¯·æ±‚å·²å‘é€")
    
    def resume_training(self, scenario_name):
        """ç»§ç»­è®­ç»ƒ"""
        self.is_paused = False
        logger.info("â–¶ï¸ ç»§ç»­è®­ç»ƒ")
        return self.train_with_preset(scenario_name)
    
    def evaluate_model(self, model_path: Path, test_data: Optional[list] = None) -> Dict[str, Any]:
        """è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info(f"ğŸ” å¼€å§‹è¯„ä¼°æ¨¡å‹: {model_path}")
        
        if not model_path.exists():
            logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return {"error": "Model file not found"}
        
        try:
            # åŠ è½½æ¨¡å‹å…ƒæ•°æ®
            if model_path.suffix == '.json':
                with open(model_path, 'r', encoding='utf-8') as f:
                    model_info = json.load(f)
            else:
                # å¯¹äºå…¶ä»–ç±»å‹çš„æ¨¡å‹æ–‡ä»¶ï¼Œåˆ›å»ºåŸºæœ¬çš„å…ƒæ•°æ®
                model_info = {
                    "model_name": model_path.stem,
                    "training_date": datetime.now().isoformat(),
                    "file_size": model_path.stat().st_size
                }
            
            # æ¨¡æ‹Ÿè¯„ä¼°è¿‡ç¨‹
            evaluation_results = {
                "model_name": model_info.get("model_name", "Unknown"),
                "evaluation_date": datetime.now().isoformat(),
                "test_samples": len(test_data) if test_data else random.randint(100, 1000),
                "accuracy": random.uniform(0.7, 0.98),
                "precision": random.uniform(0.65, 0.95),
                "recall": random.uniform(0.7, 0.9),
                "f1_score": random.uniform(0.68, 0.92),
                "loss": random.uniform(0.01, 0.5),
                "inference_time_ms": random.uniform(10, 100)
            }
            
            # ä¿å­˜è¯„ä¼°æŠ¥å‘Š
            report_dir = TRAINING_DIR / "evaluation_reports"
            report_dir.mkdir(parents=True, exist_ok=True)
            
            report_filename = f"evaluation_report_{model_path.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            report_path = report_dir / report_filename
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(evaluation_results, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼ŒæŠ¥å‘Šä¿å­˜è‡³: {report_path}")
            return evaluation_results
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return {"error": str(e)}
    
    def analyze_model_performance(self, model_path: Path) -> Dict[str, Any]:
        """åˆ†ææ¨¡å‹æ€§èƒ½å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†ææ¨¡å‹æ€§èƒ½: {model_path}")
        
        # è¯„ä¼°æ¨¡å‹
        evaluation_results = self.evaluate_model(model_path)
        
        if "error" in evaluation_results:
            return evaluation_results
        
        # ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
        performance_analysis = {
            "model_name": evaluation_results["model_name"],
            "analysis_date": datetime.now().isoformat(),
            "overall_performance": "ä¼˜ç§€" if evaluation_results["accuracy"] > 0.9 else "è‰¯å¥½" if evaluation_results["accuracy"] > 0.8 else "ä¸€èˆ¬",
            "strengths": [],
            "weaknesses": [],
            "recommendations": [],
            "metrics": evaluation_results
        }
        
        # æ ¹æ®æŒ‡æ ‡åˆ†æä¼˜åŠ¿å’ŒåŠ£åŠ¿
        if evaluation_results["accuracy"] > 0.9:
            performance_analysis["strengths"].append("é«˜å‡†ç¡®ç‡")
        else:
            performance_analysis["weaknesses"].append("å‡†ç¡®ç‡æœ‰å¾…æé«˜")
            performance_analysis["recommendations"].append("å¢åŠ è®­ç»ƒæ•°æ®é‡")
            
        if evaluation_results["f1_score"] > 0.85:
            performance_analysis["strengths"].append("è‰¯å¥½çš„å¹³è¡¡æ€§")
        else:
            performance_analysis["weaknesses"].append("ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¸å¹³è¡¡")
            performance_analysis["recommendations"].append("è°ƒæ•´åˆ†ç±»é˜ˆå€¼")
            
        if evaluation_results["inference_time_ms"] < 50:
            performance_analysis["strengths"].append("å¿«é€Ÿæ¨ç†")
        else:
            performance_analysis["weaknesses"].append("æ¨ç†é€Ÿåº¦è¾ƒæ…¢")
            performance_analysis["recommendations"].append("æ¨¡å‹ä¼˜åŒ–æˆ–é‡åŒ–")
        
        # ä¿å­˜æ€§èƒ½åˆ†ææŠ¥å‘Š
        analysis_dir = TRAINING_DIR / "performance_analysis"
        analysis_dir.mkdir(parents=True, exist_ok=True)
        
        analysis_filename = f"performance_analysis_{model_path.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        analysis_path = analysis_dir / analysis_filename
        
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(performance_analysis, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… æ¨¡å‹æ€§èƒ½åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šä¿å­˜è‡³: {analysis_path}")
        return performance_analysis
    
    def deploy_model(self, model_path: Path, deployment_target: str = "local") -> bool:
        """éƒ¨ç½²è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info(f"ğŸš€ å¼€å§‹éƒ¨ç½²æ¨¡å‹: {model_path} åˆ° {deployment_target}")
        
        if not model_path.exists():
            logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        
        try:
            # åˆ›å»ºéƒ¨ç½²ç›®å½•
            deployment_dir = TRAINING_DIR / "deployments" / deployment_target
            deployment_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ¨¡å‹æ–‡ä»¶
            deployed_model_path = deployment_dir / model_path.name
            shutil.copy2(model_path, deployed_model_path)
            
            # åˆ›å»ºéƒ¨ç½²é…ç½®
            deployment_config = {
                "model_name": model_path.stem,
                "deployment_target": deployment_target,
                "deployment_date": datetime.now().isoformat(),
                "model_path": str(deployed_model_path.relative_to(TRAINING_DIR)),
                "version": "1.0.0",
                "dependencies": [],
                "deployment_status": "success"
            }
            
            # ä¿å­˜éƒ¨ç½²é…ç½®
            config_path = deployment_dir / f"{model_path.stem}_deployment_config.json"
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(deployment_config, f, ensure_ascii=False, indent=2)
            
            # åˆ›å»ºéƒ¨ç½²æ—¥å¿—
            deployment_log = {
                "deployment_id": f"deploy_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "model_name": model_path.stem,
                "target": deployment_target,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "status": "completed",
                "details": f"Model {model_path.name} successfully deployed to {deployment_target}"
            }
            
            # ä¿å­˜éƒ¨ç½²æ—¥å¿—
            log_dir = TRAINING_DIR / "deployment_logs"
            log_dir.mkdir(parents=True, exist_ok=True)
            log_path = log_dir / f"deployment_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(log_path, 'w', encoding='utf-8') as f:
                json.dump(deployment_log, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… æ¨¡å‹éƒ¨ç½²å®Œæˆ: {deployed_model_path}")
            logger.info(f"ğŸ“„ éƒ¨ç½²é…ç½®ä¿å­˜è‡³: {config_path}")
            logger.info(f"ğŸ“ éƒ¨ç½²æ—¥å¿—ä¿å­˜è‡³: {log_path}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹éƒ¨ç½²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            
            # è®°å½•éƒ¨ç½²å¤±è´¥æ—¥å¿—
            deployment_log = {
                "deployment_id": f"deploy_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "model_name": model_path.stem,
                "target": deployment_target,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "status": "failed",
                "error": str(e)
            }
            
            log_dir = TRAINING_DIR / "deployment_logs"
            log_dir.mkdir(parents=True, exist_ok=True)
            log_path = log_dir / f"deployment_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}_failed.json"
            
            with open(log_path, 'w', encoding='utf-8') as f:
                json.dump(deployment_log, f, ensure_ascii=False, indent=2)
            
            return False
    
    def _check_system_gpu_memory(self):
        """æ£€æŸ¥ç³»ç»ŸGPUå†…å­˜"""
        try:
            import platform
            system = platform.system().lower()
            
            if system == "windows":
                # Windowsç³»ç»Ÿä½¿ç”¨WMIæ£€æŸ¥
                import subprocess
                import json
                
                result = subprocess.run([
                    "powershell.exe", 
                    "Get-WmiObject -Class Win32_VideoController | Select-Object Name, AdapterRAM | ConvertTo-Json"
                ], capture_output=True, text=True, timeout=10)
                
                if result.returncode == 0 and result.stdout.strip():
                    gpu_data = json.loads(result.stdout)
                    
                    # è®¡ç®—æ€»GPUå†…å­˜ï¼ˆä»¥GBä¸ºå•ä½ï¼‰
                    total_memory_gb = 0
                    
                    # Handle both single GPU and multiple GPU cases
                    if isinstance(gpu_data, list):
                        gpu_list = gpu_data
                    else:
                        gpu_list = [gpu_data]
                    
                    # Sum up memory from all GPUs
                    for gpu_info in gpu_list:
                        adapter_ram = gpu_info.get('AdapterRAM', 0)
                        # Convert RAM from bytes to GB
                        memory_gb = adapter_ram / (1024**3) if adapter_ram else 0
                        total_memory_gb += memory_gb
                    
                    return total_memory_gb
                    
            # For other platforms or if WMI detection failed, return 0
            return 0
        except Exception as e:
            logger.warning(f"æ£€æŸ¥ç³»ç»ŸGPUå†…å­˜æ—¶å‡ºé”™: {e}")
            return 0


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Unified AI Project æ¨¡å‹è®­ç»ƒè„šæœ¬')
    parser.add_argument('--preset', type=str, help='ä½¿ç”¨é¢„è®¾é…ç½®è¿›è¡Œè®­ç»ƒ (quick_start, comprehensive_training, vision_focus, audio_focus, full_dataset_training, math_model_training, logic_model_training, collaborative_training)')
    parser.add_argument('--config', type=str, help='æŒ‡å®šè®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--preset-config', type=str, help='æŒ‡å®šé¢„è®¾é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', action='store_true', help='ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ')
    parser.add_argument('--pause', action='store_true', help='æš‚åœè®­ç»ƒ')
    parser.add_argument('--evaluate', type=str, help='è¯„ä¼°æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶')
    parser.add_argument('--deploy', type=str, help='éƒ¨ç½²æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶')
    parser.add_argument('--target', type=str, default='local', help='éƒ¨ç½²ç›®æ ‡ (local, staging, production)')
    parser.add_argument('--auto', action='store_true', help='å¯ç”¨è‡ªåŠ¨è®­ç»ƒæ¨¡å¼ï¼ˆè‡ªåŠ¨è¯†åˆ«æ•°æ®ã€åˆ›å»ºé…ç½®ã€æ‰§è¡Œè®­ç»ƒï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸš€ Unified-AI-Project æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = ModelTrainer(
        config_path=args.config,
        preset_path=args.preset_config
    )
    
    # æ ¹æ®å‚æ•°å†³å®šæ“ä½œ
    if args.evaluate:
        # è¯„ä¼°æ¨¡å‹
        model_path = Path(args.evaluate)
        results = trainer.evaluate_model(model_path)
        if "error" not in results:
            print(f"\nğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:")
            print(f"  æ¨¡å‹åç§°: {results['model_name']}")
            print(f"  å‡†ç¡®ç‡: {results['accuracy']:.4f}")
            print(f"  ç²¾ç¡®ç‡: {results['precision']:.4f}")
            print(f"  å¬å›ç‡: {results['recall']:.4f}")
            print(f"  F1åˆ†æ•°: {results['f1_score']:.4f}")
            print(f"  æŸå¤±: {results['loss']:.4f}")
            print(f"  æ¨ç†æ—¶é—´: {results['inference_time_ms']:.2f}ms")
        else:
            print(f"\nâŒ è¯„ä¼°å¤±è´¥: {results['error']}")
    elif args.deploy:
        # éƒ¨ç½²æ¨¡å‹
        model_path = Path(args.deploy)
        success = trainer.deploy_model(model_path, args.target)
        if success:
            print(f"\nâœ… æ¨¡å‹éƒ¨ç½²æˆåŠŸ: {model_path}")
        else:
            print(f"\nâŒ æ¨¡å‹éƒ¨ç½²å¤±è´¥: {model_path}")
    elif args.auto:
        # å¯ç”¨è‡ªåŠ¨è®­ç»ƒæ¨¡å¼
        print("ğŸ¤– å¯ç”¨è‡ªåŠ¨è®­ç»ƒæ¨¡å¼")
        try:
            from training.auto_training_manager import AutoTrainingManager
            auto_trainer = AutoTrainingManager()
            report = auto_trainer.run_full_auto_training_pipeline()
            print("\nâœ… è‡ªåŠ¨è®­ç»ƒå®Œæˆ!")
            print("è¯·æŸ¥çœ‹è®­ç»ƒç›®å½•ä¸­çš„æ¨¡å‹å’ŒæŠ¥å‘Šæ–‡ä»¶")
        except Exception as e:
            print(f"\nâŒ è‡ªåŠ¨è®­ç»ƒå¤±è´¥: {e}")
            sys.exit(1)
    elif args.preset:
        # ä½¿ç”¨é¢„è®¾é…ç½®è®­ç»ƒ
        if args.pause:
            trainer.pause_training()
        elif args.resume:
            success = trainer.resume_training(args.preset)
        else:
            success = trainer.train_with_preset(args.preset)
        
        if success:
            print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
            print("è¯·æŸ¥çœ‹è®­ç»ƒç›®å½•ä¸­çš„æ¨¡å‹å’ŒæŠ¥å‘Šæ–‡ä»¶")
        else:
            print("\nâš ï¸ è®­ç»ƒæš‚åœæˆ–ä¸­æ–­ï¼Œè¯·ä½¿ç”¨ --resume å‚æ•°ç»§ç»­è®­ç»ƒ")
            sys.exit(1)
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
        success = trainer.train_with_default_config()
        
        if success:
            print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
            print("è¯·æŸ¥çœ‹è®­ç»ƒç›®å½•ä¸­çš„æ¨¡å‹å’ŒæŠ¥å‘Šæ–‡ä»¶")
        else:
            print("\nâŒ è®­ç»ƒå¤±è´¥")
            sys.exit(1)


if __name__ == "__main__":
    main()