#!/usr/bin/env python3
"""
è®­ç»ƒè¿‡ç¨‹ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹
å®ç°è®­ç»ƒè¿‡ç¨‹çš„å®æ—¶ç›‘æ§ã€æ€§èƒ½åˆ†æå’Œå¼‚å¸¸æ£€æµ‹åŠŸèƒ½
"""

import logging
import time
import threading
import psutil
import json
from pathlib import Path
from datetime import datetime
import numpy as np
from collections import defaultdict, deque

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
project_root: str = Path(__file__).parent.parent
_ = sys.path.insert(0, str(project_root))


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level: str=logging.INFO,
    format: str='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        _ = logging.FileHandler(project_root / 'training' / 'logs' / 'training_monitor.log'),
        _ = logging.StreamHandler()
    ]
)
logger: Any = logging.getLogger(__name__)

class TrainingAnomalyDetector:
    """è®­ç»ƒå¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self, window_size: int = 10) -> None:
        self.window_size = window_size
        self.metrics_history = defaultdict(lambda: deque(maxlen=window_size))
        self.baseline_metrics = {}
        self.anomaly_thresholds = {
            'loss': 2.0,  # æŸå¤±å¼‚å¸¸é˜ˆå€¼ï¼ˆæ ‡å‡†å·®å€æ•°ï¼‰
            'accuracy': 0.1,  # å‡†ç¡®ç‡å¼‚å¸¸é˜ˆå€¼ï¼ˆä¸åŸºçº¿çš„å·®å¼‚ï¼‰
            'loss_spike': 0.5,  # æŸå¤±å°–å³°é˜ˆå€¼ï¼ˆå•æ­¥å˜åŒ–ï¼‰
            'accuracy_drop': 0.05  # å‡†ç¡®ç‡ä¸‹é™é˜ˆå€¼ï¼ˆå•æ­¥å˜åŒ–ï¼‰
        }
        self.error_handler = global_error_handler
    
    def update_baseline(self, metrics: Dict[str, float]):
        """æ›´æ–°åŸºçº¿æŒ‡æ ‡"""
        context = ErrorContext("TrainingAnomalyDetector", "update_baseline")
        try:
            for metric_name, value in metrics.items():
                if metric_name not in self.baseline_metrics:
                    self.baseline_metrics[metric_name] = []
                _ = self.baseline_metrics[metric_name].append(value)
                
                # ä¿æŒåŸºçº¿å†å²ä¸è¶…è¿‡100ä¸ªç‚¹
                if len(self.baseline_metrics[metric_name]) > 100:
                    _ = self.baseline_metrics[metric_name].pop(0)
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ æ›´æ–°åŸºçº¿æŒ‡æ ‡å¤±è´¥: {e}")
    
    def detect_anomalies(self, current_metrics: Dict[str, float]) -> List[Dict[str, Any]]:
        """æ£€æµ‹å¼‚å¸¸"""
        context = ErrorContext("TrainingAnomalyDetector", "detect_anomalies")
        anomalies = []
        
        try:
            for metric_name, current_value in current_metrics.items():
                # æ·»åŠ åˆ°å†å²è®°å½•
                _ = self.metrics_history[metric_name].append(current_value)
                
                # å¦‚æœå†å²è®°å½•ä¸è¶³ï¼Œè·³è¿‡å¼‚å¸¸æ£€æµ‹
                if len(self.metrics_history[metric_name]) < 3:
                    continue
                
                # è·å–å†å²æ•°æ®
                history = list(self.metrics_history[metric_name])
                
                # æ£€æµ‹æŸå¤±å°–å³°
                if metric_name == 'loss' and len(history) >= 2:
                    recent_change = abs(history[-1] - history[-2])
                    if recent_change > self.anomaly_thresholds['loss_spike']:
                        anomalies.append({
                            'type': 'loss_spike',
                            'metric': metric_name,
                            'current_value': current_value,
                            'previous_value': history[-2],
                            'change': recent_change,
                            'threshold': self.anomaly_thresholds['loss_spike'],
                            _ = 'timestamp': datetime.now().isoformat()
                        })
                
                # æ£€æµ‹å‡†ç¡®ç‡ä¸‹é™
                if metric_name == 'accuracy' and len(history) >= 2:
                    recent_change = history[-2] - history[-1]  # æ³¨æ„è¿™é‡Œæ˜¯ä¸‹é™
                    if recent_change > self.anomaly_thresholds['accuracy_drop']:
                        anomalies.append({
                            'type': 'accuracy_drop',
                            'metric': metric_name,
                            'current_value': current_value,
                            'previous_value': history[-2],
                            'change': recent_change,
                            'threshold': self.anomaly_thresholds['accuracy_drop'],
                            _ = 'timestamp': datetime.now().isoformat()
                        })
                
                # åŸºäºç»Ÿè®¡çš„å¼‚å¸¸æ£€æµ‹
                if len(history) >= 5:
                    mean_val = np.mean(history[:-1])  # æ’é™¤å½“å‰å€¼
                    std_val = np.std(history[:-1])
                    
                    # æ£€æµ‹åç¦»å‡å€¼è¿‡å¤šçš„å€¼
                    if std_val > 0:
                        z_score = abs(current_value - mean_val) / std_val
                        if z_score > self.anomaly_thresholds['loss']:
                            anomalies.append({
                                'type': 'statistical_anomaly',
                                'metric': metric_name,
                                'current_value': current_value,
                                'mean': mean_val,
                                'std': std_val,
                                'z_score': z_score,
                                'threshold': self.anomaly_thresholds['loss'],
                                _ = 'timestamp': datetime.now().isoformat()
                            })
            
            # æ£€æµ‹åŸºçº¿åç¦»
            for metric_name, baseline_history in self.baseline_metrics.items():
                if metric_name in current_metrics and len(baseline_history) >= 10:
                    current_value = current_metrics[metric_name]
                    baseline_mean = np.mean(baseline_history)
                    baseline_std = np.std(baseline_history)
                    
                    # å¦‚æœåŸºçº¿æ ‡å‡†å·®ä¸º0ï¼Œä½¿ç”¨å°çš„é»˜è®¤å€¼
                    if baseline_std == 0:
                        baseline_std = 1e-6
                    
                    # è®¡ç®—ä¸åŸºçº¿çš„åç¦»
                    baseline_deviation = abs(current_value - baseline_mean) / baseline_std
                    
                    if metric_name == 'accuracy' and current_value < baseline_mean - self.anomaly_thresholds['accuracy']:
                        anomalies.append({
                            'type': 'baseline_deviation',
                            'metric': metric_name,
                            'current_value': current_value,
                            'baseline_mean': baseline_mean,
                            'baseline_std': baseline_std,
                            'deviation': baseline_deviation,
                            'threshold': self.anomaly_thresholds['accuracy'],
                            _ = 'timestamp': datetime.now().isoformat()
                        })
            
            if anomalies:
                _ = logger.warning(f"âš ï¸  æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸")
                for anomaly in anomalies:
                    logger.warning(f"   {anomaly['type']}: {anomaly['metric']} = {anomaly['current_value']}")
            
            return anomalies
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
            return []

class SystemResourceMonitor:
    """ç³»ç»Ÿèµ„æºç›‘æ§å™¨"""
    
    def __init__(self) -> None:
        self.error_handler = global_error_handler
        self.resource_history = deque(maxlen=100)  # ä¿å­˜æœ€è¿‘100ä¸ªæ—¶é—´ç‚¹çš„èµ„æºæ•°æ®
    
    def get_system_resources(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        context = ErrorContext("SystemResourceMonitor", "get_system_resources")
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_available = memory.available
            memory_total = memory.total
            
            # ç£ç›˜ä½¿ç”¨æƒ…å†µ
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            disk_free = disk.free
            
            # ç½‘ç»œIO
            net_io = psutil.net_io_counters()
            bytes_sent = net_io.bytes_sent
            bytes_recv = net_io.bytes_recv
            
            resources = {
                _ = 'timestamp': datetime.now().isoformat(),
                'cpu_percent': cpu_percent,
                'memory_percent': memory_percent,
                _ = 'memory_available_gb': memory_available / (1024**3),
                _ = 'memory_total_gb': memory_total / (1024**3),
                'disk_percent': disk_percent,
                _ = 'disk_free_gb': disk_free / (1024**3),
                'network_bytes_sent': bytes_sent,
                'network_bytes_recv': bytes_recv
            }
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            _ = self.resource_history.append(resources)
            
            return resources
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ è·å–ç³»ç»Ÿèµ„æºå¤±è´¥: {e}")
            return {}
    
    def check_resource_alerts(self) -> List[Dict[str, Any]]:
        """æ£€æŸ¥èµ„æºè­¦å‘Š"""
        context = ErrorContext("SystemResourceMonitor", "check_resource_alerts")
        alerts = []
        
        try:
            if not self.resource_history:
                return alerts
            
            current = self.resource_history[-1]
            
            # CPUä½¿ç”¨ç‡è­¦å‘Š
            if current['cpu_percent'] > 90:
                alerts.append({
                    'type': 'high_cpu',
                    'level': 'critical',
                    'message': f"CPUä½¿ç”¨ç‡è¿‡é«˜: {current['cpu_percent']:.1f}%",
                    'value': current['cpu_percent'],
                    'threshold': 90,
                    'timestamp': current['timestamp']
                })
            elif current['cpu_percent'] > 80:
                alerts.append({
                    'type': 'high_cpu',
                    'level': 'warning',
                    'message': f"CPUä½¿ç”¨ç‡è¾ƒé«˜: {current['cpu_percent']:.1f}%",
                    'value': current['cpu_percent'],
                    'threshold': 80,
                    'timestamp': current['timestamp']
                })
            
            # å†…å­˜ä½¿ç”¨ç‡è­¦å‘Š
            if current['memory_percent'] > 90:
                alerts.append({
                    'type': 'high_memory',
                    'level': 'critical',
                    'message': f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {current['memory_percent']:.1f}%",
                    'value': current['memory_percent'],
                    'threshold': 90,
                    'timestamp': current['timestamp']
                })
            elif current['memory_percent'] > 80:
                alerts.append({
                    'type': 'high_memory',
                    'level': 'warning',
                    'message': f"å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜: {current['memory_percent']:.1f}%",
                    'value': current['memory_percent'],
                    'threshold': 80,
                    'timestamp': current['timestamp']
                })
            
            # ç£ç›˜ç©ºé—´è­¦å‘Š
            if current['disk_percent'] > 95:
                alerts.append({
                    'type': 'low_disk',
                    'level': 'critical',
                    'message': f"ç£ç›˜ç©ºé—´ä¸è¶³: {current['disk_free_gb']:.2f}GB å¯ç”¨",
                    'value': current['disk_free_gb'],
                    'threshold': 5,  # GB
                    'timestamp': current['timestamp']
                })
            elif current['disk_percent'] > 90:
                alerts.append({
                    'type': 'low_disk',
                    'level': 'warning',
                    'message': f"ç£ç›˜ç©ºé—´ç´§å¼ : {current['disk_free_gb']:.2f}GB å¯ç”¨",
                    'value': current['disk_free_gb'],
                    'threshold': 10,  # GB
                    'timestamp': current['timestamp']
                })
            
            if alerts:
                for alert in alerts:
                    if alert['level'] == 'critical':
                        _ = logger.critical(f"ğŸš¨ {alert['message']}")
                    else:
                        _ = logger.warning(f"âš ï¸  {alert['message']}")
            
            return alerts
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ æ£€æŸ¥èµ„æºè­¦å‘Šå¤±è´¥: {e}")
            return []

class TrainingPerformanceAnalyzer:
    """è®­ç»ƒæ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self) -> None:
        self.epoch_times = deque(maxlen=50)  # ä¿å­˜æœ€è¿‘50ä¸ªepochçš„æ—¶é—´
        self.error_handler = global_error_handler
    
    def record_epoch_time(self, epoch: int, duration: float):
        """è®°å½•epochè®­ç»ƒæ—¶é—´"""
        context = ErrorContext("TrainingPerformanceAnalyzer", "record_epoch_time")
        try:
            self.epoch_times.append({
                'epoch': epoch,
                'duration': duration,
                _ = 'timestamp': datetime.now().isoformat()
            })
            
            _ = logger.info(f"â±ï¸  Epoch {epoch} å®Œæˆï¼Œè€—æ—¶ {duration:.2f} ç§’")
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ è®°å½•epochæ—¶é—´å¤±è´¥: {e}")
    
    def analyze_performance_trends(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        context = ErrorContext("TrainingPerformanceAnalyzer", "analyze_performance_trends")
        try:
            if len(self.epoch_times) < 3:
                return {'status': 'insufficient_data'}
            
            durations = [record['duration'] for record in self.epoch_times]
            epochs = [record['epoch'] for record in self.epoch_times]
            
            # è®¡ç®—åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            mean_duration = np.mean(durations)
            std_duration = np.std(durations)
            min_duration = np.min(durations)
            max_duration = np.max(durations)
            
            # è®¡ç®—è¶‹åŠ¿ï¼ˆä½¿ç”¨çº¿æ€§å›å½’çš„æ–œç‡ï¼‰
            if len(epochs) >= 2:
                slope = np.polyfit(epochs, durations, 1)[0]
                trend = 'increasing' if slope > 0.1 else 'decreasing' if slope < -0.1 else 'stable'
            else:
                slope = 0
                trend = 'unknown'
            
            # æ£€æµ‹æ€§èƒ½å¼‚å¸¸
            performance_issues = []
            recent_durations = durations[-5:] if len(durations) >= 5 else durations
            if len(recent_durations) >= 3:
                recent_mean = np.mean(recent_durations)
                if recent_mean > mean_duration * 1.5:
                    performance_issues.append({
                        'type': 'performance_degradation',
                        _ = 'message': f"æœ€è¿‘epochå¹³å‡æ—¶é—´æ˜¾è‘—å¢åŠ  ({recent_mean:.2f}s vs {mean_duration:.2f}s)",
                        'severity': 'warning'
                    })
            
            analysis = {
                'status': 'analyzed',
                'mean_duration': mean_duration,
                'std_duration': std_duration,
                'min_duration': min_duration,
                'max_duration': max_duration,
                'trend': trend,
                'slope': slope,
                _ = 'total_epochs': len(self.epoch_times),
                'performance_issues': performance_issues
            }
            
            # è®°å½•åˆ†æç»“æœ
            _ = logger.info(f"ğŸ“Š æ€§èƒ½åˆ†æ: å¹³å‡ {mean_duration:.2f}s/epoch, è¶‹åŠ¿: {trend}")
            
            return analysis
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return {'status': 'error', 'message': str(e)}

class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å™¨ä¸»ç±»"""
    
    def __init__(self, log_file: str = None) -> None:
        self.log_file = Path(log_file) if log_file else project_root / 'training' / 'logs' / 'training_monitor.log'
        self.anomaly_detector = TrainingAnomalyDetector()
        self.resource_monitor = SystemResourceMonitor()
        self.performance_analyzer = TrainingPerformanceAnalyzer()
        self.error_handler = global_error_handler
        self.monitoring_enabled = True
        self.monitoring_thread = None
        self.stop_monitoring_flag = False  # ä¿®æ”¹å˜é‡åä»¥é¿å…å†²çª
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.log_file.parent.mkdir(parents=True, exist_ok=True)
        
        _ = logger.info("ğŸ”„ è®­ç»ƒç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        context = ErrorContext("TrainingMonitor", "start_monitoring")
        try:
            if self.monitoring_thread is None or not self.monitoring_thread.is_alive():
                self.stop_monitoring_flag = False  # ä¿®æ”¹å˜é‡å
                self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
                _ = self.monitoring_thread.start()
                _ = logger.info("âœ… è®­ç»ƒç›‘æ§å·²å¯åŠ¨")
            else:
                _ = logger.info("â„¹ï¸  è®­ç»ƒç›‘æ§å·²åœ¨è¿è¡Œä¸­")
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ å¯åŠ¨ç›‘æ§å¤±è´¥: {e}")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        context = ErrorContext("TrainingMonitor", "stop_monitoring")
        try:
            self.stop_monitoring_flag = True  # ä¿®æ”¹å˜é‡å
            if self.monitoring_thread and self.monitoring_thread.is_alive():
                self.monitoring_thread.join(timeout=5)
            _ = logger.info("â¹ï¸  è®­ç»ƒç›‘æ§å·²åœæ­¢")
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ åœæ­¢ç›‘æ§å¤±è´¥: {e}")
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        context = ErrorContext("TrainingMonitor", "_monitoring_loop")
        try:
            while not self.stop_monitoring_flag:  # ä¿®æ”¹å˜é‡å
                # è·å–ç³»ç»Ÿèµ„æº
                resources = self.resource_monitor.get_system_resources()
                
                # æ£€æŸ¥èµ„æºè­¦å‘Š
                alerts = self.resource_monitor.check_resource_alerts()
                
                # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
                if self.log_file:
                    log_entry = {
                        _ = 'timestamp': datetime.now().isoformat(),
                        'type': 'system_resources',
                        'data': resources,
                        'alerts': alerts
                    }
                    try:
                        with open(self.log_file, 'a', encoding='utf-8') as f:
                            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
                    except Exception as e:
                        _ = logger.error(f"âŒ å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
                
                # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                for _ in range(5):
                    if self.stop_monitoring_flag:  # ä¿®æ”¹å˜é‡å
                        break
                    _ = time.sleep(1)
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ ç›‘æ§å¾ªç¯å‡ºé”™: {e}")
    
    def update_training_metrics(self, scenario_name: str, epoch: int, metrics: Dict[str, float]):
        """æ›´æ–°è®­ç»ƒæŒ‡æ ‡"""
        context = ErrorContext("TrainingMonitor", "update_training_metrics", {"scenario_name": scenario_name})
        try:
            # æ›´æ–°å¼‚å¸¸æ£€æµ‹å™¨çš„åŸºçº¿
            _ = self.anomaly_detector.update_baseline(metrics)
            
            # æ£€æµ‹å¼‚å¸¸
            anomalies = self.anomaly_detector.detect_anomalies(metrics)
            
            # è®°å½•åˆ°æ—¥å¿—
            log_entry = {
                _ = 'timestamp': datetime.now().isoformat(),
                'type': 'training_metrics',
                'scenario': scenario_name,
                'epoch': epoch,
                'metrics': metrics,
                'anomalies': anomalies
            }
            
            if self.log_file:
                try:
                    with open(self.log_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
                except Exception as e:
                    _ = logger.error(f"âŒ å†™å…¥è®­ç»ƒæŒ‡æ ‡æ—¥å¿—å¤±è´¥: {e}")
            
            # å¦‚æœæ£€æµ‹åˆ°ä¸¥é‡å¼‚å¸¸ï¼Œè®°å½•è­¦å‘Š
            critical_anomalies = [a for a in anomalies if a.get('type') in ['loss_spike', 'accuracy_drop']]
            if critical_anomalies:
                for anomaly in critical_anomalies:
                    logger.warning(f"âš ï¸  è®­ç»ƒå¼‚å¸¸æ£€æµ‹: {anomaly['type']} - {anomaly['metric']} = {anomaly['current_value']}")
            
            return anomalies
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ æ›´æ–°è®­ç»ƒæŒ‡æ ‡å¤±è´¥: {e}")
            return []
    
    def record_epoch_completion(self, epoch: int, duration: float):
        """è®°å½•epochå®Œæˆ"""
        context = ErrorContext("TrainingMonitor", "record_epoch_completion")
        try:
            _ = self.performance_analyzer.record_epoch_time(epoch, duration)
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ è®°å½•epochå®Œæˆå¤±è´¥: {e}")
    
    def get_performance_analysis(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½åˆ†æ"""
        context = ErrorContext("TrainingMonitor", "get_performance_analysis")
        try:
            return self.performance_analyzer.analyze_performance_trends()
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ è·å–æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return {'status': 'error', 'message': str(e)}
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        context = ErrorContext("TrainingMonitor", "get_system_status")
        try:
            resources = self.resource_monitor.get_system_resources()
            alerts = self.resource_monitor.check_resource_alerts()
            
            status = {
                'resources': resources,
                'alerts': alerts,
                'monitoring_enabled': self.monitoring_enabled
            }
            
            return status
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {'status': 'error', 'message': str(e)}

# åˆ›å»ºå…¨å±€è®­ç»ƒç›‘æ§å™¨å®ä¾‹
global_training_monitor = TrainingMonitor()

def main() -> None:
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•ç›‘æ§å™¨"""
    _ = print("ğŸ”¬ æµ‹è¯•è®­ç»ƒç›‘æ§å™¨...")
    
    # åˆ›å»ºç›‘æ§å™¨å®ä¾‹
    monitor = TrainingMonitor()
    
    # å¯åŠ¨ç›‘æ§
    _ = monitor.start_monitoring()
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    _ = print("ğŸ”„ æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹...")
    
    # æ¨¡æ‹Ÿæ­£å¸¸è®­ç»ƒæŒ‡æ ‡
    normal_metrics = [
        {'loss': 0.8, 'accuracy': 0.6},
        {'loss': 0.6, 'accuracy': 0.7},
        {'loss': 0.5, 'accuracy': 0.75},
        {'loss': 0.4, 'accuracy': 0.8},
        {'loss': 0.35, 'accuracy': 0.82}
    ]
    
    for epoch, metrics in enumerate(normal_metrics, 1):
        _ = print(f"Epoch {epoch}: {metrics}")
        anomalies = monitor.update_training_metrics("test_scenario", epoch, metrics)
        _ = monitor.record_epoch_completion(epoch, 2.5)  # å‡è®¾æ¯ä¸ªepochè€—æ—¶2.5ç§’
        _ = time.sleep(1)  # æ¨¡æ‹Ÿè®­ç»ƒé—´éš”
    
    # æ¨¡æ‹Ÿå¼‚å¸¸æƒ…å†µ
    _ = print("\nâš ï¸  æ¨¡æ‹Ÿå¼‚å¸¸æƒ…å†µ...")
    anomaly_metrics = {'loss': 1.5, 'accuracy': 0.65}  # æŸå¤±çªç„¶å¢åŠ ï¼Œå‡†ç¡®ç‡ä¸‹é™
    _ = print(f"å¼‚å¸¸æŒ‡æ ‡: {anomaly_metrics}")
    anomalies = monitor.update_training_metrics("test_scenario", 6, anomaly_metrics)
    
    # è·å–æ€§èƒ½åˆ†æ
    _ = print("\nğŸ“Š æ€§èƒ½åˆ†æ:")
    performance_analysis = monitor.get_performance_analysis()
    _ = print(f"  {performance_analysis}")
    
    # è·å–ç³»ç»ŸçŠ¶æ€
    _ = print("\nğŸ–¥ï¸  ç³»ç»ŸçŠ¶æ€:")
    system_status = monitor.get_system_status()
    _ = print(f"  CPUä½¿ç”¨ç‡: {system_status['resources'].get('cpu_percent', 'N/A')}%")
    _ = print(f"  å†…å­˜ä½¿ç”¨ç‡: {system_status['resources'].get('memory_percent', 'N/A')}%")
    
    # åœæ­¢ç›‘æ§
    _ = monitor.stop_monitoring()
    
    _ = print("\nâœ… è®­ç»ƒç›‘æ§å™¨æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    _ = main()