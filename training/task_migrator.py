#!/usr/bin/env python3
"""
ä»»åŠ¡è¿ç§»å™¨
è´Ÿè´£åœ¨èŠ‚ç‚¹æ•…éšœæ—¶å°†ä»»åŠ¡è¿ç§»åˆ°å…¶ä»–å¥åº·çš„èŠ‚ç‚¹
"""

import asyncio
import logging
import json
import time
from typing import Dict, Any, List, Optional
from datetime import datetime
from dataclasses import dataclass, asdict

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
from pathlib import Path
project_root: str = Path(__file__).parent.parent
_ = sys.path.insert(0, str(project_root))


logger: Any = logging.getLogger(__name__)

@dataclass
class TaskMigrationInfo:
    """ä»»åŠ¡è¿ç§»ä¿¡æ¯"""
    task_id: str
    source_node_id: str
    target_node_id: str
    migration_time: float
    status: str  # 'pending', 'migrating', 'completed', 'failed'
    task_state: Dict[str, Any] = None
    retry_count: int = 0

class TaskMigrator:
    """ä»»åŠ¡è¿ç§»å™¨"""
    
    def __init__(self, distributed_optimizer: Any, config: Optional[Dict[str, Any]] = None) -> None:
        self.config = config or {}
        self.error_handler = global_error_handler
        self.distributed_optimizer = distributed_optimizer
        self.migration_tasks: Dict[str, TaskMigrationInfo] = {}
        self.migration_history: List[TaskMigrationInfo] = []
        self.max_retry_attempts = self.config.get('max_retry_attempts', 3)
        self.migration_strategy = self.config.get('migration_strategy', 'load_balanced')
        
        # æ³¨å†Œæ•…éšœå›è°ƒ
        _ = global_fault_detector.register_failure_callback(self._handle_node_failure)
        
        _ = logger.info("ä»»åŠ¡è¿ç§»å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def _handle_node_failure(self, failure_info: Dict[str, Any]):
        """å¤„ç†èŠ‚ç‚¹æ•…éšœ"""
        context = ErrorContext("TaskMigrator", "_handle_node_failure", failure_info)
        try:
            node_id = failure_info.get('node_id')
            assigned_tasks = failure_info.get('assigned_tasks', [])
            
            _ = logger.info(f"å¤„ç†èŠ‚ç‚¹ {node_id} çš„æ•…éšœï¼Œéœ€è¦è¿ç§» {len(assigned_tasks)} ä¸ªä»»åŠ¡")
            
            # ä¸ºæ¯ä¸ªåˆ†é…çš„ä»»åŠ¡åˆ›å»ºè¿ç§»ä»»åŠ¡
            for task_id in assigned_tasks:
                _ = await self.migrate_task_on_failure(task_id, node_id)
                
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"å¤„ç†èŠ‚ç‚¹æ•…éšœå¤±è´¥: {e}")
    
    async def migrate_task_on_failure(self, task_id: str, failed_node_id: str) -> bool:
        """åœ¨èŠ‚ç‚¹æ•…éšœæ—¶è¿ç§»ä»»åŠ¡"""
        context = ErrorContext("TaskMigrator", "migrate_task_on_failure", {
            "task_id": task_id, 
            "failed_node_id": failed_node_id
        })
        try:
            _ = logger.info(f"å¼€å§‹è¿ç§»ä»»åŠ¡ {task_id} ä»æ•…éšœèŠ‚ç‚¹ {failed_node_id}")
            
            # åˆ›å»ºè¿ç§»ä¿¡æ¯
            migration_info = TaskMigrationInfo(
                task_id=task_id,
                source_node_id=failed_node_id,
                target_node_id="",
                migration_time=time.time(),
                status="pending",
                task_state=None,
                retry_count=0
            )
            
            self.migration_tasks[task_id] = migration_info
            
            # ä¿å­˜ä»»åŠ¡çŠ¶æ€
            task_state = await self.save_task_state(task_id)
            migration_info.task_state = task_state
            
            # é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹
            target_node = await self._select_target_node(task_id, failed_node_id)
            if not target_node:
                _ = logger.error(f"æ— æ³•ä¸ºä»»åŠ¡ {task_id} é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹")
                migration_info.status = "failed"
                return False
            
            migration_info.target_node_id = target_node
            migration_info.status = "migrating"
            
            # æ‰§è¡Œä»»åŠ¡è¿ç§»
            success = await self._execute_task_migration(migration_info)
            
            if success:
                migration_info.status = "completed"
                _ = logger.info(f"ä»»åŠ¡ {task_id} è¿ç§»æˆåŠŸåˆ°èŠ‚ç‚¹ {target_node}")
            else:
                migration_info.status = "failed"
                _ = logger.error(f"ä»»åŠ¡ {task_id} è¿ç§»å¤±è´¥")
            
            # æ·»åŠ åˆ°è¿ç§»å†å²
            _ = self.migration_history.append(migration_info)
            
            # é™åˆ¶è¿ç§»å†å²è®°å½•æ•°é‡
            if len(self.migration_history) > 100:
                self.migration_history = self.migration_history[-50:]
            
            return success
            
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"è¿ç§»ä»»åŠ¡å¤±è´¥: {task_id} - {e}")
            return False
    
    async def save_task_state(self, task_id: str) -> Optional[Dict[str, Any]]:
        """ä¿å­˜ä»»åŠ¡çŠ¶æ€"""
        context = ErrorContext("TaskMigrator", "save_task_state", {"task_id": task_id})
        try:
            # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„ä»»åŠ¡çŠ¶æ€ä¿å­˜é€»è¾‘
            # å¯èƒ½åŒ…æ‹¬æ¨¡å‹çŠ¶æ€ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€è®­ç»ƒè¿›åº¦ç­‰
            
            _ = logger.info(f"ä¿å­˜ä»»åŠ¡ {task_id} çš„çŠ¶æ€")
            
            # æ¨¡æ‹Ÿä»»åŠ¡çŠ¶æ€
            task_state = {
                'task_id': task_id,
                'epoch': 5,  # ç¤ºä¾‹epoch
                'metrics': {
                    'loss': 0.45,
                    'accuracy': 0.82
                },
                'model_state': {},  # å®é™…é¡¹ç›®ä¸­ä¼šåŒ…å«æ¨¡å‹çŠ¶æ€
                'optimizer_state': {},  # å®é™…é¡¹ç›®ä¸­ä¼šåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€
                _ = 'timestamp': datetime.now().isoformat()
            }
            
            # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨æ£€æŸ¥ç‚¹ä¿å­˜åŠŸèƒ½
            # await self.checkpoint_manager.save_checkpoint(task_state, checkpoint_type='migration')
            
            return task_state
            
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"ä¿å­˜ä»»åŠ¡çŠ¶æ€å¤±è´¥: {task_id} - {e}")
            return None
    
    async def _select_target_node(self, task_id: str, failed_node_id: str) -> Optional[str]:
        """é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹"""
        context = ErrorContext("TaskMigrator", "_select_target_node", {
            "task_id": task_id, 
            "failed_node_id": failed_node_id
        })
        try:
            # è·å–æ‰€æœ‰å¥åº·èŠ‚ç‚¹
            healthy_nodes = []
            for node_id, node_status in global_fault_detector.nodes_status.items():
                if node_status.status in ['healthy', 'warning'] and node_id != failed_node_id:
                    _ = healthy_nodes.append(node_id)
            
            if not healthy_nodes:
                _ = logger.warning("æ²¡æœ‰å¯ç”¨çš„å¥åº·èŠ‚ç‚¹è¿›è¡Œä»»åŠ¡è¿ç§»")
                return None
            
            # æ ¹æ®è¿ç§»ç­–ç•¥é€‰æ‹©èŠ‚ç‚¹
            if self.migration_strategy == 'load_balanced':
                # é€‰æ‹©è´Ÿè½½æœ€ä½çš„èŠ‚ç‚¹
                return await self._select_least_loaded_node(healthy_nodes, task_id)
            elif self.migration_strategy == 'round_robin':
                # è½®è¯¢é€‰æ‹©èŠ‚ç‚¹
                return await self._select_round_robin_node(healthy_nodes, task_id)
            else:
                # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå¥åº·èŠ‚ç‚¹
                return healthy_nodes[0]
                
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹å¤±è´¥: {e}")
            return None
    
    async def _select_least_loaded_node(self, healthy_nodes: List[str], task_id: str) -> Optional[str]:
        """é€‰æ‹©è´Ÿè½½æœ€ä½çš„èŠ‚ç‚¹"""
        context = ErrorContext("TaskMigrator", "_select_least_loaded_node", {"task_id": task_id})
        try:
            if not hasattr(self.distributed_optimizer, 'nodes'):
                return healthy_nodes[0] if healthy_nodes else None
            
            min_load = float('inf')
            selected_node = None
            
            for node_id in healthy_nodes:
                if node_id in self.distributed_optimizer.nodes:
                    node_info = self.distributed_optimizer.nodes[node_id]
                    # è®¡ç®—èŠ‚ç‚¹è´Ÿè½½ï¼ˆç®€åŒ–å®ç°ï¼‰
                    cpu_load = node_info.get('performance_metrics', {}).get('cpu_usage', 0)
                    memory_load = node_info.get('performance_metrics', {}).get('memory_usage', 0)
                    task_count = len(node_info.get('assigned_tasks', []))
                    
                    # ç»¼åˆè´Ÿè½½è®¡ç®—
                    load = cpu_load * 0.5 + memory_load * 0.3 + task_count * 10
                    
                    if load < min_load:
                        min_load = load
                        selected_node = node_id
            
            return selected_node or (healthy_nodes[0] if healthy_nodes else None)
            
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"é€‰æ‹©è´Ÿè½½æœ€ä½èŠ‚ç‚¹å¤±è´¥: {e}")
            return healthy_nodes[0] if healthy_nodes else None
    
    async def _select_round_robin_node(self, healthy_nodes: List[str], task_id: str) -> Optional[str]:
        """è½®è¯¢é€‰æ‹©èŠ‚ç‚¹"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è½®è¯¢æœºåˆ¶
        if not hasattr(self, '_last_selected_node_index'):
            self._last_selected_node_index = 0
        
        if healthy_nodes:
            selected_node = healthy_nodes[self._last_selected_node_index % len(healthy_nodes)]
            self._last_selected_node_index += 1
            return selected_node
        
        return None
    
    async def _execute_task_migration(self, migration_info: TaskMigrationInfo) -> bool:
        """æ‰§è¡Œä»»åŠ¡è¿ç§»"""
        context = ErrorContext("TaskMigrator", "_execute_task_migration", {
            "task_id": migration_info.task_id,
            "target_node_id": migration_info.target_node_id
        })
        try:
            task_id = migration_info.task_id
            target_node_id = migration_info.target_node_id
            task_state = migration_info.task_state
            
            _ = logger.info(f"æ‰§è¡Œä»»åŠ¡ {task_id} åˆ°èŠ‚ç‚¹ {target_node_id} çš„è¿ç§»")
            
            # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„ä»»åŠ¡è¿ç§»é€»è¾‘
            # å¯èƒ½åŒ…æ‹¬ï¼š
            # 1. å°†ä»»åŠ¡çŠ¶æ€å‘é€åˆ°ç›®æ ‡èŠ‚ç‚¹
            # 2. åœ¨ç›®æ ‡èŠ‚ç‚¹ä¸Šæ¢å¤ä»»åŠ¡æ‰§è¡Œ
            # 3. æ›´æ–°ä»»åŠ¡åˆ†é…è®°å½•
            
            # æ¨¡æ‹Ÿè¿ç§»è¿‡ç¨‹
            _ = await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            
            # æ¨¡æ‹Ÿè¿ç§»æˆåŠŸ
            _ = logger.info(f"ä»»åŠ¡ {task_id} è¿ç§»å®Œæˆ")
            
            # æ›´æ–°åˆ†å¸ƒå¼ä¼˜åŒ–å™¨ä¸­çš„ä»»åŠ¡åˆ†é…
            if hasattr(self.distributed_optimizer, 'nodes'):
                # ä»æºèŠ‚ç‚¹ç§»é™¤ä»»åŠ¡
                if migration_info.source_node_id in self.distributed_optimizer.nodes:
                    source_node = self.distributed_optimizer.nodes[migration_info.source_node_id]
                    if 'assigned_tasks' in source_node:
                        if task_id in source_node['assigned_tasks']:
                            _ = source_node['assigned_tasks'].remove(task_id)
                
                # æ·»åŠ ä»»åŠ¡åˆ°ç›®æ ‡èŠ‚ç‚¹
                if target_node_id in self.distributed_optimizer.nodes:
                    target_node = self.distributed_optimizer.nodes[target_node_id]
                    if 'assigned_tasks' in target_node:
                        if task_id not in target_node['assigned_tasks']:
                            _ = target_node['assigned_tasks'].append(task_id)
            
            return True
            
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"æ‰§è¡Œä»»åŠ¡è¿ç§»å¤±è´¥: {task_id} - {e}")
            return False
    
    async def retry_migration(self, task_id: str) -> bool:
        """é‡è¯•ä»»åŠ¡è¿ç§»"""
        context = ErrorContext("TaskMigrator", "retry_migration", {"task_id": task_id})
        try:
            if task_id not in self.migration_tasks:
                _ = logger.warning(f"ä»»åŠ¡ {task_id} æ²¡æœ‰è¿ç§»è®°å½•")
                return False
            
            migration_info = self.migration_tasks[task_id]
            
            # æ£€æŸ¥é‡è¯•æ¬¡æ•°
            if migration_info.retry_count >= self.max_retry_attempts:
                _ = logger.error(f"ä»»åŠ¡ {task_id} è¿ç§»é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™")
                return False
            
            migration_info.retry_count += 1
            _ = logger.info(f"é‡è¯•ä»»åŠ¡ {task_id} çš„è¿ç§» (ç¬¬ {migration_info.retry_count} æ¬¡)")
            
            # é‡æ–°é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹
            target_node = await self._select_target_node(task_id, migration_info.source_node_id)
            if not target_node:
                _ = logger.error(f"æ— æ³•ä¸ºä»»åŠ¡ {task_id} é‡æ–°é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹")
                return False
            
            migration_info.target_node_id = target_node
            
            # æ‰§è¡Œè¿ç§»
            success = await self._execute_task_migration(migration_info)
            
            if success:
                migration_info.status = "completed"
                _ = logger.info(f"ä»»åŠ¡ {task_id} é‡è¯•è¿ç§»æˆåŠŸ")
            else:
                migration_info.status = "failed"
                _ = logger.error(f"ä»»åŠ¡ {task_id} é‡è¯•è¿ç§»å¤±è´¥")
            
            return success
            
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"é‡è¯•ä»»åŠ¡è¿ç§»å¤±è´¥: {task_id} - {e}")
            return False
    
    def get_migration_status(self, task_id: str = None) -> Dict[str, Any]:
        """è·å–è¿ç§»çŠ¶æ€"""
        context = ErrorContext("TaskMigrator", "get_migration_status", {"task_id": task_id})
        try:
            if task_id:
                if task_id in self.migration_tasks:
                    return asdict(self.migration_tasks[task_id])
                else:
                    return {}
            
            # è¿”å›æ‰€æœ‰è¿ç§»ä»»åŠ¡çš„çŠ¶æ€
            status = {
                _ = 'total_migrations': len(self.migration_tasks),
                'pending_migrations': len([t for t in self.migration_tasks.values() if t.status == 'pending']),
                'migrating_tasks': len([t for t in self.migration_tasks.values() if t.status == 'migrating']),
                'completed_migrations': len([t for t in self.migration_tasks.values() if t.status == 'completed']),
                'failed_migrations': len([t for t in self.migration_tasks.values() if t.status == 'failed']),
                'migration_tasks': [asdict(task_info) for task_info in self.migration_tasks.values()]
            }
            
            return status
            
        except Exception as e:
            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"è·å–è¿ç§»çŠ¶æ€å¤±è´¥: {e}")
            return {}

# å…¨å±€ä»»åŠ¡è¿ç§»å™¨å®ä¾‹ï¼ˆéœ€è¦åœ¨å®é™…ä½¿ç”¨æ—¶åˆå§‹åŒ–ï¼‰
global_task_migrator = None

def initialize_task_migrator(distributed_optimizer: Any, config: Optional[Dict[str, Any]] = None):
    """åˆå§‹åŒ–å…¨å±€ä»»åŠ¡è¿ç§»å™¨"""
    global global_task_migrator
    global_task_migrator = TaskMigrator(distributed_optimizer, config)
    return global_task_migrator

def main() -> None:
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•ä»»åŠ¡è¿ç§»å™¨"""
    _ = print("ğŸ”¬ æµ‹è¯•ä»»åŠ¡è¿ç§»å™¨...")
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„åˆ†å¸ƒå¼ä¼˜åŒ–å™¨
    class MockDistributedOptimizer:
        def __init__(self) -> None:
            self.nodes = {
                'node1': {
                    'assigned_tasks': ['task1', 'task2'],
                    'performance_metrics': {'cpu_usage': 45.0, 'memory_usage': 60.0}
                },
                'node2': {
                    'assigned_tasks': ['task3'],
                    'performance_metrics': {'cpu_usage': 30.0, 'memory_usage': 40.0}
                }
            }
    
    mock_optimizer = MockDistributedOptimizer()
    
    # åˆå§‹åŒ–ä»»åŠ¡è¿ç§»å™¨
    config = {
        'max_retry_attempts': 3,
        'migration_strategy': 'load_balanced'
    }
    migrator = TaskMigrator(mock_optimizer, config)
    
    # æ¨¡æ‹Ÿä»»åŠ¡è¿ç§»
    _ = print("æ¨¡æ‹Ÿä»»åŠ¡è¿ç§»...")
    _ = asyncio.run(migrator.migrate_task_on_failure('task1', 'node1'))
    
    # æ˜¾ç¤ºè¿ç§»çŠ¶æ€
    _ = print("\nè¿ç§»çŠ¶æ€:")
    status = migrator.get_migration_status()
    print(json.dumps(status, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    _ = main()