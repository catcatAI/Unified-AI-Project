#!/usr/bin/env python3
"""
ç»Ÿä¸€æ‰§è¡Œæ¡†æ¶
æä¾›æ ‡å‡†åŒ–çš„æ¨¡å‹è®­ç»ƒã€èµ„æºç®¡ç†å’Œé”™è¯¯å¤„ç†æœºåˆ¶
"""

import asyncio
import logging
import sys
from typing import Dict, Any, Optional, Callable, List
from pathlib import Path
from datetime import datetime
import threading
import time
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
backend_path = project_root / "apps" / "backend"
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(backend_path))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from apps.backend.src.path_config import (
        PROJECT_ROOT, 
        DATA_DIR, 
        TRAINING_DIR, 
        MODELS_DIR,
        get_data_path, 
        resolve_path
    )
except ImportError:
    # å¦‚æœè·¯å¾„é…ç½®æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„å¤„ç†
    PROJECT_ROOT = project_root
    DATA_DIR = PROJECT_ROOT / "data"
    TRAINING_DIR = PROJECT_ROOT / "training"
    MODELS_DIR = TRAINING_DIR / "models"

# å¯¼å…¥é”™è¯¯å¤„ç†æ¡†æ¶
try:
    from training.error_handling_framework import ErrorHandler, ErrorContext, global_error_handler, ErrorRecoveryStrategy
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œåˆ›å»ºæ¨¡æ‹Ÿç±»
    class ErrorHandler:
        def handle_error(self, error, context, strategy=None):
            print(f"Error handled: {error} in {context.component}.{context.operation}")
    
    class ErrorContext:
        def __init__(self, component, operation, details=None):
            self.component = component
            self.operation = operation
            self.details = details or {}
    
    class ErrorRecoveryStrategy:
        RETRY = "retry"
        FALLBACK = "fallback"
        SKIP = "skip"
        ABORT = "abort"
    
    global_error_handler = ErrorHandler()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ExecutionConfig:
    """æ‰§è¡Œé…ç½®"""
    
    def __init__(self, 
                 batch_size: int = 32,
                 epochs: int = 10,
                 learning_rate: float = 0.001,
                 use_gpu: bool = True,
                 distributed_training: bool = False,
                 checkpoint_interval: int = 5,
                 validation_split: float = 0.2):
        self.batch_size = batch_size
        self.epochs = epochs
        self.learning_rate = learning_rate
        self.use_gpu = use_gpu
        self.distributed_training = distributed_training
        self.checkpoint_interval = checkpoint_interval
        self.validation_split = validation_split

class ExecutionContext:
    """æ‰§è¡Œä¸Šä¸‹æ–‡"""
    
    def __init__(self, 
                 task_id: str,
                 config: ExecutionConfig,
                 model_name: str,
                 data_sources: List[str]):
        self.task_id = task_id
        self.config = config
        self.model_name = model_name
        self.data_sources = data_sources
        self.start_time = datetime.now()
        self.current_epoch = 0
        self.metrics = {}
        self.status = "initialized"  # initialized, running, completed, failed, paused
        self.progress = 0.0
        self.checkpoint_path = None
        self.error_handler = global_error_handler

class ExecutionResult:
    """æ‰§è¡Œç»“æœ"""
    
    def __init__(self, 
                 task_id: str,
                 success: bool,
                 metrics: Optional[Dict[str, Any]] = None,
                 error: Optional[str] = None,
                 execution_time: Optional[float] = None):
        self.task_id = task_id
        self.success = success
        self.metrics = metrics or {}
        self.error = error
        self.execution_time = execution_time

class UnifiedExecutor:
    """ç»Ÿä¸€æ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.tasks = {}
        self.results = {}
        self.error_handler = global_error_handler
        self.logger = logging.getLogger(__name__)
        
    async def execute_training_task(self, context: ExecutionContext, 
                                  training_function: Callable) -> ExecutionResult:
        """æ‰§è¡Œè®­ç»ƒä»»åŠ¡"""
        context.status = "running"
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œè®­ç»ƒä»»åŠ¡: {context.task_id}")
            self.logger.info(f"   æ¨¡å‹: {context.model_name}")
            self.logger.info(f"   æ•°æ®æº: {context.data_sources}")
            self.logger.info(f"   æ‰¹æ¬¡å¤§å°: {context.config.batch_size}")
            self.logger.info(f"   è®­ç»ƒè½®æ•°: {context.config.epochs}")
            
            # æ‰§è¡Œè®­ç»ƒå‡½æ•°
            result = await training_function(context)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.status = "completed"
            execution_time = time.time() - start_time
            
            self.logger.info(f"âœ… è®­ç»ƒä»»åŠ¡å®Œæˆ: {context.task_id}")
            self.logger.info(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=True,
                metrics=context.metrics,
                execution_time=execution_time
            )
            
        except Exception as e:
            context.status = "failed"
            execution_time = time.time() - start_time
            
            # å¤„ç†é”™è¯¯
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="execute_training_task",
                details={
                    "task_id": context.task_id,
                    "model_name": context.model_name
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            
            self.logger.error(f"âŒ è®­ç»ƒä»»åŠ¡å¤±è´¥: {context.task_id}")
            self.logger.error(f"   é”™è¯¯: {str(e)}")
            self.logger.error(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=False,
                error=str(e),
                execution_time=execution_time
            )
            
    async def execute_data_processing_task(self, context: ExecutionContext,
                                         processing_function: Callable) -> ExecutionResult:
        """æ‰§è¡Œæ•°æ®å¤„ç†ä»»åŠ¡"""
        context.status = "running"
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ“¦ å¼€å§‹æ‰§è¡Œæ•°æ®å¤„ç†ä»»åŠ¡: {context.task_id}")
            self.logger.info(f"   æ•°æ®æº: {context.data_sources}")
            
            # æ‰§è¡Œå¤„ç†å‡½æ•°
            result = await processing_function(context)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.status = "completed"
            execution_time = time.time() - start_time
            
            self.logger.info(f"âœ… æ•°æ®å¤„ç†ä»»åŠ¡å®Œæˆ: {context.task_id}")
            self.logger.info(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=True,
                metrics=context.metrics,
                execution_time=execution_time
            )
            
        except Exception as e:
            context.status = "failed"
            execution_time = time.time() - start_time
            
            # å¤„ç†é”™è¯¯
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="execute_data_processing_task",
                details={
                    "task_id": context.task_id,
                    "data_sources": context.data_sources
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            
            self.logger.error(f"âŒ æ•°æ®å¤„ç†ä»»åŠ¡å¤±è´¥: {context.task_id}")
            self.logger.error(f"   é”™è¯¯: {str(e)}")
            self.logger.error(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=False,
                error=str(e),
                execution_time=execution_time
            )
            
    async def execute_model_inference_task(self, context: ExecutionContext,
                                         inference_function: Callable) -> ExecutionResult:
        """æ‰§è¡Œæ¨¡å‹æ¨ç†ä»»åŠ¡"""
        context.status = "running"
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ§  å¼€å§‹æ‰§è¡Œæ¨¡å‹æ¨ç†ä»»åŠ¡: {context.task_id}")
            self.logger.info(f"   æ¨¡å‹: {context.model_name}")
            self.logger.info(f"   æ•°æ®æº: {context.data_sources}")
            
            # æ‰§è¡Œæ¨ç†å‡½æ•°
            result = await inference_function(context)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.status = "completed"
            execution_time = time.time() - start_time
            
            self.logger.info(f"âœ… æ¨¡å‹æ¨ç†ä»»åŠ¡å®Œæˆ: {context.task_id}")
            self.logger.info(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=True,
                metrics=context.metrics,
                execution_time=execution_time
            )
            
        except Exception as e:
            context.status = "failed"
            execution_time = time.time() - start_time
            
            # å¤„ç†é”™è¯¯
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="execute_model_inference_task",
                details={
                    "task_id": context.task_id,
                    "model_name": context.model_name
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            
            self.logger.error(f"âŒ æ¨¡å‹æ¨ç†ä»»åŠ¡å¤±è´¥: {context.task_id}")
            self.logger.error(f"   é”™è¯¯: {str(e)}")
            self.logger.error(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=False,
                error=str(e),
                execution_time=execution_time
            )
            
    def pause_task(self, task_id: str) -> bool:
        """æš‚åœä»»åŠ¡"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            context.status = "paused"
            self.logger.info(f"â¸ï¸  ä»»åŠ¡å·²æš‚åœ: {task_id}")
            return True
        else:
            self.logger.warning(f"âš ï¸  æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}")
            return False
            
    def resume_task(self, task_id: str) -> bool:
        """æ¢å¤ä»»åŠ¡"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            if context.status == "paused":
                context.status = "running"
                self.logger.info(f"â–¶ï¸  ä»»åŠ¡å·²æ¢å¤: {task_id}")
                return True
            else:
                self.logger.warning(f"âš ï¸  ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æ¢å¤: {task_id} (å½“å‰çŠ¶æ€: {context.status})")
                return False
        else:
            self.logger.warning(f"âš ï¸  æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}")
            return False
            
    def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            context.status = "cancelled"
            self.logger.info(f"â¹ï¸  ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")
            return True
        else:
            self.logger.warning(f"âš ï¸  æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}")
            return False
            
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            return {
                "task_id": context.task_id,
                "status": context.status,
                "progress": context.progress,
                "metrics": context.metrics,
                "start_time": context.start_time.isoformat() if context.start_time else None,
                "current_epoch": context.current_epoch
            }
        else:
            return None
            
    def get_all_tasks_status(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€"""
        status_dict = {}
        for task_id, context in self.tasks.items():
            status_dict[task_id] = {
                "task_id": context.task_id,
                "status": context.status,
                "progress": context.progress,
                "metrics": context.metrics,
                "start_time": context.start_time.isoformat() if context.start_time else None,
                "current_epoch": context.current_epoch
            }
        return status_dict
        
    def save_checkpoint(self, context: ExecutionContext, checkpoint_path: str) -> bool:
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        try:
            # ç¡®ä¿æ£€æŸ¥ç‚¹ç›®å½•å­˜åœ¨
            checkpoint_dir = Path(checkpoint_path).parent
            checkpoint_dir.mkdir(parents=True, exist_ok=True)
            
            checkpoint_data = {
                "task_id": context.task_id,
                "model_name": context.model_name,
                "current_epoch": context.current_epoch,
                "metrics": context.metrics,
                "config": {
                    "batch_size": context.config.batch_size,
                    "epochs": context.config.epochs,
                    "learning_rate": context.config.learning_rate
                },
                "timestamp": datetime.now().isoformat()
            }
            
            with open(checkpoint_path, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
                
            context.checkpoint_path = checkpoint_path
            self.logger.info(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
            return True
            
        except Exception as e:
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="save_checkpoint",
                details={
                    "task_id": context.task_id,
                    "checkpoint_path": checkpoint_path
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            self.logger.error(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return False
            
    def load_checkpoint(self, context: ExecutionContext, checkpoint_path: str) -> bool:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        try:
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)
                
            context.current_epoch = checkpoint_data.get("current_epoch", 0)
            context.metrics = checkpoint_data.get("metrics", {})
            context.checkpoint_path = checkpoint_path
            
            self.logger.info(f"ğŸ“‚ æ£€æŸ¥ç‚¹å·²åŠ è½½: {checkpoint_path}")
            return True
            
        except Exception as e:
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="load_checkpoint",
                details={
                    "task_id": context.task_id,
                    "checkpoint_path": checkpoint_path
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            self.logger.error(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return False

class ResourceManager:
    """èµ„æºç®¡ç†å™¨"""
    
    def __init__(self):
        self.allocated_resources = {}
        self.logger = logging.getLogger(__name__)
        
    def allocate_cpu_resources(self, task_id: str, cores: int) -> bool:
        """åˆ†é…CPUèµ„æº"""
        try:
            # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„èµ„æºåˆ†é…é€»è¾‘
            # ç®€åŒ–å®ç°ï¼Œä»…è®°å½•åˆ†é…
            self.allocated_resources[task_id] = {
                "type": "cpu",
                "cores": cores,
                "allocated_at": datetime.now().isoformat()
            }
            
            self.logger.info(f"ğŸ–¥ï¸  å·²åˆ†é…CPUèµ„æº: {task_id} - {cores} æ ¸å¿ƒ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†é…CPUèµ„æºå¤±è´¥: {e}")
            return False
            
    def allocate_memory_resources(self, task_id: str, memory_gb: float) -> bool:
        """åˆ†é…å†…å­˜èµ„æº"""
        try:
            # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„èµ„æºåˆ†é…é€»è¾‘
            # ç®€åŒ–å®ç°ï¼Œä»…è®°å½•åˆ†é…
            self.allocated_resources[task_id] = {
                "type": "memory",
                "memory_gb": memory_gb,
                "allocated_at": datetime.now().isoformat()
            }
            
            self.logger.info(f"ğŸ§  å·²åˆ†é…å†…å­˜èµ„æº: {task_id} - {memory_gb} GB")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†é…å†…å­˜èµ„æºå¤±è´¥: {e}")
            return False
            
    def allocate_gpu_resources(self, task_id: str, gpus: int) -> bool:
        """åˆ†é…GPUèµ„æº"""
        try:
            # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„èµ„æºåˆ†é…é€»è¾‘
            # ç®€åŒ–å®ç°ï¼Œä»…è®°å½•åˆ†é…
            self.allocated_resources[task_id] = {
                "type": "gpu",
                "gpus": gpus,
                "allocated_at": datetime.now().isoformat()
            }
            
            self.logger.info(f"ğŸ® å·²åˆ†é…GPUèµ„æº: {task_id} - {gpus} GPU")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†é…GPUèµ„æºå¤±è´¥: {e}")
            return False
            
    def release_resources(self, task_id: str) -> bool:
        """é‡Šæ”¾èµ„æº"""
        if task_id in self.allocated_resources:
            resource_info = self.allocated_resources[task_id]
            resource_type = resource_info["type"]
            
            del self.allocated_resources[task_id]
            self.logger.info(f"ğŸ”„ å·²é‡Šæ”¾{resource_type.upper()}èµ„æº: {task_id}")
            return True
        else:
            self.logger.warning(f"âš ï¸  æœªæ‰¾åˆ°èµ„æºåˆ†é…è®°å½•: {task_id}")
            return False
            
    def get_resource_usage(self) -> Dict[str, Any]:
        """è·å–èµ„æºä½¿ç”¨æƒ…å†µ"""
        cpu_cores = sum(info["cores"] for info in self.allocated_resources.values() if info["type"] == "cpu")
        memory_gb = sum(info["memory_gb"] for info in self.allocated_resources.values() if info["type"] == "memory")
        gpus = sum(info["gpus"] for info in self.allocated_resources.values() if info["type"] == "gpu")
        
        return {
            "allocated_cpu_cores": cpu_cores,
            "allocated_memory_gb": memory_gb,
            "allocated_gpus": gpus,
            "total_tasks": len(self.allocated_resources)
        }

# å…¨å±€æ‰§è¡Œå™¨å’Œèµ„æºç®¡ç†å™¨å®ä¾‹
global_executor = UnifiedExecutor()
global_resource_manager = ResourceManager()

def create_training_context(task_id: str, model_name: str, data_sources: List[str],
                          config: Optional[ExecutionConfig] = None) -> ExecutionContext:
    """åˆ›å»ºè®­ç»ƒä¸Šä¸‹æ–‡"""
    if config is None:
        config = ExecutionConfig()
        
    return ExecutionContext(
        task_id=task_id,
        config=config,
        model_name=model_name,
        data_sources=data_sources
    )

def create_data_processing_context(task_id: str, data_sources: List[str],
                                 config: Optional[ExecutionConfig] = None) -> ExecutionContext:
    """åˆ›å»ºæ•°æ®å¤„ç†ä¸Šä¸‹æ–‡"""
    if config is None:
        config = ExecutionConfig()
        
    return ExecutionContext(
        task_id=task_id,
        config=config,
        model_name="data_processor",
        data_sources=data_sources
    )

def create_inference_context(task_id: str, model_name: str, data_sources: List[str],
                           config: Optional[ExecutionConfig] = None) -> ExecutionContext:
    """åˆ›å»ºæ¨ç†ä¸Šä¸‹æ–‡"""
    if config is None:
        config = ExecutionConfig()
        
    return ExecutionContext(
        task_id=task_id,
        config=config,
        model_name=model_name,
        data_sources=data_sources
    )

# ç¤ºä¾‹è®­ç»ƒå‡½æ•°
async def example_training_function(context: ExecutionContext) -> Dict[str, Any]:
    """ç¤ºä¾‹è®­ç»ƒå‡½æ•°"""
    logger.info(f"æ­£åœ¨è®­ç»ƒæ¨¡å‹: {context.model_name}")
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for epoch in range(context.config.epochs):
        context.current_epoch = epoch + 1
        context.progress = (epoch + 1) / context.config.epochs * 100
        
        # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
        context.metrics = {
            "epoch": epoch + 1,
            "loss": 1.0 - (epoch / context.config.epochs),
            "accuracy": 0.5 + (epoch / context.config.epochs) * 0.5,
            "val_loss": 1.1 - (epoch / context.config.epochs),
            "val_accuracy": 0.4 + (epoch / context.config.epochs) * 0.5
        }
        
        logger.info(f"Epoch {epoch + 1}/{context.config.epochs} - "
                   f"Loss: {context.metrics['loss']:.4f}, "
                   f"Accuracy: {context.metrics['accuracy']:.4f}")
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
        await asyncio.sleep(0.1)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % context.config.checkpoint_interval == 0:
            checkpoint_path = f"checkpoints/{context.task_id}_epoch_{epoch + 1}.json"
            global_executor.save_checkpoint(context, checkpoint_path)
    
    return {"status": "completed", "final_metrics": context.metrics}

# ç¤ºä¾‹æ•°æ®å¤„ç†å‡½æ•°
async def example_data_processing_function(context: ExecutionContext) -> Dict[str, Any]:
    """ç¤ºä¾‹æ•°æ®å¤„ç†å‡½æ•°"""
    logger.info(f"æ­£åœ¨å¤„ç†æ•°æ®æº: {context.data_sources}")
    
    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†è¿‡ç¨‹
    for i in range(10):
        context.progress = (i + 1) / 10 * 100
        
        logger.info(f"æ•°æ®å¤„ç†è¿›åº¦: {context.progress:.1f}%")
        
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        await asyncio.sleep(0.05)
    
    context.metrics = {
        "processed_files": 100,
        "processed_records": 10000,
        "processing_time": 5.0
    }
    
    return {"status": "completed", "metrics": context.metrics}

# ç¤ºä¾‹æ¨ç†å‡½æ•°
async def example_inference_function(context: ExecutionContext) -> Dict[str, Any]:
    """ç¤ºä¾‹æ¨ç†å‡½æ•°"""
    logger.info(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹ {context.model_name} è¿›è¡Œæ¨ç†")
    
    # æ¨¡æ‹Ÿæ¨ç†è¿‡ç¨‹
    for i in range(5):
        context.progress = (i + 1) / 5 * 100
        
        logger.info(f"æ¨ç†è¿›åº¦: {context.progress:.1f}%")
        
        # æ¨¡æ‹Ÿæ¨ç†æ—¶é—´
        await asyncio.sleep(0.1)
    
    context.metrics = {
        "inference_time": 2.5,
        "predictions_made": 500,
        "confidence_score": 0.85
    }
    
    return {"status": "completed", "metrics": context.metrics}

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç»Ÿä¸€æ‰§è¡Œæ¡†æ¶çš„ä½¿ç”¨"""
    logger.info("ğŸ”„ å¯åŠ¨ç»Ÿä¸€æ‰§è¡Œæ¡†æ¶æ¼”ç¤º")
    
    # åˆ›å»ºæ‰§è¡Œå™¨å’Œèµ„æºç®¡ç†å™¨
    executor = global_executor
    resource_manager = global_resource_manager
    
    # ç¤ºä¾‹1: è®­ç»ƒä»»åŠ¡
    logger.info("\nğŸ“ ç¤ºä¾‹1: è®­ç»ƒä»»åŠ¡")
    training_config = ExecutionConfig(
        batch_size=64,
        epochs=5,
        learning_rate=0.001,
        use_gpu=True,
        checkpoint_interval=2
    )
    
    training_context = create_training_context(
        task_id="train_task_001",
        model_name="vision_service",
        data_sources=["vision_samples", "flickr30k_sample"],
        config=training_config
    )
    
    # åˆ†é…èµ„æº
    resource_manager.allocate_cpu_resources("train_task_001", 4)
    resource_manager.allocate_memory_resources("train_task_001", 8.0)
    resource_manager.allocate_gpu_resources("train_task_001", 1)
    
    # æ‰§è¡Œè®­ç»ƒä»»åŠ¡
    training_result = asyncio.run(
        executor.execute_training_task(training_context, example_training_function)
    )
    
    logger.info(f"è®­ç»ƒç»“æœ: {'æˆåŠŸ' if training_result.success else 'å¤±è´¥'}")
    if training_result.success:
        logger.info(f"æœ€ç»ˆæŒ‡æ ‡: {training_result.metrics}")
    else:
        logger.error(f"é”™è¯¯ä¿¡æ¯: {training_result.error}")
    
    # é‡Šæ”¾èµ„æº
    resource_manager.release_resources("train_task_001")
    
    # ç¤ºä¾‹2: æ•°æ®å¤„ç†ä»»åŠ¡
    logger.info("\nğŸ“ ç¤ºä¾‹2: æ•°æ®å¤„ç†ä»»åŠ¡")
    processing_context = create_data_processing_context(
        task_id="process_task_001",
        data_sources=["data/vision_samples", "data/audio_samples"]
    )
    
    # åˆ†é…èµ„æº
    resource_manager.allocate_cpu_resources("process_task_001", 2)
    resource_manager.allocate_memory_resources("process_task_001", 4.0)
    
    # æ‰§è¡Œæ•°æ®å¤„ç†ä»»åŠ¡
    processing_result = asyncio.run(
        executor.execute_data_processing_task(processing_context, example_data_processing_function)
    )
    
    logger.info(f"å¤„ç†ç»“æœ: {'æˆåŠŸ' if processing_result.success else 'å¤±è´¥'}")
    if processing_result.success:
        logger.info(f"å¤„ç†æŒ‡æ ‡: {processing_result.metrics}")
    else:
        logger.error(f"é”™è¯¯ä¿¡æ¯: {processing_result.error}")
    
    # é‡Šæ”¾èµ„æº
    resource_manager.release_resources("process_task_001")
    
    # ç¤ºä¾‹3: æ¨¡å‹æ¨ç†ä»»åŠ¡
    logger.info("\nğŸ“ ç¤ºä¾‹3: æ¨¡å‹æ¨ç†ä»»åŠ¡")
    inference_context = create_inference_context(
        task_id="inference_task_001",
        model_name="causal_reasoning_engine",
        data_sources=["reasoning_samples"]
    )
    
    # åˆ†é…èµ„æº
    resource_manager.allocate_cpu_resources("inference_task_001", 2)
    resource_manager.allocate_memory_resources("inference_task_001", 2.0)
    
    # æ‰§è¡Œæ¨ç†ä»»åŠ¡
    inference_result = asyncio.run(
        executor.execute_model_inference_task(inference_context, example_inference_function)
    )
    
    logger.info(f"æ¨ç†ç»“æœ: {'æˆåŠŸ' if inference_result.success else 'å¤±è´¥'}")
    if inference_result.success:
        logger.info(f"æ¨ç†æŒ‡æ ‡: {inference_result.metrics}")
    else:
        logger.error(f"é”™è¯¯ä¿¡æ¯: {inference_result.error}")
    
    # é‡Šæ”¾èµ„æº
    resource_manager.release_resources("inference_task_001")
    
    # æ˜¾ç¤ºèµ„æºä½¿ç”¨æƒ…å†µ
    resource_usage = resource_manager.get_resource_usage()
    logger.info(f"\nğŸ“Š èµ„æºä½¿ç”¨æƒ…å†µ: {resource_usage}")
    
    # æ˜¾ç¤ºæ‰€æœ‰ä»»åŠ¡çŠ¶æ€
    all_status = executor.get_all_tasks_status()
    logger.info(f"\nğŸ“‹ æ‰€æœ‰ä»»åŠ¡çŠ¶æ€: {all_status}")
    
    logger.info("\nâœ… ç»Ÿä¸€æ‰§è¡Œæ¡†æ¶æ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    main()