#!/usr/bin/env python3
"""
统一执行框架
提供标准化的模型训练、资源管理和错误处理机制
"""

import asyncio
import logging
import sys
from typing import Dict, Any, Optional, Callable, List
from pathlib import Path
from datetime import datetime
import threading
import time
import json

# 添加项目路径
project_root = Path(__file__).parent.parent
backend_path = project_root / "apps" / "backend"
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(backend_path))

# 导入项目模块
try:
    from apps.backend.src.path_config import (
        PROJECT_ROOT, 
        DATA_DIR, 
        TRAINING_DIR, 
        MODELS_DIR,
        get_data_path, 
        resolve_path
    )
except ImportError:
    # 如果路径配置模块不可用，使用默认路径处理
    PROJECT_ROOT = project_root
    DATA_DIR = PROJECT_ROOT / "data"
    TRAINING_DIR = PROJECT_ROOT / "training"
    MODELS_DIR = TRAINING_DIR / "models"

# 导入错误处理框架
try:
    from training.error_handling_framework import ErrorHandler, ErrorContext, global_error_handler, ErrorRecoveryStrategy
except ImportError:
    # 如果无法导入，创建模拟类
    class ErrorHandler:
        def handle_error(self, error, context, strategy=None):
            print(f"Error handled: {error} in {context.component}.{context.operation}")
    
    class ErrorContext:
        def __init__(self, component, operation, details=None):
            self.component = component
            self.operation = operation
            self.details = details or {}
    
    class ErrorRecoveryStrategy:
        RETRY = "retry"
        FALLBACK = "fallback"
        SKIP = "skip"
        ABORT = "abort"
    
    global_error_handler = ErrorHandler()

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ExecutionConfig:
    """执行配置"""
    
    def __init__(self, 
                 batch_size: int = 32,
                 epochs: int = 10,
                 learning_rate: float = 0.001,
                 use_gpu: bool = True,
                 distributed_training: bool = False,
                 checkpoint_interval: int = 5,
                 validation_split: float = 0.2):
        self.batch_size = batch_size
        self.epochs = epochs
        self.learning_rate = learning_rate
        self.use_gpu = use_gpu
        self.distributed_training = distributed_training
        self.checkpoint_interval = checkpoint_interval
        self.validation_split = validation_split

class ExecutionContext:
    """执行上下文"""
    
    def __init__(self, 
                 task_id: str,
                 config: ExecutionConfig,
                 model_name: str,
                 data_sources: List[str]):
        self.task_id = task_id
        self.config = config
        self.model_name = model_name
        self.data_sources = data_sources
        self.start_time = datetime.now()
        self.current_epoch = 0
        self.metrics = {}
        self.status = "initialized"  # initialized, running, completed, failed, paused
        self.progress = 0.0
        self.checkpoint_path = None
        self.error_handler = global_error_handler

class ExecutionResult:
    """执行结果"""
    
    def __init__(self, 
                 task_id: str,
                 success: bool,
                 metrics: Optional[Dict[str, Any]] = None,
                 error: Optional[str] = None,
                 execution_time: Optional[float] = None):
        self.task_id = task_id
        self.success = success
        self.metrics = metrics or {}
        self.error = error
        self.execution_time = execution_time

class UnifiedExecutor:
    """统一执行器"""
    
    def __init__(self):
        self.tasks = {}
        self.results = {}
        self.error_handler = global_error_handler
        self.logger = logging.getLogger(__name__)
        
    async def execute_training_task(self, context: ExecutionContext, 
                                  training_function: Callable) -> ExecutionResult:
        """执行训练任务"""
        context.status = "running"
        start_time = time.time()
        
        try:
            self.logger.info(f"🚀 开始执行训练任务: {context.task_id}")
            self.logger.info(f"   模型: {context.model_name}")
            self.logger.info(f"   数据源: {context.data_sources}")
            self.logger.info(f"   批次大小: {context.config.batch_size}")
            self.logger.info(f"   训练轮数: {context.config.epochs}")
            
            # 执行训练函数
            result = await training_function(context)
            
            # 更新上下文
            context.status = "completed"
            execution_time = time.time() - start_time
            
            self.logger.info(f"✅ 训练任务完成: {context.task_id}")
            self.logger.info(f"   执行时间: {execution_time:.2f} 秒")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=True,
                metrics=context.metrics,
                execution_time=execution_time
            )
            
        except Exception as e:
            context.status = "failed"
            execution_time = time.time() - start_time
            
            # 处理错误
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="execute_training_task",
                details={
                    "task_id": context.task_id,
                    "model_name": context.model_name
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            
            self.logger.error(f"❌ 训练任务失败: {context.task_id}")
            self.logger.error(f"   错误: {str(e)}")
            self.logger.error(f"   执行时间: {execution_time:.2f} 秒")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=False,
                error=str(e),
                execution_time=execution_time
            )
            
    async def execute_data_processing_task(self, context: ExecutionContext,
                                         processing_function: Callable) -> ExecutionResult:
        """执行数据处理任务"""
        context.status = "running"
        start_time = time.time()
        
        try:
            self.logger.info(f"📦 开始执行数据处理任务: {context.task_id}")
            self.logger.info(f"   数据源: {context.data_sources}")
            
            # 执行处理函数
            result = await processing_function(context)
            
            # 更新上下文
            context.status = "completed"
            execution_time = time.time() - start_time
            
            self.logger.info(f"✅ 数据处理任务完成: {context.task_id}")
            self.logger.info(f"   执行时间: {execution_time:.2f} 秒")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=True,
                metrics=context.metrics,
                execution_time=execution_time
            )
            
        except Exception as e:
            context.status = "failed"
            execution_time = time.time() - start_time
            
            # 处理错误
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="execute_data_processing_task",
                details={
                    "task_id": context.task_id,
                    "data_sources": context.data_sources
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            
            self.logger.error(f"❌ 数据处理任务失败: {context.task_id}")
            self.logger.error(f"   错误: {str(e)}")
            self.logger.error(f"   执行时间: {execution_time:.2f} 秒")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=False,
                error=str(e),
                execution_time=execution_time
            )
            
    async def execute_model_inference_task(self, context: ExecutionContext,
                                         inference_function: Callable) -> ExecutionResult:
        """执行模型推理任务"""
        context.status = "running"
        start_time = time.time()
        
        try:
            self.logger.info(f"🧠 开始执行模型推理任务: {context.task_id}")
            self.logger.info(f"   模型: {context.model_name}")
            self.logger.info(f"   数据源: {context.data_sources}")
            
            # 执行推理函数
            result = await inference_function(context)
            
            # 更新上下文
            context.status = "completed"
            execution_time = time.time() - start_time
            
            self.logger.info(f"✅ 模型推理任务完成: {context.task_id}")
            self.logger.info(f"   执行时间: {execution_time:.2f} 秒")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=True,
                metrics=context.metrics,
                execution_time=execution_time
            )
            
        except Exception as e:
            context.status = "failed"
            execution_time = time.time() - start_time
            
            # 处理错误
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="execute_model_inference_task",
                details={
                    "task_id": context.task_id,
                    "model_name": context.model_name
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            
            self.logger.error(f"❌ 模型推理任务失败: {context.task_id}")
            self.logger.error(f"   错误: {str(e)}")
            self.logger.error(f"   执行时间: {execution_time:.2f} 秒")
            
            return ExecutionResult(
                task_id=context.task_id,
                success=False,
                error=str(e),
                execution_time=execution_time
            )
            
    def pause_task(self, task_id: str) -> bool:
        """暂停任务"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            context.status = "paused"
            self.logger.info(f"⏸️  任务已暂停: {task_id}")
            return True
        else:
            self.logger.warning(f"⚠️  未找到任务: {task_id}")
            return False
            
    def resume_task(self, task_id: str) -> bool:
        """恢复任务"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            if context.status == "paused":
                context.status = "running"
                self.logger.info(f"▶️  任务已恢复: {task_id}")
                return True
            else:
                self.logger.warning(f"⚠️  任务状态不允许恢复: {task_id} (当前状态: {context.status})")
                return False
        else:
            self.logger.warning(f"⚠️  未找到任务: {task_id}")
            return False
            
    def cancel_task(self, task_id: str) -> bool:
        """取消任务"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            context.status = "cancelled"
            self.logger.info(f"⏹️  任务已取消: {task_id}")
            return True
        else:
            self.logger.warning(f"⚠️  未找到任务: {task_id}")
            return False
            
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """获取任务状态"""
        if task_id in self.tasks:
            context = self.tasks[task_id]
            return {
                "task_id": context.task_id,
                "status": context.status,
                "progress": context.progress,
                "metrics": context.metrics,
                "start_time": context.start_time.isoformat() if context.start_time else None,
                "current_epoch": context.current_epoch
            }
        else:
            return None
            
    def get_all_tasks_status(self) -> Dict[str, Dict[str, Any]]:
        """获取所有任务状态"""
        status_dict = {}
        for task_id, context in self.tasks.items():
            status_dict[task_id] = {
                "task_id": context.task_id,
                "status": context.status,
                "progress": context.progress,
                "metrics": context.metrics,
                "start_time": context.start_time.isoformat() if context.start_time else None,
                "current_epoch": context.current_epoch
            }
        return status_dict
        
    def save_checkpoint(self, context: ExecutionContext, checkpoint_path: str) -> bool:
        """保存检查点"""
        try:
            # 确保检查点目录存在
            checkpoint_dir = Path(checkpoint_path).parent
            checkpoint_dir.mkdir(parents=True, exist_ok=True)
            
            checkpoint_data = {
                "task_id": context.task_id,
                "model_name": context.model_name,
                "current_epoch": context.current_epoch,
                "metrics": context.metrics,
                "config": {
                    "batch_size": context.config.batch_size,
                    "epochs": context.config.epochs,
                    "learning_rate": context.config.learning_rate
                },
                "timestamp": datetime.now().isoformat()
            }
            
            with open(checkpoint_path, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
                
            context.checkpoint_path = checkpoint_path
            self.logger.info(f"💾 检查点已保存: {checkpoint_path}")
            return True
            
        except Exception as e:
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="save_checkpoint",
                details={
                    "task_id": context.task_id,
                    "checkpoint_path": checkpoint_path
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            self.logger.error(f"❌ 保存检查点失败: {e}")
            return False
            
    def load_checkpoint(self, context: ExecutionContext, checkpoint_path: str) -> bool:
        """加载检查点"""
        try:
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)
                
            context.current_epoch = checkpoint_data.get("current_epoch", 0)
            context.metrics = checkpoint_data.get("metrics", {})
            context.checkpoint_path = checkpoint_path
            
            self.logger.info(f"📂 检查点已加载: {checkpoint_path}")
            return True
            
        except Exception as e:
            error_context = ErrorContext(
                component="UnifiedExecutor",
                operation="load_checkpoint",
                details={
                    "task_id": context.task_id,
                    "checkpoint_path": checkpoint_path
                }
            )
            
            self.error_handler.handle_error(e, error_context)
            self.logger.error(f"❌ 加载检查点失败: {e}")
            return False

class ResourceManager:
    """资源管理器"""
    
    def __init__(self):
        self.allocated_resources = {}
        self.logger = logging.getLogger(__name__)
        
    def allocate_cpu_resources(self, task_id: str, cores: int) -> bool:
        """分配CPU资源"""
        try:
            # 这里应该实现实际的资源分配逻辑
            # 简化实现，仅记录分配
            self.allocated_resources[task_id] = {
                "type": "cpu",
                "cores": cores,
                "allocated_at": datetime.now().isoformat()
            }
            
            self.logger.info(f"🖥️  已分配CPU资源: {task_id} - {cores} 核心")
            return True
            
        except Exception as e:
            self.logger.error(f"❌ 分配CPU资源失败: {e}")
            return False
            
    def allocate_memory_resources(self, task_id: str, memory_gb: float) -> bool:
        """分配内存资源"""
        try:
            # 这里应该实现实际的资源分配逻辑
            # 简化实现，仅记录分配
            self.allocated_resources[task_id] = {
                "type": "memory",
                "memory_gb": memory_gb,
                "allocated_at": datetime.now().isoformat()
            }
            
            self.logger.info(f"🧠 已分配内存资源: {task_id} - {memory_gb} GB")
            return True
            
        except Exception as e:
            self.logger.error(f"❌ 分配内存资源失败: {e}")
            return False
            
    def allocate_gpu_resources(self, task_id: str, gpus: int) -> bool:
        """分配GPU资源"""
        try:
            # 这里应该实现实际的资源分配逻辑
            # 简化实现，仅记录分配
            self.allocated_resources[task_id] = {
                "type": "gpu",
                "gpus": gpus,
                "allocated_at": datetime.now().isoformat()
            }
            
            self.logger.info(f"🎮 已分配GPU资源: {task_id} - {gpus} GPU")
            return True
            
        except Exception as e:
            self.logger.error(f"❌ 分配GPU资源失败: {e}")
            return False
            
    def release_resources(self, task_id: str) -> bool:
        """释放资源"""
        if task_id in self.allocated_resources:
            resource_info = self.allocated_resources[task_id]
            resource_type = resource_info["type"]
            
            del self.allocated_resources[task_id]
            self.logger.info(f"🔄 已释放{resource_type.upper()}资源: {task_id}")
            return True
        else:
            self.logger.warning(f"⚠️  未找到资源分配记录: {task_id}")
            return False
            
    def get_resource_usage(self) -> Dict[str, Any]:
        """获取资源使用情况"""
        cpu_cores = sum(info["cores"] for info in self.allocated_resources.values() if info["type"] == "cpu")
        memory_gb = sum(info["memory_gb"] for info in self.allocated_resources.values() if info["type"] == "memory")
        gpus = sum(info["gpus"] for info in self.allocated_resources.values() if info["type"] == "gpu")
        
        return {
            "allocated_cpu_cores": cpu_cores,
            "allocated_memory_gb": memory_gb,
            "allocated_gpus": gpus,
            "total_tasks": len(self.allocated_resources)
        }

# 全局执行器和资源管理器实例
global_executor = UnifiedExecutor()
global_resource_manager = ResourceManager()

def create_training_context(task_id: str, model_name: str, data_sources: List[str],
                          config: Optional[ExecutionConfig] = None) -> ExecutionContext:
    """创建训练上下文"""
    if config is None:
        config = ExecutionConfig()
        
    return ExecutionContext(
        task_id=task_id,
        config=config,
        model_name=model_name,
        data_sources=data_sources
    )

def create_data_processing_context(task_id: str, data_sources: List[str],
                                 config: Optional[ExecutionConfig] = None) -> ExecutionContext:
    """创建数据处理上下文"""
    if config is None:
        config = ExecutionConfig()
        
    return ExecutionContext(
        task_id=task_id,
        config=config,
        model_name="data_processor",
        data_sources=data_sources
    )

def create_inference_context(task_id: str, model_name: str, data_sources: List[str],
                           config: Optional[ExecutionConfig] = None) -> ExecutionContext:
    """创建推理上下文"""
    if config is None:
        config = ExecutionConfig()
        
    return ExecutionContext(
        task_id=task_id,
        config=config,
        model_name=model_name,
        data_sources=data_sources
    )

# 示例训练函数
async def example_training_function(context: ExecutionContext) -> Dict[str, Any]:
    """示例训练函数"""
    logger.info(f"正在训练模型: {context.model_name}")
    
    # 模拟训练过程
    for epoch in range(context.config.epochs):
        context.current_epoch = epoch + 1
        context.progress = (epoch + 1) / context.config.epochs * 100
        
        # 模拟训练指标
        context.metrics = {
            "epoch": epoch + 1,
            "loss": 1.0 - (epoch / context.config.epochs),
            "accuracy": 0.5 + (epoch / context.config.epochs) * 0.5,
            "val_loss": 1.1 - (epoch / context.config.epochs),
            "val_accuracy": 0.4 + (epoch / context.config.epochs) * 0.5
        }
        
        logger.info(f"Epoch {epoch + 1}/{context.config.epochs} - "
                   f"Loss: {context.metrics['loss']:.4f}, "
                   f"Accuracy: {context.metrics['accuracy']:.4f}")
        
        # 模拟训练时间
        await asyncio.sleep(0.1)
        
        # 检查是否需要保存检查点
        if (epoch + 1) % context.config.checkpoint_interval == 0:
            checkpoint_path = f"checkpoints/{context.task_id}_epoch_{epoch + 1}.json"
            global_executor.save_checkpoint(context, checkpoint_path)
    
    return {"status": "completed", "final_metrics": context.metrics}

# 示例数据处理函数
async def example_data_processing_function(context: ExecutionContext) -> Dict[str, Any]:
    """示例数据处理函数"""
    logger.info(f"正在处理数据源: {context.data_sources}")
    
    # 模拟数据处理过程
    for i in range(10):
        context.progress = (i + 1) / 10 * 100
        
        logger.info(f"数据处理进度: {context.progress:.1f}%")
        
        # 模拟处理时间
        await asyncio.sleep(0.05)
    
    context.metrics = {
        "processed_files": 100,
        "processed_records": 10000,
        "processing_time": 5.0
    }
    
    return {"status": "completed", "metrics": context.metrics}

# 示例推理函数
async def example_inference_function(context: ExecutionContext) -> Dict[str, Any]:
    """示例推理函数"""
    logger.info(f"正在使用模型 {context.model_name} 进行推理")
    
    # 模拟推理过程
    for i in range(5):
        context.progress = (i + 1) / 5 * 100
        
        logger.info(f"推理进度: {context.progress:.1f}%")
        
        # 模拟推理时间
        await asyncio.sleep(0.1)
    
    context.metrics = {
        "inference_time": 2.5,
        "predictions_made": 500,
        "confidence_score": 0.85
    }
    
    return {"status": "completed", "metrics": context.metrics}

def main():
    """主函数 - 演示统一执行框架的使用"""
    logger.info("🔄 启动统一执行框架演示")
    
    # 创建执行器和资源管理器
    executor = global_executor
    resource_manager = global_resource_manager
    
    # 示例1: 训练任务
    logger.info("\n📝 示例1: 训练任务")
    training_config = ExecutionConfig(
        batch_size=64,
        epochs=5,
        learning_rate=0.001,
        use_gpu=True,
        checkpoint_interval=2
    )
    
    training_context = create_training_context(
        task_id="train_task_001",
        model_name="vision_service",
        data_sources=["vision_samples", "flickr30k_sample"],
        config=training_config
    )
    
    # 分配资源
    resource_manager.allocate_cpu_resources("train_task_001", 4)
    resource_manager.allocate_memory_resources("train_task_001", 8.0)
    resource_manager.allocate_gpu_resources("train_task_001", 1)
    
    # 执行训练任务
    training_result = asyncio.run(
        executor.execute_training_task(training_context, example_training_function)
    )
    
    logger.info(f"训练结果: {'成功' if training_result.success else '失败'}")
    if training_result.success:
        logger.info(f"最终指标: {training_result.metrics}")
    else:
        logger.error(f"错误信息: {training_result.error}")
    
    # 释放资源
    resource_manager.release_resources("train_task_001")
    
    # 示例2: 数据处理任务
    logger.info("\n📝 示例2: 数据处理任务")
    processing_context = create_data_processing_context(
        task_id="process_task_001",
        data_sources=["data/vision_samples", "data/audio_samples"]
    )
    
    # 分配资源
    resource_manager.allocate_cpu_resources("process_task_001", 2)
    resource_manager.allocate_memory_resources("process_task_001", 4.0)
    
    # 执行数据处理任务
    processing_result = asyncio.run(
        executor.execute_data_processing_task(processing_context, example_data_processing_function)
    )
    
    logger.info(f"处理结果: {'成功' if processing_result.success else '失败'}")
    if processing_result.success:
        logger.info(f"处理指标: {processing_result.metrics}")
    else:
        logger.error(f"错误信息: {processing_result.error}")
    
    # 释放资源
    resource_manager.release_resources("process_task_001")
    
    # 示例3: 模型推理任务
    logger.info("\n📝 示例3: 模型推理任务")
    inference_context = create_inference_context(
        task_id="inference_task_001",
        model_name="causal_reasoning_engine",
        data_sources=["reasoning_samples"]
    )
    
    # 分配资源
    resource_manager.allocate_cpu_resources("inference_task_001", 2)
    resource_manager.allocate_memory_resources("inference_task_001", 2.0)
    
    # 执行推理任务
    inference_result = asyncio.run(
        executor.execute_model_inference_task(inference_context, example_inference_function)
    )
    
    logger.info(f"推理结果: {'成功' if inference_result.success else '失败'}")
    if inference_result.success:
        logger.info(f"推理指标: {inference_result.metrics}")
    else:
        logger.error(f"错误信息: {inference_result.error}")
    
    # 释放资源
    resource_manager.release_resources("inference_task_001")
    
    # 显示资源使用情况
    resource_usage = resource_manager.get_resource_usage()
    logger.info(f"\n📊 资源使用情况: {resource_usage}")
    
    # 显示所有任务状态
    all_status = executor.get_all_tasks_status()
    logger.info(f"\n📋 所有任务状态: {all_status}")
    
    logger.info("\n✅ 统一执行框架演示完成")

if __name__ == "__main__":
    main()