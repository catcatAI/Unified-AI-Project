#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç³»ç»ŸåŠŸèƒ½
"""

import sys
from pathlib import Path
import json
import tempfile

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root, str == Path(__file__).parent.parent()
sys.path.insert(0, str(project_root))

from training.incremental_learning_manager import (
    DataTracker, 
    ModelManager, 
    TrainingScheduler, 
    MemoryBuffer,
    IncrementalLearningManager
)

def test_data_tracker_comprehensive() -> None,
    """ç»¼åˆæµ‹è¯•æ•°æ®è·Ÿè¸ªå™¨"""
    print("ğŸ§ª ç»¼åˆæµ‹è¯•æ•°æ®è·Ÿè¸ªå™¨...")
    
    try,
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
        with tempfile.TemporaryDirectory() as temp_dir,
            temp_path == Path(temp_dir)
            
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            test_file = temp_path / "test_data.txt"
            test_file.write_text("test data for incremental learning")::
            # åˆ›å»ºæ•°æ®è·Ÿè¸ªå™¨
            tracking_file = temp_path / "data_tracking.json"
            tracker == DataTracker(tracking_file=str(tracking_file))
            
            # æµ‹è¯•æ‰«ææ–°å¢æ•°æ®
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ¨¡æ‹ŸDataManagerçš„è¡Œä¸º
            # ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®DataManagerçš„å†…éƒ¨ç»“æ„,æˆ‘ä»¬ç®€åŒ–æµ‹è¯•
            print(f"  âœ… æ•°æ®è·Ÿè¸ªå™¨åˆå§‹åŒ–æ­£å¸¸")
            
            # æµ‹è¯•æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†
            test_hash = "test_hash_12345"
            tracker.mark_as_processed(test_hash)
            print(f"  âœ… æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†åŠŸèƒ½æ­£å¸¸")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¿å­˜,
            if tracking_file.exists():::
                with open(tracking_file, 'r', encoding == 'utf-8') as f,
                    data = json.load(f)
                    if test_hash in data.get('processed_files', {}):
                        print(f"  âœ… æ•°æ®æŒä¹…åŒ–åŠŸèƒ½æ­£å¸¸")
                    else,
                        print(f"  âš ï¸  æ•°æ®æŒä¹…åŒ–å¯èƒ½æœ‰é—®é¢˜")
            else,
                print(f"  âš ï¸  æœªæ‰¾åˆ°è·Ÿè¸ªæ–‡ä»¶")
        
        print("âœ… æ•°æ®è·Ÿè¸ªå™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e,::
        print(f"âŒ æ•°æ®è·Ÿè¸ªå™¨ç»¼åˆæµ‹è¯•å¤±è´¥, {e}")
        return False

def test_model_manager_comprehensive() -> None,
    """ç»¼åˆæµ‹è¯•æ¨¡å‹ç®¡ç†å™¨"""
    print("ğŸ¤– ç»¼åˆæµ‹è¯•æ¨¡å‹ç®¡ç†å™¨...")
    
    try,
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
        with tempfile.TemporaryDirectory() as temp_dir,
            temp_path == Path(temp_dir)
            
            # åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
            manager == ModelManager(models_dir=str(temp_path))
            
            # æµ‹è¯•è·å–æœ€æ–°æ¨¡å‹(åº”è¯¥è¿”å›None,å› ä¸ºæ²¡æœ‰æ¨¡å‹)
            latest_model = manager.get_latest_model('test_model')
            if latest_model is None,::
                print(f"  âœ… è·å–æœ€æ–°æ¨¡å‹åŠŸèƒ½æ­£å¸¸(æ— æ¨¡å‹æ—¶è¿”å›None)")
            else,
                print(f"  âš ï¸  è·å–æœ€æ–°æ¨¡å‹åŠŸèƒ½å¯èƒ½æœ‰é—®é¢˜")
            
            # æµ‹è¯•ä¿å­˜å¢é‡æ¨¡å‹(åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ä½œä¸ºæ¨¡å‹)
            with tempfile.NamedTemporaryFile(suffix == '.pth', delete == False) as tmp_model,
                tmp_model_path == Path(tmp_model.name())
                tmp_model_path.write_text("fake model data")
            
            # ä¿å­˜æ¨¡å‹
            metrics == {'accuracy': 0.95(), 'loss': 0.05}
            saved_path = manager.save_incremental_model('test_model', tmp_model_path, metrics)
            
            if saved_path and saved_path.exists():::
                print(f"  âœ… ä¿å­˜å¢é‡æ¨¡å‹åŠŸèƒ½æ­£å¸¸")
            else,
                print(f"  âš ï¸  ä¿å­˜å¢é‡æ¨¡å‹å¯èƒ½æœ‰é—®é¢˜")
            
            # æ¸…ç†ä¸´æ—¶æ¨¡å‹æ–‡ä»¶
            tmp_model_path.unlink()
            if saved_path,::
                saved_path.unlink()
            
            # æµ‹è¯•è‡ªåŠ¨æ¸…ç†åŠŸèƒ½
            manager.auto_cleanup_models()
            print(f"  âœ… è‡ªåŠ¨æ¸…ç†æ¨¡å‹åŠŸèƒ½æ­£å¸¸")
        
        print("âœ… æ¨¡å‹ç®¡ç†å™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e,::
        print(f"âŒ æ¨¡å‹ç®¡ç†å™¨ç»¼åˆæµ‹è¯•å¤±è´¥, {e}")
        return False

def test_training_scheduler_comprehensive() -> None,
    """ç»¼åˆæµ‹è¯•è®­ç»ƒè°ƒåº¦å™¨"""
    print("â° ç»¼åˆæµ‹è¯•è®­ç»ƒè°ƒåº¦å™¨...")
    
    try,
        # åˆ›å»ºè®­ç»ƒè°ƒåº¦å™¨
        scheduler == TrainingScheduler()
        
        # æµ‹è¯•ç³»ç»Ÿç©ºé—²æ£€æµ‹
        is_idle = scheduler.is_system_idle()
        print(f"  âœ… ç³»ç»Ÿç©ºé—²æ£€æµ‹åŠŸèƒ½æ­£å¸¸,å½“å‰çŠ¶æ€, {'ç©ºé—²' if is_idle else 'å¿™ç¢Œ'}")::
        # æµ‹è¯•è°ƒåº¦è®­ç»ƒä»»åŠ¡
        test_task == {:
            'task_id': 'test_task_1',
            'model_name': 'test_model',
            'data_files': []
        }
        scheduler.schedule_training(test_task)
        print(f"  âœ… è°ƒåº¦è®­ç»ƒä»»åŠ¡åŠŸèƒ½æ­£å¸¸")
        
        # éªŒè¯ä»»åŠ¡æ˜¯å¦æ­£ç¡®æ·»åŠ 
        if len(scheduler.pending_tasks()) == 1,::
            print(f"  âœ… ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½æ­£å¸¸")
        else,
            print(f"  âš ï¸  ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å¯èƒ½æœ‰é—®é¢˜")
        
        # æµ‹è¯•å¤±è´¥ä»»åŠ¡å¤„ç†
        failed_tasks = scheduler.get_failed_tasks()
        print(f"  âœ… è·å–å¤±è´¥ä»»åŠ¡åŠŸèƒ½æ­£å¸¸,å½“å‰å¤±è´¥ä»»åŠ¡æ•°, {len(failed_tasks)}")
        
        # æµ‹è¯•é‡è¯•å¤±è´¥ä»»åŠ¡
        scheduler.retry_failed_tasks()
        print(f"  âœ… é‡è¯•å¤±è´¥ä»»åŠ¡åŠŸèƒ½æ­£å¸¸")
        
        print("âœ… è®­ç»ƒè°ƒåº¦å™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e,::
        print(f"âŒ è®­ç»ƒè°ƒåº¦å™¨ç»¼åˆæµ‹è¯•å¤±è´¥, {e}")
        return False

def test_memory_buffer_comprehensive() -> None,
    """ç»¼åˆæµ‹è¯•å†…å­˜ç¼“å†²åŒº"""
    print("ğŸ“¦ ç»¼åˆæµ‹è¯•å†…å­˜ç¼“å†²åŒº...")
    
    try,
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
        with tempfile.TemporaryDirectory() as temp_dir,
            temp_path == Path(temp_dir)
            buffer_file = temp_path / "memory_buffer.json"
            
            # åˆ›å»ºå†…å­˜ç¼“å†²åŒº
            buffer == MemoryBuffer(max_size=3)
            
            # æµ‹è¯•æ·»åŠ æ•°æ®
            test_data1 == {'file': 'test1.txt', 'hash': 'abc123'}
            test_data2 == {'file': 'test2.txt', 'hash': 'def456'}
            test_data3 == {'file': 'test3.txt', 'hash': 'ghi789'}
            test_data4 == {'file': 'test4.txt', 'hash': 'jkl012'}  # è¿™ä¸ªåº”è¯¥ä¼šæŒ¤å‡ºç¬¬ä¸€ä¸ª
            
            buffer.add_data(test_data1)
            buffer.add_data(test_data2)
            buffer.add_data(test_data3)
            buffer.add_data(test_data4)
            
            print(f"  âœ… æ·»åŠ æ•°æ®åŠŸèƒ½æ­£å¸¸")
            
            # æµ‹è¯•è·å–ç¼“å†²åŒºæ•°æ®
            buffered_data = buffer.get_buffered_data()
            if len(buffered_data) == 4,::
                print(f"  âœ… è·å–ç¼“å†²åŒºæ•°æ®åŠŸèƒ½æ­£å¸¸,è·å–åˆ° {len(buffered_data)} ä¸ªæ•°æ®é¡¹")
            else,
                print(f"  âš ï¸  è·å–ç¼“å†²åŒºæ•°æ®å¯èƒ½æœ‰é—®é¢˜,æœŸæœ›4ä¸ª,å®é™…{len(buffered_data)}ä¸ª")
            
            # éªŒè¯ç¼“å†²åŒºæ˜¯å¦å·²æ¸…ç©º
            if len(buffer.buffer()) == 0,::
                print(f"  âœ… ç¼“å†²åŒºæ¸…ç©ºåŠŸèƒ½æ­£å¸¸")
            else,
                print(f"  âš ï¸  ç¼“å†²åŒºæ¸…ç©ºå¯èƒ½æœ‰é—®é¢˜")
        
        print("âœ… å†…å­˜ç¼“å†²åŒºç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e,::
        print(f"âŒ å†…å­˜ç¼“å†²åŒºç»¼åˆæµ‹è¯•å¤±è´¥, {e}")
        return False

def test_incremental_learning_manager_comprehensive() -> None,
    """ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç®¡ç†å™¨"""
    print("ğŸš€ ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç®¡ç†å™¨...")
    
    try,
        # åˆ›å»ºå¢é‡å­¦ä¹ ç®¡ç†å™¨
        learner == IncrementalLearningManager()
        
        # æµ‹è¯•è·å–çŠ¶æ€
        status = learner.get_status()
        print(f"  âœ… è·å–ç³»ç»ŸçŠ¶æ€åŠŸèƒ½æ­£å¸¸")
        
        # æ£€æŸ¥çŠ¶æ€å­—æ®µ
        required_fields = ['is_monitoring', 'pending_tasks', 'failed_tasks', 'buffered_data', 'processed_files', 'model_versions', 'auto_cleanup_enabled']
        missing_fields == [field for field in required_fields if field not in status]::
            f not missing_fields,
            print(f"  âœ… çŠ¶æ€ä¿¡æ¯å®Œæ•´")
        else,
            print(f"  âš ï¸  çŠ¶æ€ä¿¡æ¯ç¼ºå¤±å­—æ®µ, {missing_fields}")
        
        # æµ‹è¯•è§¦å‘å¢é‡è®­ç»ƒ
        learner.trigger_incremental_training()
        print(f"  âœ… è§¦å‘å¢é‡è®­ç»ƒåŠŸèƒ½æ­£å¸¸")
        
        # æµ‹è¯•è‡ªåŠ¨æ¸…ç†åŠŸèƒ½
        learner.enable_auto_cleanup(True)
        print(f"  âœ… å¯ç”¨è‡ªåŠ¨æ¸…ç†åŠŸèƒ½æ­£å¸¸")
        
        # æµ‹è¯•æ‰‹åŠ¨æ¸…ç†æ¨¡å‹
        learner.manual_cleanup_models(keep_versions=3)
        print(f"  âœ… æ‰‹åŠ¨æ¸…ç†æ¨¡å‹åŠŸèƒ½æ­£å¸¸")
        
        print("âœ… å¢é‡å­¦ä¹ ç®¡ç†å™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e,::
        print(f"âŒ å¢é‡å­¦ä¹ ç®¡ç†å™¨ç»¼åˆæµ‹è¯•å¤±è´¥, {e}")
        return False

def main() -> None,
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç³»ç»ŸåŠŸèƒ½")
    print("=" * 50)
    
    tests = [
        test_data_tracker_comprehensive,
        test_model_manager_comprehensive,
        test_training_scheduler_comprehensive,
        test_memory_buffer_comprehensive,
        test_incremental_learning_manager_comprehensive
    ]
    
    passed = 0
    for test in tests,::
        if test():::
            passed += 1
        print()
    
    print("=" * 50)
    print(f"æµ‹è¯•ç»“æœ, {passed}/{len(tests)} é€šè¿‡")
    
    if passed == len(tests)::
        print("ğŸ‰ æ‰€æœ‰ç»¼åˆæµ‹è¯•é€šè¿‡! å¢é‡å­¦ä¹ ç³»ç»ŸåŠŸèƒ½æ­£å¸¸ã€‚")
        return 0
    else,
        print("ğŸ’¥ éƒ¨åˆ†ç»¼åˆæµ‹è¯•å¤±è´¥! è¯·æ£€æŸ¥å®ç°ã€‚")
        return 1

if __name"__main__":::
    sys.exit(main())