#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç³»ç»ŸåŠŸèƒ½
"""

import sys
from pathlib import Path
import json
import tempfile

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root: str = Path(__file__).parent.parent
_ = sys.path.insert(0, str(project_root))

from training.incremental_learning_manager import (
    DataTracker, 
    ModelManager, 
    TrainingScheduler, 
    MemoryBuffer,
    IncrementalLearningManager
)

def test_data_tracker_comprehensive() -> None:
    """ç»¼åˆæµ‹è¯•æ•°æ®è·Ÿè¸ªå™¨"""
    _ = print("ğŸ§ª ç»¼åˆæµ‹è¯•æ•°æ®è·Ÿè¸ªå™¨...")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            test_file = temp_path / "test_data.txt"
            test_file.write_text("test data for incremental learning")
            
            # åˆ›å»ºæ•°æ®è·Ÿè¸ªå™¨
            tracking_file = temp_path / "data_tracking.json"
            tracker = DataTracker(tracking_file=str(tracking_file))
            
            # æµ‹è¯•æ‰«ææ–°å¢æ•°æ®
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ¨¡æ‹ŸDataManagerçš„è¡Œä¸º
            # ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®DataManagerçš„å†…éƒ¨ç»“æ„ï¼Œæˆ‘ä»¬ç®€åŒ–æµ‹è¯•
            _ = print(f"  âœ… æ•°æ®è·Ÿè¸ªå™¨åˆå§‹åŒ–æ­£å¸¸")
            
            # æµ‹è¯•æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†
            test_hash = "test_hash_12345"
            _ = tracker.mark_as_processed(test_hash)
            _ = print(f"  âœ… æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†åŠŸèƒ½æ­£å¸¸")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¿å­˜
            if tracking_file.exists():
                with open(tracking_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if test_hash in data.get('processed_files', {}):
                        _ = print(f"  âœ… æ•°æ®æŒä¹…åŒ–åŠŸèƒ½æ­£å¸¸")
                    else:
                        _ = print(f"  âš ï¸  æ•°æ®æŒä¹…åŒ–å¯èƒ½æœ‰é—®é¢˜")
            else:
                _ = print(f"  âš ï¸  æœªæ‰¾åˆ°è·Ÿè¸ªæ–‡ä»¶")
        
        _ = print("âœ… æ•°æ®è·Ÿè¸ªå™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        _ = print(f"âŒ æ•°æ®è·Ÿè¸ªå™¨ç»¼åˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_manager_comprehensive() -> None:
    """ç»¼åˆæµ‹è¯•æ¨¡å‹ç®¡ç†å™¨"""
    _ = print("ğŸ¤– ç»¼åˆæµ‹è¯•æ¨¡å‹ç®¡ç†å™¨...")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
            manager = ModelManager(models_dir=str(temp_path))
            
            # æµ‹è¯•è·å–æœ€æ–°æ¨¡å‹ï¼ˆåº”è¯¥è¿”å›Noneï¼Œå› ä¸ºæ²¡æœ‰æ¨¡å‹ï¼‰
            latest_model = manager.get_latest_model('test_model')
            if latest_model is None:
                _ = print(f"  âœ… è·å–æœ€æ–°æ¨¡å‹åŠŸèƒ½æ­£å¸¸ï¼ˆæ— æ¨¡å‹æ—¶è¿”å›Noneï¼‰")
            else:
                _ = print(f"  âš ï¸  è·å–æœ€æ–°æ¨¡å‹åŠŸèƒ½å¯èƒ½æœ‰é—®é¢˜")
            
            # æµ‹è¯•ä¿å­˜å¢é‡æ¨¡å‹ï¼ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ä½œä¸ºæ¨¡å‹ï¼‰
            with tempfile.NamedTemporaryFile(suffix='.pth', delete=False) as tmp_model:
                tmp_model_path = Path(tmp_model.name)
                _ = tmp_model_path.write_text("fake model data")
            
            # ä¿å­˜æ¨¡å‹
            metrics = {'accuracy': 0.95, 'loss': 0.05}
            saved_path = manager.save_incremental_model('test_model', tmp_model_path, metrics)
            
            if saved_path and saved_path.exists():
                _ = print(f"  âœ… ä¿å­˜å¢é‡æ¨¡å‹åŠŸèƒ½æ­£å¸¸")
            else:
                _ = print(f"  âš ï¸  ä¿å­˜å¢é‡æ¨¡å‹å¯èƒ½æœ‰é—®é¢˜")
            
            # æ¸…ç†ä¸´æ—¶æ¨¡å‹æ–‡ä»¶
            _ = tmp_model_path.unlink()
            if saved_path:
                _ = saved_path.unlink()
            
            # æµ‹è¯•è‡ªåŠ¨æ¸…ç†åŠŸèƒ½
            _ = manager.auto_cleanup_models()
            _ = print(f"  âœ… è‡ªåŠ¨æ¸…ç†æ¨¡å‹åŠŸèƒ½æ­£å¸¸")
        
        _ = print("âœ… æ¨¡å‹ç®¡ç†å™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        _ = print(f"âŒ æ¨¡å‹ç®¡ç†å™¨ç»¼åˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_training_scheduler_comprehensive() -> None:
    """ç»¼åˆæµ‹è¯•è®­ç»ƒè°ƒåº¦å™¨"""
    _ = print("â° ç»¼åˆæµ‹è¯•è®­ç»ƒè°ƒåº¦å™¨...")
    
    try:
        # åˆ›å»ºè®­ç»ƒè°ƒåº¦å™¨
        scheduler = TrainingScheduler()
        
        # æµ‹è¯•ç³»ç»Ÿç©ºé—²æ£€æµ‹
        is_idle = scheduler.is_system_idle()
        print(f"  âœ… ç³»ç»Ÿç©ºé—²æ£€æµ‹åŠŸèƒ½æ­£å¸¸ï¼Œå½“å‰çŠ¶æ€: {'ç©ºé—²' if is_idle else 'å¿™ç¢Œ'}")
        
        # æµ‹è¯•è°ƒåº¦è®­ç»ƒä»»åŠ¡
        test_task = {
            'task_id': 'test_task_1',
            'model_name': 'test_model',
            'data_files': []
        }
        _ = scheduler.schedule_training(test_task)
        _ = print(f"  âœ… è°ƒåº¦è®­ç»ƒä»»åŠ¡åŠŸèƒ½æ­£å¸¸")
        
        # éªŒè¯ä»»åŠ¡æ˜¯å¦æ­£ç¡®æ·»åŠ 
        if len(scheduler.pending_tasks) == 1:
            _ = print(f"  âœ… ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½æ­£å¸¸")
        else:
            _ = print(f"  âš ï¸  ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å¯èƒ½æœ‰é—®é¢˜")
        
        # æµ‹è¯•å¤±è´¥ä»»åŠ¡å¤„ç†
        failed_tasks = scheduler.get_failed_tasks()
        _ = print(f"  âœ… è·å–å¤±è´¥ä»»åŠ¡åŠŸèƒ½æ­£å¸¸ï¼Œå½“å‰å¤±è´¥ä»»åŠ¡æ•°: {len(failed_tasks)}")
        
        # æµ‹è¯•é‡è¯•å¤±è´¥ä»»åŠ¡
        _ = scheduler.retry_failed_tasks()
        _ = print(f"  âœ… é‡è¯•å¤±è´¥ä»»åŠ¡åŠŸèƒ½æ­£å¸¸")
        
        _ = print("âœ… è®­ç»ƒè°ƒåº¦å™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        _ = print(f"âŒ è®­ç»ƒè°ƒåº¦å™¨ç»¼åˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_memory_buffer_comprehensive() -> None:
    """ç»¼åˆæµ‹è¯•å†…å­˜ç¼“å†²åŒº"""
    _ = print("ğŸ“¦ ç»¼åˆæµ‹è¯•å†…å­˜ç¼“å†²åŒº...")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            buffer_file = temp_path / "memory_buffer.json"
            
            # åˆ›å»ºå†…å­˜ç¼“å†²åŒº
            buffer = MemoryBuffer(max_size=3)
            
            # æµ‹è¯•æ·»åŠ æ•°æ®
            test_data1 = {'file': 'test1.txt', 'hash': 'abc123'}
            test_data2 = {'file': 'test2.txt', 'hash': 'def456'}
            test_data3 = {'file': 'test3.txt', 'hash': 'ghi789'}
            test_data4 = {'file': 'test4.txt', 'hash': 'jkl012'}  # è¿™ä¸ªåº”è¯¥ä¼šæŒ¤å‡ºç¬¬ä¸€ä¸ª
            
            _ = buffer.add_data(test_data1)
            _ = buffer.add_data(test_data2)
            _ = buffer.add_data(test_data3)
            _ = buffer.add_data(test_data4)
            
            _ = print(f"  âœ… æ·»åŠ æ•°æ®åŠŸèƒ½æ­£å¸¸")
            
            # æµ‹è¯•è·å–ç¼“å†²åŒºæ•°æ®
            buffered_data = buffer.get_buffered_data()
            if len(buffered_data) == 4:
                _ = print(f"  âœ… è·å–ç¼“å†²åŒºæ•°æ®åŠŸèƒ½æ­£å¸¸ï¼Œè·å–åˆ° {len(buffered_data)} ä¸ªæ•°æ®é¡¹")
            else:
                _ = print(f"  âš ï¸  è·å–ç¼“å†²åŒºæ•°æ®å¯èƒ½æœ‰é—®é¢˜ï¼ŒæœŸæœ›4ä¸ªï¼Œå®é™…{len(buffered_data)}ä¸ª")
            
            # éªŒè¯ç¼“å†²åŒºæ˜¯å¦å·²æ¸…ç©º
            if len(buffer.buffer) == 0:
                _ = print(f"  âœ… ç¼“å†²åŒºæ¸…ç©ºåŠŸèƒ½æ­£å¸¸")
            else:
                _ = print(f"  âš ï¸  ç¼“å†²åŒºæ¸…ç©ºå¯èƒ½æœ‰é—®é¢˜")
        
        _ = print("âœ… å†…å­˜ç¼“å†²åŒºç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        _ = print(f"âŒ å†…å­˜ç¼“å†²åŒºç»¼åˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_incremental_learning_manager_comprehensive() -> None:
    """ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç®¡ç†å™¨"""
    _ = print("ğŸš€ ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç®¡ç†å™¨...")
    
    try:
        # åˆ›å»ºå¢é‡å­¦ä¹ ç®¡ç†å™¨
        learner = IncrementalLearningManager()
        
        # æµ‹è¯•è·å–çŠ¶æ€
        status = learner.get_status()
        _ = print(f"  âœ… è·å–ç³»ç»ŸçŠ¶æ€åŠŸèƒ½æ­£å¸¸")
        
        # æ£€æŸ¥çŠ¶æ€å­—æ®µ
        required_fields = ['is_monitoring', 'pending_tasks', 'failed_tasks', 'buffered_data', 'processed_files', 'model_versions', 'auto_cleanup_enabled']
        missing_fields = [field for field in required_fields if field not in status]
        if not missing_fields:
            _ = print(f"  âœ… çŠ¶æ€ä¿¡æ¯å®Œæ•´")
        else:
            _ = print(f"  âš ï¸  çŠ¶æ€ä¿¡æ¯ç¼ºå¤±å­—æ®µ: {missing_fields}")
        
        # æµ‹è¯•è§¦å‘å¢é‡è®­ç»ƒ
        _ = learner.trigger_incremental_training()
        _ = print(f"  âœ… è§¦å‘å¢é‡è®­ç»ƒåŠŸèƒ½æ­£å¸¸")
        
        # æµ‹è¯•è‡ªåŠ¨æ¸…ç†åŠŸèƒ½
        _ = learner.enable_auto_cleanup(True)
        _ = print(f"  âœ… å¯ç”¨è‡ªåŠ¨æ¸…ç†åŠŸèƒ½æ­£å¸¸")
        
        # æµ‹è¯•æ‰‹åŠ¨æ¸…ç†æ¨¡å‹
        learner.manual_cleanup_models(keep_versions=3)
        _ = print(f"  âœ… æ‰‹åŠ¨æ¸…ç†æ¨¡å‹åŠŸèƒ½æ­£å¸¸")
        
        _ = print("âœ… å¢é‡å­¦ä¹ ç®¡ç†å™¨ç»¼åˆæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        _ = print(f"âŒ å¢é‡å­¦ä¹ ç®¡ç†å™¨ç»¼åˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main() -> None:
    """ä¸»å‡½æ•°"""
    _ = print("ğŸš€ ç»¼åˆæµ‹è¯•å¢é‡å­¦ä¹ ç³»ç»ŸåŠŸèƒ½")
    print("=" * 50)
    
    tests = [
        test_data_tracker_comprehensive,
        test_model_manager_comprehensive,
        test_training_scheduler_comprehensive,
        test_memory_buffer_comprehensive,
        test_incremental_learning_manager_comprehensive
    ]
    
    passed = 0
    for test in tests:
        if test():
            passed += 1
        _ = print()
    
    print("=" * 50)
    _ = print(f"æµ‹è¯•ç»“æœ: {passed}/{len(tests)} é€šè¿‡")
    
    if passed == len(tests):
        _ = print("ğŸ‰ æ‰€æœ‰ç»¼åˆæµ‹è¯•é€šè¿‡! å¢é‡å­¦ä¹ ç³»ç»ŸåŠŸèƒ½æ­£å¸¸ã€‚")
        return 0
    else:
        _ = print("ğŸ’¥ éƒ¨åˆ†ç»¼åˆæµ‹è¯•å¤±è´¥! è¯·æ£€æŸ¥å®ç°ã€‚")
        return 1

if __name__ == "__main__":
    _ = sys.exit(main())