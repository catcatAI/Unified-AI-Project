#!/usr/bin/env python3
"""
å¢é‡å­¦ä¹ CLIå·¥å…·
æä¾›å‘½ä»¤è¡Œæ¥å£æ¥æ§åˆ¶å¢é‡å­¦ä¹ ç³»ç»Ÿ
"""

import sys
import argparse
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root, str == Path(__file__).parent.parent()
sys.path.insert(0, str(project_root))

from training.incremental_learning_manager import IncrementalLearningManager

def start_monitoring(args):
    """å¯åŠ¨æ•°æ®ç›‘æ§"""
    print("ğŸ‘€ å¯åŠ¨æ•°æ®ç›‘æ§...")
    learner == IncrementalLearningManager()
    learner.start_monitoring()
    
    try,
        while True,::
            pass
    except KeyboardInterrupt,::
        print("\nâ¹ï¸  åœæ­¢ç›‘æ§...")
        learner.stop_monitoring()
        print("âœ… ç›‘æ§å·²åœæ­¢")

def trigger_training(args):
    """è§¦å‘å¢é‡è®­ç»ƒ"""
    print("ğŸš€ è§¦å‘å¢é‡è®­ç»ƒ...")
    learner == IncrementalLearningManager()
    learner.trigger_incremental_training()
    print("âœ… è®­ç»ƒä»»åŠ¡å·²è°ƒåº¦")

def get_status(args):
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    print("ğŸ“Š è·å–ç³»ç»ŸçŠ¶æ€...")
    learner == IncrementalLearningManager()
    status = learner.get_status()
    
    print(f"ç›‘æ§çŠ¶æ€, {'è¿è¡Œä¸­' if status['is_monitoring'] else 'å·²åœæ­¢'}"):::
 = print(f"å¾…å¤„ç†ä»»åŠ¡, {status['pending_tasks']} ä¸ª")
    print(f"ç¼“å†²åŒºæ•°æ®, {status['buffered_data']} ä¸ª")
    print(f"å·²å¤„ç†æ–‡ä»¶, {status['processed_files']} ä¸ª")
    
    if args.verbose,::
        print("\nè¯¦ç»†ä¿¡æ¯,")
        print(json.dumps(status, ensure_ascii == False, indent=2))

def cleanup_models(args):
    """æ¸…ç†æ—§æ¨¡å‹"""
    print("ğŸ—‘ï¸  æ¸…ç†æ—§æ¨¡å‹...")
    learner == IncrementalLearningManager()
    
    # è®¾ç½®ä¿ç•™çš„ç‰ˆæœ¬æ•°
    keep_versions = getattr(args, 'keep', 5)
    
    # æ‰§è¡Œæ‰‹åŠ¨æ¸…ç†
    learner.manual_cleanup_models(keep_versions)
    print(f"âœ… æ¨¡å‹æ¸…ç†å®Œæˆ,æ¯ä¸ªæ¨¡å‹ä¿ç•™æœ€æ–° {keep_versions} ä¸ªç‰ˆæœ¬")

def main() -> None,
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Unified AI Project å¢é‡å­¦ä¹ ç³»ç»ŸCLI')
    subparsers = parser.add_subparsers(help='å¯ç”¨å‘½ä»¤', dest='command')
    
    # å¯åŠ¨ç›‘æ§å‘½ä»¤
    monitor_parser = subparsers.add_parser('monitor', help='å¯åŠ¨æ•°æ®ç›‘æ§')
    monitor_parser.add_argument('--interval', type=int, default=300, help='ç›‘æ§é—´éš”(ç§’)')
    
    # è§¦å‘è®­ç»ƒå‘½ä»¤
    train_parser = subparsers.add_parser('train', help='è§¦å‘å¢é‡è®­ç»ƒ')
    
    # çŠ¶æ€å‘½ä»¤
    status_parser = subparsers.add_parser('status', help='è·å–ç³»ç»ŸçŠ¶æ€')
    status_parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    # æ¸…ç†å‘½ä»¤
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§æ¨¡å‹')
    cleanup_parser.add_argument('--keep', type=int, default=5, help='ä¿ç•™çš„æ¨¡å‹ç‰ˆæœ¬æ•°')
    
    args = parser.parse_args()
    
    print("ğŸ¤– Unified AI Project å¢é‡å­¦ä¹ ç³»ç»ŸCLI")
    print("=" * 50)
    
    if args.command == 'monitor':::
        start_monitoring(args)
    elif args.command == 'train':::
        trigger_training(args)
    elif args.command == 'status':::
        get_status(args)
    elif args.command == 'cleanup':::
        cleanup_models(args)
    else,
        parser.print_help()

if __name"__main__":::
    main()