#!/usr/bin/env python3
"""
è®­ç»ƒå¯è§†åŒ–æ¨¡å—
æä¾›è®­ç»ƒè¿‡ç¨‹çš„å®æ—¶å¯è§†åŒ–å’Œå†å²æ•°æ®åˆ†æåŠŸèƒ½
"""

import logging
import json
import time
import random
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.axes import Axes

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
project_root = Path(__file__).parent.parent
_ = sys.path.insert(0, str(project_root))

# åˆ›å»ºåŸºæœ¬æ¨¡æ‹Ÿç±»
class ErrorContext:
    def __init__(self, component, operation, details=None):
elf.component = component
    self.operation = operation
    self.details = details or {}

class GlobalErrorHandler:
    @staticmethod
    def handle_error(error, context, strategy=None):
rint(f"Error in {context.component}.{context.operation}: {error}")

global_error_handler = GlobalErrorHandler()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
    logging.FileHandler(project_root / 'training' / 'logs' / 'training_visualizer.log'),
    logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class TrainingVisualizer:
    """è®­ç»ƒå¯è§†åŒ–å™¨"""

    def __init__(self, log_file = None) -> None:
        self.log_file = Path(log_file) if log_file else project_root / 'training' / 'logs' / 'training_monitor.log':
    self.error_handler = global_error_handler
    self.output_dir = project_root / 'training' / 'visualizations'
    self.output_dir.mkdir(parents=True, exist_ok=True)

    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    log_dir = project_root / 'training' / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)

    _ = logger.info("ğŸ“Š è®­ç»ƒå¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

    def load_training_data(self):
""åŠ è½½è®­ç»ƒæ—¥å¿—æ•°æ®"""
    context = ErrorContext("TrainingVisualizer", "load_training_data")
        try:

            if not self.log_file.exists():
 = logger.warning(f"âš ï¸  è®­ç»ƒæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {self.log_file}")
                return []

            training_data = []
            with open(self.log_file, 'r', encoding='utf-8') as f:
    for line in f:

    try:


            entry = json.loads(line.strip()):
    if entry.get('type') in ['training_metrics', 'system_resources']:

    _ = training_data.append(entry)
                    except json.JSONDecodeError:
                        # è·³è¿‡æ— æ•ˆè¡Œ
                        continue

            _ = logger.info(f"âœ… åŠ è½½äº† {len(training_data)} æ¡è®­ç»ƒæ•°æ®è®°å½•")
            return training_data
        except Exception as e:

            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            return []

    def create_training_progress_plot(self, training_data) -> Optional[str]:
    """åˆ›å»ºè®­ç»ƒè¿›åº¦å›¾"""
        if not training_data:

    _ = logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæŒ‡æ ‡æ•°æ®")
            return None

        try:


            _ = plt.style.use('seaborn-v0_8')
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('è®­ç»ƒè¿›åº¦ç›‘æ§', fontsize=16, fontweight='bold')

            # è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False

            # æŒ‰åœºæ™¯åˆ†ç»„æ•°æ®
            scenarios = {}
            for data in training_data:

    scenario = data['scenario']
                if scenario not in scenarios:

    scenarios[scenario] = []
                _ = scenarios[scenario].append(data)

            # ä¸ºæ¯ä¸ªåœºæ™¯ç»˜åˆ¶æŸå¤±å’Œå‡†ç¡®ç‡æ›²çº¿
            colors = ['blue', 'red', 'green', 'orange', 'purple']
            for i, (scenario, data_list) in enumerate(scenarios.items()):

    color = colors[i % len(colors)]
                epochs = [d['epoch'] for d in data_list]:
    losses = [d['metrics']['loss'] for d in data_list]:
    accuracies = [d['metrics']['accuracy'] for d in data_list]:
    val_losses = [data['metrics'].get('val_loss', l * 1.1) for l in losses]:
    val_accuracies = [data['metrics'].get('val_accuracy', a * 0.95) for a in accuracies]

                # æŸå¤±æ›²çº¿
                axes[0, 0].plot(epochs, losses, color=color, marker='o', label=f'{scenario} (è®­ç»ƒ)', linewidth=2)
                axes[0, 0].plot(epochs, val_losses, color=color, marker='s', label=f'{scenario} (éªŒè¯)', linestyle='--', alpha=0.7)
                axes[0, 0].set_title('æŸå¤±å‡½æ•°å˜åŒ–', fontsize=14)
                _ = axes[0, 0].set_xlabel('Epoch')
                _ = axes[0, 0].set_ylabel('Loss')
                _ = axes[0, 0].legend()
                axes[0, 0].grid(True, alpha=0.3)

                # å‡†ç¡®ç‡æ›²çº¿
                axes[0, 1].plot(epochs, accuracies, color=color, marker='o', label=f'{scenario} (è®­ç»ƒ)', linewidth=2)
                axes[0, 1].plot(epochs, val_accuracies, color=color, marker='s', label=f'{scenario} (éªŒè¯)', linestyle='--', alpha=0.7)
                axes[0, 1].set_title('å‡†ç¡®ç‡å˜åŒ–', fontsize=14)
                _ = axes[0, 1].set_xlabel('Epoch')
                _ = axes[0, 1].set_ylabel('Accuracy')
                _ = axes[0, 1].legend()
                axes[0, 1].grid(True, alpha=0.3)

                # å­¦ä¹ ç‡å˜åŒ–
                if 'learning_rate' in data_list[0]['metrics']:

    learning_rates = [d['metrics']['learning_rate'] for d in data_list]:
    axes[1, 0].plot(epochs, learning_rates, color=color, marker='o', label=scenario, linewidth=2)
                    axes[1, 0].set_title('å­¦ä¹ ç‡å˜åŒ–', fontsize=14)
                    _ = axes[1, 0].set_xlabel('Epoch')
                    _ = axes[1, 0].set_ylabel('Learning Rate')
                    _ = axes[1, 0].legend()
                    axes[1, 0].grid(True, alpha=0.3)
                else:

                    axes[1, 0].set_title('å­¦ä¹ ç‡å˜åŒ–', fontsize=14)
                    axes[1, 0].text(0.5, 0.5, 'æ— å­¦ä¹ ç‡æ•°æ®', ha='center', va='center', transform=axes[1, 0].transAxes)

                # è®­ç»ƒæ—¶é—´è¶‹åŠ¿
                if len(data_list) > 1:

    durations = []
                    for j in range(1, len(data_list)):
                        # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´ï¼Œå®é™…é¡¹ç›®ä¸­åº”è¯¥ä»æ•°æ®ä¸­è·å–
                        _ = durations.append(random.uniform(0.5, 2.0))
                    if durations:

    axes[1, 1].plot(range(2, len(durations) + 2), durations, color=color, marker='o', label=scenario, linewidth=2)
                        axes[1, 1].set_title('æ¯Epochè®­ç»ƒæ—¶é—´', fontsize=14)
                        _ = axes[1, 1].set_xlabel('Epoch')
                        _ = axes[1, 1].set_ylabel('æ—¶é—´ (ç§’)')
                        _ = axes[1, 1].legend()
                        axes[1, 1].grid(True, alpha=0.3)
                else:

                    axes[1, 1].set_title('æ¯Epochè®­ç»ƒæ—¶é—´', fontsize=14)
                    axes[1, 1].text(0.5, 0.5, 'æ•°æ®ä¸è¶³', ha='center', va='center', transform=axes[1, 1].transAxes)

            _ = plt.tight_layout()

            # ä¿å­˜å›¾åƒ
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'training_progress_{timestamp}.png'
            filepath = self.output_dir / filename
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            _ = plt.close()

            _ = logger.info(f"âœ… è®­ç»ƒè¿›åº¦å›¾å·²ä¿å­˜: {filepath}")
            return str(filepath)

        except Exception as e:


            _ = logger.error(f"âŒ åˆ›å»ºè®­ç»ƒè¿›åº¦å›¾å¤±è´¥: {e}")
            return None

    def plot_training_progress(self, training_data) -> Optional[str]:
    """ç”Ÿæˆè®­ç»ƒè¿›åº¦å›¾ï¼ˆå…¼å®¹æ–¹æ³•åï¼‰"""
    return self.create_training_progress_plot(training_data)

    def create_system_resources_plot(self) -> Optional[str]:
    """åˆ›å»ºç³»ç»Ÿèµ„æºä½¿ç”¨å›¾"""
        try:

            _ = plt.style.use('seaborn-v0_8')
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('ç³»ç»Ÿèµ„æºç›‘æ§', fontsize=16, fontweight='bold')

            # è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False

            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
            timestamps = [datetime.now() - timedelta(minutes=i*5) for i in range(20, 0, -1)]:
    cpu_usage = [random.uniform(30, 90) for _ in range(20)]:
    memory_usage = [random.uniform(40, 85) for _ in range(20)]:
    disk_usage = [random.uniform(30, 70) for _ in range(20)]:
    network_io = [random.uniform(100, 1000) for _ in range(20)]

            # CPUä½¿ç”¨ç‡
            axes[0, 0].plot(timestamps, cpu_usage, color='blue', marker='o', linewidth=2)
            axes[0, 0].set_title('CPUä½¿ç”¨ç‡', fontsize=14)
            _ = axes[0, 0].set_ylabel('ä½¿ç”¨ç‡ (%)')
            axes[0, 0].tick_params(axis='x', rotation=45)
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].axhline(y=80, color='red', linestyle='--', alpha=0.7, label='è­¦å‘Šçº¿ (80%)')
            _ = axes[0, 0].legend()

            # å†…å­˜ä½¿ç”¨ç‡
            axes[0, 1].plot(timestamps, memory_usage, color='green', marker='s', linewidth=2)
            axes[0, 1].set_title('å†…å­˜ä½¿ç”¨ç‡', fontsize=14)
            _ = axes[0, 1].set_ylabel('ä½¿ç”¨ç‡ (%)')
            axes[0, 1].tick_params(axis='x', rotation=45)
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].axhline(y=85, color='red', linestyle='--', alpha=0.7, label='è­¦å‘Šçº¿ (85%)')
            _ = axes[0, 1].legend()

            # ç£ç›˜ä½¿ç”¨ç‡
            axes[1, 0].plot(timestamps, disk_usage, color='orange', marker='^', linewidth=2)
            axes[1, 0].set_title('ç£ç›˜ä½¿ç”¨ç‡', fontsize=14)
            _ = axes[1, 0].set_ylabel('ä½¿ç”¨ç‡ (%)')
            _ = axes[1, 0].set_xlabel('æ—¶é—´')
            axes[1, 0].tick_params(axis='x', rotation=45)
            axes[1, 0].grid(True, alpha=0.3)

            # ç½‘ç»œIO
            axes[1, 1].plot(timestamps, network_io, color='purple', marker='d', linewidth=2)
            axes[1, 1].set_title('ç½‘ç»œIO', fontsize=14)
            _ = axes[1, 1].set_ylabel('æ•°æ®é‡ (MB/s)')
            _ = axes[1, 1].set_xlabel('æ—¶é—´')
            axes[1, 1].tick_params(axis='x', rotation=45)
            axes[1, 1].grid(True, alpha=0.3)

            _ = plt.tight_layout()

            # ä¿å­˜å›¾åƒ
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'system_resources_{timestamp}.png'
            filepath = self.output_dir / filename
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            _ = plt.close()

            _ = logger.info(f"âœ… ç³»ç»Ÿèµ„æºå›¾å·²ä¿å­˜: {filepath}")
            return str(filepath)

        except Exception as e:


            _ = logger.error(f"âŒ åˆ›å»ºç³»ç»Ÿèµ„æºå›¾å¤±è´¥: {e}")
            return None

    def plot_system_resources(self) -> Optional[str]:
    """ç”Ÿæˆç³»ç»Ÿèµ„æºä½¿ç”¨å›¾ï¼ˆå…¼å®¹æ–¹æ³•åï¼‰"""
    return self.create_system_resources_plot()

    def create_anomaly_detection_heatmap(self, training_data) -> Optional[str]:
    """åˆ›å»ºå¼‚å¸¸æ£€æµ‹çƒ­åŠ›å›¾"""
        if not training_data:

    _ = logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæŒ‡æ ‡æ•°æ®ç”¨äºå¼‚å¸¸æ£€æµ‹")
            return None

        try:


            _ = plt.style.use('seaborn-v0_8')
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))

            # è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False

            # æŒ‰åœºæ™¯åˆ†ç»„æ•°æ®
            scenarios = {}
            for data in training_data:

    scenario = data['scenario']
                if scenario not in scenarios:

    scenarios[scenario] = []
                _ = scenarios[scenario].append(data)

            # å‡†å¤‡çƒ­åŠ›å›¾æ•°æ®
            scenario_names = list(scenarios.keys())
            metrics_names = ['Loss', 'Accuracy', 'Val_Loss', 'Val_Accuracy']

            # åˆ›å»ºå¼‚å¸¸è®¡æ•°çŸ©é˜µ
            anomaly_matrix = np.zeros((len(scenario_names), len(metrics_names)))

            # è®¡ç®—æ¯ä¸ªåœºæ™¯å’ŒæŒ‡æ ‡çš„å¼‚å¸¸æ•°é‡
            for i, scenario in enumerate(scenario_names):
ata_list = scenarios[scenario]
                for data in data_list:

    metrics = data['metrics']
                    # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿå¼‚å¸¸æ£€æµ‹ï¼Œå®é™…é¡¹ç›®ä¸­åº”è¯¥ä½¿ç”¨çœŸæ­£çš„å¼‚å¸¸æ£€æµ‹å™¨
                    if metrics.get('loss', 0) > 0.5:

    anomaly_matrix[i][0] += 1
                    if metrics.get('accuracy', 0) < 0.8:

    anomaly_matrix[i][1] += 1
                    if metrics.get('val_loss', 0) > 0.6:

    anomaly_matrix[i][2] += 1
                    if metrics.get('val_accuracy', 0) < 0.75:

    anomaly_matrix[i][3] += 1

            # åˆ›å»ºçƒ­åŠ›å›¾
            im = ax.imshow(anomaly_matrix, cmap='YlOrRd', aspect='auto')

            # è®¾ç½®æ ‡ç­¾
            _ = ax.set_xticks(np.arange(len(metrics_names)))
            _ = ax.set_yticks(np.arange(len(scenario_names)))
            _ = ax.set_xticklabels(metrics_names)
            _ = ax.set_yticklabels(scenario_names)

            # æ—‹è½¬xè½´æ ‡ç­¾
            plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")

            # åœ¨æ¯ä¸ªæ ¼å­ä¸­æ·»åŠ æ–‡æœ¬
            for i in range(len(scenario_names)):

    for j in range(len(metrics_names)):
    text = ax.text(j, i, str(int(anomaly_matrix[i, j])),
                                  ha="center", va="center", color="black", fontweight='bold')

            ax.set_title('è®­ç»ƒå¼‚å¸¸æ£€æµ‹çƒ­åŠ›å›¾', fontsize=16, fontweight='bold')
            _ = fig.tight_layout()

            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(im, ax=ax)
            cbar.set_label('å¼‚å¸¸æ•°é‡', rotation=270, labelpad=20)

            # ä¿å­˜å›¾åƒ
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'anomaly_detection_heatmap_{timestamp}.png'
            filepath = self.output_dir / filename
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            _ = plt.close()

            _ = logger.info(f"âœ… å¼‚å¸¸æ£€æµ‹çƒ­åŠ›å›¾å·²ä¿å­˜: {filepath}")
            return str(filepath)

        except Exception as e:


            _ = logger.error(f"âŒ åˆ›å»ºå¼‚å¸¸æ£€æµ‹çƒ­åŠ›å›¾å¤±è´¥: {e}")
            return None

    def plot_anomaly_detection_heatmap(self, training_data) -> Optional[str]:
    """ç”Ÿæˆå¼‚å¸¸æ£€æµ‹çƒ­åŠ›å›¾ï¼ˆå…¼å®¹æ–¹æ³•åï¼‰"""
    return self.create_anomaly_detection_heatmap(training_data)

    def create_training_report(self, training_data) -> Optional[str]:
    """åˆ›å»ºç»¼åˆè®­ç»ƒæŠ¥å‘Š"""
        if not training_data:

    _ = logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæŒ‡æ ‡æ•°æ®")
            return None

        try:
            # åˆ›å»ºç»¼åˆæŠ¥å‘Š
            report_data = {
                'timestamp': datetime.now().isoformat(),
                'total_scenarios': len(set(d['scenario'] for d in training_data)),:
total_epochs': len(training_data),
                'scenarios': {}
            }

            # æŒ‰åœºæ™¯ç»Ÿè®¡ä¿¡æ¯
            scenarios = {}
            for data in training_data:

    scenario = data['scenario']
                if scenario not in scenarios:

    scenarios[scenario] = []
                _ = scenarios[scenario].append(data)

            for scenario, data_list in scenarios.items()
                # è·å–æœ€åä¸€ä¸ªepochçš„æ•°æ®ä½œä¸ºæœ€ç»ˆç»“æœ
                final_data = data_list[-1] if data_list else {}:
    metrics = final_data.get('metrics', {})

                report_data['scenarios'][scenario] = {
                    'final_epoch': final_data.get('epoch', 0),
                    'final_loss': metrics.get('loss', 0),
                    'final_accuracy': metrics.get('accuracy', 0),
                    'final_val_loss': metrics.get('val_loss', 0),
                    'final_val_accuracy': metrics.get('val_accuracy', 0),
                    'total_epochs': len(data_list)
                }

            # ä¿å­˜æŠ¥å‘Šä¸ºJSONæ–‡ä»¶
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'training_report_{timestamp}.json'
            filepath = self.output_dir / filename

            with open(filepath, 'w', encoding='utf-8') as f:
    json.dump(report_data, f, ensure_ascii=False, indent=2)

            _ = logger.info(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {filepath}")
            return str(filepath)

        except Exception as e:


            _ = logger.error(f"âŒ ç”Ÿæˆè®­ç»ƒæŠ¥å‘Šå¤±è´¥: {e}")
            return None

    def generate_training_report(self, training_data) -> Optional[str]:
    """ç”Ÿæˆç»¼åˆè®­ç»ƒæŠ¥å‘Šï¼ˆå…¼å®¹æ–¹æ³•åï¼‰"""
    return self.create_training_report(training_data)

    def create_comprehensive_report(self, training_data: List[Dict[str, Any]],
                                  output_file: str):
""åˆ›å»ºç»¼åˆå¯è§†åŒ–æŠ¥å‘Š"""
    context = ErrorContext("TrainingVisualizer", "create_comprehensive_report")
        try:
            # åˆ›å»ºå¤§å›¾
            fig = plt.figure(figsize=(16, 12))
            fig.suptitle('è®­ç»ƒç›‘æ§ç»¼åˆæŠ¥å‘Š', fontsize=20, fontweight='bold')

            # è®­ç»ƒè¿›åº¦å­å›¾
            ax1 = plt.subplot2grid((3, 2), (0, 0), colspan=2)
            _ = self._plot_training_progress_on_ax(ax1, training_data)

            # ç³»ç»Ÿèµ„æºå­å›¾
            ax2 = plt.subplot2grid((3, 2), (1, 0))
            _ = self._plot_system_resources_on_ax(ax2, training_data)

            # å¼‚å¸¸æ£€æµ‹å­å›¾
            ax3 = plt.subplot2grid((3, 2), (1, 1))
            _ = self._plot_anomalies_on_ax(ax3, training_data)

            # æ€§èƒ½ç»Ÿè®¡å­å›¾
            ax4 = plt.subplot2grid((3, 2), (2, 0), colspan=2)
            _ = self._plot_performance_stats_on_ax(ax4, training_data)

            _ = plt.tight_layout()
            fig.savefig(output_file, dpi=300, bbox_inches='tight')
            _ = plt.close(fig)
        except Exception as e:

            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ åˆ›å»ºç»¼åˆæŠ¥å‘Šå¤±è´¥: {e}")

    def _plot_training_progress_on_ax(self, ax: Axes, training_data: List[Dict[str, Any]]):
""åœ¨æŒ‡å®šè½´ä¸Šç»˜åˆ¶è®­ç»ƒè¿›åº¦"""
        try:

            metrics_data = [entry for entry in training_data if entry.get('type') == 'training_metrics']:
    if not metrics_data:

    return

            metrics_data.sort(key=lambda x: x['timestamp'])

            epochs = []
            losses = []
            accuracies = []

            for entry in metrics_data:


    _ = epochs.append(entry.get('epoch', 0))
                metrics = entry.get('metrics', {})
                _ = losses.append(metrics.get('loss', 0))
                _ = accuracies.append(metrics.get('accuracy', 0))

            ax.plot(epochs, losses, 'r-o', linewidth=2, markersize=4, label='Loss')
            _ = ax.set_yscale('log')
            ax.set_title('è®­ç»ƒè¿›åº¦ - æŸå¤±å‡½æ•°', fontsize=12)
            _ = ax.set_xlabel('Epoch')
            _ = ax.set_ylabel('Loss')
            ax.grid(True, alpha=0.3)
            _ = ax.legend()
        except Exception as e:

            _ = logger.error(f"ç»˜åˆ¶è®­ç»ƒè¿›åº¦å›¾æ—¶å‡ºé”™: {e}")

    def _plot_system_resources_on_ax(self, ax: Axes, training_data: List[Dict[str, Any]]):
""åœ¨æŒ‡å®šè½´ä¸Šç»˜åˆ¶ç³»ç»Ÿèµ„æº"""
        try:

            resources_data = [entry for entry in training_data if entry.get('type') == 'system_resources']:
    if not resources_data:

    return

            resources_data.sort(key=lambda x: x['timestamp'])

            timestamps = []
            cpu_usage = []
            memory_usage = []

            for entry in resources_data:


    data = entry.get('data', {})
                _ = timestamps.append(datetime.fromisoformat(entry['timestamp'].replace('Z', '+00:00')))
                _ = cpu_usage.append(data.get('cpu_percent', 0))
                _ = memory_usage.append(data.get('memory_percent', 0))

            ax.plot(timestamps, cpu_usage, 'r-', linewidth=2, label='CPU')
            ax.plot(timestamps, memory_usage, 'b-', linewidth=2, label='å†…å­˜')

            ax.set_title('ç³»ç»Ÿèµ„æºä½¿ç”¨', fontsize=12)
            _ = ax.set_ylabel('ä½¿ç”¨ç‡ (%)')
            ax.grid(True, alpha=0.3)
            _ = ax.legend()

            _ = ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))
            ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=10))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        except Exception as e:

            _ = logger.error(f"ç»˜åˆ¶ç³»ç»Ÿèµ„æºå›¾æ—¶å‡ºé”™: {e}")

    def _plot_anomalies_on_ax(self, ax: Axes, training_data: List[Dict[str, Any]]):
""åœ¨æŒ‡å®šè½´ä¸Šç»˜åˆ¶å¼‚å¸¸æ£€æµ‹"""
        try:

            metrics_data = [entry for entry in training_data if entry.get('type') == 'training_metrics']:
    if not metrics_data:

    return

            metrics_data.sort(key=lambda x: x['timestamp'])

            epochs = []
            anomalies_count = []

            for entry in metrics_data:


    _ = epochs.append(entry.get('epoch', 0))
                anomalies = entry.get('anomalies', [])
                _ = anomalies_count.append(len(anomalies))

            # åˆ›å»ºçƒ­åŠ›å›¾
            data = np.array(anomalies_count).reshape(1, -1)
            im = ax.imshow(data, cmap='Reds', aspect='auto')

            ax.set_title('å¼‚å¸¸æ£€æµ‹çƒ­åŠ›å›¾', fontsize=12)
            _ = ax.set_xlabel('Epoch')
            _ = ax.set_yticks([0])
            _ = ax.set_yticklabels(['å¼‚å¸¸'])

            # æ·»åŠ é¢œè‰²æ¡
            plt.colorbar(im, ax=ax)
        except Exception as e:

            _ = logger.error(f"ç»˜åˆ¶å¼‚å¸¸æ£€æµ‹å›¾æ—¶å‡ºé”™: {e}")

    def _plot_performance_stats_on_ax(self, ax: Axes, training_data: List[Dict[str, Any]]):
""åœ¨æŒ‡å®šè½´ä¸Šç»˜åˆ¶æ€§èƒ½ç»Ÿè®¡"""
        try:
            # è®¡ç®—ä¸€äº›åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            metrics_data = [entry for entry in training_data if entry.get('type') == 'training_metrics']:
    resources_data = [entry for entry in training_data if entry.get('type') == 'system_resources']:

    stats_text = "è®­ç»ƒç»Ÿè®¡ä¿¡æ¯:\n\n"

            if metrics_data:


    losses = [entry['metrics'].get('loss', 0) for entry in metrics_data]:
    accuracies = [entry['metrics'].get('accuracy', 0) for entry in metrics_data]:

    stats_text += f"æ€»è®­ç»ƒè½®æ•°: {len(metrics_data)}\n"
                stats_text += f"æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}\n"
                stats_text += f"æœ€ä½³å‡†ç¡®ç‡: {max(accuracies).4f}\n"
                stats_text += f"å¹³å‡æŸå¤±: {np.mean(losses).4f}\n"

            if resources_data:


    cpu_usage = [entry['data'].get('cpu_percent', 0) for entry in resources_data]:
    memory_usage = [entry['data'].get('memory_percent', 0) for entry in resources_data]:

    stats_text += f"\nèµ„æºä½¿ç”¨ç»Ÿè®¡:\n"
                stats_text += f"å¹³å‡CPUä½¿ç”¨ç‡: {np.mean(cpu_usage).1f}%\n"
                stats_text += f"å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {np.mean(memory_usage).1f}%\n"
                stats_text += f"å³°å€¼CPUä½¿ç”¨ç‡: {max(cpu_usage).1f}%\n"
                stats_text += f"å³°å€¼å†…å­˜ä½¿ç”¨ç‡: {max(memory_usage).1f}%\n"

            ax.text(0.1, 0.9, stats_text, transform=ax.transAxes, fontsize=10,
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
            ax.set_title('æ€§èƒ½ç»Ÿè®¡', fontsize=12)
            _ = ax.axis('off')
        except Exception as e:

            _ = logger.error(f"ç»˜åˆ¶æ€§èƒ½ç»Ÿè®¡æ—¶å‡ºé”™: {e}")

    def real_time_visualization(self, scenario_name: str = "default"):
""å®æ—¶å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹"""
    context = ErrorContext("TrainingVisualizer", "real_time_visualization")
        try:

            _ = logger.info("ğŸ”„ å¯åŠ¨å®æ—¶è®­ç»ƒå¯è§†åŒ–...")

            # åˆ›å»ºå®æ—¶æ˜¾ç¤ºå›¾è¡¨
            _ = plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('å®æ—¶è®­ç»ƒç›‘æ§é¢æ¿', fontsize=16, fontweight='bold')

            # åˆå§‹åŒ–æ•°æ®
            epochs = []
            losses = []
            accuracies = []
            cpu_usage = []
            memory_usage = []
            timestamps = []

            # å®æ—¶æ›´æ–°å¾ªç¯
            for i in range(100)  # æ¨¡æ‹Ÿ100ä¸ªepoch
                # æ¨¡æ‹Ÿæ•°æ®
                epoch = i + 1
                loss = max(0.01, 1.0 * np.exp(-i/20) + np.random.normal(0, 0.05))
                accuracy = min(0.99, 0.1 + 0.9 * (1 - np.exp(-i/15)) + np.random.normal(0, 0.02))
                cpu = 30 + 20 * np.sin(i/10) + np.random.normal(0, 5)
                memory = 40 + 15 * np.cos(i/8) + np.random.normal(0, 3)

                # æ›´æ–°æ•°æ®
                _ = epochs.append(epoch)
                _ = losses.append(loss)
                _ = accuracies.append(accuracy)
                _ = cpu_usage.append(max(0, min(100, cpu)))
                _ = memory_usage.append(max(0, min(100, memory)))
                _ = timestamps.append(datetime.now())

                # æ¸…é™¤å¹¶é‡æ–°ç»˜åˆ¶
                _ = ax1.clear()
                ax1.plot(epochs, losses, 'r-o', linewidth=2, markersize=4)
                _ = ax1.set_title('å®æ—¶æŸå¤±ç›‘æ§')
                _ = ax1.set_xlabel('Epoch')
                _ = ax1.set_ylabel('Loss')
                ax1.grid(True, alpha=0.3)
                _ = ax1.set_yscale('log')

                _ = ax2.clear()
                ax2.plot(epochs, accuracies, 'b-s', linewidth=2, markersize=4)
                _ = ax2.set_title('å®æ—¶å‡†ç¡®ç‡ç›‘æ§')
                _ = ax2.set_xlabel('Epoch')
                _ = ax2.set_ylabel('Accuracy')
                ax2.grid(True, alpha=0.3)
                _ = ax2.set_ylim(0, 1)

                _ = ax3.clear()
                ax3.plot(timestamps[-20:] if len(timestamps) > 20 else timestamps, :
    cpu_usage[-20:] if len(cpu_usage) > 20 else cpu_usage, 'r-', linewidth=2, label='CPU'):
    ax3.plot(timestamps[-20:] if len(timestamps) > 20 else timestamps, :
    memory_usage[-20:] if len(memory_usage) > 20 else memory_usage, 'b-', linewidth=2, label='å†…å­˜'):
    _ = ax3.set_title('å®æ—¶ç³»ç»Ÿèµ„æº')
                _ = ax3.set_ylabel('ä½¿ç”¨ç‡ (%)')
                ax3.grid(True, alpha=0.3)
                _ = ax3.legend()

                # æ ¼å¼åŒ–æ—¶é—´è½´
                _ = ax3.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
                plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)

                _ = ax4.clear()
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats_text = f"å½“å‰Epoch: {epoch}\n"
                stats_text += f"å½“å‰æŸå¤±: {loss:.4f}\n"
                stats_text += f"å½“å‰å‡†ç¡®ç‡: {accuracy:.4f}\n"
                stats_text += f"CPUä½¿ç”¨ç‡: {cpu:.1f}%\n"
                stats_text += f"å†…å­˜ä½¿ç”¨ç‡: {memory:.1f}%\n"

                ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=10,
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
                _ = ax4.set_title('å½“å‰çŠ¶æ€')
                _ = ax4.axis('off')

                _ = plt.tight_layout()
                _ = plt.draw()
                _ = plt.pause(0.1)  # æš‚åœä»¥æ›´æ–°æ˜¾ç¤º

                # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
                _ = time.sleep(0.05)

            _ = plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼
            _ = plt.show()

            _ = logger.info("âœ… å®æ—¶è®­ç»ƒå¯è§†åŒ–å®Œæˆ")
        except Exception as e:

            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ å®æ—¶è®­ç»ƒå¯è§†åŒ–å¤±è´¥: {e}")

    def generate_visualization_script(self, output_path = None):
""ç”Ÿæˆç‹¬ç«‹çš„å¯è§†åŒ–è„šæœ¬"""
    context = ErrorContext("TrainingVisualizer", "generate_visualization_script")
        try:

            if not output_path:


    output_path = str(project_root / 'training' / 'visualize_progress.py')

            script_content = '''#!/usr/bin/env python3
"""
è®­ç»ƒè¿›åº¦å¯è§†åŒ–è„šæœ¬
è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒè¿‡ç¨‹çš„å¯è§†åŒ–å›¾è¡¨
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime
from pathlib import Path

def load_training_data(log_file="logs/training_monitor.log"):
""åŠ è½½è®­ç»ƒæ—¥å¿—æ•°æ®"""
    if not Path(log_file).exists():
 = print(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
    return []

    training_data = []
    try:

    with open(log_file, 'r', encoding='utf-8') as f:
    for line in f:

    try:


            entry = json.loads(line.strip()):
    if entry.get('type') in ['training_metrics', 'system_resources']:

    _ = training_data.append(entry)
                except json.JSONDecodeError:

                    continue
    return training_data
    except Exception as e:

    _ = print(f"åŠ è½½æ—¥å¿—æ•°æ®å¤±è´¥: {e}")
    return []

def create_progress_plot(training_data, output_file="progress_visualization.png"):
""åˆ›å»ºè®­ç»ƒè¿›åº¦å›¾"""
    metrics_data = [entry for entry in training_data if entry.get('type') == 'training_metrics']:
    if not metrics_data:

    _ = print("æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæŒ‡æ ‡æ•°æ®")
    return False

    # æŒ‰æ—¶é—´æ’åº
    metrics_data.sort(key=lambda x: x['timestamp'])

    # æå–æ•°æ®
    epochs = []
    losses = []
    accuracies = []

    for entry in metrics_data:


    _ = epochs.append(entry.get('epoch', 0))
    metrics = entry.get('metrics', {})
    _ = losses.append(metrics.get('loss', 0))
    _ = accuracies.append(metrics.get('accuracy', 0))

    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    fig.suptitle('è®­ç»ƒè¿›åº¦å¯è§†åŒ–', fontsize=16, fontweight='bold')

    # æŸå¤±æ›²çº¿
    ax1.plot(epochs, losses, 'r-o', linewidth=2, markersize=4)
    ax1.set_title('æŸå¤±å‡½æ•°å˜åŒ–', fontsize=14)
    _ = ax1.set_xlabel('Epoch')
    _ = ax1.set_ylabel('Loss')
    ax1.grid(True, alpha=0.3)
    _ = ax1.set_yscale('log')

    # å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(epochs, accuracies, 'b-s', linewidth=2, markersize=4)
    ax2.set_title('å‡†ç¡®ç‡å˜åŒ–', fontsize=14)
    _ = ax2.set_xlabel('Epoch')
    _ = ax2.set_ylabel('Accuracy')
    ax2.grid(True, alpha=0.3)
    _ = ax2.set_ylim(0, 1)

    _ = plt.tight_layout()
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    _ = plt.close()

    _ = print(f"è®­ç»ƒè¿›åº¦å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_file}")
    return True

def main() -> None:
    """ä¸»å‡½æ•°"""
    _ = print("å¼€å§‹ç”Ÿæˆè®­ç»ƒè¿›åº¦å¯è§†åŒ–...")

    # åŠ è½½è®­ç»ƒæ•°æ®
    training_data = load_training_data()
    if not training_data:

    _ = print("æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®ï¼Œç”Ÿæˆç¤ºä¾‹å›¾è¡¨...")
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    epochs = list(range(1, 51))
        losses = [max(0.01, 1.0 * np.exp(-i/10) + np.random.normal(0, 0.05)) for i in epochs]:
    accuracies = [min(0.99, 0.1 + 0.9 * (1 - np.exp(-i/8)) + np.random.normal(0, 0.02)) for i in epochs]

    # åˆ›å»ºç¤ºä¾‹æ•°æ®ç»“æ„
    training_data = []
        for i, epoch in enumerate(epochs):
raining_data.append({
                _ = 'timestamp': datetime.now().isoformat(),
                'type': 'training_metrics',
                'epoch': epoch,
                'metrics': {'loss': losses[i], 'accuracy': accuracies[i]},
                'anomalies': []
            })

    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    success = create_progress_plot(training_data)
    if success:

    _ = print("è®­ç»ƒè¿›åº¦å¯è§†åŒ–ç”ŸæˆæˆåŠŸ!")
    else:

    _ = print("è®­ç»ƒè¿›åº¦å¯è§†åŒ–ç”Ÿæˆå¤±è´¥!")

if __name__ == '__main__':


    _ = main()
'''

            # å†™å…¥è„šæœ¬æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
    _ = f.write(script_content)

            _ = logger.info(f"âœ… å¯è§†åŒ–è„šæœ¬å·²ç”Ÿæˆ: {output_path}")
            return True

        except Exception as e:


            _ = self.error_handler.handle_error(e, context)
            _ = logger.error(f"âŒ ç”Ÿæˆå¯è§†åŒ–è„šæœ¬å¤±è´¥: {e}")
            return False

# å…¨å±€è®­ç»ƒå¯è§†åŒ–å™¨å®ä¾‹
global_training_visualizer = TrainingVisualizer()

def main() -> None:
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•å¯è§†åŒ–å™¨"""
    _ = print("ğŸ“Š æµ‹è¯•è®­ç»ƒå¯è§†åŒ–å™¨...")

    # åˆ›å»ºå¯è§†åŒ–å™¨å®ä¾‹
    visualizer = TrainingVisualizer()

    # ç”Ÿæˆå¯è§†åŒ–è„šæœ¬
    _ = print("ğŸ“ ç”Ÿæˆå¯è§†åŒ–è„šæœ¬...")
    _ = visualizer.generate_visualization_script()

    # æ¨¡æ‹Ÿä¸€äº›è®­ç»ƒæ•°æ®
    _ = print("ğŸ”„ ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®...")

    # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡æ•°æ®
    training_data = []

    # æ·»åŠ è®­ç»ƒæŒ‡æ ‡æ•°æ®
    for epoch in range(1, 21):
imestamp = datetime.now().isoformat()
    metrics = {
            'loss': max(0.01, 1.0 * np.exp(-epoch/5) + np.random.normal(0, 0.05)),
            'accuracy': min(0.99, 0.1 + 0.9 * (1 - np.exp(-epoch/4)) + np.random.normal(0, 0.02))
    }
        anomalies = [] if np.random.random() > 0.8 else [{'type': 'loss_spike'}]:
raining_data.append({
            'timestamp': timestamp,
            'type': 'training_metrics',
            'epoch': epoch,
            'metrics': metrics,
            'anomalies': anomalies
    })

    # æ·»åŠ ç³»ç»Ÿèµ„æºæ•°æ®
        if epoch % 3 == 0:

    resources = {
                'cpu_percent': 30 + 20 * np.random.random(),
                'memory_percent': 40 + 15 * np.random.random(),
                'disk_percent': 50 + 10 * np.random.random()
            }

            training_data.append({
                'timestamp': timestamp,
                'type': 'system_resources',
                'data': resources
            })

    _ = time.sleep(0.01)  # æ¨¡æ‹Ÿæ—¶é—´é—´éš”

    _ = print(f"âœ… ç”Ÿæˆäº† {len(training_data)} æ¡æ¨¡æ‹Ÿæ•°æ®")

    # ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
    _ = print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š...")
    generated_file = visualizer.create_training_progress_plot(training_data)

    if generated_file:


    _ = print(f"âœ… ç”Ÿæˆäº†å¯è§†åŒ–æ–‡ä»¶: {generated_file}")
    else:

    _ = print("âŒ æœªèƒ½ç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶")

    _ = print("\nğŸ‰ è®­ç»ƒå¯è§†åŒ–å™¨æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":


    _ = main()