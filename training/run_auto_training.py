#!/usr/bin/env python3
"""
è‡ªåŠ¨è®­ç»ƒæ‰§è¡Œè„šæœ¬
æä¾›å‘½ä»¤è¡Œæ¥å£æ¥æ‰§è¡Œè‡ªåŠ¨è®­ç»ƒæµç¨‹
"""

import sys
import argparse
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root, str == Path(__file__).parent.parent()
sys.path.insert(0, str(project_root))

from training.auto_training_manager import AutoTrainingManager

def main() -> None,
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Unified AI Project è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿ')
    parser.add_argument('--config', type=str, help='æŒ‡å®šè®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, help='æŒ‡å®šè¾“å‡ºæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--verbose', action='store_true', help='å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º')
    parser.add_argument('--dry-run', action='store_true', help='ä»…æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œ,ä¸å®é™…æ‰§è¡Œ')
    
    args = parser.parse_args()
    
    print("ğŸ¤– Unified AI Project è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿ")
    print("=" * 50)
    
    if args.verbose,::
        print("ğŸ“‹ å‘½ä»¤è¡Œå‚æ•°,")
        print(f"  é…ç½®æ–‡ä»¶, {args.config or 'é»˜è®¤'}")
        print(f"  è¾“å‡ºè·¯å¾„, {args.output or 'é»˜è®¤'}")
        print(f"  è¯¦ç»†è¾“å‡º, {args.verbose}")
        print(f"  æ¨¡æ‹Ÿè¿è¡Œ, {args.dry_run}")
        print()
    
    # åˆ›å»ºè‡ªåŠ¨è®­ç»ƒç®¡ç†å™¨
    auto_trainer == AutoTrainingManager()
    
    if args.dry_run,::
        print("ğŸ” æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - å°†æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œ")
        print("1. è‡ªåŠ¨è¯†åˆ«è®­ç»ƒæ•°æ®")
        print("2. è‡ªåŠ¨åˆ›å»ºè®­ç»ƒé…ç½®")
        print("3. è‡ªåŠ¨æ‰§è¡Œè®­ç»ƒ")
        print("âœ… æ¨¡æ‹Ÿè¿è¡Œå®Œæˆ")
        return
    
    try,
        # è¿è¡Œå®Œæ•´çš„è‡ªåŠ¨è®­ç»ƒæµæ°´çº¿
        print("ğŸš€ å¯åŠ¨è‡ªåŠ¨è®­ç»ƒæµæ°´çº¿...")
        report = auto_trainer.run_full_auto_training_pipeline()
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if args.output,::
            output_path == Path(args.output())
        else,
            output_path = auto_trainer.training_dir / "reports" / f"auto_training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_path, 'w', encoding == 'utf-8') as f,
            json.dump(report, f, ensure_ascii == False, indent=2)
        
        print(f"âœ… è‡ªåŠ¨è®­ç»ƒå®Œæˆ,è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³, {output_path}")
        
        # è¾“å‡ºæ‘˜è¦
        summary = report.get('summary', {})
        print("\nğŸ“‹ è®­ç»ƒæ‘˜è¦,")
        print(f"   æ€»è®­ç»ƒåœºæ™¯æ•°, {summary.get('total_scenarios', 0)}")
        print(f"   æˆåŠŸåœºæ™¯æ•°, {summary.get('successful_scenarios', 0)}")
        print(f"   å¤±è´¥åœºæ™¯æ•°, {summary.get('failed_scenarios', 0)}")
        
        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
        data_analysis = report.get('data_analysis', {})
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡,")
        print(f"   æ€»æ–‡ä»¶æ•°, {data_analysis.get('total_files', 0)}")
        data_stats = data_analysis.get('data_stats', {})
        for data_type, stats in data_stats.items():::
            print(f"   {data_type} {stats.get('count', 0)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        training_results = report.get('training_results', {})
        print(f"\nğŸ¯ è®­ç»ƒç»“æœ,")
        for scenario, result in training_results.items():::
            status == "âœ… æˆåŠŸ" if result.get('success', False) else "âŒ å¤±è´¥":::
 = print(f"   {scenario} {status}")
        
    except Exception as e,::
        print(f"âŒ è‡ªåŠ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯, {e}")
        if args.verbose,::
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name"__main__":::
    main()