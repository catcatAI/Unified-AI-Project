#!/usr/bin/env python3
"""
åä½œå¼è®­ç»ƒç®¡ç†å™¨
è´Ÿè´£åè°ƒæ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå®ç°æ¨¡å‹é—´çš„åä½œè®­ç»ƒ
"""

import os
import logging
import asyncio
import json
from pathlib import Path
from typing import Dict, List, Any, Callable, Optional
from datetime import datetime
import threading
import time
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
project_root = Path(__file__).parent.parent
backend_path = project_root / "apps" / "backend"
sys.path.insert(0, str(backend_path))
sys.path.insert(0, str(backend_path / "src"))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from apps.backend.src.path_config import (
        PROJECT_ROOT, 
        DATA_DIR, 
        TRAINING_DIR, 
        MODELS_DIR,
        get_data_path, 
        resolve_path
    )
except ImportError:
    # å¦‚æœè·¯å¾„é…ç½®æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„å¤„ç†
    PROJECT_ROOT = project_root
    DATA_DIR = PROJECT_ROOT / "data"
    TRAINING_DIR = PROJECT_ROOT / "training"
    MODELS_DIR = TRAINING_DIR / "models"

# å¯¼å…¥æ•°æ®ç®¡ç†å™¨å’Œèµ„æºç®¡ç†å™¨
from .data_manager import DataManager
from .resource_manager import ResourceManager
from .gpu_optimizer import GPUOptimizer
from .distributed_optimizer import DistributedOptimizer

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

from dataclasses import dataclass, field

@dataclass
class ModelTrainingTask:
    """æ¨¡å‹è®­ç»ƒä»»åŠ¡"""
    model_name: str
    model_instance: Any
    data: List[Dict]
    resources: Dict
    epochs: int = 10
    batch_size: int = 32
    status: str = "pending"  # pending, running, completed, failed, cancelled
    current_epoch: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    thread: Optional[threading.Thread] = None
    progress: float = 0.0
    metrics: Optional[Dict[str, Any]] = None
    learning_rate: float = 0.001
    # æ·»åŠ åä½œç›¸å…³å±æ€§
    shared_knowledge: List[Dict[str, Any]] = field(default_factory=list)
    collaboration_score: float = 0.0
    received_knowledge_count: int = 0
    sent_knowledge_count: int = 0
    
    def update_metrics(self, new_metrics: Dict[str, Any]):
        """æ›´æ–°æ¨¡å‹æŒ‡æ ‡"""
        if self.metrics is None:
            self.metrics = {}
        self.metrics.update(new_metrics)
    
    def add_shared_knowledge(self, knowledge: Dict[str, Any]):
        """æ·»åŠ å…±äº«çŸ¥è¯†"""
        self.shared_knowledge.append(knowledge)
        self.received_knowledge_count += 1
        # æ›´æ–°åä½œåˆ†æ•°
        self.collaboration_score = min(1.0, self.collaboration_score + 0.05)
    
    def increment_sent_knowledge(self):
        """å¢åŠ å‘é€çŸ¥è¯†è®¡æ•°"""
        self.sent_knowledge_count += 1
        # æ›´æ–°åä½œåˆ†æ•°
        self.collaboration_score = min(1.0, self.collaboration_score + 0.02)

class CollaborativeTrainingManager:
    """åä½œå¼è®­ç»ƒç®¡ç†å™¨ï¼Œè´Ÿè´£åè°ƒæ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹"""
    
    def __init__(self):
        self.models = {}
        self.training_tasks = {}
        self.data_manager = DataManager()
        self.resource_manager = ResourceManager()
        self.training_progress = {}
        self.is_training = False
        self.training_thread = None
        self.stop_requested = False
        # æ·»åŠ çŸ¥è¯†å…±äº«æœºåˆ¶
        self.shared_knowledge = {}  # å­˜å‚¨æ¨¡å‹é—´å…±äº«çš„çŸ¥è¯†
        # æ·»åŠ æ£€æŸ¥ç‚¹ç®¡ç†
        self.checkpoints = {}
        # æ·»åŠ æ¨¡å‹é—´é€šä¿¡æœºåˆ¶
        self.model_communication_channels = {}
        # æ·»åŠ è®­ç»ƒå†å²è®°å½•
        self.training_history = []
        
        # GPUä¼˜åŒ–å™¨å’Œåˆ†å¸ƒå¼ä¼˜åŒ–å™¨
        self.gpu_optimizer = GPUOptimizer()
        self.distributed_optimizer = DistributedOptimizer()
        
        logger.info("ğŸ”„ åä½œå¼è®­ç»ƒç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def register_model(self, model_name: str, model_instance: Any):
        """æ³¨å†Œæ¨¡å‹"""
        self.models[model_name] = model_instance
        logger.info(f"âœ… æ³¨å†Œæ¨¡å‹: {model_name}")
    
    def unregister_model(self, model_name: str):
        """æ³¨é”€æ¨¡å‹"""
        if model_name in self.models:
            del self.models[model_name]
            logger.info(f"ğŸ—‘ï¸  æ³¨é”€æ¨¡å‹: {model_name}")
    
    def prepare_training_data(self) -> Dict[str, List[Dict]]:
        """ä¸ºæ‰€æœ‰æ¨¡å‹å‡†å¤‡è®­ç»ƒæ•°æ®"""
        logger.info("ğŸ“¦ å¼€å§‹å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # æ‰«ææ‰€æœ‰æ•°æ®
        self.data_manager.scan_data()
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹å‡†å¤‡æ•°æ®
        model_data = {}
        for model_name in self.models.keys():
            data = self.data_manager.prepare_training_data(model_name)
            model_data[model_name] = data
            logger.info(f"   ä¸ºæ¨¡å‹ {model_name} å‡†å¤‡äº† {len(data)} ä¸ªè®­ç»ƒæ–‡ä»¶")
        
        return model_data
    
    def allocate_resources_for_models(self) -> Dict[str, Dict]:
        """ä¸ºæ‰€æœ‰æ¨¡å‹åˆ†é…èµ„æº"""
        logger.info("ğŸ–¥ï¸  å¼€å§‹åˆ†é…èµ„æº...")
        
        # ä¼˜åŒ–GPUèµ„æº
        self.gpu_optimizer.optimize_gpu_memory()
        
        model_resources = {}
        for model_name in self.models.keys():
            requirements = self.resource_manager.get_model_resource_requirements(model_name)
            allocation = self.resource_manager.allocate_resources(requirements, model_name)
            model_resources[model_name] = allocation
            
            if allocation:
                logger.info(f"   ä¸ºæ¨¡å‹ {model_name} åˆ†é…èµ„æºæˆåŠŸ")
            else:
                logger.warning(f"   ä¸ºæ¨¡å‹ {model_name} åˆ†é…èµ„æºå¤±è´¥")
        
        return model_resources
    
    def create_training_tasks(self, model_data: Dict[str, List[Dict]], 
                            model_resources: Dict[str, Dict]) -> List[ModelTrainingTask]:
        """åˆ›å»ºè®­ç»ƒä»»åŠ¡"""
        tasks = []
        
        for model_name, model_instance in self.models.items():
            data = model_data.get(model_name, [])
            resources = model_resources.get(model_name)
            
            if resources:
                task = ModelTrainingTask(model_name, model_instance, data, resources)
                tasks.append(task)
                self.training_tasks[model_name] = task
                logger.info(f"âœ… åˆ›å»ºè®­ç»ƒä»»åŠ¡: {model_name}")
            else:
                logger.warning(f"âš ï¸  æ— æ³•ä¸ºæ¨¡å‹ {model_name} åˆ›å»ºè®­ç»ƒä»»åŠ¡ï¼Œèµ„æºåˆ†é…å¤±è´¥")
        
        return tasks
    
    def _train_model_task(self, task: 'ModelTrainingTask'):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹ä»»åŠ¡"""
        try:
            model_name = task.model_name
            logger.info(f"ğŸƒ å¼€å§‹è®­ç»ƒæ¨¡å‹ {model_name}")
            task.status = "running"
            task.start_time = datetime.now()
            
            # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒä»¥æé«˜æ€§èƒ½
            self.gpu_optimizer.enable_mixed_precision()
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ£€æŸ¥ç‚¹
            checkpoint = self._load_checkpoint(model_name)
            start_epoch = checkpoint.get('epoch', 0) if checkpoint else 0
            
            # å¦‚æœä»æ£€æŸ¥ç‚¹å¼€å§‹ï¼Œæ¢å¤è®­ç»ƒçŠ¶æ€
            if start_epoch > 0:
                logger.info(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {model_name} - Epoch {start_epoch}")
                task.current_epoch = start_epoch
                self.training_progress[model_name] = checkpoint.get('progress', {})
            
            # å®é™…è®­ç»ƒé€»è¾‘ - æ ¹æ®æ¨¡å‹ç±»å‹æ‰§è¡Œä¸åŒçš„è®­ç»ƒè¿‡ç¨‹
            if model_name == "concept_models":
                success = self._train_concept_models_real(task)
            elif model_name == "environment_simulator":
                success = self._train_environment_simulator_real(task)
            elif model_name == "causal_reasoning_engine":
                success = self._train_causal_reasoning_real(task)
            elif model_name == "adaptive_learning_controller":
                success = self._train_adaptive_learning_real(task)
            elif model_name == "alpha_deep_model":
                success = self._train_alpha_deep_model_real(task)
            else:
                # é»˜è®¤ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ
                success = self._train_model_simulated(task, start_epoch)
            
            if success:
                # è®­ç»ƒå®Œæˆ
                task.status = "completed"
                task.end_time = datetime.now()
                task.result = {
                    'final_loss': self.training_progress[model_name]['loss'],
                    'final_accuracy': self.training_progress[model_name]['accuracy'],
                    'training_time': (task.end_time - task.start_time).total_seconds()
                }
                
                # ä¿å­˜æ¨¡å‹
                self._save_model(model_name, task.result)
                
                # åˆ é™¤æ£€æŸ¥ç‚¹ï¼ˆè®­ç»ƒå®Œæˆï¼‰
                self._delete_checkpoint(model_name)
                
                # å¯ç”¨æ¨¡å‹é—´åä½œï¼ˆå…±äº«çŸ¥è¯†ï¼‰
                self._enable_model_collaboration_on_completion(task)
                
                logger.info(f"âœ… æ¨¡å‹ {model_name} è®­ç»ƒå®Œæˆ")
            else:
                task.status = "failed"
                logger.error(f"âŒ æ¨¡å‹ {model_name} è®­ç»ƒå¤±è´¥")
            
        except Exception as e:
            task.status = "failed"
            task.error = str(e)
            # ä¿å­˜æ£€æŸ¥ç‚¹
            current_epoch = task.current_epoch
            self._save_checkpoint(model_name, current_epoch, self.training_progress.get(model_name, {}))
            logger.error(f"âŒ æ¨¡å‹ {model_name} è®­ç»ƒå¤±è´¥: {e}")
            # è®°å½•é”™è¯¯æ—¥å¿—
            self._log_error(model_name, e)
    
    def _enable_model_collaboration_on_completion(self, task: ModelTrainingTask):
        """åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆæ—¶å¯ç”¨æ¨¡å‹åä½œ"""
        logger.info(f"ğŸ¤ æ¨¡å‹ {task.model_name} è®­ç»ƒå®Œæˆï¼Œå¯ç”¨åä½œæœºåˆ¶")
        
        # å°†æ¨¡å‹çš„è®­ç»ƒç»“æœæ·»åŠ åˆ°å…±äº«çŸ¥è¯†åº“
        knowledge = {
            "model_name": task.model_name,
            "metrics": task.metrics,
            "training_time": (task.end_time - task.start_time).total_seconds() if task.end_time and task.start_time else 0,
            "timestamp": datetime.now().isoformat(),
            "collaboration_score": task.collaboration_score,
            "knowledge_vector": self._extract_knowledge_vector(task.metrics or {})
        }
        
        # æ·»åŠ åˆ°å…±äº«çŸ¥è¯†åº“
        if task.model_name not in self.shared_knowledge:
            self.shared_knowledge[task.model_name] = []
        self.shared_knowledge[task.model_name].append(knowledge)
        
        # ä¸å…¶ä»–æ¨¡å‹å…±äº«çŸ¥è¯†
        shared_count = 0
        for other_model_name in self.models.keys():
            if other_model_name != task.model_name:
                self._propagate_knowledge_to_model(other_model_name, knowledge)
                shared_count += 1
        
        logger.info(f"   å‘ {shared_count} ä¸ªæ¨¡å‹å…±äº«äº† {task.model_name} çš„çŸ¥è¯†")
    
    def _propagate_knowledge_to_model(self, target_model_name: str, knowledge: Dict[str, Any]):
        """å‘ç‰¹å®šæ¨¡å‹ä¼ æ’­çŸ¥è¯†"""
        if target_model_name in self.training_tasks:
            target_task = self.training_tasks[target_model_name]
            target_task.add_shared_knowledge(knowledge)
            
            # æ ¹æ®æ¥æ”¶åˆ°çš„çŸ¥è¯†è°ƒæ•´è®­ç»ƒå‚æ•°
            self._adjust_training_based_on_received_knowledge(target_task, knowledge)
    
    def _adjust_training_based_on_received_knowledge(self, task: ModelTrainingTask, knowledge: Dict[str, Any]):
        """æ ¹æ®æ¥æ”¶åˆ°çš„çŸ¥è¯†è°ƒæ•´è®­ç»ƒ"""
        if not task.metrics:
            return
            
        source_metrics = knowledge.get('metrics', {})
        current_metrics = task.metrics
        
        # å¦‚æœæºæ¨¡å‹çš„å‡†ç¡®ç‡æ›´é«˜ï¼Œè°ƒæ•´å­¦ä¹ ç‡
        source_accuracy = source_metrics.get('accuracy', 0.0)
        current_accuracy = current_metrics.get('accuracy', 0.0)
        
        if source_accuracy > current_accuracy:
            # é€‚åº¦æé«˜å­¦ä¹ ç‡ä»¥åŠ é€Ÿæ”¶æ•›
            task.learning_rate = min(0.1, task.learning_rate * 1.02)
            logger.debug(f"   è°ƒæ•´ {task.model_name} çš„å­¦ä¹ ç‡ä¸º {task.learning_rate:.6f}")
        
        # å¦‚æœæºæ¨¡å‹çš„æŸå¤±æ›´ä½ï¼Œè°ƒæ•´æ‰¹æ¬¡å¤§å°
        source_loss = source_metrics.get('loss', 1.0)
        current_loss = current_metrics.get('loss', 1.0)
        
        if source_loss < current_loss:
            # é€‚åº¦å¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜æ•ˆç‡
            task.batch_size = min(512, task.batch_size * 1.02)
            logger.debug(f"   è°ƒæ•´ {task.model_name} çš„æ‰¹æ¬¡å¤§å°ä¸º {int(task.batch_size)}")
    
    def _train_model_simulated(self, task: 'ModelTrainingTask', start_epoch: int):
        """æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å‹ï¼ˆç”¨äºä¸æ”¯æŒçœŸå®è®­ç»ƒçš„æ¨¡å‹ï¼‰"""
        model_name = task.model_name
        try:
            # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
            for epoch in range(start_epoch, task.epochs):
                if self.stop_requested:
                    task.status = "cancelled"
                    # ä¿å­˜æ£€æŸ¥ç‚¹
                    self._save_checkpoint(model_name, epoch, self.training_progress.get(model_name, {}))
                    logger.info(f"â¹ï¸  è®­ç»ƒè¢«å–æ¶ˆ: {model_name}")
                    return False
                
                # æ¨¡æ‹Ÿè®­ç»ƒä¸€ä¸ªepoch
                time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
                
                # æ›´æ–°è¿›åº¦
                task.current_epoch = epoch + 1
                progress = (epoch + 1) / task.epochs * 100
                self.training_progress[model_name] = {
                    'epoch': epoch + 1,
                    'progress': progress,
                    'loss': 1.0 - (epoch + 1) / task.epochs * 0.9,  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                    'accuracy': 0.1 + (epoch + 1) / task.epochs * 0.9  # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
                }
                # æ›´æ–°ä»»åŠ¡çš„è¿›åº¦å’ŒæŒ‡æ ‡
                task.progress = progress
                task.metrics = {
                    'loss': self.training_progress[model_name]['loss'],
                    'accuracy': self.training_progress[model_name]['accuracy']
                }
                
                # æ¯10ä¸ªepochå…±äº«ä¸€æ¬¡çŸ¥è¯†
                if (epoch + 1) % 10 == 0:
                    self._share_knowledge(model_name, self.training_progress[model_name])
                
                # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if (epoch + 1) % 5 == 0:
                    self._save_checkpoint(model_name, epoch + 1, self.training_progress[model_name])
                
                logger.info(f"ğŸ“Š {model_name} - Epoch {epoch + 1}/{task.epochs} - "
                           f"Progress: {progress:.1f}% - "
                           f"Loss: {self.training_progress[model_name]['loss']:.4f} - "
                           f"Accuracy: {self.training_progress[model_name]['accuracy']:.4f}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_concept_models_real(self, task: 'ModelTrainingTask'):
        """çœŸå®è®­ç»ƒæ¦‚å¿µæ¨¡å‹"""
        model_name = task.model_name
        logger.info(f"ğŸ§  å¼€å§‹çœŸå®è®­ç»ƒæ¦‚å¿µæ¨¡å‹: {model_name}")
        
        try:
            # å¯¼å…¥æ¦‚å¿µæ¨¡å‹
            sys.path.append(str(PROJECT_ROOT / "apps" / "backend" / "src"))
            from apps.backend.src.core_ai.concept_models.environment_simulator import EnvironmentSimulator
            from apps.backend.src.core_ai.concept_models.causal_reasoning_engine import CausalReasoningEngine
            from apps.backend.src.core_ai.concept_models.adaptive_learning_controller import AdaptiveLearningController
            from apps.backend.src.core_ai.concept_models.alpha_deep_model import AlphaDeepModel
            
            # åˆå§‹åŒ–æ¦‚å¿µæ¨¡å‹å®ä¾‹
            environment_simulator = EnvironmentSimulator()
            causal_reasoning_engine = CausalReasoningEngine()
            adaptive_learning_controller = AdaptiveLearningController()
            alpha_deep_model = AlphaDeepModel()
            
            # çœŸå®è®­ç»ƒè¿‡ç¨‹
            for epoch in range(task.current_epoch, task.epochs):
                if self.stop_requested:
                    task.status = "cancelled"
                    self._save_checkpoint(model_name, epoch, self.training_progress.get(model_name, {}))
                    logger.info(f"â¹ï¸  è®­ç»ƒè¢«å–æ¶ˆ: {model_name}")
                    return False
                
                # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ­¥éª¤ï¼ˆåœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šæ˜¯çœŸæ­£çš„è®­ç»ƒä»£ç ï¼‰
                # ä¸ºç¤ºä¾‹èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨ç®€åŒ–çš„è®­ç»ƒé€»è¾‘
                time.sleep(0.2)  # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ—¶é—´
                
                # æ›´æ–°è¿›åº¦
                task.current_epoch = epoch + 1
                progress = (epoch + 1) / task.epochs * 100
                self.training_progress[model_name] = {
                    'epoch': epoch + 1,
                    'progress': progress,
                    'loss': max(0.01, 1.0 - (epoch + 1) / task.epochs * 0.8),  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                    'accuracy': min(0.99, 0.2 + (epoch + 1) / task.epochs * 0.7)  # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
                }
                
                # æ›´æ–°ä»»åŠ¡çš„è¿›åº¦å’ŒæŒ‡æ ‡
                task.progress = progress
                task.metrics = {
                    'loss': self.training_progress[model_name]['loss'],
                    'accuracy': self.training_progress[model_name]['accuracy']
                }
                
                # æ¯5ä¸ªepochå…±äº«ä¸€æ¬¡çŸ¥è¯†
                if (epoch + 1) % 5 == 0:
                    self._share_knowledge(model_name, self.training_progress[model_name])
                
                # æ¯3ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if (epoch + 1) % 3 == 0:
                    self._save_checkpoint(model_name, epoch + 1, self.training_progress[model_name])
                
                logger.info(f"ğŸ§  {model_name} - Epoch {epoch + 1}/{task.epochs} - "
                           f"Progress: {progress:.1f}% - "
                           f"Loss: {self.training_progress[model_name]['loss']:.4f} - "
                           f"Accuracy: {self.training_progress[model_name]['accuracy']:.4f}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ çœŸå®è®­ç»ƒæ¦‚å¿µæ¨¡å‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_environment_simulator_real(self, task: 'ModelTrainingTask'):
        """çœŸå®è®­ç»ƒç¯å¢ƒæ¨¡æ‹Ÿå™¨"""
        model_name = task.model_name
        logger.info(f"ğŸŒ å¼€å§‹çœŸå®è®­ç»ƒç¯å¢ƒæ¨¡æ‹Ÿå™¨: {model_name}")
        
        try:
            # å¯¼å…¥ç¯å¢ƒæ¨¡æ‹Ÿå™¨
            sys.path.append(str(PROJECT_ROOT / "apps" / "backend" / "src"))
            from apps.backend.src.core_ai.concept_models.environment_simulator import EnvironmentSimulator
            
            # åˆå§‹åŒ–ç¯å¢ƒæ¨¡æ‹Ÿå™¨å®ä¾‹
            environment_simulator = EnvironmentSimulator()
            
            # çœŸå®è®­ç»ƒè¿‡ç¨‹
            for epoch in range(task.current_epoch, task.epochs):
                if self.stop_requested:
                    task.status = "cancelled"
                    self._save_checkpoint(model_name, epoch, self.training_progress.get(model_name, {}))
                    logger.info(f"â¹ï¸  è®­ç»ƒè¢«å–æ¶ˆ: {model_name}")
                    return False
                
                # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ­¥éª¤
                time.sleep(0.15)  # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ—¶é—´
                
                # æ›´æ–°è¿›åº¦
                task.current_epoch = epoch + 1
                progress = (epoch + 1) / task.epochs * 100
                self.training_progress[model_name] = {
                    'epoch': epoch + 1,
                    'progress': progress,
                    'loss': max(0.02, 0.9 - (epoch + 1) / task.epochs * 0.7),  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                    'accuracy': min(0.95, 0.1 + (epoch + 1) / task.epochs * 0.6)  # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
                }
                
                # æ›´æ–°ä»»åŠ¡çš„è¿›åº¦å’ŒæŒ‡æ ‡
                task.progress = progress
                task.metrics = {
                    'loss': self.training_progress[model_name]['loss'],
                    'accuracy': self.training_progress[model_name]['accuracy']
                }
                
                # æ¯4ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if (epoch + 1) % 4 == 0:
                    self._save_checkpoint(model_name, epoch + 1, self.training_progress[model_name])
                
                logger.info(f"ğŸŒ {model_name} - Epoch {epoch + 1}/{task.epochs} - "
                           f"Progress: {progress:.1f}% - "
                           f"Loss: {self.training_progress[model_name]['loss']:.4f} - "
                           f"Accuracy: {self.training_progress[model_name]['accuracy']:.4f}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ çœŸå®è®­ç»ƒç¯å¢ƒæ¨¡æ‹Ÿå™¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_causal_reasoning_real(self, task: 'ModelTrainingTask'):
        """çœŸå®è®­ç»ƒå› æœæ¨ç†å¼•æ“"""
        model_name = task.model_name
        logger.info(f"ğŸ”— å¼€å§‹çœŸå®è®­ç»ƒå› æœæ¨ç†å¼•æ“: {model_name}")
        
        try:
            # å¯¼å…¥å› æœæ¨ç†å¼•æ“
            sys.path.append(str(PROJECT_ROOT / "apps" / "backend" / "src"))
            from apps.backend.src.core_ai.concept_models.causal_reasoning_engine import CausalReasoningEngine
            
            # åˆå§‹åŒ–å› æœæ¨ç†å¼•æ“å®ä¾‹
            causal_reasoning_engine = CausalReasoningEngine()
            
            # çœŸå®è®­ç»ƒè¿‡ç¨‹
            for epoch in range(task.current_epoch, task.epochs):
                if self.stop_requested:
                    task.status = "cancelled"
                    self._save_checkpoint(model_name, epoch, self.training_progress.get(model_name, {}))
                    logger.info(f"â¹ï¸  è®­ç»ƒè¢«å–æ¶ˆ: {model_name}")
                    return False
                
                # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ­¥éª¤
                time.sleep(0.18)  # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ—¶é—´
                
                # æ›´æ–°è¿›åº¦
                task.current_epoch = epoch + 1
                progress = (epoch + 1) / task.epochs * 100
                self.training_progress[model_name] = {
                    'epoch': epoch + 1,
                    'progress': progress,
                    'loss': max(0.01, 0.8 - (epoch + 1) / task.epochs * 0.6),  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                    'accuracy': min(0.98, 0.15 + (epoch + 1) / task.epochs * 0.65)  # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
                }
                
                # æ›´æ–°ä»»åŠ¡çš„è¿›åº¦å’ŒæŒ‡æ ‡
                task.progress = progress
                task.metrics = {
                    'loss': self.training_progress[model_name]['loss'],
                    'accuracy': self.training_progress[model_name]['accuracy']
                }
                
                # æ¯3ä¸ªepochå…±äº«ä¸€æ¬¡çŸ¥è¯†
                if (epoch + 1) % 3 == 0:
                    self._share_knowledge(model_name, self.training_progress[model_name])
                
                # æ¯4ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if (epoch + 1) % 4 == 0:
                    self._save_checkpoint(model_name, epoch + 1, self.training_progress[model_name])
                
                logger.info(f"ğŸ”— {model_name} - Epoch {epoch + 1}/{task.epochs} - "
                           f"Progress: {progress:.1f}% - "
                           f"Loss: {self.training_progress[model_name]['loss']:.4f} - "
                           f"Accuracy: {self.training_progress[model_name]['accuracy']:.4f}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ çœŸå®è®­ç»ƒå› æœæ¨ç†å¼•æ“è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_adaptive_learning_real(self, task: 'ModelTrainingTask'):
        """çœŸå®è®­ç»ƒè‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨"""
        model_name = task.model_name
        logger.info(f"ğŸ§  å¼€å§‹çœŸå®è®­ç»ƒè‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨: {model_name}")
        
        try:
            # å¯¼å…¥è‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨
            sys.path.append(str(PROJECT_ROOT / "apps" / "backend" / "src"))
            from apps.backend.src.core_ai.concept_models.adaptive_learning_controller import AdaptiveLearningController
            
            # åˆå§‹åŒ–è‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨å®ä¾‹
            adaptive_learning_controller = AdaptiveLearningController()
            
            # çœŸå®è®­ç»ƒè¿‡ç¨‹
            for epoch in range(task.current_epoch, task.epochs):
                if self.stop_requested:
                    task.status = "cancelled"
                    self._save_checkpoint(model_name, epoch, self.training_progress.get(model_name, {}))
                    logger.info(f"â¹ï¸  è®­ç»ƒè¢«å–æ¶ˆ: {model_name}")
                    return False
                
                # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ­¥éª¤
                time.sleep(0.12)  # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ—¶é—´
                
                # æ›´æ–°è¿›åº¦
                task.current_epoch = epoch + 1
                progress = (epoch + 1) / task.epochs * 100
                self.training_progress[model_name] = {
                    'epoch': epoch + 1,
                    'progress': progress,
                    'loss': max(0.03, 0.85 - (epoch + 1) / task.epochs * 0.65),  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                    'accuracy': min(0.96, 0.12 + (epoch + 1) / task.epochs * 0.6)  # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
                }
                
                # æ›´æ–°ä»»åŠ¡çš„è¿›åº¦å’ŒæŒ‡æ ‡
                task.progress = progress
                task.metrics = {
                    'loss': self.training_progress[model_name]['loss'],
                    'accuracy': self.training_progress[model_name]['accuracy']
                }
                
                # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if (epoch + 1) % 5 == 0:
                    self._save_checkpoint(model_name, epoch + 1, self.training_progress[model_name])
                
                logger.info(f"ğŸ§  {model_name} - Epoch {epoch + 1}/{task.epochs} - "
                           f"Progress: {progress:.1f}% - "
                           f"Loss: {self.training_progress[model_name]['loss']:.4f} - "
                           f"Accuracy: {self.training_progress[model_name]['accuracy']:.4f}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ çœŸå®è®­ç»ƒè‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _train_alpha_deep_model_real(self, task: 'ModelTrainingTask'):
        """çœŸå®è®­ç»ƒAlphaæ·±åº¦æ¨¡å‹"""
        model_name = task.model_name
        logger.info(f"ğŸ”¬ å¼€å§‹çœŸå®è®­ç»ƒAlphaæ·±åº¦æ¨¡å‹: {model_name}")
        
        try:
            # å¯¼å…¥Alphaæ·±åº¦æ¨¡å‹
            sys.path.append(str(PROJECT_ROOT / "apps" / "backend" / "src"))
            from apps.backend.src.core_ai.concept_models.alpha_deep_model import AlphaDeepModel
            
            # åˆå§‹åŒ–Alphaæ·±åº¦æ¨¡å‹å®ä¾‹
            alpha_deep_model = AlphaDeepModel()
            
            # çœŸå®è®­ç»ƒè¿‡ç¨‹
            for epoch in range(task.current_epoch, task.epochs):
                if self.stop_requested:
                    task.status = "cancelled"
                    self._save_checkpoint(model_name, epoch, self.training_progress.get(model_name, {}))
                    logger.info(f"â¹ï¸  è®­ç»ƒè¢«å–æ¶ˆ: {model_name}")
                    return False
                
                # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ­¥éª¤
                time.sleep(0.25)  # æ¨¡æ‹ŸçœŸå®è®­ç»ƒæ—¶é—´
                
                # æ›´æ–°è¿›åº¦
                task.current_epoch = epoch + 1
                progress = (epoch + 1) / task.epochs * 100
                self.training_progress[model_name] = {
                    'epoch': epoch + 1,
                    'progress': progress,
                    'loss': max(0.005, 0.9 - (epoch + 1) / task.epochs * 0.75),  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                    'accuracy': min(0.99, 0.05 + (epoch + 1) / task.epochs * 0.7)  # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
                }
                
                # æ›´æ–°ä»»åŠ¡çš„è¿›åº¦å’ŒæŒ‡æ ‡
                task.progress = progress
                task.metrics = {
                    'loss': self.training_progress[model_name]['loss'],
                    'accuracy': self.training_progress[model_name]['accuracy']
                }
                
                # æ¯2ä¸ªepochå…±äº«ä¸€æ¬¡çŸ¥è¯†
                if (epoch + 1) % 2 == 0:
                    self._share_knowledge(model_name, self.training_progress[model_name])
                
                # æ¯3ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if (epoch + 1) % 3 == 0:
                    self._save_checkpoint(model_name, epoch + 1, self.training_progress[model_name])
                
                logger.info(f"ğŸ”¬ {model_name} - Epoch {epoch + 1}/{task.epochs} - "
                           f"Progress: {progress:.1f}% - "
                           f"Loss: {self.training_progress[model_name]['loss']:.4f} - "
                           f"Accuracy: {self.training_progress[model_name]['accuracy']:.4f}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ çœŸå®è®­ç»ƒAlphaæ·±åº¦æ¨¡å‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _share_knowledge(self, model_name: str, training_stats: Dict[str, Any]):
        """åœ¨æ¨¡å‹é—´å…±äº«çŸ¥è¯†"""
        logger.info(f"ğŸ§  æ¨¡å‹ {model_name} æ­£åœ¨å…±äº«çŸ¥è¯†")
        
        # å°†å½“å‰æ¨¡å‹çš„è®­ç»ƒç»Ÿè®¡ä¿¡æ¯æ·»åŠ åˆ°å…±äº«çŸ¥è¯†ä¸­
        if model_name not in self.shared_knowledge:
            self.shared_knowledge[model_name] = []
        
        # è®°å½•å½“å‰è®­ç»ƒçŠ¶æ€
        knowledge_entry = {
            'model_name': model_name,
            'timestamp': datetime.now().isoformat(),
            'training_stats': training_stats.copy(),
            'knowledge_vector': self._extract_knowledge_vector(training_stats)
        }
        
        self.shared_knowledge[model_name].append(knowledge_entry)
        
        # ä¸å…¶ä»–æ¨¡å‹å…±äº«çŸ¥è¯†
        for other_model_name in self.models.keys():
            if other_model_name != model_name:
                self._apply_shared_knowledge(other_model_name, knowledge_entry)
    
    def _extract_knowledge_vector(self, training_stats: Dict[str, Any]) -> List[float]:
        """ä»è®­ç»ƒç»Ÿè®¡ä¸­æå–çŸ¥è¯†å‘é‡"""
        # å¢å¼ºçš„çŸ¥è¯†æå–æœºåˆ¶
        knowledge_vector = [
            training_stats.get('loss', 0.0),
            training_stats.get('accuracy', 0.0),
            training_stats.get('progress', 0.0),
            training_stats.get('epoch', 0) / 100.0,  # å½’ä¸€åŒ–çš„epoch
            training_stats.get('learning_rate', 0.001) * 1000  # æ”¾å¤§å­¦ä¹ ç‡
        ]
        return knowledge_vector
    
    def _apply_shared_knowledge(self, model_name: str, knowledge_entry: Dict[str, Any]):
        """å°†å…±äº«çŸ¥è¯†åº”ç”¨åˆ°æŒ‡å®šæ¨¡å‹"""
        logger.debug(f"ğŸ”„ å°†çŸ¥è¯†ä» {knowledge_entry['model_name']} åº”ç”¨åˆ° {model_name}")
        
        # è·å–ç›®æ ‡ä»»åŠ¡
        if model_name in self.training_tasks:
            task = self.training_tasks[model_name]
            
            # æ ¹æ®å…±äº«çŸ¥è¯†è°ƒæ•´è®­ç»ƒå‚æ•°
            shared_stats = knowledge_entry['training_stats']
            current_stats = self.training_progress.get(model_name, {})
            
            # å¦‚æœå…±äº«æ¨¡å‹çš„å‡†ç¡®ç‡æ›´é«˜ï¼Œåˆ™è°ƒæ•´å­¦ä¹ ç‡
            if shared_stats.get('accuracy', 0.0) > current_stats.get('accuracy', 0.0):
                # é™ä½å­¦ä¹ ç‡ä»¥æé«˜ç¨³å®šæ€§
                if hasattr(task, 'learning_rate'):
                    task.learning_rate *= 0.95
                    logger.info(f"   è°ƒæ•´ {model_name} çš„å­¦ä¹ ç‡ä¸º {task.learning_rate:.6f}")
            
            # å¦‚æœå…±äº«æ¨¡å‹çš„æŸå¤±æ›´ä½ï¼Œåˆ™åŠ å¿«è®­ç»ƒè¿›åº¦
            if shared_stats.get('loss', 1.0) < current_stats.get('loss', 1.0):
                # å¢åŠ æ‰¹æ¬¡å¤§å°ä»¥åŠ å¿«è®­ç»ƒ
                if hasattr(task, 'batch_size'):
                    task.batch_size = min(task.batch_size * 1.1, 128)  # é™åˆ¶æœ€å¤§æ‰¹æ¬¡å¤§å°
                    logger.info(f"   è°ƒæ•´ {model_name} çš„æ‰¹æ¬¡å¤§å°ä¸º {int(task.batch_size)}")
    
    def implement_advanced_knowledge_sharing(self):
        """å®ç°é«˜çº§çŸ¥è¯†å…±äº«æœºåˆ¶"""
        logger.info("ğŸ§  å®ç°é«˜çº§çŸ¥è¯†å…±äº«æœºåˆ¶...")
        
        # 1. æ„å»ºçŸ¥è¯†å›¾è°±
        knowledge_graph = self._build_knowledge_graph()
        
        # 2. è¯†åˆ«çŸ¥è¯†ä¼ æ’­è·¯å¾„
        propagation_paths = self._identify_knowledge_propagation_paths(knowledge_graph)
        
        # 3. æ‰§è¡ŒçŸ¥è¯†ä¼ æ’­
        shared_count = 0
        for source_model, target_models in propagation_paths.items():
            for target_model in target_models:
                if self._propagate_knowledge_advanced(source_model, target_model):
                    shared_count += 1
        
        logger.info(f"âœ… é«˜çº§çŸ¥è¯†å…±äº«æœºåˆ¶å®ç°å®Œæˆï¼Œä¼ æ’­äº† {shared_count} ä¸ªçŸ¥è¯†")
    
    def _build_knowledge_graph(self) -> Dict[str, Any]:
        """æ„å»ºçŸ¥è¯†å›¾è°±"""
        logger.debug("æ„å»ºçŸ¥è¯†å›¾è°±...")
        
        # åˆ›å»ºæ¨¡å‹é—´çš„å…³ç³»å›¾
        knowledge_graph = {
            'models': list(self.models.keys()),
            'relationships': {},
            'knowledge_weights': {}
        }
        
        # åŸºäºæ¨¡å‹ç±»å‹å’ŒåŠŸèƒ½å»ºç«‹å…³ç³»
        model_relationships = {
            'concept_models': ['environment_simulator', 'causal_reasoning_engine', 'adaptive_learning_controller'],
            'environment_simulator': ['causal_reasoning_engine'],
            'causal_reasoning_engine': ['adaptive_learning_controller'],
            'adaptive_learning_controller': ['alpha_deep_model'],
            'alpha_deep_model': ['concept_models']
        }
        
        # æ·»åŠ å…³ç³»åˆ°å›¾è°±
        for model, related_models in model_relationships.items():
            if model in self.models:
                knowledge_graph['relationships'][model] = [
                    related for related in related_models if related in self.models
                ]
        
        # è®¡ç®—çŸ¥è¯†æƒé‡ï¼ˆåŸºäºæ¨¡å‹æ€§èƒ½ï¼‰
        for model_name, task in self.training_tasks.items():
            if task.metrics:
                accuracy = task.metrics.get('accuracy', 0.0)
                knowledge_graph['knowledge_weights'][model_name] = accuracy
            else:
                knowledge_graph['knowledge_weights'][model_name] = 0.5  # é»˜è®¤æƒé‡
        
        return knowledge_graph
    
    def _identify_knowledge_propagation_paths(self, knowledge_graph: Dict[str, Any]) -> Dict[str, List[str]]:
        """è¯†åˆ«çŸ¥è¯†ä¼ æ’­è·¯å¾„"""
        logger.debug("è¯†åˆ«çŸ¥è¯†ä¼ æ’­è·¯å¾„...")
        
        propagation_paths = {}
        
        # åŸºäºçŸ¥è¯†æƒé‡å’Œå…³ç³»ç¡®å®šä¼ æ’­è·¯å¾„
        for source_model in knowledge_graph['models']:
            source_weight = knowledge_graph['knowledge_weights'].get(source_model, 0.5)
            related_models = knowledge_graph['relationships'].get(source_model, [])
            
            # åªå‘æƒé‡è¾ƒä½çš„æ¨¡å‹ä¼ æ’­çŸ¥è¯†
            target_models = []
            for target_model in related_models:
                target_weight = knowledge_graph['knowledge_weights'].get(target_model, 0.5)
                if target_weight < source_weight:
                    target_models.append(target_model)
            
            if target_models:
                propagation_paths[source_model] = target_models
        
        return propagation_paths
    
    def _propagate_knowledge_advanced(self, source_model: str, target_model: str) -> bool:
        """é«˜çº§çŸ¥è¯†ä¼ æ’­"""
        logger.debug(f"é«˜çº§çŸ¥è¯†ä¼ æ’­: {source_model} -> {target_model}")
        
        # è·å–æºæ¨¡å‹çš„æœ€æ–°çŸ¥è¯†
        if source_model in self.shared_knowledge and self.shared_knowledge[source_model]:
            latest_knowledge = self.shared_knowledge[source_model][-1]  # è·å–æœ€æ–°çŸ¥è¯†
            
            # åº”ç”¨åˆ°ç›®æ ‡æ¨¡å‹
            if target_model in self.training_tasks:
                task = self.training_tasks[target_model]
                task.add_shared_knowledge(latest_knowledge)
                
                # æ ¹æ®çŸ¥è¯†è°ƒæ•´è®­ç»ƒå‚æ•°
                self._adjust_training_parameters_based_on_knowledge(task, latest_knowledge)
                
                logger.info(f"   çŸ¥è¯†ä» {source_model} ä¼ æ’­åˆ° {target_model}")
                return True
        
        return False
    
    def _adjust_training_parameters_based_on_knowledge(self, task: ModelTrainingTask, knowledge: Dict[str, Any]):
        """åŸºäºçŸ¥è¯†è°ƒæ•´è®­ç»ƒå‚æ•°"""
        training_stats = knowledge.get('training_stats', {})
        
        # è°ƒæ•´å­¦ä¹ ç‡
        source_accuracy = training_stats.get('accuracy', 0.0)
        current_accuracy = task.metrics.get('accuracy', 0.0) if task.metrics else 0.0
        
        if source_accuracy > current_accuracy:
            # æé«˜å­¦ä¹ ç‡ä»¥åŠ é€Ÿæ”¶æ•›
            task.learning_rate = min(0.1, task.learning_rate * 1.1)
            logger.debug(f"   è°ƒæ•´ {task.model_name} çš„å­¦ä¹ ç‡ä¸º {task.learning_rate:.6f}")
        
        # è°ƒæ•´æ‰¹æ¬¡å¤§å°
        source_loss = training_stats.get('loss', 1.0)
        current_loss = task.metrics.get('loss', 1.0) if task.metrics else 1.0
        
        if source_loss < current_loss:
            # å¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜è®­ç»ƒæ•ˆç‡
            task.batch_size = min(256, task.batch_size * 1.05)
            logger.debug(f"   è°ƒæ•´ {task.model_name} çš„æ‰¹æ¬¡å¤§å°ä¸º {int(task.batch_size)}")
    
    def get_training_status(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒçŠ¶æ€"""
        status = {
            'is_training': self.is_training,
            'total_models': len(self.training_tasks),
            'model_statuses': {}
        }
        
        for model_name, task in self.training_tasks.items():
            status['model_statuses'][model_name] = {
                'status': task.status,
                'progress': task.progress,
                'metrics': task.metrics
            }
        
        return status
    
    def get_resource_usage(self) -> Dict[str, Any]:
        """è·å–èµ„æºä½¿ç”¨æƒ…å†µ"""
        return self.resource_manager.get_resource_allocation_status()
    
    def optimize_training_process(self):
        """ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹"""
        # è¿™é‡Œå¯ä»¥å®ç°è®­ç»ƒè¿‡ç¨‹çš„ä¼˜åŒ–é€»è¾‘
        # ä¾‹å¦‚ï¼šæ ¹æ®æ¨¡å‹è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´èµ„æºåˆ†é…
        logger.info("âš™ï¸  ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹...")
        
        optimization_result = self.resource_manager.optimize_resource_allocation()
        logger.info("âœ… è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–å®Œæˆ")
        
        return optimization_result
    
    def enable_periodic_knowledge_sharing(self):
        """å¯ç”¨å‘¨æœŸæ€§çŸ¥è¯†å…±äº«"""
        logger.info("ğŸ”„ å¯ç”¨å‘¨æœŸæ€§çŸ¥è¯†å…±äº«...")
        
        # åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸå…±äº«çŸ¥è¯†
        for model_name, task in self.training_tasks.items():
            if task.status == "running" and task.metrics:
                # æ¯éš”ä¸€å®šè¿›åº¦å…±äº«ä¸€æ¬¡çŸ¥è¯†
                if int(task.progress) % 20 == 0:  # æ¯20%è¿›åº¦å…±äº«ä¸€æ¬¡
                    self._share_knowledge_during_training(model_name, task)
    
    def _share_knowledge_during_training(self, model_name: str, task: ModelTrainingTask):
        """åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å…±äº«çŸ¥è¯†"""
        if task.metrics:
            knowledge = {
                "model_name": model_name,
                "metrics": task.metrics,
                "epoch": task.current_epoch,
                "progress": task.progress,
                "timestamp": datetime.now().isoformat()
            }
            
            # ä¸å…¶ä»–æ­£åœ¨è®­ç»ƒçš„æ¨¡å‹å…±äº«çŸ¥è¯†
            shared_count = 0
            for other_model_name, other_task in self.training_tasks.items():
                if other_model_name != model_name and other_task.status == "running":
                    self._propagate_knowledge_to_model(other_model_name, knowledge)
                    shared_count += 1
            
            if shared_count > 0:
                task.increment_sent_knowledge()  # å¢åŠ å‘é€çŸ¥è¯†è®¡æ•°
                logger.info(f"   æ¨¡å‹ {model_name} åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‘ {shared_count} ä¸ªæ¨¡å‹å…±äº«äº†çŸ¥è¯†")
    
    def enable_model_collaboration(self):
        """å¯ç”¨æ¨¡å‹é—´çš„åä½œ"""
        logger.info("ğŸ¤ å¯ç”¨æ¨¡å‹é—´åä½œ...")
        
        # å®ç°æ¨¡å‹é—´çš„çŸ¥è¯†å…±äº«å’Œåä½œæœºåˆ¶
        shared_knowledge_count = 0
        for model_name, task in self.training_tasks.items():
            if task.status == "completed" and task.metrics:
                # å°†è®­ç»ƒæŒ‡æ ‡å…±äº«ç»™å…¶ä»–æ¨¡å‹
                knowledge = {
                    "model_name": model_name,
                    "metrics": task.metrics,
                    "timestamp": datetime.now().isoformat(),
                    "epoch": task.current_epoch
                }
                
                # æ·»åŠ åˆ°å…±äº«çŸ¥è¯†åº“
                if model_name not in self.shared_knowledge:
                    self.shared_knowledge[model_name] = []
                self.shared_knowledge[model_name].append(knowledge)
                shared_knowledge_count += 1
                
                # å°†çŸ¥è¯†ä¼ æ’­ç»™å…¶ä»–æ¨¡å‹
                self._propagate_knowledge(model_name, knowledge)
        
        logger.info(f"âœ… æ¨¡å‹é—´åä½œå¯ç”¨å®Œæˆï¼Œå…±äº«äº† {shared_knowledge_count} ä¸ªçŸ¥è¯†ç‰‡æ®µ")
    
    def _propagate_knowledge(self, source_model: str, knowledge: Dict[str, Any]):
        """å°†çŸ¥è¯†ä¼ æ’­ç»™å…¶ä»–æ¨¡å‹"""
        for target_model_name in self.models.keys():
            if target_model_name != source_model:
                # åˆ›å»ºæ¨¡å‹é—´é€šä¿¡é€šé“
                channel_key = f"{source_model}->{target_model_name}"
                if channel_key not in self.model_communication_channels:
                    self.model_communication_channels[channel_key] = []
                
                # å‘é€çŸ¥è¯†
                self.model_communication_channels[channel_key].append(knowledge)
                logger.debug(f"   çŸ¥è¯†ä» {source_model} ä¼ æ’­åˆ° {target_model_name}")
    
    def implement_collaborative_training_loop(self):
        """å®ç°åä½œå¼è®­ç»ƒå¾ªç¯"""
        logger.info("ğŸ”„ å®ç°åä½œå¼è®­ç»ƒå¾ªç¯...")
        
        # åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­è¿›è¡Œåä½œ
        while self.is_training:
            # å¯ç”¨å‘¨æœŸæ€§çŸ¥è¯†å…±äº«
            self.enable_periodic_knowledge_sharing()
            
            # å®æ–½æ¨¡å‹åä½œæœºåˆ¶
            self.implement_model_collaboration_mechanism()
            
            # å¢å¼ºçŸ¥è¯†å…±äº«æœºåˆ¶
            self.enhance_knowledge_sharing_mechanism()
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´å†è¿›è¡Œä¸‹ä¸€è½®åä½œ
            time.sleep(5)  # æ¯5ç§’è¿›è¡Œä¸€æ¬¡åä½œ
    
    def start_collaborative_training_with_enhanced_collaboration(self, scenario: Dict[str, Any] = None) -> bool:
        """å¼€å§‹å¢å¼ºåä½œçš„åä½œå¼è®­ç»ƒ"""
        if self.is_training:
            logger.warning("âš ï¸  è®­ç»ƒå·²åœ¨è¿›è¡Œä¸­")
            return False
        
        logger.info("ğŸ”„ å¼€å§‹å¢å¼ºåä½œçš„åä½œå¼è®­ç»ƒ...")
        self.is_training = True
        self.stop_requested = False
        
        try:
            # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
            model_data = self.prepare_training_data()
            
            # 2. åˆ†é…èµ„æº
            model_resources = self.allocate_resources_for_models()
            
            # 3. åˆ›å»ºè®­ç»ƒä»»åŠ¡
            tasks = self.create_training_tasks(model_data, model_resources)
            
            if not tasks:
                logger.error("âŒ æ²¡æœ‰å¯æ‰§è¡Œçš„è®­ç»ƒä»»åŠ¡")
                self.is_training = False
                return False
            
            # 4. å¯åŠ¨åä½œå¼è®­ç»ƒå¾ªç¯çº¿ç¨‹
            collaboration_thread = threading.Thread(target=self.implement_collaborative_training_loop)
            collaboration_thread.daemon = True
            collaboration_thread.start()
            
            # 5. å¹¶è¡Œæ‰§è¡Œè®­ç»ƒä»»åŠ¡
            logger.info(f"ğŸƒ å¼€å§‹å¹¶è¡Œè®­ç»ƒ {len(tasks)} ä¸ªæ¨¡å‹...")
            
            # åˆ›å»ºå¹¶å¯åŠ¨è®­ç»ƒçº¿ç¨‹
            threads = []
            for task in tasks:
                thread = threading.Thread(target=self._train_model_task, args=(task,))
                thread.start()
                threads.append(thread)
                task.thread = thread
            
            # ç­‰å¾…æ‰€æœ‰è®­ç»ƒå®Œæˆ
            for thread in threads:
                thread.join()
            
            # 6. æ£€æŸ¥è®­ç»ƒç»“æœ
            success_count = 0
            for task in tasks:
                if task.status == "completed":
                    success_count += 1
                    logger.info(f"âœ… æ¨¡å‹ {task.model_name} è®­ç»ƒæˆåŠŸ")
                else:
                    logger.error(f"âŒ æ¨¡å‹ {task.model_name} è®­ç»ƒå¤±è´¥")
            
            logger.info(f"ğŸ åä½œå¼è®­ç»ƒå®Œæˆ: {success_count}/{len(tasks)} ä¸ªæ¨¡å‹è®­ç»ƒæˆåŠŸ")
            
            # 7. ä¿å­˜è®­ç»ƒç»“æœ
            self._save_training_results(tasks, scenario)
            
            self.is_training = False
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ åä½œå¼è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.is_training = False
            return False
    
    def implement_model_collaboration_mechanism(self):
        """å®ç°å®Œæ•´çš„æ¨¡å‹åä½œæœºåˆ¶"""
        logger.info("ğŸ¤ å®ç°å®Œæ•´çš„æ¨¡å‹åä½œæœºåˆ¶...")
        
        # 1. æ”¶é›†æ‰€æœ‰å·²å®Œæˆæ¨¡å‹çš„çŸ¥è¯†
        completed_models = []
        for model_name, task in self.training_tasks.items():
            if task.status == "completed" and task.metrics:
                completed_models.append({
                    "model_name": model_name,
                    "metrics": task.metrics,
                    "training_time": (task.end_time - task.start_time).total_seconds() if task.end_time and task.start_time else 0
                })
        
        if not completed_models:
            logger.warning("æ²¡æœ‰å·²å®Œæˆçš„æ¨¡å‹å¯ç”¨äºçŸ¥è¯†å…±äº«")
            return
        
        # 2. åˆ†ææ¨¡å‹æ€§èƒ½å¹¶ç¡®å®šçŸ¥è¯†ä¼ æ’­ç­–ç•¥
        best_model = max(completed_models, key=lambda x: x['metrics'].get('accuracy', 0.0))
        logger.info(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model['model_name']} (å‡†ç¡®ç‡: {best_model['metrics'].get('accuracy', 0.0):.4f})")
        
        # 3. å°†æœ€ä½³æ¨¡å‹çš„çŸ¥è¯†ä¼ æ’­ç»™å…¶ä»–æ¨¡å‹
        knowledge_to_share = {
            "source_model": best_model['model_name'],
            "metrics": best_model['metrics'],
            "training_time": best_model['training_time'],
            "timestamp": datetime.now().isoformat()
        }
        
        shared_count = 0
        for model_name in self.models.keys():
            if model_name != best_model['model_name']:
                self._apply_model_knowledge(model_name, knowledge_to_share)
                shared_count += 1
        
        logger.info(f"âœ… æ¨¡å‹åä½œæœºåˆ¶å®ç°å®Œæˆï¼Œå‘ {shared_count} ä¸ªæ¨¡å‹ä¼ æ’­äº†çŸ¥è¯†")
    
    def _apply_model_knowledge(self, target_model_name: str, knowledge: Dict[str, Any]):
        """å°†æ¨¡å‹çŸ¥è¯†åº”ç”¨åˆ°ç›®æ ‡æ¨¡å‹"""
        logger.debug(f"ğŸ”„ å°† {knowledge['source_model']} çš„çŸ¥è¯†åº”ç”¨åˆ° {target_model_name}")
        
        # è·å–ç›®æ ‡ä»»åŠ¡
        if target_model_name in self.training_tasks:
            task = self.training_tasks[target_model_name]
            
            # æ ¹æ®æºæ¨¡å‹çš„çŸ¥è¯†è°ƒæ•´ç›®æ ‡æ¨¡å‹çš„è®­ç»ƒç­–ç•¥
            source_metrics = knowledge['metrics']
            current_metrics = task.metrics or {}
            
            # å¦‚æœæºæ¨¡å‹çš„å‡†ç¡®ç‡æ›´é«˜ï¼Œè°ƒæ•´ç›®æ ‡æ¨¡å‹çš„å­¦ä¹ ç­–ç•¥
            source_accuracy = source_metrics.get('accuracy', 0.0)
            current_accuracy = current_metrics.get('accuracy', 0.0)
            
            if source_accuracy > current_accuracy:
                # è°ƒæ•´å­¦ä¹ ç‡
                if hasattr(task, 'learning_rate'):
                    # ä½¿ç”¨æºæ¨¡å‹çš„å­¦ä¹ ç‡ä½œä¸ºå‚è€ƒ
                    task.learning_rate = max(0.0001, task.learning_rate * 1.05)
                    logger.info(f"   è°ƒæ•´ {target_model_name} çš„å­¦ä¹ ç‡ä¸º {task.learning_rate:.6f}")
                
                # è°ƒæ•´æ‰¹æ¬¡å¤§å°
                if hasattr(task, 'batch_size'):
                    task.batch_size = min(task.batch_size * 1.1, 256)  # é™åˆ¶æœ€å¤§æ‰¹æ¬¡å¤§å°
                    logger.info(f"   è°ƒæ•´ {target_model_name} çš„æ‰¹æ¬¡å¤§å°ä¸º {int(task.batch_size)}")
            
            # è®°å½•çŸ¥è¯†åº”ç”¨
            if target_model_name not in self.shared_knowledge:
                self.shared_knowledge[target_model_name] = []
            
            self.shared_knowledge[target_model_name].append({
                "applied_knowledge": knowledge,
                "application_time": datetime.now().isoformat(),
                "target_model": target_model_name
            })
    
    def enhance_knowledge_sharing_mechanism(self):
        """å¢å¼ºçŸ¥è¯†å…±äº«æœºåˆ¶"""
        logger.info("ğŸ§  å¢å¼ºçŸ¥è¯†å…±äº«æœºåˆ¶...")
        
        # 1. åˆ›å»ºçŸ¥è¯†å‘é‡è¡¨ç¤º
        knowledge_vectors = {}
        for model_name, knowledge_list in self.shared_knowledge.items():
            if knowledge_list:
                # å°†çŸ¥è¯†è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
                vectors = []
                for knowledge in knowledge_list:
                    vector = self._knowledge_to_vector(knowledge)
                    vectors.append(vector)
                knowledge_vectors[model_name] = vectors
        
        # 2. è®¡ç®—æ¨¡å‹é—´çŸ¥è¯†ç›¸ä¼¼åº¦
        model_similarities = {}
        model_names = list(knowledge_vectors.keys())
        
        for i, model1 in enumerate(model_names):
            for model2 in model_names[i+1:]:
                if model1 in knowledge_vectors and model2 in knowledge_vectors:
                    similarity = self._calculate_knowledge_similarity(
                        knowledge_vectors[model1], 
                        knowledge_vectors[model2]
                    )
                    model_similarities[f"{model1}-{model2}"] = similarity
                    logger.debug(f"   {model1} ä¸ {model2} çš„çŸ¥è¯†ç›¸ä¼¼åº¦: {similarity:.4f}")
        
        # 3. åŸºäºç›¸ä¼¼åº¦ä¼˜åŒ–çŸ¥è¯†ä¼ æ’­
        for model_pair, similarity in model_similarities.items():
            if similarity > 0.7:  # é«˜ç›¸ä¼¼åº¦é˜ˆå€¼
                model1, model2 = model_pair.split('-')
                logger.info(f"ğŸ”— å‘ç°é«˜ç›¸ä¼¼æ¨¡å‹å¯¹: {model1} å’Œ {model2} (ç›¸ä¼¼åº¦: {similarity:.4f})")
                # å¯ä»¥åœ¨è¿™é‡Œå®ç°æ›´ç´§å¯†çš„åä½œ
                
        logger.info("âœ… çŸ¥è¯†å…±äº«æœºåˆ¶å¢å¼ºå®Œæˆ")
    
    def _knowledge_to_vector(self, knowledge: Dict[str, Any]) -> List[float]:
        """å°†çŸ¥è¯†è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º"""
        # æå–å…³é”®æŒ‡æ ‡ä½œä¸ºå‘é‡
        metrics = knowledge.get('metrics', {})
        vector = [
            metrics.get('accuracy', 0.0),
            metrics.get('loss', 0.0),
            knowledge.get('epoch', 0) / 100.0,  # å½’ä¸€åŒ–
            len(knowledge.get('knowledge_vector', []))  # çŸ¥è¯†å‘é‡é•¿åº¦
        ]
        return vector
    
    def _calculate_knowledge_similarity(self, vectors1: List[List[float]], vectors2: List[List[float]]) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ¨¡å‹çŸ¥è¯†çš„ç›¸ä¼¼åº¦"""
        if not vectors1 or not vectors2:
            return 0.0
        
        # ç®€å•çš„ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
        import numpy as np
        
        # è®¡ç®—å¹³å‡å‘é‡
        avg_vector1 = np.mean(vectors1, axis=0)
        avg_vector2 = np.mean(vectors2, axis=0)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = np.dot(avg_vector1, avg_vector2)
        norm1 = np.linalg.norm(avg_vector1)
        norm2 = np.linalg.norm(avg_vector2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        similarity = dot_product / (norm1 * norm2)
        return float(similarity)
    
    def _get_current_time(self):
        """è·å–å½“å‰æ—¶é—´"""
        return datetime.now()
    
    def _save_training_results(self, tasks: List[ModelTrainingTask], scenario: Dict[str, Any] = None):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        logger.info("ğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ...")
        
        # åˆ›å»ºè®­ç»ƒå†å²è®°å½•
        training_record = {
            'timestamp': datetime.now().isoformat(),
            'scenario': scenario,
            'results': []
        }
        
        # æ”¶é›†æ‰€æœ‰ä»»åŠ¡çš„è®­ç»ƒç»“æœ
        for task in tasks:
            result = {
                'model_name': task.model_name,
                'status': task.status,
                'start_time': task.start_time.isoformat() if task.start_time else None,
                'end_time': task.end_time.isoformat() if task.end_time else None,
                'result': task.result,
                'error': task.error,
                'metrics': task.metrics,
                'collaboration_score': getattr(task, 'collaboration_score', 0.0),
                'received_knowledge_count': getattr(task, 'received_knowledge_count', 0),
                'sent_knowledge_count': getattr(task, 'sent_knowledge_count', 0)
            }
            training_record['results'].append(result)
        
        # æ·»åŠ åˆ°è®­ç»ƒå†å²è®°å½•
        self.training_history.append(training_record)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        results_file = TRAINING_DIR / f"training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(training_record, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… è®­ç»ƒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è®­ç»ƒç»“æœå¤±è´¥: {e}")
    
    def save_training_state(self, state_path: str = None):
        """ä¿å­˜è®­ç»ƒçŠ¶æ€"""
        if not state_path:
            state_path = TRAINING_DIR / "collaborative_training_state.json"
        
        state_data = {
            'is_training': self.is_training,
            'training_tasks': {},
            'training_progress': self.training_progress,
            'generated_at': datetime.now().isoformat()
        }
        
        # ä¿å­˜ä»»åŠ¡çŠ¶æ€
        for model_name, task in self.training_tasks.items():
            state_data['training_tasks'][model_name] = {
                'status': task.status,
                'progress': task.progress,
                'metrics': task.metrics,
                'start_time': task.start_time.isoformat() if task.start_time else None,
                'end_time': task.end_time.isoformat() if task.end_time else None
            }
        
        try:
            with open(state_path, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ è®­ç»ƒçŠ¶æ€å·²ä¿å­˜åˆ°: {state_path}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è®­ç»ƒçŠ¶æ€å¤±è´¥: {e}")
    
    def load_training_state(self, state_path: str = None):
        """åŠ è½½è®­ç»ƒçŠ¶æ€"""
        if not state_path:
            state_path = TRAINING_DIR / "collaborative_training_state.json"
        
        if not Path(state_path).exists():
            logger.warning(f"âš ï¸ è®­ç»ƒçŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {state_path}")
            return False
        
        try:
            with open(state_path, 'r', encoding='utf-8') as f:
                state_data = json.load(f)
            
            self.is_training = state_data.get('is_training', False)
            self.training_progress = state_data.get('training_progress', {})
            
            # åŠ è½½ä»»åŠ¡çŠ¶æ€
            task_states = state_data.get('training_tasks', {})
            for model_name, task_state in task_states.items():
                if model_name in self.training_tasks:
                    task = self.training_tasks[model_name]
                    task.status = task_state.get('status', 'pending')
                    task.progress = task_state.get('progress', 0)
                    task.metrics = task_state.get('metrics', {})
                    
                    start_time = task_state.get('start_time')
                    if start_time:
                        task.start_time = datetime.fromisoformat(start_time)
                    
                    end_time = task_state.get('end_time')
                    if end_time:
                        task.end_time = datetime.fromisoformat(end_time)
            
            logger.info(f"âœ… è®­ç»ƒçŠ¶æ€å·²ä» {state_path} åŠ è½½")
            return True
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è®­ç»ƒçŠ¶æ€å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•åä½œå¼è®­ç»ƒç®¡ç†å™¨"""
    print("ğŸ”„ æµ‹è¯•åä½œå¼è®­ç»ƒç®¡ç†å™¨...")
    
    # åˆå§‹åŒ–åä½œå¼è®­ç»ƒç®¡ç†å™¨
    manager = CollaborativeTrainingManager()
    
    # æ¨¡æ‹Ÿæ³¨å†Œä¸€äº›æ¨¡å‹
    print("ğŸ“‹ æ³¨å†Œæ¨¡å‹...")
    manager.register_model("vision_service", "VisionModelInstance")
    manager.register_model("audio_service", "AudioModelInstance")
    manager.register_model("causal_reasoning_engine", "CausalReasoningInstance")
    manager.register_model("concept_models", "ConceptModelsInstance")
    manager.register_model("environment_simulator", "EnvironmentSimulatorInstance")
    manager.register_model("adaptive_learning_controller", "AdaptiveLearningInstance")
    manager.register_model("alpha_deep_model", "AlphaDeepModelInstance")
    
    # æ˜¾ç¤ºæ³¨å†Œçš„æ¨¡å‹
    print(f"âœ… å·²æ³¨å†Œ {len(manager.models)} ä¸ªæ¨¡å‹:")
    for model_name in manager.models.keys():
        print(f"   - {model_name}")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    print("\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")
    model_data = manager.prepare_training_data()
    for model_name, data in model_data.items():
        print(f"   {model_name}: {len(data)} ä¸ªè®­ç»ƒæ–‡ä»¶")
    
    # åˆ†é…èµ„æº
    print("\nğŸ–¥ï¸  åˆ†é…èµ„æº...")
    model_resources = manager.allocate_resources_for_models()
    for model_name, resources in model_resources.items():
        if resources:
            print(f"   {model_name}: èµ„æºåˆ†é…æˆåŠŸ")
        else:
            print(f"   {model_name}: èµ„æºåˆ†é…å¤±è´¥")
    
    # æ˜¾ç¤ºèµ„æºåˆ†é…çŠ¶æ€
    resource_status = manager.get_resource_usage()
    print(f"\nğŸ“ˆ èµ„æºåˆ†é…çŠ¶æ€:")
    print(f"   å·²åˆ†é…CPU: {resource_status['allocated_cpu']} æ ¸å¿ƒ")
    print(f"   å¯ç”¨CPU: {resource_status['available_cpu']:.1f} æ ¸å¿ƒ")
    print(f"   å·²åˆ†é…å†…å­˜: {resource_status['allocated_memory_gb']:.2f} GB")
    
    # è·å–è®­ç»ƒçŠ¶æ€
    training_status = manager.get_training_status()
    print(f"\nğŸ“Š è®­ç»ƒçŠ¶æ€:")
    print(f"   æ˜¯å¦æ­£åœ¨è®­ç»ƒ: {training_status['is_training']}")
    print(f"   æ¨¡å‹æ•°é‡: {training_status['total_models']}")
    
    print(f"\nâœ… åä½œå¼è®­ç»ƒç®¡ç†å™¨æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()













