#!/usr/bin/env python3
"""
åä½œå¼è®­ç»ƒç®¡ç†å™¨
è´Ÿè´£åè°ƒæ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå®ç°æ¨¡å‹é—´çš„åä½œè®­ç»ƒ
"""

import os
import logging
import asyncio
import json
from pathlib import Path
from typing import Dict, List, Any, Callable, Optional
from datetime import datetime
import threading
import time
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
project_root = Path(__file__).parent.parent
backend_path = project_root / "apps" / "backend"
sys.path.insert(0, str(backend_path))
sys.path.insert(0, str(backend_path / "src"))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from apps.backend.src.path_config import (
        PROJECT_ROOT, 
        DATA_DIR, 
        TRAINING_DIR, 
        MODELS_DIR,
        get_data_path, 
        resolve_path
    )
except ImportError:
    # å¦‚æœè·¯å¾„é…ç½®æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„å¤„ç†
    PROJECT_ROOT = project_root
    DATA_DIR = PROJECT_ROOT / "data"
    TRAINING_DIR = PROJECT_ROOT / "training"
    MODELS_DIR = TRAINING_DIR / "models"

# å¯¼å…¥æ•°æ®ç®¡ç†å™¨å’Œèµ„æºç®¡ç†å™¨
from .data_manager import DataManager
from .resource_manager import ResourceManager

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

from dataclasses import dataclass

@dataclass
class ModelTrainingTask:
    """æ¨¡å‹è®­ç»ƒä»»åŠ¡"""
    model_name: str
    model_instance: Any
    data: List[Dict]
    resources: Dict
    epochs: int = 10
    batch_size: int = 32
    status: str = "pending"  # pending, running, completed, failed, cancelled
    current_epoch: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    thread: Optional[threading.Thread] = None
    progress: float = 0.0
    metrics: Optional[Dict[str, Any]] = None

class CollaborativeTrainingManager:
    """åä½œå¼è®­ç»ƒç®¡ç†å™¨ï¼Œè´Ÿè´£åè°ƒæ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹"""
    
    def __init__(self):
        self.models = {}
        self.training_tasks = {}
        self.data_manager = DataManager()
        self.resource_manager = ResourceManager()
        self.training_progress = {}
        self.is_training = False
        self.training_thread = None
        self.stop_requested = False
        # æ·»åŠ çŸ¥è¯†å…±äº«æœºåˆ¶
        self.shared_knowledge = {}  # å­˜å‚¨æ¨¡å‹é—´å…±äº«çš„çŸ¥è¯†
        # æ·»åŠ æ£€æŸ¥ç‚¹ç®¡ç†
        self.checkpoints = {}
        
        logger.info("ğŸ”„ åä½œå¼è®­ç»ƒç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def register_model(self, model_name: str, model_instance: Any):
        """æ³¨å†Œæ¨¡å‹"""
        self.models[model_name] = model_instance
        logger.info(f"âœ… æ³¨å†Œæ¨¡å‹: {model_name}")
    
    def unregister_model(self, model_name: str):
        """æ³¨é”€æ¨¡å‹"""
        if model_name in self.models:
            del self.models[model_name]
            logger.info(f"ğŸ—‘ï¸  æ³¨é”€æ¨¡å‹: {model_name}")
    
    def prepare_training_data(self) -> Dict[str, List[Dict]]:
        """ä¸ºæ‰€æœ‰æ¨¡å‹å‡†å¤‡è®­ç»ƒæ•°æ®"""
        logger.info("ğŸ“¦ å¼€å§‹å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # æ‰«ææ‰€æœ‰æ•°æ®
        self.data_manager.scan_data()
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹å‡†å¤‡æ•°æ®
        model_data = {}
        for model_name in self.models.keys():
            data = self.data_manager.prepare_training_data(model_name)
            model_data[model_name] = data
            logger.info(f"   ä¸ºæ¨¡å‹ {model_name} å‡†å¤‡äº† {len(data)} ä¸ªè®­ç»ƒæ–‡ä»¶")
        
        return model_data
    
    def allocate_resources_for_models(self) -> Dict[str, Dict]:
        """ä¸ºæ‰€æœ‰æ¨¡å‹åˆ†é…èµ„æº"""
        logger.info("ğŸ–¥ï¸  å¼€å§‹åˆ†é…èµ„æº...")
        
        model_resources = {}
        for model_name in self.models.keys():
            requirements = self.resource_manager.get_model_resource_requirements(model_name)
            allocation = self.resource_manager.allocate_resources(requirements, model_name)
            model_resources[model_name] = allocation
            
            if allocation:
                logger.info(f"   ä¸ºæ¨¡å‹ {model_name} åˆ†é…èµ„æºæˆåŠŸ")
            else:
                logger.warning(f"   ä¸ºæ¨¡å‹ {model_name} åˆ†é…èµ„æºå¤±è´¥")
        
        return model_resources
    
    def create_training_tasks(self, model_data: Dict[str, List[Dict]], 
                            model_resources: Dict[str, Dict]) -> List[ModelTrainingTask]:
        """åˆ›å»ºè®­ç»ƒä»»åŠ¡"""
        tasks = []
        
        for model_name, model_instance in self.models.items():
            data = model_data.get(model_name, [])
            resources = model_resources.get(model_name)
            
            if resources:
                task = ModelTrainingTask(model_name, model_instance, data, resources)
                tasks.append(task)
                self.training_tasks[model_name] = task
                logger.info(f"âœ… åˆ›å»ºè®­ç»ƒä»»åŠ¡: {model_name}")
            else:
                logger.warning(f"âš ï¸  æ— æ³•ä¸ºæ¨¡å‹ {model_name} åˆ›å»ºè®­ç»ƒä»»åŠ¡ï¼Œèµ„æºåˆ†é…å¤±è´¥")
        
        return tasks
    
    def _train_model_task(self, task: 'ModelTrainingTask'):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹ä»»åŠ¡"""
        try:
            model_name = task.model_name
            logger.info(f"ğŸƒ å¼€å§‹è®­ç»ƒæ¨¡å‹ {model_name}")
            task.status = "running"
            task.start_time = datetime.now()
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ£€æŸ¥ç‚¹
            checkpoint = self._load_checkpoint(model_name)
            start_epoch = checkpoint.get('epoch', 0) if checkpoint else 0
            
            # å¦‚æœä»æ£€æŸ¥ç‚¹å¼€å§‹ï¼Œæ¢å¤è®­ç»ƒçŠ¶æ€
            if start_epoch > 0:
                logger.info(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {model_name} - Epoch {start_epoch}")
                task.current_epoch = start_epoch
                self.training_progress[model_name] = checkpoint.get('progress', {})
            
            # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
            for epoch in range(start_epoch, task.epochs):
                if self.stop_requested:
                    task.status = "cancelled"
                    # ä¿å­˜æ£€æŸ¥ç‚¹
                    self._save_checkpoint(model_name, epoch, self.training_progress.get(model_name, {}))
                    logger.info(f"â¹ï¸  è®­ç»ƒè¢«å–æ¶ˆ: {model_name}")
                    return
                
                # æ¨¡æ‹Ÿè®­ç»ƒä¸€ä¸ªepoch
                time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
                
                # æ›´æ–°è¿›åº¦
                task.current_epoch = epoch + 1
                progress = (epoch + 1) / task.epochs * 100
                self.training_progress[model_name] = {
                    'epoch': epoch + 1,
                    'progress': progress,
                    'loss': 1.0 - (epoch + 1) / task.epochs * 0.9,  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                    'accuracy': 0.1 + (epoch + 1) / task.epochs * 0.9  # æ¨¡æ‹Ÿå‡†ç¡®ç‡ä¸Šå‡
                }
                # æ›´æ–°ä»»åŠ¡çš„è¿›åº¦å’ŒæŒ‡æ ‡
                task.progress = progress
                task.metrics = {
                    'loss': self.training_progress[model_name]['loss'],
                    'accuracy': self.training_progress[model_name]['accuracy']
                }
                
                # æ¯10ä¸ªepochå…±äº«ä¸€æ¬¡çŸ¥è¯†
                if (epoch + 1) % 10 == 0:
                    self._share_knowledge(model_name, self.training_progress[model_name])
                
                # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if (epoch + 1) % 5 == 0:
                    self._save_checkpoint(model_name, epoch + 1, self.training_progress[model_name])
                
                logger.info(f"ğŸ“Š {model_name} - Epoch {epoch + 1}/{task.epochs} - "
                           f"Progress: {progress:.1f}% - "
                           f"Loss: {self.training_progress[model_name]['loss']:.4f} - "
                           f"Accuracy: {self.training_progress[model_name]['accuracy']:.4f}")
            
            # è®­ç»ƒå®Œæˆ
            task.status = "completed"
            task.end_time = datetime.now()
            task.result = {
                'final_loss': self.training_progress[model_name]['loss'],
                'final_accuracy': self.training_progress[model_name]['accuracy'],
                'training_time': (task.end_time - task.start_time).total_seconds()
            }
            
            # ä¿å­˜æ¨¡å‹
            self._save_model(model_name, task.result)
            
            # åˆ é™¤æ£€æŸ¥ç‚¹ï¼ˆè®­ç»ƒå®Œæˆï¼‰
            self._delete_checkpoint(model_name)
            
            logger.info(f"âœ… æ¨¡å‹ {model_name} è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            task.status = "failed"
            task.error = str(e)
            # ä¿å­˜æ£€æŸ¥ç‚¹
            current_epoch = task.current_epoch
            self._save_checkpoint(model_name, current_epoch, self.training_progress.get(model_name, {}))
            logger.error(f"âŒ æ¨¡å‹ {model_name} è®­ç»ƒå¤±è´¥: {e}")
            # è®°å½•é”™è¯¯æ—¥å¿—
            self._log_error(model_name, e)
    
    def _share_knowledge(self, model_name: str, training_stats: Dict[str, Any]):
        """åœ¨æ¨¡å‹é—´å…±äº«çŸ¥è¯†"""
        logger.info(f"ğŸ§  æ¨¡å‹ {model_name} æ­£åœ¨å…±äº«çŸ¥è¯†")
        
        # å°†å½“å‰æ¨¡å‹çš„è®­ç»ƒç»Ÿè®¡ä¿¡æ¯æ·»åŠ åˆ°å…±äº«çŸ¥è¯†ä¸­
        if model_name not in self.shared_knowledge:
            self.shared_knowledge[model_name] = []
        
        # è®°å½•å½“å‰è®­ç»ƒçŠ¶æ€
        knowledge_entry = {
            'model_name': model_name,
            'timestamp': datetime.now().isoformat(),
            'training_stats': training_stats.copy(),
            'knowledge_vector': self._extract_knowledge_vector(training_stats)
        }
        
        self.shared_knowledge[model_name].append(knowledge_entry)
        
        # ä¸å…¶ä»–æ¨¡å‹å…±äº«çŸ¥è¯†
        for other_model_name in self.models.keys():
            if other_model_name != model_name:
                self._apply_shared_knowledge(other_model_name, knowledge_entry)
    
    def _extract_knowledge_vector(self, training_stats: Dict[str, Any]) -> List[float]:
        """ä»è®­ç»ƒç»Ÿè®¡ä¸­æå–çŸ¥è¯†å‘é‡"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„çŸ¥è¯†æå–æœºåˆ¶
        knowledge_vector = [
            training_stats.get('loss', 0.0),
            training_stats.get('accuracy', 0.0),
            training_stats.get('progress', 0.0)
        ]
        return knowledge_vector
    
    def _apply_shared_knowledge(self, model_name: str, knowledge_entry: Dict[str, Any]):
        """å°†å…±äº«çŸ¥è¯†åº”ç”¨åˆ°æŒ‡å®šæ¨¡å‹"""
        logger.debug(f"ğŸ”„ å°†çŸ¥è¯†ä» {knowledge_entry['model_name']} åº”ç”¨åˆ° {model_name}")
        
        # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šæ›´æ–°æ¨¡å‹çš„å‚æ•°æˆ–è®­ç»ƒç­–ç•¥
        # ç®€åŒ–å®ç°ï¼Œä»…è®°å½•æ—¥å¿—
        pass
    
    def _save_model(self, model_name: str, training_result: Dict[str, Any]):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        model_dir = MODELS_DIR / model_name
        model_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹å…ƒæ•°æ®
        metadata = {
            'model_name': model_name,
            'training_result': training_result,
            'saved_at': datetime.now().isoformat(),
            'shared_knowledge_count': len(self.shared_knowledge.get(model_name, []))
        }
        
        metadata_file = model_dir / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹ {model_name} å·²ä¿å­˜åˆ° {model_dir}")
    
    def _save_checkpoint(self, model_name: str, epoch: int, progress: Dict[str, Any]):
        """ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹"""
        checkpoint_dir = TRAINING_DIR / "checkpoints"
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        checkpoint_data = {
            'model_name': model_name,
            'epoch': epoch,
            'progress': progress,
            'timestamp': datetime.now().isoformat()
        }
        
        checkpoint_file = checkpoint_dir / f"{model_name}_checkpoint_epoch_{epoch}.json"
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
        
        # æ›´æ–°æœ€æ–°çš„æ£€æŸ¥ç‚¹è®°å½•
        self.checkpoints[model_name] = checkpoint_file
        logger.info(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_file}")
    
    def _load_checkpoint(self, model_name: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½è®­ç»ƒæ£€æŸ¥ç‚¹"""
        checkpoint_file = self.checkpoints.get(model_name)
        if checkpoint_file and checkpoint_file.exists():
            try:
                with open(checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint_data = json.load(f)
                logger.info(f"ğŸ“‚ æ£€æŸ¥ç‚¹å·²åŠ è½½: {checkpoint_file}")
                return checkpoint_data
            except Exception as e:
                logger.error(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
                return None
        return None
    
    def _delete_checkpoint(self, model_name: str):
        """åˆ é™¤è®­ç»ƒæ£€æŸ¥ç‚¹"""
        checkpoint_file = self.checkpoints.get(model_name)
        if checkpoint_file and checkpoint_file.exists():
            try:
                checkpoint_file.unlink()
                del self.checkpoints[model_name]
                logger.info(f"ğŸ—‘ï¸  æ£€æŸ¥ç‚¹å·²åˆ é™¤: {checkpoint_file}")
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def _log_error(self, model_name: str, error: Exception):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        error_log_dir = TRAINING_DIR / "error_logs"
        error_log_dir.mkdir(parents=True, exist_ok=True)
        
        error_data = {
            'model_name': model_name,
            'error': str(error),
            'timestamp': datetime.now().isoformat(),
            'traceback': str(error.__traceback__) if error.__traceback__ else None
        }
        
        error_file = error_log_dir / f"{model_name}_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(error_file, 'w', encoding='utf-8') as f:
            json.dump(error_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“ é”™è¯¯æ—¥å¿—å·²ä¿å­˜: {error_file}")
    
    def start_collaborative_training(self, scenario: Dict[str, Any] = None) -> bool:
        """å¼€å§‹åä½œå¼è®­ç»ƒ"""
        if self.is_training:
            logger.warning("âš ï¸  è®­ç»ƒå·²åœ¨è¿›è¡Œä¸­")
            return False
        
        logger.info("ğŸ”„ å¼€å§‹åä½œå¼è®­ç»ƒ...")
        self.is_training = True
        self.stop_requested = False
        
        try:
            # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
            model_data = self.prepare_training_data()
            
            # 2. åˆ†é…èµ„æº
            model_resources = self.allocate_resources_for_models()
            
            # 3. åˆ›å»ºè®­ç»ƒä»»åŠ¡
            tasks = self.create_training_tasks(model_data, model_resources)
            
            if not tasks:
                logger.error("âŒ æ²¡æœ‰å¯æ‰§è¡Œçš„è®­ç»ƒä»»åŠ¡")
                self.is_training = False
                return False
            
            # 4. å¹¶è¡Œæ‰§è¡Œè®­ç»ƒä»»åŠ¡
            logger.info(f"ğŸƒ å¼€å§‹å¹¶è¡Œè®­ç»ƒ {len(tasks)} ä¸ªæ¨¡å‹...")
            
            # åˆ›å»ºå¹¶å¯åŠ¨è®­ç»ƒçº¿ç¨‹
            threads = []
            for task in tasks:
                thread = threading.Thread(target=self._train_model_task, args=(task,))
                thread.start()
                threads.append(thread)
                task.thread = thread
            
            # ç­‰å¾…æ‰€æœ‰è®­ç»ƒå®Œæˆ
            for thread in threads:
                thread.join()
            
            # 5. æ£€æŸ¥è®­ç»ƒç»“æœ
            success_count = 0
            for task in tasks:
                if task.status == "completed":
                    success_count += 1
                    logger.info(f"âœ… æ¨¡å‹ {task.model_name} è®­ç»ƒæˆåŠŸ")
                else:
                    logger.error(f"âŒ æ¨¡å‹ {task.model_name} è®­ç»ƒå¤±è´¥")
            
            logger.info(f"ğŸ åä½œå¼è®­ç»ƒå®Œæˆ: {success_count}/{len(tasks)} ä¸ªæ¨¡å‹è®­ç»ƒæˆåŠŸ")
            
            # 6. ä¿å­˜è®­ç»ƒç»“æœ
            self._save_training_results(tasks, scenario)
            
            self.is_training = False
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ åä½œå¼è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.is_training = False
            return False
    
    def _save_training_results(self, tasks: List[ModelTrainingTask], scenario: Dict[str, Any] = None):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        results = {
            'training_date': datetime.now().isoformat(),
            'total_models': len(tasks),
            'successful_models': 0,
            'failed_models': 0,
            'model_results': []
        }
        
        for task in tasks:
            model_result = {
                'model_name': task.model_name,
                'status': task.status,
                'progress': task.progress,
                'metrics': task.metrics,
                'start_time': task.start_time.isoformat() if task.start_time else None,
                'end_time': task.end_time.isoformat() if task.end_time else None,
                'data_files_count': len(task.data)
            }
            
            results['model_results'].append(model_result)
            
            if task.status == "completed":
                results['successful_models'] += 1
            else:
                results['failed_models'] += 1
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        results_file = TRAINING_DIR / f"collaborative_training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ è®­ç»ƒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è®­ç»ƒç»“æœå¤±è´¥: {e}")
    
    def stop_training(self):
        """åœæ­¢è®­ç»ƒ"""
        if self.is_training:
            logger.info("â¹ï¸  è¯·æ±‚åœæ­¢è®­ç»ƒ...")
            self.stop_requested = True
            
            # ç­‰å¾…è®­ç»ƒçº¿ç¨‹ç»“æŸ
            if self.training_thread and self.training_thread.is_alive():
                self.training_thread.join(timeout=5)
            
            self.is_training = False
            logger.info("âœ… è®­ç»ƒå·²åœæ­¢")
        else:
            logger.info("â„¹ï¸  å½“å‰æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„è®­ç»ƒ")
    
    def get_training_status(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒçŠ¶æ€"""
        status = {
            'is_training': self.is_training,
            'total_models': len(self.training_tasks),
            'model_statuses': {}
        }
        
        for model_name, task in self.training_tasks.items():
            status['model_statuses'][model_name] = {
                'status': task.status,
                'progress': task.progress,
                'metrics': task.metrics
            }
        
        return status
    
    def get_resource_usage(self) -> Dict[str, Any]:
        """è·å–èµ„æºä½¿ç”¨æƒ…å†µ"""
        return self.resource_manager.get_resource_allocation_status()
    
    def optimize_training_process(self):
        """ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹"""
        # è¿™é‡Œå¯ä»¥å®ç°è®­ç»ƒè¿‡ç¨‹çš„ä¼˜åŒ–é€»è¾‘
        # ä¾‹å¦‚ï¼šæ ¹æ®æ¨¡å‹è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´èµ„æºåˆ†é…
        logger.info("âš™ï¸  ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹...")
        
        optimization_result = self.resource_manager.optimize_resource_allocation()
        logger.info("âœ… è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–å®Œæˆ")
        
        return optimization_result
    
    def enable_model_collaboration(self):
        """å¯ç”¨æ¨¡å‹é—´çš„åä½œ"""
        # è¿™é‡Œå¯ä»¥å®ç°æ¨¡å‹é—´çš„çŸ¥è¯†å…±äº«å’Œåä½œæœºåˆ¶
        logger.info("ğŸ¤ å¯ç”¨æ¨¡å‹é—´åä½œ...")
        
        # ç¤ºä¾‹ï¼šå®ç°ç®€å•çš„æ¨¡å‹é—´çŸ¥è¯†å…±äº«
        for model_name, task in self.training_tasks.items():
            if task.status == "completed" and task.metrics:
                # å°†è®­ç»ƒæŒ‡æ ‡å…±äº«ç»™å…¶ä»–æ¨¡å‹
                logger.info(f"   æ¨¡å‹ {model_name} åˆ†äº«è®­ç»ƒç»éªŒ")
        
        logger.info("âœ… æ¨¡å‹é—´åä½œå¯ç”¨å®Œæˆ")
    
    def save_training_state(self, state_path: str = None):
        """ä¿å­˜è®­ç»ƒçŠ¶æ€"""
        if not state_path:
            state_path = TRAINING_DIR / "collaborative_training_state.json"
        
        state_data = {
            'is_training': self.is_training,
            'training_tasks': {},
            'training_progress': self.training_progress,
            'generated_at': datetime.now().isoformat()
        }
        
        # ä¿å­˜ä»»åŠ¡çŠ¶æ€
        for model_name, task in self.training_tasks.items():
            state_data['training_tasks'][model_name] = {
                'status': task.status,
                'progress': task.progress,
                'metrics': task.metrics,
                'start_time': task.start_time.isoformat() if task.start_time else None,
                'end_time': task.end_time.isoformat() if task.end_time else None
            }
        
        try:
            with open(state_path, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ è®­ç»ƒçŠ¶æ€å·²ä¿å­˜åˆ°: {state_path}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è®­ç»ƒçŠ¶æ€å¤±è´¥: {e}")
    
    def load_training_state(self, state_path: str = None):
        """åŠ è½½è®­ç»ƒçŠ¶æ€"""
        if not state_path:
            state_path = TRAINING_DIR / "collaborative_training_state.json"
        
        if not Path(state_path).exists():
            logger.warning(f"âš ï¸ è®­ç»ƒçŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {state_path}")
            return False
        
        try:
            with open(state_path, 'r', encoding='utf-8') as f:
                state_data = json.load(f)
            
            self.is_training = state_data.get('is_training', False)
            self.training_progress = state_data.get('training_progress', {})
            
            # åŠ è½½ä»»åŠ¡çŠ¶æ€
            task_states = state_data.get('training_tasks', {})
            for model_name, task_state in task_states.items():
                if model_name in self.training_tasks:
                    task = self.training_tasks[model_name]
                    task.status = task_state.get('status', 'pending')
                    task.progress = task_state.get('progress', 0)
                    task.metrics = task_state.get('metrics', {})
                    
                    start_time = task_state.get('start_time')
                    if start_time:
                        task.start_time = datetime.fromisoformat(start_time)
                    
                    end_time = task_state.get('end_time')
                    if end_time:
                        task.end_time = datetime.fromisoformat(end_time)
            
            logger.info(f"âœ… è®­ç»ƒçŠ¶æ€å·²ä» {state_path} åŠ è½½")
            return True
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è®­ç»ƒçŠ¶æ€å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•åä½œå¼è®­ç»ƒç®¡ç†å™¨"""
    print("ğŸ”„ æµ‹è¯•åä½œå¼è®­ç»ƒç®¡ç†å™¨...")
    
    # åˆå§‹åŒ–åä½œå¼è®­ç»ƒç®¡ç†å™¨
    manager = CollaborativeTrainingManager()
    
    # æ¨¡æ‹Ÿæ³¨å†Œä¸€äº›æ¨¡å‹
    print("ğŸ“‹ æ³¨å†Œæ¨¡å‹...")
    manager.register_model("vision_service", "VisionModelInstance")
    manager.register_model("audio_service", "AudioModelInstance")
    manager.register_model("causal_reasoning_engine", "CausalReasoningInstance")
    manager.register_model("concept_models", "ConceptModelsInstance")
    
    # æ˜¾ç¤ºæ³¨å†Œçš„æ¨¡å‹
    print(f"âœ… å·²æ³¨å†Œ {len(manager.models)} ä¸ªæ¨¡å‹:")
    for model_name in manager.models.keys():
        print(f"   - {model_name}")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    print("\nğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®...")
    model_data = manager.prepare_training_data()
    for model_name, data in model_data.items():
        print(f"   {model_name}: {len(data)} ä¸ªè®­ç»ƒæ–‡ä»¶")
    
    # åˆ†é…èµ„æº
    print("\nğŸ–¥ï¸  åˆ†é…èµ„æº...")
    model_resources = manager.allocate_resources_for_models()
    for model_name, resources in model_resources.items():
        if resources:
            print(f"   {model_name}: èµ„æºåˆ†é…æˆåŠŸ")
        else:
            print(f"   {model_name}: èµ„æºåˆ†é…å¤±è´¥")
    
    # æ˜¾ç¤ºèµ„æºåˆ†é…çŠ¶æ€
    resource_status = manager.get_resource_usage()
    print(f"\nğŸ“ˆ èµ„æºåˆ†é…çŠ¶æ€:")
    print(f"   å·²åˆ†é…CPU: {resource_status['allocated_cpu']} æ ¸å¿ƒ")
    print(f"   å¯ç”¨CPU: {resource_status['available_cpu']:.1f} æ ¸å¿ƒ")
    print(f"   å·²åˆ†é…å†…å­˜: {resource_status['allocated_memory_gb']:.2f} GB")
    
    # è·å–è®­ç»ƒçŠ¶æ€
    training_status = manager.get_training_status()
    print(f"\nğŸ“Š è®­ç»ƒçŠ¶æ€:")
    print(f"   æ˜¯å¦æ­£åœ¨è®­ç»ƒ: {training_status['is_training']}")
    print(f"   æ¨¡å‹æ•°é‡: {training_status['total_models']}")
    
    print(f"\nâœ… åä½œå¼è®­ç»ƒç®¡ç†å™¨æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()



