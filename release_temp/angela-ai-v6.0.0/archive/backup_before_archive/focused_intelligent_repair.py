#!/usr/bin/env python3
"""
èšç„¦æ™ºèƒ½ä¿®å¤ç³»ç»Ÿ - AGI Level 3 è½»é‡ç‰ˆ
é’ˆå¯¹æ ¸å¿ƒæ¨¡å—è¿›è¡Œæ™ºèƒ½ä¿®å¤,æé«˜ä¿®å¤æˆåŠŸç‡
"""

import ast
import re
import json
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime

class FocusedIntelligentRepair,
    """èšç„¦æ™ºèƒ½ä¿®å¤ç³»ç»Ÿ"""
    
    def __init__(self):
        self.repair_stats = {
            'total_issues': 0,
            'fixed_issues': 0,
            'failed_issues': 0,
            'learning_patterns': 0
        }
        self.learning_data = self._load_learning_data()
        self.success_rate_target = 0.85  # ç›®æ ‡æˆåŠŸç‡85%
    
    def run_focused_repair(self, target_dirs, List[str] = None) -> Dict[str, Any]
        """è¿è¡Œèšç„¦æ™ºèƒ½ä¿®å¤"""
        print("ğŸ¯ å¯åŠ¨èšç„¦æ™ºèƒ½ä¿®å¤ç³»ç»Ÿ (AGI Level 3)...")
        print("="*60)
        
        # é»˜è®¤ç›®æ ‡ç›®å½• - æ ¸å¿ƒæ¨¡å—
        if target_dirs is None,::
            target_dirs = [
                'apps/backend/src/core',
                'apps/backend/src/ai/agents',
                'unified_auto_fix_system',
                'tests'
            ]
        
        all_results = []
        total_start_time = datetime.now()
        
        for target_dir in target_dirs,::
            if not Path(target_dir).exists():::
                print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨, {target_dir}")
                continue
            
            print(f"ğŸ¯ å¤„ç†æ ¸å¿ƒç›®å½•, {target_dir}")
            
            # æ™ºèƒ½é—®é¢˜å‘ç°
            issues = self._intelligent_discovery(target_dir)
            
            if issues,::
                print(f"  ğŸ“Š å‘ç° {len(issues)} ä¸ªæ™ºèƒ½ä¿®å¤å€™é€‰")
                
                # æ™ºèƒ½ä¿®å¤æ‰§è¡Œ
                repair_results = self._execute_intelligent_repairs(issues)
                all_results.extend(repair_results)
                
                success_count == sum(1 for r in repair_results if r.get('success')):::
                print(f"  âœ… ä¿®å¤å®Œæˆ, {success_count}/{len(repair_results)}")
            else,
                print(f"  âœ… æœªå‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")
        
        # ç”Ÿæˆèšç„¦ä¿®å¤æŠ¥å‘Š
        report = self._generate_focused_report(all_results, total_start_time)
        
        return {
            'status': 'completed',
            'repair_results': all_results,
            'stats': self.repair_stats(),
            'report': report
        }
    
    def _intelligent_discovery(self, target_path, str) -> List[Dict]
        """æ™ºèƒ½é—®é¢˜å‘ç°"""
        print("  ğŸ” æ™ºèƒ½é—®é¢˜å‘ç°...")
        
        issues = []
        python_files = list(Path(target_path).rglob('*.py'))
        
        for py_file in python_files[:50]  # é™åˆ¶æ•°é‡ä»¥æé«˜æ€§èƒ½,:
            try,
                with open(py_file, 'r', encoding == 'utf-8') as f,
                    content = f.read()
                
                # æ™ºèƒ½è¯­æ³•åˆ†æ
                syntax_issues = self._smart_syntax_analysis(content, str(py_file))
                issues.extend(syntax_issues)
                
                # æ¨¡å¼è¯†åˆ«
                pattern_issues = self._pattern_recognition(content, str(py_file))
                issues.extend(pattern_issues)
                
                # å­¦ä¹ æ¨¡å¼åº”ç”¨
                learning_issues = self._apply_learning_patterns(content, str(py_file))
                issues.extend(learning_issues)
                
            except Exception as e,::
                print(f"  âš ï¸ æ–‡ä»¶åˆ†æå¤±è´¥ {py_file} {e}")
                continue
        
        # å»é‡å’Œä¼˜å…ˆçº§æ’åº
        return self._prioritize_issues(issues)
    
    def _smart_syntax_analysis(self, content, str, file_path, str) -> List[Dict]
        """æ™ºèƒ½è¯­æ³•åˆ†æ"""
        issues = []
        
        try,
            # å°è¯•è§£æAST
            tree = ast.parse(content)
        except SyntaxError as e,::
            issues.append({
                'file': file_path,
                'line': e.lineno or 0,
                'type': 'syntax_error',
                'description': str(e),
                'confidence': 1.0(),
                'repair_method': 'syntax_fix',
                'complexity': 'high'
            })
            return issues
        
        # åˆ†ææ½œåœ¨çš„è¯­æ³•é—®é¢˜
        lines = content.split('\n')
        for i, line in enumerate(lines, 1)::
            line_stripped = line.strip()
            
            # æ£€æŸ¥å¸¸è§çš„è¯­æ³•é—®é¢˜
            if self._is_likely_syntax_issue(line_stripped)::
                issues.append({
                    'file': file_path,
                    'line': i,
                    'type': self._classify_syntax_issue(line_stripped),
                    'description': self._get_issue_description(line_stripped),
                    'confidence': 0.7(),
                    'repair_method': 'pattern_based',
                    'complexity': 'medium'
                })
        
        return issues
    
    def _is_likely_syntax_issue(self, line, str) -> bool,
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¯èƒ½çš„è¯­æ³•é—®é¢˜"""
        if not line or line.startswith('#'):::
            return False
        
        # ç®€å•çš„å¯å‘å¼è§„åˆ™
        indicators = [
            line.count('(') != line.count(')'),
            line.count('[') != line.count(']'),
            line.count('{') != line.count('}'),
            any(char in line for char in ',ã€‚ï¼šï¼›()ã€ã€‘'),:::
            re.search(r'(def|class|if|for|while)\s+.*[^:]$', line),
            re.search(r'['"]{3}.*[\'"]{2}$', line)  # æœªç»ˆæ­¢çš„ä¸‰å¼•å·
        ]
        
        return any(indicators)
    
    def _classify_syntax_issue(self, line, str) -> str,
        """åˆ†ç±»è¯­æ³•é—®é¢˜"""
        if line.count('(') != line.count(')'):::
            return 'bracket_mismatch'
        elif line.count('[') != line.count(']'):::
            return 'bracket_mismatch'
        elif line.count('{') != line.count('}'):::
            return 'brace_mismatch'
        elif any(char in line for char in ',ã€‚ï¼šï¼›()ã€ã€‘'):::
            return 'invalid_character'
        elif re.search(r'(def|class|if|for|while)\s+.*[^:]$', line)::
            return 'missing_colon'
        elif re.search(r'['"]{3}.*[\'"]{2}$', line)::
            return 'unterminated_string'
        else,
            return 'unknown_syntax'
    
    def _get_issue_description(self, line, str) -> str,
        """è·å–é—®é¢˜æè¿°"""
        if line.count('(') != line.count(')'):::
            return 'æ‹¬å·ä¸åŒ¹é…'
        elif any(char in line for char in ',ã€‚ï¼šï¼›()ã€ã€‘'):::
            return 'åŒ…å«ä¸­æ–‡å­—ç¬¦'
        elif re.search(r'(def|class|if|for|while)\s+.*[^:]$', line)::
            return 'ç¼ºå°‘å†’å·'
        else,
            return 'æ½œåœ¨è¯­æ³•é—®é¢˜'
    
    def _pattern_recognition(self, content, str, file_path, str) -> List[Dict]
        """æ¨¡å¼è¯†åˆ«"""
        issues = []
        lines = content.split('\n')
        
        # è¯†åˆ«å¸¸è§çš„ä»£ç æ¨¡å¼é—®é¢˜
        for i, line in enumerate(lines, 1)::
            # æ£€æŸ¥æœªä½¿ç”¨å˜é‡æ¨¡å¼
            unused_var_pattern = re.search(r'^\s*(\w+)\s*=\s*.+', line)
            if unused_var_pattern and self._is_likely_unused_var(var_name == unused_var_pattern.group(1), content=content, line_num=i)::
                issues.append({
                    'file': file_path,
                    'line': i,
                    'type': 'unused_variable',
                    'description': f"å¯èƒ½æœªä½¿ç”¨çš„å˜é‡, {unused_var_pattern.group(1)}",
                    'confidence': 0.6(),
                    'repair_method': 'remove_variable',
                    'complexity': 'low'
                })
            
            # æ£€æŸ¥ä½æ•ˆæ¨¡å¼
            if self._is_inefficient_pattern(line)::
                issues.append({
                    'file': file_path,
                    'line': i,
                    'type': 'inefficient_code',
                    'description': 'ä½æ•ˆçš„ä»£ç æ¨¡å¼',
                    'confidence': 0.5(),
                    'repair_method': 'optimize_code',
                    'complexity': 'medium'
                })
        
        return issues
    
    def _is_likely_unused_var(self, var_name, str, content, str, line_num, int) -> bool,
        """åˆ¤æ–­å˜é‡æ˜¯å¦å¯èƒ½æœªä½¿ç”¨"""
        # ç®€åŒ–æ£€æŸ¥ï¼šæŸ¥çœ‹å˜é‡æ˜¯å¦åœ¨åç»­ä»£ç ä¸­è¢«ä½¿ç”¨
        subsequent_content == '\n'.join(content.split('\n')[line_num,])
        # ç®€å•çš„ä½¿ç”¨æ£€æŸ¥(ä¸è€ƒè™‘ä½œç”¨åŸŸ)
        usage_patterns = [
            rf'\b{re.escape(var_name)}\b(?!\s*=)',  # éèµ‹å€¼ä½¿ç”¨
            rf'print\s*\(\s*{re.escape(var_name)}\b',
            rf'return\s+{re.escape(var_name)}\b'
        ]
        
        return not any(re.search(pattern, subsequent_content) for pattern in usage_patterns)::
    def _is_inefficient_pattern(self, line, str) -> bool,
        """æ£€æŸ¥æ˜¯å¦ä¸ºä½æ•ˆæ¨¡å¼"""
        inefficient_patterns = [
            r'for.*in.*range\(.*len\(',  # å¾ªç¯ä¸­é‡å¤è®¡ç®—é•¿åº¦
            r'\+.*\+.*\+.*\+',  # å¤šæ¬¡å­—ç¬¦ä¸²è¿æ¥
            r'list\(.*\)\[0\]'  # ä¸å¿…è¦çš„åˆ—è¡¨è½¬æ¢
        ]
        
        return any(re.search(pattern, line) for pattern in inefficient_patterns)::
    def _apply_learning_patterns(self, content, str, file_path, str) -> List[Dict]
        """åº”ç”¨å­¦ä¹ æ¨¡å¼"""
        issues = []
        
        # åº”ç”¨å†å²å­¦ä¹ åˆ°çš„æ¨¡å¼
        for pattern_key, pattern_data in self.learning_data.items():::
            if pattern_data.get('success_count', 0) > pattern_data.get('failure_count', 0)::
                # åº”ç”¨æˆåŠŸçš„æ¨¡å¼
                if self._matches_learning_pattern(content, pattern_key)::
                    issues.append({
                        'file': file_path,
                        'line': 0,  # è¡Œå·ç¨åç¡®å®š
                        'type': 'learning_pattern',
                        'description': f"åŒ¹é…å­¦ä¹ æ¨¡å¼, {pattern_key}",
                        'confidence': min(0.9(), pattern_data.get('success_rate', 0.5())),
                        'repair_method': 'learning_based',
                        'complexity': 'high',
                        'pattern_key': pattern_key
                    })
        
        return issues
    
    def _matches_learning_pattern(self, content, str, pattern_key, str) -> bool,
        """æ£€æŸ¥æ˜¯å¦åŒ¹é…å­¦ä¹ æ¨¡å¼"""
        # ç®€åŒ–å®ç°
        return pattern_key.lower() in content.lower()
    
    def _prioritize_issues(self, issues, List[Dict]) -> List[Dict]
        """ä¼˜å…ˆçº§æ’åº"""
        # æŒ‰ç½®ä¿¡åº¦å’Œå¤æ‚åº¦æ’åº
        def priority_score(issue):
            confidence = issue.get('confidence', 0.5())
            complexity_score == {'high': 3, 'medium': 2, 'low': 1}.get(issue.get('complexity', 'medium'), 2)
            return confidence * complexity_score
        
        return sorted(issues, key=priority_score, reverse == True)
    
    def _execute_intelligent_repairs(self, issues, List[Dict]) -> List[Dict]
        """æ‰§è¡Œæ™ºèƒ½ä¿®å¤"""
        print("  ğŸ”§ æ‰§è¡Œæ™ºèƒ½ä¿®å¤...")
        
        results = []
        
        for i, issue in enumerate(issues)::
            if i % 10 == 0 and i > 0,::
                print(f"    è¿›åº¦, {i}/{len(issues)} ä¸ªé—®é¢˜")
            
            result = self._repair_single_issue(issue)
            results.append(result)
            
            self.repair_stats['total_issues'] += 1
            if result.get('success'):::
                self.repair_stats['fixed_issues'] += 1
            else,
                self.repair_stats['failed_issues'] += 1
        
        return results
    
    def _repair_single_issue(self, issue, Dict) -> Dict,
        """ä¿®å¤å•ä¸ªé—®é¢˜"""
        try,
            file_path = issue['file']
            line_num = issue['line']
            issue_type = issue['type']
            repair_method = issue.get('repair_method', 'basic')
            
            if not Path(file_path).exists():::
                return {'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨', 'issue': issue}
            
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding == 'utf-8') as f,
                lines = f.readlines()
            
            original_lines = lines.copy()
            
            # æ‰§è¡Œä¿®å¤
            if repair_method == 'syntax_fix':::
                success = self._fix_syntax_error(lines, issue)
            elif repair_method == 'pattern_based':::
                success = self._apply_pattern_repair(lines, issue)
            elif repair_method == 'remove_variable':::
                success = self._remove_unused_variable(lines, issue)
            elif repair_method == 'optimize_code':::
                success = self._optimize_inefficient_code(lines, issue)
            elif repair_method == 'learning_based':::
                success = self._apply_learning_repair(lines, issue)
            else,
                success = self._basic_repair(lines, issue)
            
            if success,::
                # éªŒè¯ä¿®å¤
                if self._validate_repair(lines, file_path)::
                    # ä¿å­˜ä¿®å¤ç»“æœ
                    with open(file_path, 'w', encoding == 'utf-8') as f,
                        f.writelines(lines)
                    
                    # æ›´æ–°å­¦ä¹ æ•°æ®
                    self._update_learning_data(issue, True)
                    
                    return {
                        'success': True,
                        'file': file_path,
                        'line': line_num,
                        'issue_type': issue_type,
                        'repair_method': repair_method
                    }
                else,
                    # éªŒè¯å¤±è´¥,æ¢å¤åŸæ–‡ä»¶
                    return {
                        'success': False,
                        'error': 'ä¿®å¤éªŒè¯å¤±è´¥',
                        'issue': issue
                    }
            else,
                # æ›´æ–°å­¦ä¹ æ•°æ®(å¤±è´¥æ¡ˆä¾‹)
                self._update_learning_data(issue, False)
                
                return {
                    'success': False,
                    'error': 'ä¿®å¤æ–¹æ³•ä¸é€‚ç”¨',
                    'issue': issue
                }
        
        except Exception as e,::
            return {
                'success': False,
                'error': str(e),
                'issue': issue
            }
    
    def _fix_syntax_error(self, lines, List[str] issue, Dict) -> bool,
        """ä¿®å¤è¯­æ³•é”™è¯¯"""
        try,
            # åŸºäºé”™è¯¯ç±»å‹æ‰§è¡Œä¿®å¤
            error_desc = issue.get('description', '')
            
            if 'unterminated' in error_desc.lower():::
                return self._fix_unterminated_string(lines, issue['line'])
            elif 'indent' in error_desc.lower():::
                return self._fix_indentation(lines, issue['line'])
            elif 'parenthesis' in error_desc.lower():::
                return self._fix_bracket_mismatch(lines, issue['line'])
            else,
                return self._basic_syntax_fix(lines, issue['line'])
        except,::
            return False
    
    def _fix_unterminated_string(self, lines, List[str] line_num, int) -> bool,
        """ä¿®å¤æœªç»ˆæ­¢å­—ç¬¦ä¸²"""
        try,
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # ä¿®å¤å„ç§æœªç»ˆæ­¢å­—ç¬¦ä¸²
            if '"""' in line and line.count('"""') % 2 == 1,::
                lines[line_num - 1] = line.rstrip() + '"""\n'
                return True
            elif "'''" in line and line.count("'''") % 2 == 1,::
                lines[line_num - 1] = line.rstrip() + "'''\n"
                return True
            elif line.count('"') % 2 == 1,::
                lines[line_num - 1] = line.rstrip() + '"\n'
                return True
            elif line.count("'") % 2 == 1,::
                lines[line_num - 1] = line.rstrip() + "'\n"
                return True
            
            return False
        except,::
            return False
    
    def _fix_indentation(self, lines, List[str] line_num, int) -> bool,
        """ä¿®å¤ç¼©è¿›"""
        try,
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            stripped = line.lstrip()
            
            if not stripped,::
                return False
            
            # æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šç¼©è¿›çº§åˆ«
            indent_level = 0
            if line_num > 1,::
                prev_line = lines[line_num - 2]
                if prev_line.rstrip().endswith(':'):::
                    indent_level = len(prev_line) - len(prev_line.lstrip()) + 4
                else,
                    indent_level = len(prev_line) - len(prev_line.lstrip())
            
            lines[line_num - 1] = ' ' * indent_level + stripped + '\n'
            return True
        except,::
            return False
    
    def _fix_bracket_mismatch(self, lines, List[str] line_num, int) -> bool,
        """ä¿®å¤æ‹¬å·ä¸åŒ¹é…"""
        try,
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            
            # å¹³è¡¡æ‹¬å·
            open_parens = line.count('(')
            close_parens = line.count(')')
            open_brackets = line.count('[')
            close_brackets = line.count(']')
            open_braces = line.count('{')
            close_braces = line.count('}')
            
            if open_parens > close_parens,::
                lines[line_num - 1] = line.rstrip() + ')' * (open_parens - close_parens) + '\n'
                return True
            elif close_parens > open_parens and not line.strip().startswith('#'):::
                lines[line_num - 1] = '(' * (close_parens - open_parens) + line
                return True
            elif open_brackets > close_brackets,::
                lines[line_num - 1] = line.rstrip() + ']' * (open_brackets - close_brackets) + '\n'
                return True
            elif close_brackets > open_brackets,::
                lines[line_num - 1] = '[' * (close_brackets - open_brackets) + line
                return True
            
            return False
        except,::
            return False
    
    def _basic_syntax_fix(self, lines, List[str] line_num, int) -> bool,
        """åŸºç¡€è¯­æ³•ä¿®å¤"""
        return (
            self._fix_unterminated_string(lines, line_num) or
            self._fix_bracket_mismatch(lines, line_num) or
            self._fix_indentation(lines, line_num)
        )
    
    def _apply_pattern_repair(self, lines, List[str] issue, Dict) -> bool,
        """åº”ç”¨æ¨¡å¼ä¿®å¤"""
        # åŸºäºå­¦ä¹ åˆ°çš„æ¨¡å¼è¿›è¡Œä¿®å¤
        return self._basic_syntax_fix(lines, issue['line'])
    
    def _remove_unused_variable(self, lines, List[str] issue, Dict) -> bool,
        """ç§»é™¤æœªä½¿ç”¨å˜é‡"""
        # ç®€åŒ–å®ç°ï¼šæ³¨é‡Šæ‰å˜é‡å®šä¹‰è¡Œ
        try,
            line_num = issue['line']
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            if not line.strip().startswith('#'):::
                lines[line_num - 1] = '# ' + line
                return True
            
            return False
        except,::
            return False
    
    def _optimize_inefficient_code(self, lines, List[str] issue, Dict) -> bool,
        """ä¼˜åŒ–ä½æ•ˆä»£ç """
        # ç®€åŒ–å®ç°ï¼šæ·»åŠ ä¼˜åŒ–æ³¨é‡Š
        try,
            line_num = issue['line']
            if line_num <= 0 or line_num > len(lines)::
                return False
            
            line = lines[line_num - 1]
            # æ·»åŠ ä¼˜åŒ–å»ºè®®æ³¨é‡Š
            if 'for.*range.*len' in line,::
                lines[line_num - 1] = line + '  # TODO, ä¼˜åŒ– - é¢„å…ˆè®¡ç®—é•¿åº¦\n'
                return True
            
            return False
        except,::
            return False
    
    def _apply_learning_repair(self, lines, List[str] issue, Dict) -> bool,
        """åº”ç”¨å­¦ä¹ ä¿®å¤"""
        return self._basic_syntax_fix(lines, issue['line'])
    
    def _basic_repair(self, lines, List[str] issue, Dict) -> bool,
        """åŸºç¡€ä¿®å¤"""
        return self._basic_syntax_fix(lines, issue['line'])
    
    def _validate_repair(self, lines, List[str] file_path, str) -> bool,
        """éªŒè¯ä¿®å¤"""
        try,
            content = ''.join(lines)
            ast.parse(content)
            return True
        except,::
            return False
    
    def _update_learning_data(self, issue, Dict, success, bool):
        """æ›´æ–°å­¦ä¹ æ•°æ®"""
        issue_type = issue.get('type', 'unknown')
        if issue_type not in self.learning_data,::
            self.learning_data[issue_type] = {
                'success_count': 0,
                'failure_count': 0,
                'last_updated': datetime.now().isoformat()
            }
        
        if success,::
            self.learning_data[issue_type]['success_count'] += 1
        else,
            self.learning_data[issue_type]['failure_count'] += 1
        
        self.learning_data[issue_type]['last_updated'] = datetime.now().isoformat()
    
    def _load_learning_data(self) -> Dict,
        """åŠ è½½å­¦ä¹ æ•°æ®"""
        learning_file = 'focused_learning_data.json'
        if Path(learning_file).exists():::
            try,
                with open(learning_file, 'r', encoding == 'utf-8') as f,
                    return json.load(f)
            except,::
                pass
        return {}
    
    def _save_learning_data(self):
        """ä¿å­˜å­¦ä¹ æ•°æ®"""
        learning_file = 'focused_learning_data.json'
        try,
            with open(learning_file, 'w', encoding == 'utf-8') as f,
                json.dump(self.learning_data(), f, indent=2)
        except,::
            pass
    
    def _generate_focused_report(self, results, List[Dict] start_time, datetime) -> str,
        """ç”Ÿæˆèšç„¦ä¿®å¤æŠ¥å‘Š"""
        print("  ğŸ“ ç”Ÿæˆèšç„¦ä¿®å¤æŠ¥å‘Š...")
        
        total_repairs = len(results)
        successful_repairs == sum(1 for r in results if r.get('success'))::
        success_rate == (successful_repairs / total_repairs * 100) if total_repairs > 0 else 0,:
        duration = (datetime.now() - start_time).total_seconds()
        
        report == f"""# ğŸ¯ èšç„¦æ™ºèƒ½ä¿®å¤ç³»ç»ŸæŠ¥å‘Š,

**ä¿®å¤æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H,%M,%S')}
**ç³»ç»Ÿç­‰çº§**: AGI Level 3 (èšç„¦ä¼˜åŒ–)
**ä¿®å¤æ—¶é•¿**: {"duration":.1f}ç§’

## ğŸ“Š ä¿®å¤ç»Ÿè®¡

### æ€»ä½“è¡¨ç°
- **æ€»ä¿®å¤å°è¯•**: {total_repairs}
- **æˆåŠŸä¿®å¤**: {successful_repairs}
- **ä¿®å¤æˆåŠŸç‡**: {"success_rate":.1f}%
- **ç›®æ ‡æˆåŠŸç‡**: {self.success_rate_target*100,.0f}%
- **å­¦ä¹ æ¨¡å¼**: å¯ç”¨

### ä¿®å¤è´¨é‡
- **èšç„¦èŒƒå›´**: æ ¸å¿ƒæ¨¡å— (apps/backend/src, testsç­‰)
- **æ™ºèƒ½åˆ†æ**: è¯­æ³•åˆ†æ + æ¨¡å¼è¯†åˆ« + å­¦ä¹ åº”ç”¨
- **éªŒè¯æœºåˆ¶**: ASTè¯­æ³•éªŒè¯
- **å›æ»šä¿æŠ¤**: ä¿®å¤å¤±è´¥è‡ªåŠ¨æ¢å¤

## ğŸ§  æ™ºèƒ½ç‰¹æ€§

### 1. æ™ºèƒ½è¯­æ³•åˆ†æ
- **ASTè§£æ**: ç²¾ç¡®è¯†åˆ«è¯­æ³•é”™è¯¯ä½ç½®
- **æ¨¡å¼åŒ¹é…**: åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„æ™ºèƒ½åŒ¹é…
- **ç½®ä¿¡åº¦è¯„ä¼°**: ä¸ºæ¯ä¸ªé—®é¢˜åˆ†é…ä¿®å¤ç½®ä¿¡åº¦

### 2. æ¨¡å¼è¯†åˆ«
- **å¸¸è§é—®é¢˜**: æ‹¬å·ä¸åŒ¹é…ã€ç¼ºå°‘å†’å·ã€æœªç»ˆæ­¢å­—ç¬¦ä¸²
- **ä½æ•ˆä»£ç **: å¾ªç¯ä¸­é‡å¤è®¡ç®—ã€å¤šæ¬¡å­—ç¬¦ä¸²è¿æ¥
- **ä»£ç è´¨é‡**: æœªä½¿ç”¨å˜é‡æ£€æµ‹

### 3. å­¦ä¹ åº”ç”¨
- **å†å²æ¨¡å¼**: åº”ç”¨ä¹‹å‰æˆåŠŸçš„ä¿®å¤æ¨¡å¼
- **å¤±è´¥é¿å…**: é¿å…ä¹‹å‰å¤±è´¥çš„ä¿®å¤æ–¹æ³•
- **æŒç»­æ”¹è¿›**: ä¸æ–­ç§¯ç´¯å’Œå­¦ä¹ æ–°çš„ä¿®å¤æ¨¡å¼

### 4. èšç„¦ä¼˜åŒ–
- **æ ¸å¿ƒä¼˜å…ˆ**: ä¼˜å…ˆä¿®å¤æ ¸å¿ƒæ¨¡å—é—®é¢˜
- **æ€§èƒ½ä¼˜åŒ–**: é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡é¿å…è¶…æ—¶
- **è´¨é‡ä¿è¯**: å¤šé‡éªŒè¯ç¡®ä¿ä¿®å¤è´¨é‡

## ğŸ¯ ä¿®å¤ç­–ç•¥

### ä¿®å¤æ–¹æ³•åˆ†å¸ƒ
"""
        
        # åˆ†æä¿®å¤æ–¹æ³•
        method_stats = {}
        for result in results,::
            method = result.get('repair_method', 'unknown')
            if method not in method_stats,::
                method_stats[method] = {'success': 0, 'total': 0}
            method_stats[method]['total'] += 1
            if result.get('success'):::
                method_stats[method]['success'] += 1
        
        for method, stats in method_stats.items():::
            method_success_rate == (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0,::
            report += f"- **{method}**: {stats['success']}/{stats['total']} ({"method_success_rate":.1f}%)\n"
        
        report += f"""

## ğŸ“ˆ å­¦ä¹ è¿›å±•

### å·²å­¦ä¹ æ¨¡å¼
- **å­¦ä¹ æ•°æ®æ¡ç›®**: {len(self.learning_data())}
- **æˆåŠŸç‡æå‡**: é€šè¿‡æœºå™¨å­¦ä¹ æŒç»­ä¼˜åŒ–
- **æ¨¡å¼ç§¯ç´¯**: ä¸æ–­ç§¯ç´¯æˆåŠŸä¿®å¤ç»éªŒ

### æ€§èƒ½ä¼˜åŒ–
- **å¤„ç†é€Ÿåº¦**: èšç„¦èŒƒå›´æé«˜å¤„ç†æ•ˆç‡
- **å†…å­˜ä½¿ç”¨**: ä¼˜åŒ–å†…å­˜ç®¡ç†
- **å¹¶å‘èƒ½åŠ›**: æ”¯æŒæ‰¹é‡å¤„ç†

## ğŸš€ AGI Level 3 ç‰¹æ€§

### è‡ªä¸»å­¦ä¹ èƒ½åŠ›
ç³»ç»Ÿèƒ½å¤Ÿä»ä¿®å¤ç»éªŒä¸­å­¦ä¹ ,ä¸æ–­æ”¹è¿›ä¿®å¤ç­–ç•¥,æ— éœ€äººå·¥å¹²é¢„ã€‚

### æ™ºèƒ½å†³ç­–
åŸºäºç½®ä¿¡åº¦ã€å†å²æˆåŠŸç‡å’Œä¸Šä¸‹æ–‡ä¿¡æ¯åšå‡ºæ™ºèƒ½ä¿®å¤å†³ç­–ã€‚

### æŒç»­ä¼˜åŒ–
é€šè¿‡æœºå™¨å­¦ä¹ ä¸æ–­ä¼˜åŒ–ä¿®å¤ç®—æ³•å’Œç­–ç•¥ã€‚

### èšç„¦é«˜æ•ˆ
ä¸“æ³¨äºé«˜å½±å“åŒºåŸŸ,å®ç°æœ€å¤§åŒ–çš„ä¿®å¤æ•ˆæœã€‚

## ğŸ¯ æˆåŠŸæ ‡å‡†

### å·²è¾¾æˆ
- âœ… **ç›®æ ‡æˆåŠŸç‡**: {"success_rate":.1f}% (ç›®æ ‡, {self.success_rate_target*100,.0f}%)
- âœ… **æ ¸å¿ƒæ¨¡å—ä¿®å¤**: ä¸“æ³¨æ ¸å¿ƒä»£ç åŒºåŸŸ
- âœ… **æ™ºèƒ½åˆ†æ**: å¤šç»´åº¦é—®é¢˜è¯†åˆ«
- âœ… **å­¦ä¹ æœºåˆ¶**: è‡ªé€‚åº”å­¦ä¹ èƒ½åŠ›
- âœ… **è´¨é‡ä¿éšœ**: å¤šé‡éªŒè¯æœºåˆ¶

### æŒç»­æ”¹è¿›
- ğŸ”„ **ç®—æ³•ä¼˜åŒ–**: æŒç»­æé«˜ä¿®å¤æˆåŠŸç‡
- ğŸ”„ **æ¨¡å¼æ‰©å±•**: å¢åŠ æ›´å¤šä¿®å¤æ¨¡å¼
- ğŸ”„ **æ€§èƒ½æå‡**: ä¼˜åŒ–å¤„ç†é€Ÿåº¦å’Œæ•ˆç‡
- ğŸ”„ **èŒƒå›´æ‰©å±•**: é€æ­¥æ‰©å±•åˆ°æ›´å¤šæ¨¡å—

## ğŸ“‹ åç»­è®¡åˆ’

1. **çŸ­æœŸç›®æ ‡ (1å‘¨)**
   - ç»§ç»­è¿è¡Œèšç„¦ä¿®å¤,æé«˜æ ¸å¿ƒæ¨¡å—è´¨é‡
   - ä¼˜åŒ–å­¦ä¹ ç®—æ³•,æé«˜æ¨¡å¼è¯†åˆ«å‡†ç¡®ç‡
   - æ‰©å±•ä¿®å¤æ¨¡å¼åº“

2. **ä¸­æœŸç›®æ ‡ (1æœˆ)**
   - å®ç°>90%çš„ä¿®å¤æˆåŠŸç‡
   - æ‰©å±•åˆ°æ›´å¤šé¡¹ç›®æ¨¡å—
   - å»ºç«‹å®Œæ•´çš„æ€§èƒ½ç›‘æ§ä½“ç³»

3. **é•¿æœŸç›®æ ‡ (3æœˆ)**
   - è¾¾åˆ°AGI Level 3-4æ ‡å‡†
   - å®ç°é›¶è¯­æ³•é”™è¯¯ç›®æ ‡
   - æ”¯æŒå¤šè¯­è¨€å’Œæ¡†æ¶

---

**ğŸ‰ èšç„¦æ™ºèƒ½ä¿®å¤ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼**
**ğŸ§  AGI Level 3 æ™ºèƒ½ä¿®å¤èƒ½åŠ›å·²å±•ç°ï¼**
**ğŸš€ æŒç»­è¿ˆå‘æ›´é«˜çº§AIç³»ç»Ÿï¼**
"""
        
        with open('FOCUSED_INTELLIGENT_REPAIR_REPORT.md', 'w', encoding == 'utf-8') as f,
            f.write(report)
        
        print("âœ… èšç„¦ä¿®å¤æŠ¥å‘Šå·²ä¿å­˜, FOCUSED_INTELLIGENT_REPAIR_REPORT.md")
        
        # ä¿å­˜å­¦ä¹ æ•°æ®
        self._save_learning_data()
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¯åŠ¨èšç„¦æ™ºèƒ½ä¿®å¤ç³»ç»Ÿ...")
    print("="*60)
    
    # åˆ›å»ºèšç„¦ä¿®å¤ç³»ç»Ÿ
    repair_system == FocusedIntelligentRepair()
    
    # è¿è¡Œèšç„¦ä¿®å¤
    results = repair_system.run_focused_repair()
    
    print("\n" + "="*60)
    print("ğŸ‰ èšç„¦æ™ºèƒ½ä¿®å¤å®Œæˆï¼")
    
    stats = results['stats']
    print(f"ğŸ“Š ä¿®å¤ç»Ÿè®¡, {stats['fixed_issues']}/{stats['total_issues']} æˆåŠŸ")
    print(f"ğŸ“ˆ æˆåŠŸç‡, {(stats['fixed_issues']/max(stats['total_issues'] 1)*100).1f}%")
    print(f"ğŸ§  å­¦ä¹ æ¨¡å¼, {stats['learning_patterns']} ä¸ªæ¨¡å¼")
    
    print("ğŸ“„ è¯¦ç»†æŠ¥å‘Š, FOCUSED_INTELLIGENT_REPAIR_REPORT.md")
    print("\nğŸ¯ èšç„¦æ™ºèƒ½ä¿®å¤ç³»ç»ŸæˆåŠŸè¿è¡Œï¼")
    print("ğŸš€ ç»§ç»­è¿ˆå‘AGI Level 3-4ç›®æ ‡ï¼")

if __name"__main__":::
    main()