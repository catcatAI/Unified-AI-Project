# LLM 服务 (LLM Service)

## 概述
LLM 服务 (`llm_service.py`) 負責管理與各種大型語言模型 (LLM) 的互動。它提供了一個統一的介面，用於生成文本回應，並抽象化了底層 LLM 提供商的細節。

## 當前狀態 (模擬)
目前，LLM 服务處於**模擬狀態**。它不與任何真實的 LLM API 進行互動，而是根據輸入提示返回預設的模擬回應。這使得 Agent 可以在不依賴外部 LLM 服務的情況下進行開發和測試。

## 核心組件
- **`LLMManager`**: 負責載入和管理不同的 LLM 提供商。它根據請求的模型名稱將生成請求路由到適當的提供商。
- **`LLMResponse`**: 一個標準化的回應物件，用於封裝從 LLM 服務返回的文本回應、模型名稱、使用情況和提供商名稱。

## 整合點
- **`model_manager.py`**: 包含 `LLMManager` 的核心邏輯，包括動態載入提供商和路由請求。
- **`base_provider.py`**: 定義了 `BaseLLMProvider` 抽象基類和 `LLMResponse` 數據模型，確保所有 LLM 提供商都遵循統一的介面。

## 未來發展
- **真實 API 整合**: 將 `LLMManager` 擴展為整合真實的 LLM API (例如 OpenAI, Gemini, Hugging Face 等)，需要配置相應的 API 金鑰和憑證。
- **模型管理**: 實現更複雜的模型管理策略，例如負載平衡、故障轉移和模型版本控制。
- **性能優化**: 引入緩存、批處理和異步處理等技術，以提高 LLM 互動的性能。
