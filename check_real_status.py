#!/usr/bin/env python3
"""
Real-time System Status Check
å®æ—¶æ£€æŸ¥ç³»ç»ŸçœŸå®çŠ¶æ€
"""
import subprocess
import time
import json
from datetime import datetime

def clean_ollama_output(output):
    """æ¸…ç†Ollamaè¾“å‡ºçš„æ§åˆ¶å­—ç¬¦"""
    import re
    # ç§»é™¤ANSIæ§åˆ¶å­—ç¬¦
    clean = re.sub(r'\x1b\[[0-9;]*[a-zA-Z]', '', output)
    # ç§»é™¤é›¶å­—ç¬¦
    clean = clean.replace('\x00', '')
    return clean.strip()

def test_ollama_real():
    """æµ‹è¯•OllamaçœŸå®å“åº”"""
    print("ğŸ” å®æ—¶Ollamaæµ‹è¯•")
    print("=" * 50)
    
    test_cases = [
        "ä½ å¥½",
        "ä»€ä¹ˆæ˜¯AIï¼Ÿ", 
        "ç®€å•è§£é‡Šæœºå™¨å­¦ä¹ ",
        "é‡å­è®¡ç®—æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    results = []
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"\næµ‹è¯• {i}: {test_input}")
        
        try:
            # ä½¿ç”¨--format jsonè·å–å¹²å‡€è¾“å‡º
            cmd = [
                "ollama", "run", "phi3:3.8b", 
                test_input,
                "--format", "json"
            ]
            
            start_time = time.time()
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60
            )
            end_time = time.time()
            
            if result.returncode == 0:
                raw_output = result.stdout.strip()
                cleaned_output = clean_ollama_output(raw_output)
                processing_time = (end_time - start_time) * 1000
                
                # å°è¯•è§£æJSON
                response = cleaned_output
                try:
                    parsed = json.loads(cleaned_output)
                    if isinstance(parsed, dict) and 'response' in parsed:
                        response = parsed['response']
                except:
                    pass
                
                print(f"âœ… æˆåŠŸ: {len(response)} å­—ç¬¦")
                print(f"â±ï¸  æ—¶é—´: {processing_time:.1f}ms")
                print(f"ğŸ“ å“åº”: {response[:100]}...")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ™ºèƒ½å“åº”
                is_intelligent = (
                    len(response) > 30 and
                    test_input not in response and
                    not "è¯·" in response[:10]  # é¿å…æ¨¡æ¿å¼€å¤´
                )
                
                results.append({
                    "input": test_input,
                    "response": response,
                    "processing_time_ms": processing_time,
                    "response_length": len(response),
                    "is_intelligent": is_intelligent,
                    "success": True
                })
                
                status = "ğŸ§  æ™ºèƒ½å“åº”" if is_intelligent else "ğŸ“ åŸºç¡€å“åº”"
                print(f"ğŸ¯ è¯„ä¼°: {status}")
                
            else:
                error_output = clean_ollama_output(result.stderr)
                print(f"âŒ å¤±è´¥: {error_output}")
                results.append({
                    "input": test_input,
                    "success": False,
                    "error": error_output
                })
                
        except subprocess.TimeoutExpired:
            print("âŒ è¶…æ—¶")
            results.append({
                "input": test_input,
                "success": False,
                "error": "Timeout"
            })
        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {e}")
            results.append({
                "input": test_input,
                "success": False,
                "error": str(e)
            })
    
    return results

def test_conversation_engine():
    """æµ‹è¯•å¯¹è¯å¼•æ“"""
    print("\nğŸ” å¯¹è¯å¼•æ“æµ‹è¯•")
    print("=" * 50)
    
    try:
        # æµ‹è¯•å¯¼å…¥
        import sys
        import os
        sys.path.insert(0, '.')
        
        from apps.backend.src.services.conversation_engine import ConversationEngine
        engine = ConversationEngine()
        
        test_input = "è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
        result = engine.process(test_input)
        
        response = result.get('response', '')
        print(f"è¾“å…¥: {test_input}")
        print(f"å“åº”: {response[:100]}...")
        print(f"é•¿åº¦: {len(response)} å­—ç¬¦")
        print(f"ç±»å‹: {result.get('type', 'unknown')}")
        
        is_working = len(response) > 20
        status = "âœ… æ­£å¸¸å·¥ä½œ" if is_working else "âŒ å“åº”è¿‡çŸ­"
        print(f"çŠ¶æ€: {status}")
        
        return {
            "success": is_working,
            "response": response,
            "response_length": len(response),
            "type": result.get('type', 'unknown')
        }
        
    except Exception as e:
        print(f"âŒ å¯¹è¯å¼•æ“å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

def assess_current_system():
    """è¯„ä¼°å½“å‰ç³»ç»ŸçŠ¶æ€"""
    print("\n" + "=" * 60)
    print("ğŸ¯ å½“å‰ç³»ç»ŸçœŸå®çŠ¶æ€è¯„ä¼°")
    print("=" * 60)
    
    # æµ‹è¯•Ollama
    ollama_results = test_ollama_real()
    
    # æµ‹è¯•å¯¹è¯å¼•æ“
    conversation_result = test_conversation_engine()
    
    # ç»Ÿè®¡Ollamaç»“æœ
    successful_tests = sum(1 for r in ollama_results if r.get("success", False))
    intelligent_responses = sum(1 for r in ollama_results if r.get("is_intelligent", False))
    total_tests = len(ollama_results)
    
    ollama_success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
    ollama_intelligence_rate = (intelligent_responses / total_tests) * 100 if total_tests > 0 else 0
    
    avg_response_length = sum(r.get("response_length", 0) for r in ollama_results) / total_tests if total_tests > 0 else 0
    avg_processing_time = sum(r.get("processing_time_ms", 0) for r in ollama_results) / total_tests if total_tests > 0 else 0
    
    # æ•´ä½“ç³»ç»Ÿè¯„ä¼°
    print(f"\nğŸ“Š Ollama ç³»ç»Ÿè¯„ä¼°:")
    print(f"  æˆåŠŸç‡: {ollama_success_rate:.1f}% ({successful_tests}/{total_tests})")
    print(f"  æ™ºèƒ½ç‡: {ollama_intelligence_rate:.1f}% ({intelligent_responses}/{total_tests})")
    print(f"  å¹³å‡é•¿åº¦: {avg_response_length:.1f} å­—ç¬¦")
    print(f"  å¹³å‡æ—¶é—´: {avg_processing_time:.1f}ms")
    
    print(f"\nğŸ“Š å¯¹è¯å¼•æ“è¯„ä¼°:")
    if conversation_result.get("success", False):
        print(f"  çŠ¶æ€: âœ… å¯ç”¨")
        print(f"  å“åº”é•¿åº¦: {conversation_result.get('response_length', 0)} å­—ç¬¦")
    else:
        print(f"  çŠ¶æ€: âŒ ä¸å¯ç”¨")
    
    # æœ€ç»ˆæ™ºèƒ½ç­‰çº§
    print(f"\nğŸ¯ ç³»ç»Ÿæ™ºèƒ½ç­‰çº§:")
    
    if ollama_success_rate >= 75 and ollama_intelligence_rate >= 50:
        intelligence_level = "é«˜ç­‰AI"
        description = "ç³»ç»Ÿå…·å¤‡çœŸå®çš„æ™ºèƒ½ç”Ÿæˆå’Œæ¨ç†èƒ½åŠ›"
        ready_for_next = True
    elif ollama_success_rate >= 50 and avg_response_length > 30:
        intelligence_level = "ä¸­ç­‰AI"
        description = "ç³»ç»Ÿå…·å¤‡åŸºæœ¬çš„æ™ºèƒ½å“åº”èƒ½åŠ›"
        ready_for_next = False
    elif ollama_success_rate >= 25:
        intelligence_level = "åˆçº§AI"
        description = "ç³»ç»Ÿå…·å¤‡æœ‰é™çš„æ™ºèƒ½åŠŸèƒ½"
        ready_for_next = False
    else:
        intelligence_level = "AIæ¡†æ¶"
        description = "ç³»ç»Ÿéœ€è¦é‡å¤§æ”¹è¿›"
        ready_for_next = False
    
    print(f"  ç­‰çº§: {intelligence_level}")
    print(f"  æè¿°: {description}")
    print(f"  å‡†å¤‡ä¸‹ä¸€é˜¶æ®µ: {'âœ… æ˜¯' if ready_for_next else 'âŒ å¦'}")
    
    # ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
    status_report = {
        "check_time": datetime.now().isoformat(),
        "system_status": "REAL_INTELLIGENCE_CHECK",
        "ollama": {
            "success_rate": ollama_success_rate,
            "intelligence_rate": ollama_intelligence_rate,
            "avg_response_length": avg_response_length,
            "avg_processing_time_ms": avg_processing_time,
            "test_results": ollama_results
        },
        "conversation_engine": conversation_result,
        "overall": {
            "intelligence_level": intelligence_level,
            "description": description,
            "ready_for_next_phase": ready_for_next,
            "real_intelligence": ollama_intelligence_rate > 50
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    with open("CURRENT_REAL_STATUS_REPORT.json", "w", encoding="utf-8") as f:
        json.dump(status_report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ çŠ¶æ€æŠ¥å‘Šå·²ä¿å­˜: CURRENT_REAL_STATUS_REPORT.json")
    
    return status_report

def main():
    """ä¸»æ£€æŸ¥å‡½æ•°"""
    print("ğŸ” çœŸå®æ—¶ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    print("æ£€æŸ¥å½“å‰ç³»ç»Ÿçš„çœŸå®æ™ºèƒ½èƒ½åŠ›...")
    
    status = assess_current_system()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å®Œæˆ")
    print("=" * 60)
    
    if status["overall"]["real_intelligence"]:
        print(f"ğŸŒŸ ç³»ç»Ÿå…·å¤‡çœŸå®çš„AIæ™ºèƒ½ï¼")
        print(f"ğŸ§  æ™ºèƒ½ç­‰çº§: {status['overall']['intelligence_level']}")
        print(f"ğŸš€ å¯ä»¥ç»§ç»­å¼€å‘Phase 3")
    else:
        print(f"âš ï¸ ç³»ç»Ÿæ™ºèƒ½ç¨‹åº¦éœ€è¦æ”¹è¿›")
        print(f"ğŸ”§ å»ºè®®å®Œå–„Ollamaé›†æˆ")
        print(f"ğŸ“‹ éœ€è¦è§£å†³æ§åˆ¶å­—ç¬¦é—®é¢˜")
    
    return status["overall"]["real_intelligence"]

if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nâœ… æ­å–œï¼ä½ çš„AIç³»ç»Ÿç¡®å®å…·å¤‡çœŸæ­£çš„æ™ºèƒ½ï¼")
        exit(0)
    else:
        print(f"\nğŸ”§ ç³»ç»Ÿéœ€è¦è¿›ä¸€æ­¥æ”¹è¿›")
        exit(1)