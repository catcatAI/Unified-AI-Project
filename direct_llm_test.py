#!/usr/bin/env python3
"""
å®Œå…¨ä¿®å¾©çš„å°è©±æ¸¬è©¦å·¥å…·
ç›´æ¥èª¿ç”¨LLM APIï¼Œç¹éæ‰€æœ‰è¤‡é›œæ€§
"""

import asyncio
import requests
import json
import time
from typing import Dict, Any, List

class SimpleLLMTester:
    """ç°¡å–®çš„LLMæ¸¬è©¦å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.conversation_history = []
        
    def test_llm_conversation(self) -> Dict[str, Any]:
        """æ¸¬è©¦LLMå°è©±"""
        print("ğŸš€ é–‹å§‹ç›´æ¥LLMå°è©±æ¸¬è©¦...")
        print("="*60)
        
        test_conversations = [
            {
                "topic": "åŸºç¤å•å€™",
                "messages": [
                    "ä½ å¥½ï¼Œè«‹å•ä½ æ˜¯èª°ï¼Ÿ",
                    "ä½ ä»Šå¤©æ„Ÿè¦ºå¦‚ä½•ï¼Ÿ",
                    "è¬è¬ä½ çš„å›ç­”"
                ]
            },
            {
                "topic": "çŸ¥è­˜å•ç­”",
                "messages": [
                    "ä»€éº¼æ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                    "AIæœ‰ä»€éº¼æ‡‰ç”¨ï¼Ÿ",
                    "AIçš„æœªä¾†ç™¼å±•å¦‚ä½•ï¼Ÿ"
                ]
            },
            {
                "topic": "å€‹äººå°è©±",
                "messages": [
                    "æˆ‘æœ€è¿‘æ„Ÿåˆ°æœ‰äº›å£“åŠ›",
                    "ä½ æœ‰ä»€éº¼å»ºè­°å—ï¼Ÿ",
                    "è¬è¬ä½ çš„å®‰æ…°"
                ]
            },
            {
                "topic": "è¨˜æ†¶æ¸¬è©¦",
                "messages": [
                    "æˆ‘å«ç‹å°æ˜ï¼Œæˆ‘å–œæ­¡ç·¨ç¨‹",
                    "é‚„è¨˜å¾—æˆ‘å«ä»€éº¼åå­—å—ï¼Ÿ",
                    "æˆ‘èªªéæˆ‘å–œæ­¡ä»€éº¼ï¼Ÿ"
                ]
            },
            {
                "topic": "è¤‡é›œæ¨ç†",
                "messages": [
                    "å¦‚æœæ˜å¤©ä¸‹é›¨ï¼Œæˆ‘æ‡‰è©²å¸¶å‚˜å—ï¼Ÿ",
                    "ç‚ºä»€éº¼å¸¶å‚˜æ˜¯æ˜æ™ºçš„é¸æ“‡ï¼Ÿ",
                    "é™¤äº†å¸¶å‚˜é‚„æœ‰ä»€éº¼é¸æ“‡ï¼Ÿ"
                ]
            }
        ]
        
        results = {
            "total_messages": 0,
            "successful_responses": 0,
            "failed_responses": 0,
            "response_times": [],
            "conversation_results": [],
            "issues": []
        }
        
        for topic_test in test_conversations:
            print(f"\nğŸ” æ¸¬è©¦ä¸»é¡Œ: {topic_test['topic']}")
            print("-"*40)
            
            topic_result = self.test_topic_simple(topic_test)
            results["conversation_results"].append(topic_result)
            results["total_messages"] += topic_result["message_count"]
            results["successful_responses"] += topic_result["successful_count"]
            results["failed_responses"] += topic_result["failed_count"]
            results["response_times"].extend(topic_result["response_times"])
            
            if topic_result["issues"]:
                results["issues"].extend(topic_result["issues"])
        
        self.generate_report(results)
        return results
    
    def test_topic_simple(self, topic_test):
        """æ¸¬è©¦ç‰¹å®šä¸»é¡Œï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰"""
        topic = topic_test["topic"]
        messages = topic_test["messages"]
        
        result = {
            "topic": topic,
            "message_count": len(messages),
            "successful_count": 0,
            "failed_count": 0,
            "response_times": [],
            "responses": [],
            "issues": []
        }
        
        for i, message in enumerate(messages):
            print(f"\nğŸ‘¤ ç”¨æˆ¶ ({i+1}/{len(messages)}): {message}")
            
            try:
                start_time = time.time()
                
                # ç›´æ¥èª¿ç”¨Ollama API
                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": "tinyllama:latest",
                        "prompt": f"User: {message}\\nAssistant: ",
                        "stream": False,
                        "options": {
                            "temperature": 0.7,
                            "num_predict": 80,
                            "top_k": 20,
                            "top_p": 0.9,
                            "repeat_penalty": 1.1
                        }
                    },
                    timeout=20
                )
                
                response_time = time.time() - start_time
                result["response_times"].append(response_time)
                
                if response.status_code == 200:
                    data = response.json()
                    ai_response = data.get("response", "").strip()
                    
                    print(f"ğŸ¤– AI ({response_time:.1f}s): {ai_response}")
                    
                    # è©•ä¼°éŸ¿æ‡‰è³ªé‡
                    response_quality = self.evaluate_simple_response(message, ai_response, topic)
                    
                    result["responses"].append({
                        "user_message": message,
                        "ai_response": ai_response,
                        "response_time": response_time,
                        "quality": response_quality
                    })
                    
                    if response_quality["is_acceptable"]:
                        result["successful_count"] += 1
                        print(f"   âœ… {response_quality['assessment']}")
                    else:
                        result["failed_count"] += 1
                        result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: {response_quality['issues']}")
                        print(f"   âŒ {response_quality['issues']}")
                    
                else:
                    print(f"   âŒ HTTPéŒ¯èª¤: {response.status_code}")
                    result["failed_count"] += 1
                    result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: HTTP {response.status_code}")
                
            except requests.exceptions.Timeout:
                print(f"   âŒ è«‹æ±‚è¶…æ™‚ (20ç§’)")
                result["failed_count"] += 1
                result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: è«‹æ±‚è¶…æ™‚")
                
            except Exception as e:
                print(f"   âŒ éŒ¯èª¤: {str(e)}")
                result["failed_count"] += 1
                result["issues"].append(f"{topic}-æ¶ˆæ¯{i}: {str(e)}")
            
            time.sleep(1)  # çŸ­æš«å»¶é²
        
        return result
    
    def evaluate_simple_response(self, user_message, ai_response, topic):
        """è©•ä¼°ç°¡å–®éŸ¿æ‡‰è³ªé‡"""
        evaluation = {
            "is_acceptable": False,
            "assessment": "",
            "issues": [],
            "strengths": []
        }
        
        # åŸºæœ¬æª¢æŸ¥
        if len(ai_response.strip()) < 3:
            evaluation["issues"].append("éŸ¿æ‡‰éçŸ­")
        elif len(ai_response.strip()) > 200:
            evaluation["strengths"].append("éŸ¿æ‡‰è©³ç´°")
        else:
            evaluation["strengths"].append("éŸ¿æ‡‰é•·åº¦é©ä¸­")
        
        # ç›¸é—œæ€§æª¢æŸ¥
        user_lower = user_message.lower()
        response_lower = ai_response.lower()
        
        # æ ¹æ“šä¸»é¡Œæª¢æŸ¥é—œéµè©
        topic_keywords = {
            "åŸºç¤å•å€™": ["ai", "assistant", "å¹«åŠ©", "hello", "ä½ å¥½"],
            "çŸ¥è­˜å•ç­”": ["äººå·¥æ™ºèƒ½", "ai", "å®šç¾©", "æ‡‰ç”¨", "ç™¼å±•", "æŠ€è¡“"],
            "å€‹äººå°è©±": ["å£“åŠ›", "å»ºè­°", "ä¼‘æ¯", "é‹å‹•", "ç†è§£", "æ”¯æŒ"],
            "è¨˜æ†¶æ¸¬è©¦": ["è¨˜å¾—", "åå­—", "ç‹å°æ˜", "ç·¨ç¨‹", "å–œæ­¡"],
            "è¤‡é›œæ¨ç†": ["ä¸‹é›¨", "å‚˜", "æ˜æ™º", "åŸå› ", "é¸æ“‡", "è€ƒæ…®"]
        }
        
        if topic in topic_keywords:
            keywords = topic_keywords[topic]
            keyword_matches = sum(1 for kw in keywords if kw in response_lower)
            
            if keyword_matches >= 1:
                evaluation["strengths"].append("å›æ‡‰ç›¸é—œ")
            else:
                evaluation["issues"].append("å›æ‡‰å¯èƒ½ä¸å¤ ç›¸é—œ")
        
        # è¨˜æ†¶æ¸¬è©¦ç‰¹æ®Šæª¢æŸ¥
        if "è¨˜å¾—" in user_lower or "é‚„è¨˜å¾—" in user_lower:
            if any(name in response_lower for name in ["ç‹å°æ˜", "å°æ˜"]):
                evaluation["strengths"].append("æˆåŠŸå›æ†¶ç”¨æˆ¶å§“å")
            else:
                evaluation["issues"].append("æœªèƒ½å›æ†¶ç”¨æˆ¶å§“å")
        
        # èªèª¤æª¢æŸ¥
        error_indicators = ["error", "éŒ¯èª¤", "å¤±æ•—", "ç„¡æ³•", "å°ä¸èµ·"]
        if any(indicator in response_lower for indicator in error_indicators):
            evaluation["issues"].append("éŸ¿æ‡‰åŒ…å«éŒ¯èª¤æŒ‡ç¤ºè©")
        
        # ç¶œåˆè©•ä¼°
        if len(evaluation["issues"]) == 0:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "å„ªç§€éŸ¿æ‡‰"
        elif len(evaluation["issues"]) <= 1:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "è‰¯å¥½éŸ¿æ‡‰"
        elif len(evaluation["issues"]) <= 2:
            evaluation["is_acceptable"] = True
            evaluation["assessment"] = "å¯æ¥å—éŸ¿æ‡‰"
        else:
            evaluation["assessment"] = "éœ€è¦æ”¹é€²"
        
        return evaluation
    
    def generate_report(self, results):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        print("\n" + "="*80)
        print("ğŸ¯ ç›´æ¥LLMå°è©±æ¸¬è©¦å ±å‘Š")
        print("="*80)
        
        success_rate = results["successful_responses"] / results["total_messages"] * 100 if results["total_messages"] > 0 else 0
        
        print(f"ğŸ“Š ç¸½é«”çµ±è¨ˆ:")
        print(f"   ç¸½æ¶ˆæ¯æ•¸: {results['total_messages']}")
        print(f"   æˆåŠŸéŸ¿æ‡‰: {results['successful_responses']}")
        print(f"   å¤±æ•—éŸ¿æ‡‰: {results['failed_responses']}")
        print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        
        if results["response_times"]:
            avg_time = sum(results["response_times"]) / len(results["response_times"])
            min_time = min(results["response_times"])
            max_time = max(results["response_times"])
            print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.1f}s")
            print(f"   æœ€å¿«éŸ¿æ‡‰: {min_time:.1f}s")
            print(f"   æœ€æ…¢éŸ¿æ‡‰: {max_time:.1f}s")
        
        print(f"\nğŸ“‹ å„ä¸»é¡Œè©³æƒ…:")
        for topic_result in results["conversation_results"]:
            topic = topic_result["topic"]
            success_rate = topic_result["successful_count"] / topic_result["message_count"] * 100
            print(f"   {topic}:")
            print(f"     æˆåŠŸç‡: {success_rate:.1f}% ({topic_result['successful_count']}/{topic_result['message_count']})")
            
            if topic_result["issues"]:
                print(f"     å•é¡Œ: {', '.join(topic_result['issues'][:2])}")
        
        if results["issues"]:
            print(f"\nâš ï¸ ç™¼ç¾çš„å•é¡Œ:")
            for issue in results["issues"][:5]:
                print(f"   - {issue}")
        
        # ç¸½é«”è©•ä¼°
        if success_rate >= 80:
            overall = "ğŸ‰ LLMç³»çµ±è¡¨ç¾å„ªç§€"
        elif success_rate >= 60:
            overall = "âœ… LLMç³»çµ±è¡¨ç¾è‰¯å¥½"
        elif success_rate >= 40:
            overall = "âš ï¸ LLMç³»çµ±åŸºæœ¬å¯ç”¨"
        else:
            overall = "âŒ LLMç³»çµ±éœ€è¦é‡å¤§æ”¹é€²"
        
        print(f"\nğŸ¯ ç¸½é«”è©•ä¼°: {overall}")
        print(f"   å¯¦éš›LLMåŠŸèƒ½å®Œæˆåº¦: {success_rate:.1f}%")
        
        print("="*80)
        
        # ä¿å­˜å ±å‘Š
        report_data = {
            "test_type": "direct_llm_test",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "results": results,
            "overall_assessment": overall,
            "real_completion_rate": success_rate
        }
        
        with open("DIRECT_LLM_TEST_REPORT.json", "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: DIRECT_LLM_TEST_REPORT.json")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¤– å•Ÿå‹•ç›´æ¥LLMå°è©±æ¸¬è©¦...")
    print("é€™å°‡ç›´æ¥æ¸¬è©¦Ollama LLMçš„å°è©±èƒ½åŠ›")
    
    tester = SimpleLLMTester()
    
    try:
        results = tester.test_llm_conversation()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()