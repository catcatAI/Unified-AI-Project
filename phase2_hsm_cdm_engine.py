"""
Phase 2: HSM+CDM Core Implementation
å¯å‘å¼æ¨¡æ‹Ÿæœºåˆ¶ (HSM) + è®¤çŸ¥é…æ¯æ¨¡å‹ (CDM)

æ ¸å¿ƒå…¬å¼ï¼š
HSM = C_Gap Ã— E_M2
CDM = Logic Unit + Memory Encoding + Dynamic Retrieval
"""
import asyncio
import hashlib
import json
import logging
import math
import time
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional, Tuple
from uuid import uuid4
import numpy as np

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CognitiveGapDetector:
    """è®¤çŸ¥ç¼ºå£æ£€æµ‹å™¨ - C_Gap è®¡ç®—"""
    
    def __init__(self):
        self.knowledge_base = {}  # ç®€åŒ–çŸ¥è¯†åº“
        self.gap_threshold = 0.7  # ç¼ºå£é˜ˆå€¼
        
    def calculate_cognitive_gap(self, input_data: Dict[str, Any]) -> Dict[str, float]:
        """
        è®¡ç®—è®¤çŸ¥ç¼ºå£ C_Gap = |New_Information - Existing_Structure|
        
        Returns:
            Dict with gap metrics: magnitude, confidence, complexity
        """
        try:
            # æå–è¾“å…¥ç‰¹å¾
            content = input_data.get("content", "")
            context = input_data.get("context", "")
            
            # ç®€åŒ–çš„è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
            input_features = self._extract_features(content + " " + context)
            
            # æœç´¢çŸ¥è¯†åº“ä¸­çš„åŒ¹é…é¡¹
            max_similarity = 0.0
            for knowledge_id, knowledge in self.knowledge_base.items():
                knowledge_features = self._extract_features(knowledge["content"])
                similarity = self._cosine_similarity(input_features, knowledge_features)
                max_similarity = max(max_similarity, similarity)
            
            # è®¡ç®—ç¼ºå£å¤§å°
            gap_magnitude = 1.0 - max_similarity  # ç›¸ä¼¼åº¦è¶Šä½ï¼Œç¼ºå£è¶Šå¤§
            
            # è®¡ç®—ç½®ä¿¡åº¦
            gap_confidence = min(0.95, gap_magnitude * 1.2)
            
            # è®¡ç®—å¤æ‚åº¦
            gap_complexity = min(1.0, len(content.split()) / 50.0)  # åŸºäºè¯æ•°
            
            return {
                "magnitude": gap_magnitude,
                "confidence": gap_confidence, 
                "complexity": gap_complexity,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            logger.error(f"C_Gap calculation error: {e}")
            return {"magnitude": 0.5, "confidence": 0.5, "complexity": 0.5}
    
    def _extract_features(self, text: str) -> Dict[str, float]:
        """æå–æ–‡æœ¬ç‰¹å¾å‘é‡"""
        words = text.lower().split()
        features = {}
        
        # ç®€åŒ–çš„TF-IDFç‰¹å¾
        total_words = len(words)
        if total_words == 0:
            return {}
            
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
            
        for word, freq in word_freq.items():
            features[word] = freq / total_words
            
        return features
    
    def _cosine_similarity(self, vec1: Dict[str, float], vec2: Dict[str, float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if not vec1 or not vec2:
            return 0.0
            
        # è®¡ç®—ç‚¹ç§¯
        dot_product = 0.0
        for word in vec1:
            if word in vec2:
                dot_product += vec1[word] * vec2[word]
        
        # è®¡ç®—å‘é‡é•¿åº¦
        norm1 = math.sqrt(sum(val**2 for val in vec1.values()))
        norm2 = math.sqrt(sum(val**2 for val in vec2.values()))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        return dot_product / (norm1 * norm2)
    
    def should_trigger_learning(self, gap_metrics: Dict[str, float]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘å­¦ä¹ æœºåˆ¶"""
        magnitude = gap_metrics.get("magnitude", 0.0)
        confidence = gap_metrics.get("confidence", 0.0)
        
        # ç»¼åˆåˆ¤æ–­ï¼šç¼ºå£å¤§å°è¶…è¿‡é˜ˆå€¼ä¸”ç½®ä¿¡åº¦è¶³å¤Ÿé«˜
        trigger_score = magnitude * confidence
        return trigger_score > self.gap_threshold

class HeuristicSimulationMechanism:
    """å¯å‘å¼æ¨¡æ‹Ÿæœºåˆ¶ - HSM å®ç°"""
    
    def __init__(self):
        self.em2_factor = 0.1  # E_M2 éšæœºæ¢ç´¢å› å­
        self.temperature = 1.0  # æ¢ç´¢æ¸©åº¦å‚æ•°
        
    def simulate_solution(self, problem: Dict[str, Any], gap_metrics: Dict[str, float]) -> Dict[str, Any]:
        """
        HSM = C_Gap Ã— E_M2
        
        åŸºäºè®¤çŸ¥ç¼ºå£è¿›è¡Œå¯å‘å¼æ¢ç´¢ï¼Œç”Ÿæˆè§£å†³æ–¹æ¡ˆ
        """
        try:
            gap_magnitude = gap_metrics.get("magnitude", 0.5)
            complexity = gap_metrics.get("complexity", 0.5)
            
            # è°ƒæ•´æ¢ç´¢å¼ºåº¦
            exploration_intensity = gap_magnitude * self.em2_factor
            
            # ç”Ÿæˆå€™é€‰è§£å†³æ–¹æ¡ˆ
            candidates = self._generate_candidates(problem, exploration_intensity, complexity)
            
            # è¯„ä¼°å’Œé€‰æ‹©æœ€ä½³æ–¹æ¡ˆ
            best_candidate = self._evaluate_candidates(candidates, problem)
            
            return {
                "solution": best_candidate,
                "hsm_score": exploration_intensity,
                "candidates_explored": len(candidates),
                "confidence": best_candidate.get("confidence", 0.5),
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            logger.error(f"HSM simulation error: {e}")
            return {
                "solution": {"content": "åŸºç¡€å›åº”", "confidence": 0.3},
                "hsm_score": 0.0,
                "candidates_explored": 1,
                "confidence": 0.3
            }
    
    def _generate_candidates(self, problem: Dict[str, Any], intensity: float, complexity: float) -> List[Dict]:
        """ç”Ÿæˆå€™é€‰è§£å†³æ–¹æ¡ˆ"""
        candidates = []
        content = problem.get("content", "")
        
        # åŸºç¡€å€™é€‰ï¼šç›´æ¥å›ç­”
        candidates.append({
            "content": f"åŸºäº'{content}'çš„åˆ†æå›åº”",
            "confidence": 0.7,
            "type": "direct_response"
        })
        
        # æ¢ç´¢å€™é€‰ï¼šåŸºäºéšæœºæ¢ç´¢
        if intensity > 0.05:
            candidates.append({
                "content": f"é€šè¿‡å¯å‘å¼æ¢ç´¢å¯¹'{content}'çš„åˆ›æ–°æ€§å›åº”",
                "confidence": 0.6 + np.random.random() * 0.2,
                "type": "exploratory_response"
            })
        
        # å¤æ‚å€™é€‰ï¼šé’ˆå¯¹å¤æ‚é—®é¢˜çš„æ·±åº¦å›åº”
        if complexity > 0.7:
            candidates.append({
                "content": f"å¯¹å¤æ‚é—®é¢˜'{content}'çš„å¤šå±‚æ¬¡æ·±åº¦å›åº”",
                "confidence": 0.8 + np.random.random() * 0.1,
                "type": "complex_response"
            })
        
        return candidates
    
    def _evaluate_candidates(self, candidates: List[Dict], problem: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å€™é€‰æ–¹æ¡ˆå¹¶é€‰æ‹©æœ€ä½³"""
        if not candidates:
            return {"content": "æ— å¯ç”¨æ–¹æ¡ˆ", "confidence": 0.0}
        
        # ç®€åŒ–è¯„ä¼°ï¼šé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æ–¹æ¡ˆ
        best_candidate = max(candidates, key=lambda x: x.get("confidence", 0.0))
        best_candidate["evaluation_time"] = datetime.now(timezone.utc).isoformat()
        
        return best_candidate

class CognitiveDividendModel:
    """è®¤çŸ¥é…æ¯æ¨¡å‹ - CDM å®ç°"""
    
    def __init__(self):
        self.logic_units = {}  # å­˜å‚¨é€»è¾‘å•å…ƒ
        self.unit_counter = 0
        self.decay_rate = 0.01  # é—å¿˜é€Ÿç‡
        
    def solidify_logic_unit(self, experience: Dict[str, Any], solution: Dict[str, Any]) -> str:
        """
        å°†ç»éªŒå’Œè§£å†³æ–¹æ¡ˆå›ºåŒ–ä¸ºé€»è¾‘å•å…ƒ
        
        Returns:
            Logic Unit ID
        """
        try:
            # ç”Ÿæˆé€»è¾‘å•å…ƒID
            unit_id = f"LU_{self.unit_counter:06d}"
            self.unit_counter += 1
            
            # åˆ›å»ºé€»è¾‘å•å…ƒ
            logic_unit = {
                "id": unit_id,
                "content": experience.get("content", ""),
                "solution": solution.get("solution", {}),
                "confidence": solution.get("confidence", 0.5),
                "hsm_score": solution.get("hsm_score", 0.0),
                "type": solution.get("solution", {}).get("type", "unknown"),
                "created_at": datetime.now(timezone.utc).isoformat(),
                "last_accessed": datetime.now(timezone.utc).isoformat(),
                "access_count": 0,
                "effectiveness": 0.5,  # åˆå§‹æ•ˆæœå€¼
                "metadata": {
                    "experience": experience,
                    "gap_metrics": experience.get("gap_metrics", {}),
                    "candidates": solution.get("candidates_explored", 1)
                }
            }
            
            # å­˜å‚¨é€»è¾‘å•å…ƒ
            self.logic_units[unit_id] = logic_unit
            
            logger.info(f"CDM: Solidified logic unit {unit_id}")
            return unit_id
            
        except Exception as e:
            logger.error(f"CDM solidification error: {e}")
            return "ERROR"
    
    def retrieve_relevant_units(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³é€»è¾‘å•å…ƒ"""
        try:
            query_features = self._extract_features(query)
            
            # è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ’åº
            scored_units = []
            for unit_id, unit in self.logic_units.items():
                unit_content = unit.get("content", "")
                unit_features = self._extract_features(unit_content)
                
                similarity = self._cosine_similarity(query_features, unit_features)
                
                # ç»¼åˆè¯„åˆ†ï¼šç›¸ä¼¼åº¦ + æ•ˆæœ + è®¿é—®é¢‘ç‡
                access_bonus = math.log(1 + unit.get("access_count", 0)) * 0.1
                effectiveness = unit.get("effectiveness", 0.5)
                
                total_score = similarity * 0.6 + effectiveness * 0.3 + access_bonus * 0.1
                
                scored_units.append((total_score, unit))
            
            # æŒ‰è¯„åˆ†æ’åºå¹¶è¿”å›å‰Nä¸ª
            scored_units.sort(key=lambda x: x[0], reverse=True)
            top_units = [unit for score, unit in scored_units[:limit]]
            
            # æ›´æ–°è®¿é—®ç»Ÿè®¡
            for unit in top_units:
                unit["last_accessed"] = datetime.now(timezone.utc).isoformat()
                unit["access_count"] += 1
            
            return top_units
            
        except Exception as e:
            logger.error(f"CDM retrieval error: {e}")
            return []
    
    def update_effectiveness(self, unit_id: str, feedback_score: float):
        """åŸºäºåé¦ˆæ›´æ–°é€»è¾‘å•å…ƒæ•ˆæœ"""
        if unit_id in self.logic_units:
            unit = self.logic_units[unit_id]
            current_effectiveness = unit.get("effectiveness", 0.5)
            
            # æŒ‡æ•°ç§»åŠ¨å¹³å‡æ›´æ–°
            alpha = 0.2  # å­¦ä¹ ç‡
            new_effectiveness = alpha * feedback_score + (1 - alpha) * current_effectiveness
            
            unit["effectiveness"] = new_effectiveness
            unit["last_updated"] = datetime.now(timezone.utc).isoformat()
            
            logger.info(f"CDM: Updated unit {unit_id} effectiveness to {new_effectiveness:.3f}")
    
    def _extract_features(self, text: str) -> Dict[str, float]:
        """æå–æ–‡æœ¬ç‰¹å¾"""
        words = text.lower().split()
        features = {}
        
        total_words = len(words)
        if total_words == 0:
            return {}
            
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
            
        for word, freq in word_freq.items():
            features[word] = freq / total_words
            
        return features
    
    def _cosine_similarity(self, vec1: Dict[str, float], vec2: Dict[str, float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if not vec1 or not vec2:
            return 0.0
            
        dot_product = 0.0
        for word in vec1:
            if word in vec2:
                dot_product += vec1[word] * vec2[word]
        
        norm1 = math.sqrt(sum(val**2 for val in vec1.values()))
        norm2 = math.sqrt(sum(val**2 for val in vec2.values()))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        return dot_product / (norm1 * norm2)

class HSMCDMEngine:
    """HSM+CDM é›†æˆå¼•æ“"""
    
    def __init__(self):
        self.gap_detector = CognitiveGapDetector()
        self.hsm = HeuristicSimulationMechanism()
        self.cdm = CognitiveDividendModel()
        
        # æ€§èƒ½æŒ‡æ ‡
        self.metrics = {
            "total_processed": 0,
            "learning_triggered": 0,
            "units_created": 0,
            "units_retrieved": 0,
            "average_confidence": 0.0
        }
        
        logger.info("HSM+CDM Engine initialized")
    
    def process_input(self, user_input: str) -> Dict[str, Any]:
        """
        å®Œæ•´çš„ HSM+CDM å¤„ç†æµç¨‹ï¼š
        1. C_Gap æ£€æµ‹
        2. HSM æ¨¡æ‹Ÿï¼ˆå¦‚éœ€è¦ï¼‰
        3. CDM å›ºåŒ–/æ£€ç´¢
        4. å“åº”ç”Ÿæˆ
        """
        start_time = time.time()
        self.metrics["total_processed"] += 1
        
        try:
            # Step 1: è®¤çŸ¥ç¼ºå£æ£€æµ‹
            input_data = {"content": user_input, "context": ""}
            gap_metrics = self.gap_detector.calculate_cognitive_gap(input_data)
            
            response = None
            learned_new_unit = False
            
            # Step 2: åˆ¤æ–­æ˜¯å¦éœ€è¦å­¦ä¹ 
            if self.gap_detector.should_trigger_learning(gap_metrics):
                logger.info(f"Triggering learning for input: {user_input[:50]}...")
                self.metrics["learning_triggered"] += 1
                
                # Step 3: HSM å¯å‘å¼æ¨¡æ‹Ÿ
                problem = {"content": user_input}
                hsm_result = self.hsm.simulate_solution(problem, gap_metrics)
                
                # Step 4: CDM å›ºåŒ–æ–°é€»è¾‘å•å…ƒ
                experience = {
                    "content": user_input,
                    "gap_metrics": gap_metrics,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
                
                unit_id = self.cdm.solidify_logic_unit(experience, hsm_result)
                if unit_id != "ERROR":
                    self.metrics["units_created"] += 1
                    learned_new_unit = True
                
                response = hsm_result.get("solution", {}).get("content", "æ­£åœ¨å­¦ä¹ ä¸­...")
                
            else:
                # Step 5: ä» CDM æ£€ç´¢ç›¸å…³é€»è¾‘å•å…ƒ
                relevant_units = self.cdm.retrieve_relevant_units(user_input, limit=3)
                self.metrics["units_retrieved"] += len(relevant_units)
                
                if relevant_units:
                    # ä½¿ç”¨æœ€ç›¸å…³çš„é€»è¾‘å•å…ƒç”Ÿæˆå“åº”
                    best_unit = relevant_units[0]
                    response = best_unit.get("solution", {}).get("content", "åŸºäºå·²æœ‰çŸ¥è¯†å›åº”...")
                    
                    # æä¾›åé¦ˆæœºåˆ¶
                    logger.info(f"Retrieved logic unit: {best_unit['id']}")
                else:
                    # é»˜è®¤å›åº”
                    response = f"æˆ‘ç†è§£æ‚¨è¯´çš„ï¼š{user_input}"
            
            # Step 6: æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
            confidence = gap_metrics.get("confidence", 0.5)
            total_conf = self.metrics["average_confidence"] * (self.metrics["total_processed"] - 1) + confidence
            self.metrics["average_confidence"] = total_conf / self.metrics["total_processed"]
            
            processing_time = time.time() - start_time
            
            return {
                "response": response,
                "metadata": {
                    "gap_magnitude": gap_metrics.get("magnitude", 0.0),
                    "gap_confidence": gap_metrics.get("confidence", 0.0),
                    "learning_triggered": learned_new_unit,
                    "units_retrieved": len(relevant_units) if not learned_new_unit else 0,
                    "processing_time_ms": processing_time * 1000,
                    "engine": "HSM+CDM",
                    "timestamp": datetime.now(timezone.utc).isoformat()
                },
                "metrics": self.metrics.copy()
            }
            
        except Exception as e:
            logger.error(f"HSM+CDM processing error: {e}")
            return {
                "response": f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                "metadata": {"error": str(e), "engine": "HSM+CDM_ERROR"},
                "metrics": self.metrics.copy()
            }
    
    def get_engine_status(self) -> Dict[str, Any]:
        """è·å–å¼•æ“çŠ¶æ€"""
        return {
            "engine": "HSM+CDM",
            "status": "active",
            "metrics": self.metrics.copy(),
            "components": {
                "gap_detector": "active",
                "hsm": "active", 
                "cdm": {
                    "total_units": len(self.cdm.logic_units),
                    "average_effectiveness": np.mean([unit.get("effectiveness", 0.5) for unit in self.cdm.logic_units.values()]) if self.cdm.logic_units else 0.0
                }
            },
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    
    def provide_feedback(self, response_id: str, feedback_score: float):
        """ä¸ºå“åº”æä¾›åé¦ˆä»¥æ”¹è¿›ç³»ç»Ÿ"""
        # è¿™é‡Œå¯ä»¥å®ç°åé¦ˆæœºåˆ¶æ¥æ”¹è¿›é€»è¾‘å•å…ƒæ•ˆæœ
        logger.info(f"Feedback provided for response {response_id}: {feedback_score}")
        
        # å¯ä»¥æ ¹æ®åé¦ˆå†…å®¹æ›´æ–°ç›¸å…³çš„é€»è¾‘å•å…ƒ
        # è¿™é‡Œæ˜¯ç®€åŒ–å®ç°
        return {"status": "feedback_recorded"}

# Phase 2 æµ‹è¯•å’Œæ¼”ç¤º
async def demo_hsm_cdm():
    """æ¼”ç¤º HSM+CDM ç³»ç»ŸåŠŸèƒ½"""
    print("ğŸš€ Phase 2: HSM+CDM ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    engine = HSMCDMEngine()
    
    # æµ‹è¯•è¾“å…¥
    test_inputs = [
        "ä½ å¥½ï¼Œæˆ‘æ˜¯æ–°ç”¨æˆ·",
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "è¯·è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†",
        "ç»™æˆ‘è®²ä¸€ä¸ªå…³äºAIçš„æ•…äº‹",
        "é‡å­è®¡ç®—åœ¨AIä¸­çš„åº”ç”¨æœ‰å“ªäº›ï¼Ÿ",  # åº”è¯¥è§¦å‘å·²æœ‰å•å…ƒæ£€ç´¢
        "ä»€ä¹ˆæ˜¯è®¤çŸ¥ç§‘å­¦ï¼Ÿ",  # å¯èƒ½è§¦å‘æ–°å­¦ä¹ 
        "æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬åˆšæ‰çš„å¯¹è¯"  # å¤æ‚æŸ¥è¯¢
    ]
    
    print("å¼€å§‹å¤„ç†æµ‹è¯•è¾“å…¥...\n")
    
    for i, user_input in enumerate(test_inputs, 1):
        print(f"ğŸ“ æµ‹è¯• {i}: {user_input}")
        
        result = await engine.process_input(user_input)
        
        print(f"ğŸ¤– å›åº”: {result['response'][:100]}...")
        print(f"ğŸ“Š å…ƒæ•°æ®: å­¦ä¹ è§¦å‘={result['metadata']['learning_triggered']}, "
              f"æ£€ç´¢å•å…ƒ={result['metadata']['units_retrieved']}, "
              f"å¤„ç†æ—¶é—´={result['metadata']['processing_time_ms']:.1f}ms")
        print()
        
        # æ¨¡æ‹Ÿåé¦ˆ
        if result['metadata']['learning_triggered']:
            feedback = 0.8  # å‡è®¾è‰¯å¥½åé¦ˆ
            engine.provide_feedback(f"response_{i}", feedback)
            print(f"ğŸ”„ æä¾›äº†åé¦ˆ: {feedback}")
        
        print("-" * 40)
    
    # æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
    status = engine.get_engine_status()
    print("\nğŸ“ˆ HSM+CDM ç³»ç»Ÿæœ€ç»ˆçŠ¶æ€:")
    print(f"  æ€»å¤„ç†æ•°: {status['metrics']['total_processed']}")
    print(f"  å­¦ä¹ è§¦å‘: {status['metrics']['learning_triggered']}")
    print(f"  åˆ›å»ºå•å…ƒ: {status['metrics']['units_created']}")
    print(f"  æ£€ç´¢å•å…ƒ: {status['metrics']['units_retrieved']}")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {status['metrics']['average_confidence']:.3f}")
    print(f"  CDMå•å…ƒæ€»æ•°: {status['components']['cdm']['total_units']}")
    print(f"  CDMå¹³å‡æ•ˆæœ: {status['components']['cdm']['average_effectiveness']:.3f}")
    
    return engine

if __name__ == "__main__":
    asyncio.run(demo_hsm_cdm())