{
    "id": "dialogue.response.v1",
    "name": "Dialogue Response Module",
    "version": "1.0.0",
    "description": "Generates a dialogue response using an LLM.",
    "input_schema": {
        "type": "object",
        "properties": {
            "user_input": {"type": "string", "description": "The user's input.", "min_length": 1},
            "context": {"type": "string", "description": "Additional context for the LLM.", "default": ""}
        },
        "required": ["user_input"]
    },
    "output_schema": {
        "type": "object",
        "properties": {
            "response": {"type": "string", "description": "The generated dialogue response.", "min_length": 0}
        },
        "required": ["response"]
    },
    "steps": [
        {
            "step_id": "llm_generate_response",
            "block_manifest_id": "llm.inference.v1",
            "input_data_mapping": {
                "prompt": {
                    "literal_value": "Generate a helpful and friendly response to the following user input, considering the context:\nUser: {user_input}\nContext: {context}\nResponse: "
                }
            },
            "runtime_config_mapping": {
                "model_name": {"literal_value": "mock-creative-v1"}, 
                "params": {"literal_value": {"temperature": 0.7}}
            }
        }
    ],
    "final_output_mapping": {"source_step_id": "llm_generate_response", "source_step_output_field": "result"}
}